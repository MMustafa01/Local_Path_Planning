{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Env deebugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from RL_envdirectcontrol import CarENV\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import DQN\n",
    "import os \n",
    "import stable_baselines3\n",
    "print(stable_baselines3.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is printrf Discrete\n"
     ]
    }
   ],
   "source": [
    "start_end_dic = {7:[8,9,15,16,19,20], \n",
    "                 6:[8,9,15,16,19,20],\n",
    "                 121: [12,13,14,11],\n",
    "                 13: [6,7,8,9,11,12,15,16,20],\n",
    "                 14: [6,7,8,9,11,12,15,16,20]\n",
    "                 }\n",
    "actor = CarENV(show_local_view=False, no_render_mode=False, Debugger= False , start_end_dic= start_end_dic, action_space_type='Discrete') \n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "# check_env(actor, warn=True, skip_render_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import StopTrainingOnMaxEpisodes\n",
    "\n",
    "\n",
    "callback_max_episodes = StopTrainingOnMaxEpisodes(max_episodes= 5000, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "[]\n",
      "The environmnet has been reset. The total reward was 0. And steps were 0 and the episode is 0 and the total_steps are 0\n",
      "Logging to trainingdir/DQN_logs_trainig_DC_PP_synchronous\\DQN_2\n",
      "Done condition: collision\n",
      "[2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 1 and the episode is 1 and the total_steps are 1\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 1, 0, 3, 1, 2, 3, 3, 0, 2, 0, 2, 1, 1, 2, 3, 0, 2, 1, 3, 1, 2, 1, 0, 2, 1, 3, 0, 3, 2, 1, 2, 2, 0, 2, 1, 1, 1, 2, 3, 2, 1, 1, 2, 2, 3, 1, 0, 2, 0, 1, 0, 3, 1, 0, 3, 1, 3, 1, 0, 1, 0, 3, 0, 0, 3, 1, 3, 1, 3, 2, 0, 3, 3, 2, 3, 1, 2, 3, 1, 2, 1, 0, 0, 3, 3, 2, 3, 0, 1, 1, 0, 1, 3, 0, 0, 3, 0, 1, 2, 3, 3, 2, 1, 3, 3, 1, 2, 1, 0, 0, 3, 3, 2, 3, 3, 2, 3, 1, 0, 2, 1, 3, 2, 2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 1, 3, 3, 3, 2, 0, 0, 3, 3, 1, 1, 1, 0, 3, 0, 2, 2, 3, 1, 0, 2, 1, 2, 2, 1, 2, 2, 2, 0, 0, 2, 1, 1, 1, 3, 1, 3, 3, 0, 2, 3, 1, 2, 1, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1183. And steps were 185 and the episode is 2 and the total_steps are 186\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 2, 0, 0, 2, 2, 1, 3, 3, 2, 2, 0, 3, 2, 0, 2, 1, 2, 3, 1, 1, 2, 0, 3, 3, 1, 0, 1, 3, 1, 0, 1, 2, 0, 1, 1, 3, 1, 2, 0, 2, 3, 3, 1, 2, 2, 1, 3, 2, 0, 0, 0, 2, 1, 1, 1, 3, 2, 0, 3, 0, 2, 1, 2, 1, 1, 0, 1, 3, 1, 2, 3, 0, 0, 2, 2, 1, 2, 2, 2, 3, 1, 1, 0, 2, 0, 2, 2, 0, 2, 0, 2, 3, 0, 0, 2, 1, 0, 1, 0, 3, 3, 1, 3, 0, 2, 2, 1, 3, 0, 3, 2, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 3, 0, 3, 1, 0, 1, 1, 0, 1, 2, 0, 2, 3, 0, 0, 0, 0, 2, 1, 1, 3, 1, 3, 2, 1, 1, 2, 2, 3, 0, 0, 0, 0, 2, 2, 1, 0, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -882. And steps were 170 and the episode is 3 and the total_steps are 356\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 0, 3, 0, 3, 2, 2, 2, 3, 2, 3, 1, 0, 3, 2, 1, 3, 1, 1, 3, 0, 1, 0, 3, 2, 1, 3, 3, 3, 0, 0, 1, 3, 0, 1, 3, 1, 0, 3, 2, 2, 3, 0, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 3, 2, 2, 3, 1, 3, 3, 0, 2, 3, 2, 1, 0, 0, 1, 1, 3, 3, 0, 3, 0, 0, 0, 1, 3, 1, 0, 1, 2, 1, 1, 2, 0, 2, 2, 0, 2, 0, 0, 1, 3, 2, 3, 0, 2, 2, 0, 0, 3, 1, 1, 1, 0, 0, 1, 3, 0, 0, 0, 3, 3, 1, 1, 0, 3, 2, 0, 2, 1, 0, 1, 2, 3, 3, 2, 1, 2, 1, 1, 2, 1, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 0, 1, 0, 2, 3, 0, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1156. And steps were 158 and the episode is 4 and the total_steps are 514\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 128       |\n",
      "|    ep_rew_mean      | -1.06e+03 |\n",
      "|    exploration_rate | 1         |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 41        |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 514       |\n",
      "-----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 1, 2, 0, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 0, 3, 1, 1, 2, 2, 3, 0, 1, 3, 2, 0, 0, 2, 3, 1, 0, 1, 1, 2, 3, 1, 0, 3, 3, 2, 2, 0, 2, 2, 1, 0, 1, 2, 1, 2, 2, 0, 0, 3, 2, 0, 2, 0, 2, 2, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -943. And steps were 67 and the episode is 5 and the total_steps are 581\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 1, 3, 1, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 3, 1, 2, 0, 0, 2, 3, 1, 0, 2, 0, 2, 2, 1, 2, 3, 0, 3, 3, 1, 0, 1, 2, 3, 0, 3, 3, 0, 2, 0, 1, 1, 1, 3, 2, 3, 0, 1, 3, 2, 0, 1, 1, 1, 3, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 71 and the episode is 6 and the total_steps are 652\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 3, 2, 3, 2, 0, 1, 3, 0, 1, 2, 1, 1, 3, 0, 3, 1, 2, 3, 1, 3, 1, 2, 0, 1, 0, 1, 3, 2, 2, 2, 1, 0, 0, 2, 1, 2, 3, 2, 2, 3, 2, 1, 1, 0, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1045. And steps were 50 and the episode is 7 and the total_steps are 702\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 0, 2, 1, 0, 3, 2, 0, 2, 3, 2, 1, 3, 2, 1, 0, 3, 2, 1, 0, 2, 1, 3, 1, 3, 2, 0, 3, 0, 3, 3, 1, 2, 1, 3, 2, 1, 2, 1, 1, 2, 2, 2, 2, 3, 2, 2, 1, 0, 1, 2, 2, 3, 1, 2, 3, 0, 3, 1, 2, 1, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 68 and the episode is 8 and the total_steps are 770\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.2     |\n",
      "|    ep_rew_mean      | -757     |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 770      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 3, 1, 1, 3, 0, 1, 3, 2, 1, 1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 2, 3, 1, 2, 1, 3, 3, 1, 0, 3, 0, 2, 1, 1, 3, 1, 1, 1, 0, 3, 0, 1, 2, 3, 0, 1, 1, 1, 2, 1, 3, 0, 3, 2, 0, 1, 0, 2, 0, 0, 0, 3, 3, 0, 2, 3, 1, 0, 3, 2, 1, 3, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 79 and the episode is 9 and the total_steps are 849\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 3, 3, 2, 1, 1, 3, 3, 0, 3, 1, 1, 3, 2, 1, 1, 3, 2, 2, 0, 1, 3, 1, 0, 0, 0, 1, 1, 3, 3, 0, 1, 0, 3, 1, 2, 2, 1, 2, 2, 0, 2, 3, 2, 1, 3, 2, 2, 1, 2, 0, 0, 0, 3, 1, 1, 0, 3, 1, 2, 1, 2, 1, 0, 3, 2, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 73 and the episode is 10 and the total_steps are 922\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 2, 2, 0, 3, 2, 0, 2, 1, 0, 0, 3, 3, 0, 0, 0, 2, 2, 3, 0, 1, 3, 0, 2, 3, 1, 3, 2, 1, 1, 0, 0, 0, 3, 0, 0, 3, 2, 0, 2, 3, 3, 1, 1, 0, 0, 1, 0, 3, 2, 1, 3, 2, 0, 2, 2, 2, 0, 1, 2, 3, 0, 3, 3, 1, 1, 0, 0, 3, 1, 2, 2, 3, 3, 3, 2, 1, 0, 0, 1, 3, 1, 0, 1, 3, 0, 0, 2, 1, 1, 2, 2, 1, 1, 2, 1, 3, 3, 3, 0, 3, 2, 1, 0, 3, 0, 2, 2, 1, 0, 0, 1, 1, 2, 2, 1, 1, 2, 3, 1, 2, 3, 1, 0, 2, 2, 0, 1, 0, 3, 3, 1, 3, 2, 0, 2, 3, 0, 1, 1, 1, 1, 3, 1, 3, 0, 0, 3, 1, 1, 2, 2, 2, 3, 2, 3, 3, 0, 2, 3, 2, 1, 2, 3, 0, 1, 3, 1, 2, 2, 1, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -840. And steps were 188 and the episode is 11 and the total_steps are 1110\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 1, 2, 1, 3, 0, 1, 3, 3, 1, 1, 3, 2, 1, 1, 0, 2, 0, 3, 1, 2, 0, 3, 3, 3, 3, 2, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 2, 3, 0, 2, 2, 1, 0, 0, 0, 3, 2, 3, 1, 0, 3, 1, 1, 2, 3, 2, 1, 3, 3, 2, 2, 3, 3, 2, 3, 2, 3, 2, 2, 1, 0, 0, 1, 1, 0, 2, 0, 3, 3, 3, 3, 0, 0, 1, 2, 1, 0, 1, 1, 2, 1, 0, 3, 0, 3, 1, 2, 2, 2, 3, 1, 1, 2, 2, 2, 0, 2, 2, 3, 1, 2, 0, 3, 3, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 122 and the episode is 12 and the total_steps are 1232\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -817     |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 52       |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 1232     |\n",
      "----------------------------------\n",
      "Done condition: max time steps reached\n",
      "[3, 3, 1, 3, 2, 1, 3, 2, 3, 1, 2, 0, 1, 1, 0, 1, 2, 3, 1, 1, 1, 3, 2, 2, 2, 0, 1, 1, 2, 2, 1, 1, 3, 0, 1, 3, 1, 3, 3, 3, 3, 3, 2, 0, 2, 1, 1, 1, 2, 0, 2, 0, 0, 3, 0, 0, 3, 1, 3, 3, 3, 0, 3, 3, 3, 2, 3, 0, 0, 0, 3, 2, 2, 1, 1, 2, 3, 1, 1, 1, 3, 3, 2, 2, 0, 3, 3, 0, 2, 0, 0, 1, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 0, 2, 1, 1, 3, 0, 1, 2, 1, 2, 2, 0, 2, 0, 3, 2, 0, 1, 1, 0, 1, 3, 1, 0, 2, 1, 0, 3, 0, 2, 0, 2, 1, 3, 3, 3, 0, 0, 3, 0, 0, 2, 1, 2, 3, 1, 0, 3, 3, 1, 1, 2, 1, 2, 3, 1, 0, 1, 3, 1, 3, 0, 3, 0, 1, 3, 2, 2, 1, 2, 3, 0, 0, 0, 3, 0, 1, 0, 3, 3, 1, 2, 3, 1, 3, 1, 1, 3, 0, 3, 3, 3, 3, 0, 1, 3, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1269. And steps were 202 and the episode is 13 and the total_steps are 1434\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 3, 3, 1, 0, 2, 2, 2, 2, 2, 0, 1, 3, 2, 1, 3, 1, 0, 2, 1, 1, 3, 1, 2, 2, 1, 3, 1, 3, 2, 1, 0, 1, 3, 0, 1, 2, 1, 0, 1, 1, 0, 3, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1043. And steps were 48 and the episode is 14 and the total_steps are 1482\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 2, 0, 1, 3, 2, 3, 2, 3, 1, 0, 3, 0, 3, 2, 1, 2, 3, 2, 2, 1, 3, 3, 0, 0, 3, 0, 3, 3, 0, 1, 2, 2, 2, 2, 1, 3, 0, 3, 2, 3, 2, 0, 1, 2, 0, 3, 0, 2, 0, 0, 3, 0, 2, 1, 0, 2, 0, 0, 2, 3, 1, 2, 1, 0, 3, 0, 2, 0, 2, 3, 1, 1, 2, 3, 2, 2, 3, 0, 2, 3, 3, 1, 2, 3, 0, 3, 0, 0, 0, 1, 1, 3, 0, 1, 0, 3, 2, 3, 2, 2, 3, 3, 3, 1, 2, 1, 0, 3, 0, 0, 1, 3, 3, 1, 3, 0, 3, 2, 1, 1, 0, 3, 1, 2, 3, 3, 3, 3, 3, 0, 3, 1, 1, 0, 3, 3, 2, 2, 0, 2, 2, 2, 3, 2, 2, 3, 3, 2, 1, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -859. And steps were 157 and the episode is 15 and the total_steps are 1639\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 0, 0, 3, 3, 1, 0, 1, 0, 2, 2, 2, 2, 0, 1, 0, 2, 0, 2, 3, 2, 0, 2, 0, 2, 3, 2, 3, 1, 2, 0, 1, 1, 0, 1, 3, 1, 3, 0, 3, 0, 3, 2, 3, 3, 0, 3, 0, 0, 0, 1, 0, 2, 3, 3, 2, 3, 2, 0, 2, 2, 3, 3, 1, 2, 2, 0, 1, 0, 0, 0, 0, 3, 0, 3, 1, 1, 2, 2, 1, 0, 1, 2, 3, 1, 3, 1, 3, 1, 0, 2, 2, 3, 0, 2, 2, 3, 0, 1, 3, 3, 2, 0, 1, 2, 3, 1, 1, 2, 0, 3, 3, 1, 1, 0, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 0, 3, 2, 2, 0, 2, 2, 0, 2, 3, 1, 2, 3, 1, 3, 3, 0, 1, 1, 0, 1, 1, 1, 0, 0, 3, 0, 0, 1, 2, 2, 1, 1, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -895. And steps were 165 and the episode is 16 and the total_steps are 1804\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | -737     |\n",
      "|    exploration_rate | 0.998    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 1804     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 0, 0, 1, 0, 0, 0, 3, 1, 1, 3, 1, 2, 1, 2, 1, 1, 0, 0, 1, 0, 0, 1, 1, 2, 1, 2, 3, 1, 1, 3, 3, 3, 3, 1, 3, 2, 3, 0, 3, 2, 3, 1, 0, 0, 3, 0, 3, 0, 0, 2, 3, 2, 1, 2, 1, 3, 1, 1, 2, 3, 2, 2, 0, 0, 3, 2, 0, 2, 0, 0, 0, 3, 2, 3, 1, 1, 2, 0, 0, 0, 1, 3, 1, 1, 2, 3, 0, 2, 1, 1, 1, 3, 1, 2, 0, 2, 3, 1, 0, 0, 2, 1, 0, 0, 1, 3, 2, 2, 1, 1, 1, 2, 0, 0, 3, 2, 2, 0, 2, 2, 2, 3, 2, 0, 1, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -883. And steps were 133 and the episode is 17 and the total_steps are 1937\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 2, 1, 3, 2, 1, 3, 2, 2, 0, 1, 0, 2, 1, 1, 1, 3, 0, 3, 0, 2, 0, 1, 3, 2, 1, 2, 3, 1, 1, 1, 2, 0, 0, 2, 2, 2, 0, 2, 2, 3, 1, 0, 1, 0, 1, 0, 0, 3, 1, 2, 0, 1, 0, 1, 2, 0, 1, 1, 3, 1, 3, 2, 2, 1, 0, 0, 1, 1, 3, 1, 2, 1, 1, 2, 2, 0, 1, 1, 3, 3, 3, 0, 1, 2, 1, 1, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 94 and the episode is 18 and the total_steps are 2031\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 0, 1, 0, 3, 1, 3, 3, 1, 1, 2, 2, 0, 0, 2, 2, 0, 2, 0, 3, 2, 0, 3, 1, 2, 0, 2, 2, 2, 1, 0, 0, 3, 0, 3, 0, 0, 1, 0, 0, 2, 0, 2, 1, 0, 0, 2, 2, 2, 3, 1, 3, 1, 0, 3, 3, 1, 3, 2, 1, 0, 3, 1, 3, 0, 3, 3, 0, 3, 1, 2, 3, 1, 1, 3, 1, 3, 0, 3, 2, 3, 3, 3, 1, 2, 0, 2, 2, 0, 2, 3, 1, 0, 2, 1, 2, 3, 2, 1, 2, 3, 2, 3, 2, 1, 3, 2, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1112. And steps were 114 and the episode is 19 and the total_steps are 2145\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 3, 3, 0, 1, 3, 0, 1, 3, 3, 1, 3, 1, 1, 1, 2, 3, 1, 0, 3, 0, 2, 2, 1, 3, 2, 0, 0, 1, 0, 1, 0, 3, 2, 3, 1, 3, 2, 0, 0, 3, 1, 2, 2, 0, 3, 0, 0, 1, 1, 2, 1, 2, 0, 2, 3, 0, 2, 3, 0, 1, 3, 3, 3, 1, 3, 0, 1, 1, 2, 1, 2, 1, 1, 1, 3, 2, 0, 0, 1, 0, 1, 2, 2, 2, 0, 2, 0, 0, 2, 1, 2, 1, 2, 3, 2, 2, 2, 2, 1, 2, 0, 1, 2, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -915. And steps were 111 and the episode is 20 and the total_steps are 2256\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | -784     |\n",
      "|    exploration_rate | 0.998    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 56       |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 2256     |\n",
      "----------------------------------\n",
      "Done condition: max time steps reached\n",
      "[1, 3, 1, 0, 3, 0, 0, 1, 0, 2, 2, 3, 2, 0, 3, 0, 0, 2, 2, 1, 2, 2, 1, 0, 1, 0, 0, 3, 0, 1, 0, 2, 2, 3, 3, 1, 0, 2, 3, 0, 1, 0, 2, 0, 2, 3, 2, 3, 1, 0, 2, 2, 1, 3, 3, 0, 1, 1, 0, 0, 3, 3, 3, 0, 0, 1, 1, 1, 3, 3, 2, 2, 2, 1, 0, 0, 2, 3, 1, 0, 2, 0, 0, 0, 2, 1, 3, 0, 0, 2, 0, 3, 2, 1, 0, 2, 0, 1, 2, 1, 0, 1, 0, 2, 2, 1, 1, 0, 2, 1, 0, 2, 3, 3, 2, 2, 3, 0, 2, 2, 1, 1, 1, 0, 1, 3, 0, 0, 2, 2, 2, 1, 3, 3, 0, 0, 1, 3, 3, 3, 0, 3, 3, 0, 2, 3, 0, 2, 1, 3, 3, 2, 1, 1, 1, 1, 0, 1, 0, 3, 2, 3, 2, 0, 1, 1, 0, 3, 3, 0, 3, 1, 2, 1, 1, 2, 2, 1, 3, 1, 1, 2, 2, 0, 3, 3, 2, 3, 3, 3, 1, 0, 2, 3, 3, 1, 1, 3, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1047. And steps were 202 and the episode is 21 and the total_steps are 2458\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 2, 3, 3, 3, 0, 0, 3, 3, 3, 2, 3, 0, 1, 0, 1, 3, 3, 0, 2, 3, 2, 0, 0, 1, 3, 3, 2, 1, 3, 3, 0, 1, 2, 1, 3, 1, 3, 0, 1, 1, 1, 3, 1, 0, 2, 1, 3, 2, 2, 2, 1, 1, 3, 0, 3, 0, 1, 0, 0, 0, 0, 0, 3, 2, 1, 0, 1, 2, 1, 2, 0, 2, 2, 3, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -928. And steps were 82 and the episode is 22 and the total_steps are 2540\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 3, 1, 0, 2, 2, 2, 3, 1, 2, 1, 2, 0, 3, 3, 2, 0, 0, 3, 3, 1, 2, 1, 3, 3, 2, 2, 3, 3, 3, 2, 3, 0, 3, 2, 1, 1, 2, 2, 0, 3, 0, 3, 2, 3, 2, 1, 1, 2, 0, 3, 1, 1, 2, 3, 2, 3, 2, 1, 0, 1, 0, 3, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 70 and the episode is 23 and the total_steps are 2610\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 0, 1, 2, 2, 2, 1, 0, 3, 0, 3, 0, 3, 0, 0, 2, 2, 1, 0, 3, 1, 0, 0, 2, 1, 0, 1, 0, 3, 2, 0, 1, 1, 0, 1, 1, 2, 0, 0, 0, 1, 1, 3, 3, 0, 3, 2, 1, 0, 2, 3, 3, 2, 3, 0, 1, 1, 2, 0, 2, 3, 0, 0, 1, 1, 1, 1, 3, 2, 1, 2, 0, 1, 1, 2, 2, 1, 1, 2, 3, 0, 2, 1, 3, 1, 1, 2, 0, 2, 1, 2, 2, 3, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -930. And steps were 100 and the episode is 24 and the total_steps are 2710\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | -814     |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 57       |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 2710     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 2, 2, 1, 2, 3, 3, 0, 1, 1, 0, 3, 3, 3, 0, 3, 0, 0, 2, 2, 2, 2, 2, 3, 1, 3, 0, 1, 0, 2, 0, 2, 1, 1, 0, 0, 2, 3, 3, 3, 3, 0, 3, 2, 1, 1, 0, 0, 1, 3, 2, 1, 1, 3, 3, 2, 1, 3, 2, 3, 3, 2, 1, 2, 1, 3, 1, 2, 0, 1, 0, 3, 2, 1, 0, 1, 0, 3, 3, 0, 2, 2, 1, 1, 1, 1, 1, 3, 0, 3, 0, 3, 0, 1, 1, 2, 1, 2, 1, 2, 0, 0, 1, 0, 3, 0, 3, 2, 3, 3, 3, 0, 2, 3, 1, 0, 2, 1, 1, 1, 0, 1, 3, 3, 0, 0, 2, 3, 0, 1, 2, 3, 1, 0, 1, 1, 1, 3, 1, 2, 1, 3, 1, 0, 0, 1, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -915. And steps were 153 and the episode is 25 and the total_steps are 2863\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 1, 2, 3, 1, 0, 0, 2, 2, 1, 0, 0, 1, 1, 0, 2, 3, 3, 3, 3, 3, 0, 1, 1, 3, 0, 2, 3, 2, 1, 3, 1, 3, 3, 3, 1, 0, 3, 3, 1, 1, 1, 1, 2, 1, 0, 1, 3, 3, 0, 1, 0, 0, 0, 3, 1, 0, 1, 3, 3, 2, 1, 3, 1, 2, 1, 1, 1, 3, 3, 3, 2, 3, 2, 3, 3, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1081. And steps were 83 and the episode is 26 and the total_steps are 2946\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 3, 0, 2, 3, 0, 1, 0, 1, 2, 1, 2, 1, 0, 3, 1, 3, 1, 2, 3, 1, 1, 2, 0, 2, 3, 0, 3, 1, 2, 0, 0, 0, 3, 3, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1048. And steps were 49 and the episode is 27 and the total_steps are 2995\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 0, 2, 2, 3, 2, 1, 2, 1, 1, 0, 3, 2, 1, 2, 3, 1, 3, 2, 0, 0, 3, 3, 3, 1, 3, 1, 2, 1, 2, 2, 0, 0, 2, 2, 0, 1, 2, 1, 2, 2, 0, 0, 3, 3, 1, 0, 0, 1, 0, 1, 3, 1, 0, 2, 3, 2, 2, 3, 2, 0, 0, 3, 0, 3, 3, 3, 1, 2, 1, 3, 0, 2, 1, 0, 1, 2, 2, 3, 1, 1, 0, 2, 3, 1, 3, 1, 3, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 95 and the episode is 28 and the total_steps are 3090\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | -767     |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 57       |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 3090     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 3, 2, 3, 3, 1, 2, 3, 0, 3, 3, 1, 2, 2, 0, 1, 2, 2, 0, 1, 2, 3, 2, 0, 1, 0, 0, 2, 1, 0, 1, 0, 2, 0, 3, 1, 2, 3, 2, 1, 3, 2, 0, 2, 1, 1, 3, 0, 3, 3, 1, 2, 3, 0, 2, 3, 2, 2, 1, 2, 2, 0, 3, 3, 0, 0, 2, 1, 2, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 82 and the episode is 29 and the total_steps are 3172\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 3, 1, 3, 0, 3, 0, 3, 0, 3, 3, 1, 2, 1, 1, 2, 1, 3, 2, 2, 0, 0, 2, 1, 1, 0, 3, 3, 3, 0, 3, 0, 1, 1, 3, 3, 2, 2, 1, 1, 2, 0, 3, 0, 2, 0, 2, 2, 0, 2, 3, 1, 0, 2, 1, 3, 1, 0, 2, 1, 3, 0, 0, 1, 1, 0, 1, 3, 0, 2, 1, 3, 2, 0, 2, 0, 2, 0, 3, 1, 3, 3, 2, 0, 2, 1, 0, 0, 1, 3, 2, 0, 3, 2, 3, 2, 0, 2, 2, 0, 3, 2, 3, 0, 0, 0, 1, 3, 0, 3, 0, 0, 0, 0, 1, 3, 0, 0, 2, 0, 0, 2, 2, 1, 3, 0, 1, 2, 1, 0, 1, 0, 3, 2, 3, 3, 2, 1, 2, 3, 0, 1, 2, 3, 0, 2, 3, 1, 1, 1, 2, 1, 2, 0, 3, 2, 1, 2, 3, 0, 2, 0, 1, 2, 3, 3, 2, 1, 1, 1, 2, 2, 3, 2, 0, 1, 1, 1, 3, 0, 1, 0, 0, 0, 1, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -840. And steps were 192 and the episode is 30 and the total_steps are 3364\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 0, 1, 0, 1, 3, 2, 0, 0, 1, 2, 0, 2, 1, 3, 3, 1, 1, 1, 0, 1, 3, 1, 0, 0, 1, 2, 1, 3, 3, 3, 3, 3, 1, 1, 1, 0, 3, 2, 0, 3, 2, 0, 3, 3, 1, 1, 3, 3, 1, 3, 0, 3, 1, 2, 1, 3, 3, 0, 0, 0, 1, 2, 0, 0, 3, 0, 0, 2, 0, 2, 2, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 79 and the episode is 31 and the total_steps are 3443\n",
      "Done condition: max time steps reached\n",
      "[3, 2, 1, 3, 2, 1, 2, 0, 3, 3, 3, 0, 1, 0, 0, 1, 0, 1, 2, 3, 1, 1, 2, 0, 3, 0, 0, 2, 1, 0, 3, 3, 0, 2, 3, 0, 3, 2, 0, 1, 3, 0, 0, 3, 0, 2, 0, 1, 0, 3, 0, 1, 3, 1, 2, 2, 3, 1, 0, 3, 3, 2, 0, 3, 1, 1, 2, 0, 2, 2, 2, 3, 1, 1, 3, 1, 3, 1, 3, 1, 2, 0, 3, 3, 0, 2, 3, 2, 3, 3, 0, 3, 0, 2, 2, 2, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 3, 2, 1, 0, 1, 3, 2, 3, 3, 0, 3, 0, 0, 2, 0, 3, 3, 1, 0, 0, 2, 3, 0, 2, 3, 3, 2, 0, 0, 2, 1, 1, 3, 3, 0, 1, 0, 3, 3, 3, 3, 1, 1, 2, 2, 2, 1, 1, 1, 0, 0, 0, 3, 2, 1, 1, 0, 2, 1, 1, 2, 1, 0, 2, 1, 2, 3, 2, 3, 1, 3, 2, 1, 2, 0, 2, 3, 2, 2, 3, 1, 3, 1, 1, 2, 3, 1, 0, 1, 3, 3, 1, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 202 and the episode is 32 and the total_steps are 3645\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | -790     |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 58       |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 3645     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 2, 1, 2, 0, 3, 0, 0, 3, 0, 3, 0, 1, 3, 1, 3, 0, 0, 2, 3, 2, 2, 0, 3, 2, 3, 3, 3, 2, 3, 3, 2, 3, 2, 2, 3, 1, 3, 3, 3, 3, 1, 2, 3, 2, 1, 3, 3, 2, 2, 2, 2, 2, 3, 1, 3, 3, 2, 0, 2, 2, 2, 0, 1, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 71 and the episode is 33 and the total_steps are 3716\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 3, 0, 2, 2, 3, 2, 0, 0, 1, 3, 3, 1, 0, 0, 0, 3, 1, 0, 3, 1, 2, 3, 0, 0, 1, 2, 3, 1, 3, 1, 2, 1, 2, 1, 0, 0, 0, 1, 3, 1, 3, 0, 3, 0, 1, 1, 1, 3, 1, 3, 3, 0, 3, 0, 1, 0, 2, 1, 1, 1, 3, 2, 3, 0, 1, 1, 1, 1, 0, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 77 and the episode is 34 and the total_steps are 3793\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 0, 2, 3, 1, 1, 0, 1, 2, 0, 0, 1, 2, 2, 2, 2, 1, 0, 1, 0, 0, 3, 3, 3, 0, 1, 3, 0, 1, 2, 1, 0, 3, 2, 0, 3, 0, 0, 2, 3, 3, 3, 0, 1, 2, 3, 0, 0, 0, 2, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1054. And steps were 55 and the episode is 35 and the total_steps are 3848\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 2, 0, 0, 2, 2, 2, 0, 1, 3, 2, 1, 0, 0, 0, 3, 0, 3, 3, 2, 1, 0, 2, 3, 2, 0, 3, 3, 1, 1, 2, 1, 0, 3, 1, 0, 2, 1, 0, 2, 2, 1, 1, 3, 2, 3, 2, 2, 3, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1054. And steps were 56 and the episode is 36 and the total_steps are 3904\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | -756     |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 58       |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 3904     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 1, 2, 1, 0, 1, 1, 1, 2, 3, 1, 1, 0, 3, 0, 3, 2, 3, 1, 3, 3, 3, 2, 2, 0, 0, 0, 3, 0, 3, 2, 2, 3, 0, 2, 0, 3, 2, 0, 2, 3, 0, 2, 3, 2, 3, 0, 2, 1, 1, 2, 2, 0, 0, 0, 0, 3, 1, 2, 0, 0, 2, 1, 2, 0, 2, 2, 0, 1, 3, 2, 2, 3, 2, 1, 3, 3, 2, 3, 3, 1, 3, 2, 2, 0, 0, 1, 1, 3, 0, 1, 3, 0, 1, 0, 2, 3, 1, 2, 2, 0, 3, 0, 3, 3, 2, 1, 3, 3, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 1, 1, 1, 2, 2, 0, 0, 2, 2, 1, 3, 0, 2, 0, 1, 2, 2, 1, 3, 2, 3, 0, 3, 3, 0, 2, 1, 1, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -917. And steps were 155 and the episode is 37 and the total_steps are 4059\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 1, 1, 3, 0, 0, 2, 0, 2, 2, 3, 0, 1, 0, 1, 3, 3, 2, 0, 0, 2, 3, 0, 0, 3, 2, 2, 2, 3, 3, 2, 1, 1, 1, 0, 1, 1, 1, 2, 1, 3, 2, 2, 3, 1, 0, 1, 3, 3, 0, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 2, 0, 3, 3, 1, 3, 2, 1, 1, 1, 0, 2, 3, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 1, 0, 0, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 94 and the episode is 38 and the total_steps are 4153\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 1, 3, 2, 1, 1, 3, 3, 0, 3, 1, 2, 3, 3, 3, 2, 2, 3, 0, 3, 0, 3, 3, 0, 1, 2, 1, 3, 2, 0, 3, 2, 3, 1, 1, 1, 3, 2, 3, 3, 1, 0, 1, 1, 1, 2, 2, 3, 1, 2, 3, 0, 3, 2, 0, 0, 0, 3, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 0, 3, 3, 0, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 3, 0, 2, 3, 1, 2, 3, 0, 3, 3, 1, 0, 0, 2, 1, 0, 1, 2, 2, 2, 2, 3, 2, 0, 2, 0, 2, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -905. And steps were 117 and the episode is 39 and the total_steps are 4270\n",
      "Done condition: collision\n",
      "[3, 0, 0, 3, 2, 0, 3, 2, 0, 3, 0, 1, 0, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 1, 0, 1, 1, 3, 2, 2, 2, 1, 3, 2, 3, 1, 3, 0, 2, 1, 0, 3, 2, 3, 2, 1, 3, 3, 1, 1, 0, 1, 1, 2, 0, 3, 3, 2, 3, 1, 0, 2, 2, 3, 3, 0, 3, 0, 1, 1, 3, 1, 0, 1, 3, 1, 2, 1, 3, 2, 2, 0, 0, 3, 1, 3, 3, 0, 0, 3, 1, 0, 0, 0, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 98 and the episode is 40 and the total_steps are 4368\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | -776     |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 4368     |\n",
      "----------------------------------\n",
      "Done condition: max time steps reached\n",
      "[3, 3, 2, 2, 2, 3, 1, 1, 2, 3, 2, 0, 0, 1, 2, 2, 0, 2, 2, 3, 2, 1, 2, 1, 0, 3, 3, 3, 1, 0, 3, 2, 0, 0, 0, 1, 3, 3, 3, 0, 2, 2, 3, 1, 2, 3, 2, 3, 0, 3, 3, 0, 2, 3, 0, 1, 2, 3, 0, 0, 1, 0, 0, 1, 2, 0, 1, 1, 3, 3, 3, 0, 1, 2, 0, 0, 2, 3, 1, 2, 1, 1, 2, 1, 0, 1, 3, 1, 0, 3, 0, 3, 2, 2, 0, 2, 2, 3, 2, 1, 2, 0, 2, 0, 0, 1, 0, 1, 1, 2, 1, 0, 2, 2, 2, 1, 2, 3, 1, 3, 0, 3, 3, 3, 1, 0, 0, 0, 3, 0, 2, 0, 2, 0, 0, 0, 0, 2, 1, 3, 2, 2, 3, 0, 0, 3, 3, 3, 3, 0, 0, 2, 0, 3, 3, 0, 2, 2, 0, 3, 3, 1, 0, 3, 2, 3, 3, 3, 2, 1, 2, 0, 2, 1, 3, 3, 3, 2, 2, 1, 2, 3, 3, 2, 3, 2, 1, 3, 2, 2, 1, 0, 1, 2, 1, 2, 3, 2, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 202 and the episode is 41 and the total_steps are 4570\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 3, 3, 3, 1, 0, 1, 0, 2, 0, 0, 3, 2, 1, 1, 3, 0, 1, 1, 3, 3, 1, 0, 2, 1, 3, 1, 3, 3, 3, 0, 2, 0, 2, 3, 1, 0, 0, 2, 1, 3, 1, 3, 1, 3, 2, 3, 0, 1, 3, 1, 2, 0, 2, 2, 0, 3, 2, 1, 1, 2, 2, 2, 1, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1069. And steps were 71 and the episode is 42 and the total_steps are 4641\n",
      "Done condition: max time steps reached\n",
      "[0, 2, 0, 3, 2, 3, 2, 3, 2, 0, 3, 2, 3, 3, 2, 2, 0, 1, 1, 0, 2, 1, 3, 3, 2, 2, 0, 3, 2, 1, 0, 3, 2, 0, 1, 3, 2, 0, 1, 1, 1, 0, 0, 2, 0, 3, 2, 1, 0, 3, 0, 3, 3, 2, 3, 1, 1, 1, 3, 2, 1, 1, 0, 2, 3, 2, 1, 2, 2, 3, 2, 0, 3, 3, 3, 0, 3, 2, 3, 0, 0, 3, 3, 3, 1, 0, 0, 1, 1, 0, 1, 3, 3, 1, 3, 0, 2, 1, 2, 3, 1, 0, 1, 3, 1, 3, 2, 2, 2, 3, 2, 3, 1, 3, 1, 3, 3, 0, 0, 1, 0, 1, 0, 0, 2, 2, 3, 3, 0, 3, 3, 2, 1, 0, 0, 0, 1, 1, 0, 0, 3, 0, 2, 0, 2, 2, 0, 0, 1, 2, 0, 2, 2, 1, 1, 3, 3, 2, 1, 1, 1, 1, 1, 3, 3, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 1, 1, 3, 1, 1, 3, 1, 3, 2, 3, 0, 0, 1, 1, 1, 2, 3, 1, 1, 1, 0, 3, 3, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1109. And steps were 202 and the episode is 43 and the total_steps are 4843\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 2, 1, 1, 0, 1, 1, 2, 1, 2, 3, 1, 3, 3, 1, 0, 2, 1, 0, 1, 1, 3, 0, 1, 3, 0, 1, 0, 2, 1, 1, 2, 3, 0, 3, 3, 1, 2, 3, 2, 2, 3, 0, 0, 1, 2, 1, 1, 0, 3, 2, 0, 3, 3, 3, 0, 2, 1, 0, 0, 1, 1, 3, 1, 2, 1, 0, 2, 2, 0, 0, 0, 0, 3, 2, 3, 0, 1, 2, 1, 1, 0, 1, 0, 2, 0, 0, 2, 1, 1, 3, 0, 1, 3, 1, 1, 3, 1, 2, 2, 3, 2, 0, 0, 1, 3, 2, 3, 0, 0, 1, 3, 3, 0, 3, 3, 3, 1, 3, 1, 2, 2, 2, 0, 1, 3, 2, 2, 0, 2, 0, 3, 1, 1, 1, 1, 1, 0, 2, 2, 3, 2, 0, 0, 2, 0, 1, 0, 2, 2, 3, 0, 1, 3, 1, 2, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -845. And steps were 163 and the episode is 44 and the total_steps are 5006\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | -798     |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 5006     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 3, 2, 2, 0, 0, 2, 1, 1, 0, 0, 3, 3, 0, 3, 0, 2, 1, 3, 2, 1, 3, 0, 3, 3, 3, 3, 1, 0, 3, 2, 1, 3, 1, 2, 1, 3, 0, 1, 0, 0, 2, 3, 2, 1, 1, 3, 2, 1, 3, 0, 0, 2, 3, 0, 1, 0, 0, 2, 0, 1, 1, 3, 2, 1, 3, 3, 3, 0, 2, 0, 3, 0, 3, 2, 0, 3, 1, 1, 2, 3, 1, 2, 2, 2, 1, 3, 2, 1, 3, 1, 0, 0, 3, 3, 3, 1, 1, 0, 2, 2, 2, 0, 3, 3, 3, 1, 2, 0, 2, 0, 3, 3, 2, 3, 3, 2, 1, 0, 1, 1, 3, 2, 1, 2, 2, 1, 3, 1, 2, 1, 2, 2, 0, 1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1149. And steps were 151 and the episode is 45 and the total_steps are 5157\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 2, 1, 3, 1, 1, 2, 1, 3, 3, 2, 3, 3, 2, 3, 1, 3, 2, 2, 3, 0, 0, 1, 0, 1, 3, 0, 1, 0, 2, 0, 1, 1, 3, 3, 0, 2, 2, 2, 1, 0, 1, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was 1046. And steps were 47 and the episode is 46 and the total_steps are 5204\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 3, 2, 3, 3, 1, 0, 0, 3, 3, 2, 3, 0, 0, 1, 0, 1, 2, 2, 0, 3, 2, 3, 2, 3, 1, 2, 0, 2, 0, 1, 3, 0, 3, 1, 0, 0, 2, 3, 2, 3, 0, 1, 3, 3, 3, 3, 2, 2, 1, 1, 2, 1, 0, 1, 1, 2, 2, 0, 2, 3, 3, 3, 0, 0, 1, 0, 2, 2, 2, 0, 3, 0, 0, 3, 1, 2, 2, 1, 2, 1, 0, 2, 2, 0, 0, 2, 3, 2, 0, 3, 3, 3, 0, 3, 1, 0, 2, 2, 1, 2, 3, 0, 0, 2, 1, 1, 0, 3, 2, 0, 1, 2, 0, 2, 3, 3, 2, 3, 0, 3, 3, 0, 1, 3, 3, 0, 3, 2, 0, 2, 1, 1, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -924. And steps were 140 and the episode is 47 and the total_steps are 5344\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 3, 0, 2, 2, 2, 1, 0, 1, 2, 3, 3, 0, 0, 1, 0, 3, 3, 3, 0, 0, 0, 2, 3, 1, 1, 0, 0, 0, 0, 3, 2, 3, 0, 0, 0, 3, 2, 1, 2, 1, 3, 3, 0, 1, 2, 3, 3, 2, 1, 1, 0, 2, 1, 1, 0, 2, 0, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1063. And steps were 65 and the episode is 48 and the total_steps are 5409\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | -775     |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 5409     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 2, 3, 3, 2, 1, 2, 3, 2, 2, 0, 1, 3, 2, 0, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 2, 0, 1, 1, 3, 3, 1, 0, 0, 3, 2, 3, 1, 3, 1, 0, 1, 3, 3, 2, 0, 0, 2, 2, 3, 3, 0, 2, 2, 1, 2, 1, 3, 0, 2, 1, 3, 1, 0, 3, 2, 3, 2, 1, 0, 2, 2, 2, 2, 1, 0, 3, 0, 2, 1, 0, 3, 3, 2, 0, 0, 1, 2, 2, 3, 0, 2, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -947. And steps were 99 and the episode is 49 and the total_steps are 5508\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 1, 1, 3, 0, 0, 3, 2, 1, 3, 0, 1, 2, 0, 0, 2, 2, 0, 1, 1, 1, 0, 1, 0, 0, 1, 3, 3, 2, 0, 1, 0, 3, 2, 2, 2, 3, 3, 1, 0, 2, 3, 1, 3, 2, 2, 0, 1, 0, 0, 1, 2, 3, 0, 0, 0, 2, 2, 1, 3, 3, 0, 3, 0, 0, 2, 0, 3, 1, 1, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1075. And steps were 77 and the episode is 50 and the total_steps are 5585\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 3, 3, 0, 2, 0, 2, 0, 3, 2, 0, 3, 2, 0, 0, 2, 0, 3, 1, 0, 2, 0, 0, 3, 0, 1, 0, 1, 0, 1, 0, 2, 2, 3, 3, 1, 1, 3, 3, 2, 0, 2, 0, 1, 1, 3, 0, 3, 2, 1, 2, 1, 0, 1, 3, 0, 1, 2, 3, 1, 3, 1, 2, 0, 2, 0, 2, 2, 1, 0, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 77 and the episode is 51 and the total_steps are 5662\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 0, 1, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 0, 0, 1, 0, 3, 2, 0, 0, 1, 2, 3, 2, 1, 1, 2, 2, 0, 3, 0, 2, 0, 3, 1, 1, 1, 2, 0, 1, 3, 3, 0, 3, 0, 0, 2, 2, 2, 1, 1, 1, 2, 0, 2, 0, 2, 3, 2, 3, 0, 2, 2, 1, 1, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -937. And steps were 73 and the episode is 52 and the total_steps are 5735\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | -791     |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 5735     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 2, 0, 3, 1, 0, 3, 3, 1, 1, 3, 3, 2, 0, 0, 1, 0, 0, 2, 3, 0, 0, 2, 1, 3, 2, 1, 2, 0, 3, 3, 3, 3, 3, 0, 3, 1, 3, 2, 3, 3, 0, 2, 1, 0, 2, 2, 0, 2, 0, 3, 3, 0, 0, 3, 1, 0, 2, 0, 1, 2, 1, 0, 3, 2, 3, 3, 1, 2, 2, 3, 0, 0, 0, 2, 3, 1, 3, 3, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -942. And steps were 86 and the episode is 53 and the total_steps are 5821\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 2, 2, 1, 1, 2, 3, 0, 3, 2, 2, 0, 2, 0, 2, 1, 3, 2, 0, 0, 0, 1, 2, 0, 2, 0, 3, 0, 0, 1, 3, 2, 1, 2, 3, 0, 3, 1, 3, 3, 2, 0, 3, 1, 2, 2, 3, 0, 3, 1, 1, 3, 2, 0, 2, 2, 2, 3, 2, 2, 2, 0, 2, 1, 3, 2, 3, 0, 0, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 76 and the episode is 54 and the total_steps are 5897\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 3, 1, 1, 2, 3, 2, 2, 2, 2, 3, 0, 3, 3, 1, 1, 1, 1, 0, 0, 0, 2, 3, 0, 3, 3, 1, 1, 1, 1, 2, 1, 1, 2, 0, 0, 1, 0, 1, 0, 2, 0, 1, 3, 2, 2, 0, 1, 0, 0, 3, 2, 3, 2, 1, 2, 0, 2, 2, 3, 0, 0, 3, 3, 0, 2, 0, 3, 3, 1, 1, 0, 2, 1, 0, 1, 0, 0, 2, 1, 2, 3, 2, 2, 2, 1, 3, 1, 2, 3, 2, 3, 0, 1, 1, 3, 0, 2, 2, 0, 0, 0, 1, 2, 3, 0, 2, 0, 1, 2, 2, 2, 3, 0, 2, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 122 and the episode is 55 and the total_steps are 6019\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 3, 3, 3, 2, 2, 1, 2, 3, 2, 2, 0, 0, 0, 2, 1, 1, 3, 2, 1, 2, 0, 1, 3, 0, 1, 0, 3, 1, 3, 1, 0, 1, 1, 0, 2, 1, 1, 3, 0, 0, 1, 3, 2, 3, 0, 1, 2, 1, 3, 1, 1, 1, 2, 3, 3, 1, 3, 2, 1, 3, 1, 1, 0, 2, 3, 0, 3, 3, 1, 2, 3, 1, 0, 3, 1, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -943. And steps were 83 and the episode is 56 and the total_steps are 6102\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | -804     |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 6102     |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 1, 3, 3, 3, 3, 2, 2, 0, 3, 0, 3, 1, 1, 0, 1, 1, 2, 0, 2, 0, 0, 0, 1, 2, 3, 0, 1, 2, 1, 2, 2, 2, 3, 0, 2, 2, 1, 2, 3, 1, 1, 2, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1047. And steps were 48 and the episode is 57 and the total_steps are 6150\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 1, 3, 3, 1, 1, 3, 2, 3, 1, 2, 1, 0, 1, 3, 0, 2, 2, 1, 2, 3, 2, 1, 2, 0, 0, 2, 1, 2, 1, 0, 3, 0, 1, 1, 0, 0, 0, 3, 1, 2, 0, 2, 2, 2, 3, 1, 1, 0, 3, 1, 2, 1, 1, 3, 2, 0, 2, 0, 3, 1, 3, 2, 3, 2, 0, 0, 3, 3, 1, 2, 2, 0, 3, 3, 0, 3, 2, 0, 1, 3, 0, 0, 0, 1, 2, 2, 0, 2, 1, 0, 3, 1, 3, 0, 2, 3, 3, 0, 0, 3, 3, 2, 1, 2, 2, 3, 1, 0, 0, 1, 3, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -947. And steps were 119 and the episode is 58 and the total_steps are 6269\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 2, 1, 1, 3, 0, 3, 1, 2, 0, 3, 3, 1, 3, 2, 0, 3, 1, 0, 2, 1, 2, 1, 3, 3, 0, 0, 1, 0, 2, 1, 1, 2, 0, 0, 1, 3, 1, 0, 3, 0, 0, 3, 1, 2, 3, 0, 1, 1, 3, 3, 0, 0, 1, 0, 3, 1, 0, 0, 1, 2, 3, 2, 0, 3, 0, 0, 3, 0, 1, 2, 1, 2, 1, 3, 1, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 3, 1, 2, 3, 0, 2, 1, 0, 1, 3, 1, 1, 3, 3, 3, 2, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -915. And steps were 111 and the episode is 59 and the total_steps are 6380\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 0, 0, 3, 1, 1, 1, 1, 0, 3, 1, 3, 3, 2, 0, 2, 2, 3, 1, 0, 3, 0, 2, 3, 0, 2, 3, 1, 1, 1, 3, 0, 1, 0, 2, 1, 1, 1, 3, 3, 1, 3, 0, 0, 1, 2, 0, 0, 2, 1, 0, 3, 1, 3, 1, 2, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 69 and the episode is 60 and the total_steps are 6449\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | -781     |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 6449     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 1, 3, 1, 3, 1, 2, 0, 3, 1, 1, 2, 1, 0, 3, 1, 1, 1, 2, 1, 0, 3, 0, 2, 1, 0, 1, 2, 0, 1, 2, 1, 0, 0, 0, 3, 1, 2, 0, 0, 1, 3, 3, 2, 3, 1, 0, 0, 1, 3, 3, 2, 2, 0, 0, 0, 1, 1, 1, 3, 3, 1, 0, 1, 1, 3, 3, 3, 0, 1, 1, 3, 2, 3, 0, 3, 3, 0, 3, 2, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -933. And steps were 87 and the episode is 61 and the total_steps are 6536\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 3, 2, 2, 1, 2, 2, 3, 2, 2, 0, 0, 2, 3, 1, 3, 1, 2, 0, 0, 3, 2, 3, 0, 1, 0, 1, 0, 3, 3, 1, 2, 2, 0, 0, 1, 2, 2, 2, 1, 1, 0, 2, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1043. And steps were 48 and the episode is 62 and the total_steps are 6584\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 3, 1, 2, 1, 3, 3, 1, 2, 3, 2, 3, 2, 0, 3, 1, 0, 0, 1, 2, 2, 1, 0, 3, 1, 2, 1, 0, 0, 2, 3, 3, 3, 0, 3, 3, 0, 0, 2, 3, 1, 0, 2, 1, 0, 1, 3, 0, 1, 1, 1, 1, 1, 3, 1, 3, 3, 1, 1, 2, 3, 0, 2, 2, 0, 2, 3, 1, 3, 1, 2, 3, 3, 3, 0, 2, 0, 0, 0, 1, 0, 3, 0, 2, 0, 2, 0, 0, 0, 0, 3, 3, 1, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 100 and the episode is 63 and the total_steps are 6684\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 1, 3, 2, 1, 2, 0, 1, 0, 1, 3, 3, 1, 2, 3, 3, 2, 1, 2, 3, 0, 3, 1, 2, 3, 0, 2, 3, 0, 2, 3, 2, 0, 3, 3, 0, 1, 3, 2, 2, 1, 2, 0, 2, 0, 2, 1, 2, 1, 3, 1, 2, 3, 2, 1, 3, 2, 3, 0, 0, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1065. And steps were 67 and the episode is 64 and the total_steps are 6751\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -762     |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 6751     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 1, 3, 3, 1, 2, 0, 1, 0, 3, 1, 2, 2, 2, 2, 2, 1, 3, 2, 2, 1, 3, 2, 1, 0, 3, 2, 2, 0, 0, 3, 2, 0, 2, 2, 1, 3, 1, 3, 0, 1, 2, 3, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1044. And steps were 47 and the episode is 65 and the total_steps are 6798\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 3, 3, 0, 1, 1, 3, 1, 1, 0, 0, 0, 2, 0, 1, 3, 3, 2, 1, 2, 3, 3, 3, 1, 3, 3, 3, 3, 3, 2, 2, 3, 3, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1035. And steps were 38 and the episode is 66 and the total_steps are 6836\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 1, 2, 0, 2, 0, 1, 0, 1, 0, 0, 0, 3, 2, 0, 1, 2, 3, 0, 3, 0, 1, 1, 0, 3, 0, 2, 3, 2, 1, 1, 2, 3, 0, 2, 0, 2, 0, 3, 3, 0, 1, 1, 1, 3, 1, 3, 0, 2, 3, 3, 1, 3, 0, 2, 3, 2, 0, 3, 1, 2, 0, 0, 0, 0, 2, 0, 1, 1, 0, 3, 1, 1, 0, 3, 1, 2, 3, 3, 0, 2, 1, 1, 1, 2, 1, 1, 0, 3, 3, 1, 1, 1, 0, 0, 3, 2, 1, 2, 2, 2, 3, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -907. And steps were 109 and the episode is 67 and the total_steps are 6945\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 1, 0, 3, 1, 1, 1, 0, 2, 1, 3, 3, 3, 3, 0, 1, 2, 1, 3, 2, 1, 0, 2, 0, 2, 1, 3, 2, 0, 0, 2, 2, 0, 3, 0, 2, 2, 2, 3, 2, 0, 0, 3, 1, 1, 0, 3, 1, 1, 3, 1, 0, 1, 0, 2, 2, 1, 2, 1, 3, 0, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 68 and the episode is 68 and the total_steps are 7013\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -714     |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 7013     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 1, 1, 0, 2, 3, 2, 2, 2, 0, 1, 3, 2, 0, 1, 3, 0, 1, 2, 2, 2, 1, 1, 1, 3, 0, 0, 1, 3, 0, 0, 1, 2, 0, 1, 0, 0, 0, 1, 1, 1, 2, 2, 0, 2, 2, 0, 0, 1, 3, 3, 1, 3, 2, 2, 1, 3, 1, 3, 2, 2, 2, 3, 1, 2, 1, 0, 1, 3, 1, 0, 0, 1, 3, 2, 3, 2, 3, 2, 1, 1, 1, 2, 0, 3, 0, 1, 2, 0, 0, 1, 0, 2, 2, 2, 3, 0, 3, 3, 3, 3, 0, 2, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -936. And steps were 110 and the episode is 69 and the total_steps are 7123\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 0, 3, 3, 1, 3, 1, 1, 0, 0, 1, 0, 2, 1, 2, 0, 2, 2, 1, 3, 3, 0, 1, 0, 2, 1, 2, 0, 1, 0, 1, 2, 3, 3, 0, 3, 1, 0, 2, 3, 0, 1, 2, 3, 2, 2, 0, 3, 0, 2, 3, 3, 1, 0, 3, 3, 0, 3, 2, 3, 3, 3, 1, 0, 0, 0, 0, 2, 0, 1, 3, 1, 0, 0, 1, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 82 and the episode is 70 and the total_steps are 7205\n",
      "Done condition: max time steps reached\n",
      "[1, 1, 1, 3, 0, 1, 3, 2, 0, 1, 0, 0, 3, 0, 0, 3, 0, 1, 1, 2, 0, 0, 3, 0, 3, 3, 1, 3, 2, 3, 0, 1, 3, 3, 0, 2, 3, 0, 2, 2, 3, 2, 2, 1, 0, 2, 0, 3, 3, 0, 2, 0, 2, 1, 0, 0, 0, 2, 0, 0, 1, 0, 3, 1, 1, 0, 3, 1, 2, 0, 0, 0, 0, 3, 2, 0, 3, 2, 1, 3, 3, 1, 0, 2, 0, 2, 2, 2, 0, 2, 3, 2, 2, 1, 1, 2, 1, 0, 1, 3, 2, 3, 1, 3, 2, 1, 0, 1, 0, 0, 1, 2, 2, 1, 2, 3, 0, 1, 1, 0, 1, 3, 2, 2, 1, 1, 2, 1, 2, 3, 3, 0, 2, 3, 1, 2, 0, 0, 0, 0, 2, 1, 1, 1, 0, 2, 3, 3, 1, 0, 1, 0, 0, 1, 3, 1, 0, 2, 3, 3, 3, 2, 3, 2, 1, 0, 2, 1, 0, 1, 3, 2, 3, 2, 2, 3, 1, 1, 1, 2, 3, 1, 1, 1, 1, 3, 2, 0, 2, 3, 2, 1, 2, 0, 1, 3, 3, 1, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1077. And steps were 202 and the episode is 71 and the total_steps are 7407\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 1, 2, 1, 1, 3, 1, 2, 0, 3, 3, 1, 3, 0, 3, 1, 1, 3, 0, 2, 2, 1, 1, 3, 3, 3, 1, 1, 3, 0, 0, 1, 0, 3, 3, 0, 2, 2, 3, 2, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 3, 0, 0, 3, 1, 2, 0, 3, 1, 3, 3, 3, 3, 1, 2, 1, 1, 1, 3, 0, 1, 3, 1, 2, 1, 3, 1, 0, 2, 3, 2, 3, 3, 2, 2, 1, 0, 2, 3, 2, 2, 2, 3, 2, 2, 2, 0, 0, 1, 2, 1, 2, 3, 2, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 112 and the episode is 72 and the total_steps are 7519\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -730     |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 7519     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 1, 0, 0, 1, 2, 3, 1, 3, 1, 2, 3, 3, 3, 2, 1, 0, 0, 2, 0, 1, 2, 2, 2, 0, 3, 1, 2, 2, 0, 3, 1, 2, 2, 0, 1, 0, 3, 1, 2, 3, 2, 2, 1, 0, 1, 1, 1, 3, 1, 3, 2, 1, 1, 1, 0, 0, 3, 0, 2, 0, 3, 0, 2, 2, 3, 3, 0, 2, 1, 3, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 78 and the episode is 73 and the total_steps are 7597\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 1, 2, 1, 1, 2, 3, 3, 3, 1, 3, 1, 3, 3, 2, 0, 0, 0, 1, 0, 3, 0, 0, 2, 3, 0, 1, 1, 0, 3, 0, 1, 2, 1, 1, 3, 3, 3, 2, 2, 3, 1, 0, 2, 0, 3, 1, 2, 0, 0, 2, 1, 1, 0, 1, 0, 3, 2, 1, 0, 2, 1, 3, 2, 1, 0, 3, 1, 3, 2, 0, 3, 2, 0, 0, 1, 2, 2, 3, 3, 2, 0, 0, 3, 3, 3, 0, 1, 3, 3, 2, 3, 3, 0, 3, 1, 2, 1, 1, 1, 2, 2, 0, 3, 1, 2, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 113 and the episode is 74 and the total_steps are 7710\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 2, 0, 2, 3, 3, 1, 3, 2, 0, 3, 1, 1, 1, 1, 1, 2, 3, 3, 2, 0, 1, 2, 1, 0, 2, 3, 1, 3, 2, 1, 0, 2, 2, 0, 2, 2, 3, 1, 3, 0, 2, 2, 1, 1, 2, 1, 0, 1, 0, 2, 3, 0, 2, 0, 0, 3, 1, 0, 3, 0, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 0, 3, 3, 1, 3, 1, 3, 1, 0, 1, 0, 2, 2, 1, 1, 0, 3, 0, 2, 2, 3, 3, 1, 3, 1, 1, 1, 3, 0, 3, 2, 0, 1, 1, 2, 1, 3, 1, 3, 3, 0, 1, 3, 2, 0, 1, 2, 2, 1, 1, 1, 0, 0, 3, 0, 1, 1, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -923. And steps were 135 and the episode is 75 and the total_steps are 7845\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 1, 2, 0, 1, 0, 1, 0, 0, 2, 0, 0, 2, 2, 2, 1, 2, 1, 3, 2, 2, 3, 2, 1, 1, 1, 0, 3, 0, 0, 1, 3, 0, 1, 3, 3, 2, 2, 2, 2, 1, 3, 1, 1, 3, 2, 2, 2, 0, 3, 2, 3, 0, 3, 1, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1060. And steps were 62 and the episode is 76 and the total_steps are 7907\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -745     |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 7907     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 3, 2, 1, 0, 3, 3, 3, 2, 1, 3, 3, 0, 1, 3, 3, 3, 1, 0, 2, 0, 0, 0, 1, 3, 2, 1, 0, 1, 2, 1, 0, 2, 1, 0, 3, 3, 2, 3, 3, 0, 3, 2, 0, 1, 1, 2, 2, 0, 1, 0, 2, 0, 1, 2, 3, 3, 2, 0, 2, 1, 0, 1, 0, 3, 2, 1, 2, 2, 0, 2, 0, 3, 3, 1, 1, 0, 0, 2, 3, 1, 3, 2, 0, 3, 0, 3, 0, 3, 2, 0, 2, 3, 2, 2, 3, 1, 1, 2, 3, 0, 2, 0, 2, 1, 3, 1, 2, 0, 3, 3, 1, 1, 1, 0, 0, 0, 2, 2, 2, 1, 3, 2, 0, 1, 2, 2, 0, 0, 0, 2, 2, 3, 1, 2, 1, 0, 2, 2, 1, 1, 0, 3, 1, 1, 1, 3, 1, 0, 2, 1, 0, 0, 2, 3, 3, 0, 2, 3, 0, 1, 2, 3, 0, 2, 2, 2, 1, 2, 3, 3, 3, 1, 1, 3, 0, 0, 2, 3, 1, 0, 1, 3, 3, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1073. And steps were 191 and the episode is 77 and the total_steps are 8098\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 0, 2, 0, 0, 1, 1, 0, 3, 0, 1, 1, 2, 1, 2, 1, 1, 0, 2, 2, 2, 2, 2, 3, 0, 3, 2, 1, 0, 1, 3, 3, 3, 3, 0, 2, 1, 3, 2, 3, 2, 1, 3, 2, 0, 2, 2, 0, 0, 3, 0, 0, 1, 2, 0, 3, 1, 3, 0, 1, 3, 0, 3, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 70 and the episode is 78 and the total_steps are 8168\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 1, 2, 0, 0, 0, 0, 1, 3, 3, 1, 3, 3, 0, 2, 3, 1, 3, 0, 2, 1, 2, 0, 1, 1, 1, 0, 1, 0, 1, 2, 1, 2, 3, 1, 0, 0, 1, 1, 3, 2, 0, 3, 3, 0, 1, 1, 1, 0, 2, 0, 1, 1, 0, 0, 1, 0, 3, 0, 3, 3, 2, 3, 2, 0, 3, 2, 1, 2, 3, 0, 0, 0, 3, 0, 2, 1, 0, 3, 3, 3, 1, 1, 0, 0, 2, 3, 0, 2, 3, 2, 0, 3, 3, 0, 2, 0, 0, 0, 3, 0, 2, 1, 2, 2, 0, 2, 2, 3, 3, 1, 1, 0, 3, 3, 1, 1, 1, 0, 1, 3, 3, 1, 0, 3, 2, 3, 1, 0, 0, 2, 0, 2, 1, 0, 1, 1, 0, 0, 2, 0, 2, 1, 0, 3, 3, 3, 3, 0, 1, 3, 1, 1, 3, 0, 1, 0, 1, 3, 0, 1, 0, 0, 3, 3, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 172 and the episode is 79 and the total_steps are 8340\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 0, 2, 3, 1, 0, 2, 3, 2, 2, 0, 3, 2, 2, 2, 3, 1, 3, 0, 1, 1, 1, 0, 0, 0, 3, 1, 2, 2, 2, 1, 1, 3, 2, 0, 1, 3, 2, 0, 0, 1, 0, 1, 0, 2, 0, 2, 2, 0, 3, 3, 3, 2, 1, 2, 1, 2, 2, 1, 0, 1, 2, 3, 1, 1, 3, 1, 3, 1, 0, 0, 2, 3, 0, 0, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 82 and the episode is 80 and the total_steps are 8422\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -758     |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 8422     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 2, 2, 1, 3, 1, 2, 3, 1, 0, 2, 0, 2, 1, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 3, 0, 1, 3, 3, 0, 1, 1, 0, 2, 2, 3, 0, 0, 0, 3, 1, 2, 2, 3, 1, 1, 1, 2, 3, 1, 0, 0, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 63 and the episode is 81 and the total_steps are 8485\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 2, 3, 0, 2, 2, 3, 2, 1, 2, 2, 0, 1, 2, 2, 0, 1, 3, 1, 1, 3, 1, 2, 3, 1, 2, 1, 0, 1, 2, 1, 3, 1, 3, 2, 0, 0, 0, 1, 0, 3, 2, 3, 3, 3, 0, 1, 0, 1, 0, 3, 1, 2, 0, 2, 0, 3, 2, 0, 0, 1, 2, 3, 2, 0, 0, 1, 3, 2, 1, 2, 0, 2, 3, 1, 2, 3, 0, 2, 0, 2, 1, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -919. And steps were 89 and the episode is 82 and the total_steps are 8574\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 0, 2, 2, 0, 1, 1, 1, 0, 3, 2, 3, 1, 0, 1, 3, 3, 1, 2, 0, 3, 0, 1, 1, 0, 1, 0, 3, 3, 1, 3, 0, 2, 2, 2, 2, 2, 0, 3, 0, 2, 1, 2, 2, 0, 0, 0, 3, 0, 3, 0, 0, 2, 3, 0, 2, 2, 0, 2, 1, 0, 2, 2, 3, 2, 2, 0, 1, 3, 1, 1, 2, 3, 3, 2, 2, 3, 3, 3, 3, 0, 0, 2, 1, 3, 3, 1, 0, 1, 2, 2, 2, 3, 0, 0, 3, 1, 2, 1, 0, 0, 3, 2, 3, 2, 3, 2, 2, 0, 3, 1, 1, 1, 3, 0, 3, 3, 2, 2, 3, 1, 2, 3, 3, 2, 0, 3, 0, 0, 1, 2, 0, 3, 0, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -903. And steps were 141 and the episode is 83 and the total_steps are 8715\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 2, 1, 3, 0, 0, 0, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 1, 3, 1, 2, 2, 2, 1, 2, 0, 3, 1, 3, 2, 2, 0, 3, 1, 1, 3, 0, 3, 3, 3, 2, 2, 2, 3, 2, 3, 0, 0, 3, 0, 1, 3, 3, 3, 0, 1, 2, 0, 3, 3, 3, 1, 2, 2, 3, 3, 0, 3, 3, 1, 1, 3, 1, 3, 3, 0, 3, 2, 1, 0, 0, 3, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -937. And steps were 89 and the episode is 84 and the total_steps are 8804\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -766     |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 8804     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 1, 3, 3, 2, 0, 1, 3, 2, 1, 3, 2, 0, 3, 3, 0, 3, 0, 2, 2, 3, 1, 3, 1, 1, 0, 2, 0, 2, 0, 2, 3, 0, 1, 3, 1, 3, 0, 2, 1, 1, 2, 0, 1, 3, 3, 0, 3, 0, 0, 1, 1, 2, 0, 1, 3, 1, 3, 0, 2, 2, 1, 2, 2, 0, 3, 3, 1, 2, 2, 0, 0, 0, 1, 0, 3, 2, 3, 0, 1, 2, 1, 3, 3, 2, 0, 2, 3, 2, 1, 2, 2, 3, 3, 2, 3, 3, 2, 0, 3, 1, 3, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -921. And steps were 109 and the episode is 85 and the total_steps are 8913\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 1, 3, 3, 3, 0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 3, 3, 0, 0, 2, 3, 3, 1, 3, 3, 3, 1, 2, 2, 2, 2, 2, 0, 2, 0, 3, 2, 3, 3, 2, 1, 1, 3, 2, 1, 3, 2, 1, 3, 2, 0, 0, 1, 2, 1, 2, 2, 1, 1, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 67 and the episode is 86 and the total_steps are 8980\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 3, 2, 1, 1, 2, 3, 0, 1, 1, 0, 1, 2, 3, 1, 2, 0, 3, 3, 0, 0, 1, 3, 2, 0, 3, 0, 2, 0, 0, 3, 2, 2, 0, 3, 2, 1, 2, 1, 1, 0, 3, 3, 3, 2, 1, 1, 3, 2, 2, 3, 2, 0, 3, 3, 0, 2, 1, 2, 1, 2, 0, 3, 2, 2, 0, 2, 1, 1, 2, 1, 0, 1, 3, 0, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 82 and the episode is 87 and the total_steps are 9062\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 3, 3, 2, 3, 1, 2, 3, 0, 2, 1, 0, 0, 3, 0, 1, 1, 0, 3, 1, 2, 3, 1, 2, 3, 1, 0, 1, 0, 1, 3, 3, 0, 2, 3, 3, 1, 3, 3, 1, 1, 1, 3, 0, 1, 2, 0, 3, 3, 3, 0, 3, 3, 3, 1, 0, 2, 0, 0, 2, 2, 3, 3, 2, 2, 0, 3, 0, 2, 1, 3, 0, 0, 3, 3, 1, 1, 2, 0, 1, 0, 2, 0, 1, 2, 3, 1, 1, 2, 0, 2, 0, 0, 2, 0, 1, 3, 0, 1, 0, 3, 1, 3, 1, 2, 2, 1, 1, 2, 1, 3, 0, 3, 3, 3, 3, 1, 1, 1, 0, 2, 1, 0, 1, 3, 1, 3, 1, 2, 3, 2, 3, 1, 0, 0, 2, 0, 3, 2, 3, 3, 0, 1, 2, 1, 0, 2, 3, 0, 2, 0, 2, 3, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -936. And steps were 160 and the episode is 88 and the total_steps are 9222\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -775     |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 9222     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 1, 0, 0, 3, 1, 3, 3, 3, 1, 0, 2, 2, 2, 2, 3, 3, 0, 1, 2, 0, 2, 0, 2, 1, 1, 1, 0, 0, 2, 3, 2, 1, 0, 0, 3, 1, 0, 1, 2, 2, 0, 2, 0, 3, 2, 2, 3, 1, 3, 1, 0, 2, 3, 0, 2, 2, 1, 1, 2, 3, 3, 0, 3, 0, 3, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -937. And steps were 73 and the episode is 89 and the total_steps are 9295\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 0, 3, 1, 1, 0, 0, 3, 1, 0, 3, 3, 0, 2, 0, 0, 0, 2, 2, 3, 0, 0, 1, 0, 3, 1, 1, 0, 1, 1, 3, 1, 2, 2, 3, 2, 1, 1, 1, 0, 2, 1, 1, 2, 3, 0, 2, 0, 3, 1, 2, 1, 3, 3, 3, 1, 3, 1, 0, 0, 2, 0, 2, 0, 1, 0, 2, 2, 2, 3, 2, 0, 1, 1, 1, 3, 2, 0, 0, 3, 3, 1, 3, 1, 3, 0, 0, 2, 1, 0, 0, 0, 3, 1, 2, 0, 2, 3, 2, 1, 0, 2, 2, 2, 3, 2, 0, 1, 1, 3, 3, 3, 1, 2, 1, 1, 0, 0, 1, 1, 2, 0, 3, 2, 1, 3, 3, 3, 0, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1068. And steps were 136 and the episode is 90 and the total_steps are 9431\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 0, 3, 1, 0, 2, 3, 3, 3, 3, 2, 3, 1, 2, 1, 3, 1, 2, 1, 3, 0, 2, 1, 2, 0, 2, 0, 3, 2, 0, 1, 2, 1, 0, 1, 3, 1, 2, 0, 2, 3, 0, 2, 1, 0, 2, 0, 3, 0, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1053. And steps were 54 and the episode is 91 and the total_steps are 9485\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 2, 2, 0, 3, 1, 1, 0, 3, 0, 1, 0, 0, 1, 3, 2, 1, 1, 0, 0, 3, 2, 3, 1, 1, 0, 3, 2, 1, 3, 0, 2, 3, 3, 0, 2, 0, 0, 3, 2, 1, 2, 1, 3, 3, 1, 3, 3, 3, 3, 3, 2, 1, 2, 2, 0, 0, 0, 2, 3, 1, 2, 2, 0, 1, 1, 2, 3, 0, 2, 2, 2, 0, 1, 2, 1, 3, 3, 2, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -922. And steps were 86 and the episode is 92 and the total_steps are 9571\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -761     |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 9571     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 0, 0, 3, 0, 0, 0, 0, 3, 1, 3, 2, 1, 0, 2, 1, 2, 1, 1, 1, 1, 0, 2, 2, 1, 3, 0, 3, 1, 0, 2, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 2, 0, 3, 1, 2, 1, 0, 3, 1, 3, 2, 2, 1, 3, 2, 0, 2, 0, 2, 1, 0, 3, 0, 0, 1, 3, 2, 0, 1, 2, 0, 1, 0, 0, 2, 1, 0, 1, 3, 0, 2, 1, 1, 2, 3, 2, 1, 1, 3, 1, 1, 3, 1, 2, 2, 3, 1, 0, 3, 0, 1, 1, 3, 0, 3, 0, 3, 1, 0, 2, 0, 1, 2, 0, 3, 2, 1, 3, 0, 3, 0, 1, 2, 2, 2, 2, 2, 3, 1, 0, 3, 1, 0, 0, 0, 0, 2, 1, 1, 3, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1145. And steps were 147 and the episode is 93 and the total_steps are 9718\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 1, 0, 3, 2, 1, 0, 1, 2, 1, 0, 1, 1, 3, 0, 3, 0, 1, 2, 2, 0, 0, 3, 3, 3, 0, 3, 0, 0, 3, 0, 0, 0, 2, 1, 1, 2, 2, 1, 1, 0, 3, 3, 1, 3, 0, 3, 1, 0, 1, 1, 0, 3, 2, 0, 1, 2, 1, 3, 0, 3, 3, 2, 3, 3, 1, 3, 3, 1, 3, 2, 0, 1, 0, 2, 2, 1, 3, 0, 1, 0, 1, 1, 1, 1, 2, 2, 0, 1, 2, 1, 3, 1, 0, 2, 2, 2, 1, 3, 0, 1, 2, 1, 2, 1, 2, 3, 0, 0, 0, 1, 2, 1, 0, 3, 2, 3, 2, 1, 3, 0, 2, 2, 1, 1, 3, 3, 0, 1, 3, 0, 1, 0, 1, 2, 0, 0, 2, 0, 3, 3, 2, 0, 0, 3, 1, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 153 and the episode is 94 and the total_steps are 9871\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 3, 0, 3, 2, 0, 0, 2, 2, 0, 1, 3, 2, 1, 0, 3, 2, 3, 2, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 0, 2, 3, 3, 3, 3, 1, 2, 1, 2, 3, 3, 0, 0, 2, 3, 2, 1, 3, 2, 1, 0, 2, 3, 1, 2, 2, 1, 2, 3, 2, 2, 2, 0, 0, 0, 0, 1, 0, 3, 1, 3, 3, 2, 0, 0, 1, 2, 3, 1, 0, 0, 0, 3, 3, 0, 0, 3, 3, 3, 0, 3, 2, 3, 1, 1, 3, 3, 2, 1, 0, 2, 1, 1, 2, 0, 3, 0, 2, 1, 2, 2, 0, 2, 3, 1, 0, 2, 2, 2, 3, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -896. And steps were 130 and the episode is 95 and the total_steps are 10001\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 2, 1, 2, 1, 0, 3, 2, 0, 2, 0, 3, 1, 3, 1, 2, 0, 0, 0, 0, 1, 1, 2, 1, 2, 3, 2, 2, 1, 2, 2, 3, 1, 0, 1, 1, 1, 1, 1, 0, 2, 3, 1, 1, 0, 3, 3, 2, 0, 1, 2, 0, 2, 0, 1, 1, 2, 3, 0, 1, 3, 1, 1, 3, 3, 1, 3, 3, 1, 3, 0, 2, 3, 1, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1079. And steps were 81 and the episode is 96 and the total_steps are 10082\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -773     |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 10082    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 1, 3, 3, 3, 0, 3, 2, 1, 2, 1, 0, 1, 1, 1, 1, 3, 3, 0, 1, 0, 2, 3, 1, 1, 1, 0, 3, 3, 2, 1, 1, 0, 0, 2, 2, 3, 1, 2, 1, 1, 1, 3, 2, 0, 2, 1, 3, 3, 0, 3, 3, 2, 2, 3, 3, 0, 1, 3, 3, 2, 2, 0, 1, 3, 1, 3, 3, 2, 3, 0, 0, 2, 2, 1, 0, 1, 2, 0, 2, 1, 1, 1, 0, 3, 1, 2, 2, 2, 2, 2, 3, 2, 1, 2, 3, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 103 and the episode is 97 and the total_steps are 10185\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 0, 3, 3, 3, 3, 0, 0, 1, 2, 1, 2, 3, 1, 1, 3, 0, 2, 2, 2, 1, 2, 3, 2, 3, 3, 2, 0, 0, 2, 2, 0, 1, 3, 2, 0, 0, 1, 0, 1, 2, 1, 0, 0, 1, 1, 0, 0, 0, 2, 0, 3, 1, 0, 0, 3, 0, 2, 0, 3, 3, 2, 0, 0, 1, 0, 2, 3, 2, 2, 0, 2, 1, 0, 0, 3, 3, 1, 3, 1, 3, 1, 2, 2, 1, 3, 3, 1, 0, 1, 3, 3, 1, 2, 2, 1, 3, 3, 0, 2, 3, 2, 3, 2, 2, 0, 3, 3, 0, 0, 1, 0, 3, 3, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 121 and the episode is 98 and the total_steps are 10306\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 0, 1, 1, 0, 3, 3, 0, 2, 3, 1, 1, 0, 3, 2, 0, 1, 0, 0, 0, 1, 0, 2, 0, 2, 1, 2, 2, 0, 0, 1, 0, 2, 1, 2, 0, 1, 1, 1, 1, 2, 0, 0, 2, 2, 0, 1, 0, 2, 3, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was 1054. And steps were 55 and the episode is 99 and the total_steps are 10361\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 2, 1, 2, 3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 0, 3, 2, 3, 1, 2, 1, 3, 0, 1, 1, 2, 3, 1, 2, 2, 3, 3, 3, 3, 2, 3, 3, 0, 2, 1, 0, 2, 0, 1, 1, 2, 0, 0, 2, 0, 1, 2, 1, 0, 1, 1, 0, 2, 1, 3, 2, 1, 2, 0, 3, 1, 3, 0, 2, 1, 2, 1, 0, 2, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 81 and the episode is 100 and the total_steps are 10442\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -761     |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 10442    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 2, 3, 2, 3, 3, 3, 2, 0, 1, 2, 1, 0, 0, 3, 0, 1, 1, 1, 2, 3, 2, 2, 2, 0, 1, 0, 3, 0, 2, 0, 2, 0, 0, 2, 1, 3, 0, 2, 1, 2, 2, 2, 3, 2, 2, 2, 1, 3, 3, 1, 3, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 59 and the episode is 101 and the total_steps are 10501\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 3, 1, 1, 0, 3, 3, 1, 2, 3, 2, 0, 2, 1, 3, 3, 3, 1, 2, 1, 2, 0, 3, 3, 0, 2, 2, 0, 3, 3, 2, 2, 0, 0, 1, 1, 3, 1, 3, 3, 1, 1, 3, 1, 0, 2, 3, 3, 3, 3, 1, 2, 0, 1, 1, 3, 3, 1, 2, 1, 3, 0, 2, 1, 0, 0, 2, 1, 0, 3, 3, 1, 3, 0, 0, 3, 0, 1, 3, 0, 3, 1, 2, 0, 3, 3, 3, 1, 0, 2, 1, 1, 1, 0, 0, 1, 0, 1, 2, 0, 2, 1, 0, 0, 2, 3, 2, 3, 2, 1, 3, 0, 2, 0, 1, 0, 3, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 124 and the episode is 102 and the total_steps are 10625\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 1, 2, 1, 1, 3, 2, 3, 1, 3, 2, 3, 1, 1, 1, 3, 0, 2, 1, 3, 3, 1, 1, 3, 3, 2, 0, 3, 2, 2, 2, 0, 3, 0, 0, 2, 2, 0, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 3, 0, 2, 2, 1, 1, 3, 0, 2, 3, 1, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1064. And steps were 66 and the episode is 103 and the total_steps are 10691\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 2, 1, 3, 0, 2, 0, 2, 2, 3, 2, 3, 0, 2, 0, 0, 1, 3, 0, 3, 3, 0, 0, 2, 3, 2, 1, 3, 3, 1, 0, 1, 1, 0, 0, 0, 0, 2, 3, 3, 2, 2, 0, 2, 0, 0, 2, 1, 1, 1, 2, 0, 3, 1, 1, 3, 3, 0, 2, 2, 1, 2, 3, 3, 3, 1, 1, 0, 3, 0, 2, 3, 1, 0, 0, 1, 0, 2, 2, 3, 0, 1, 2, 2, 3, 2, 1, 1, 0, 3, 3, 2, 1, 3, 3, 2, 3, 1, 2, 2, 2, 0, 2, 3, 2, 2, 2, 3, 0, 3, 1, 1, 1, 1, 3, 3, 0, 0, 2, 3, 1, 2, 3, 2, 3, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -894. And steps were 132 and the episode is 104 and the total_steps are 10823\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -758     |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 10823    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 0, 0, 2, 0, 0, 2, 1, 2, 3, 3, 2, 0, 2, 2, 1, 0, 2, 3, 3, 3, 1, 3, 3, 0, 0, 0, 2, 1, 3, 3, 1, 2, 1, 0, 1, 2, 0, 2, 0, 3, 3, 1, 1, 0, 1, 3, 0, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 3, 0, 2, 0, 1, 0, 1, 1, 0, 1, 0, 3, 2, 1, 2, 2, 2, 3, 3, 0, 1, 1, 1, 1, 2, 3, 3, 3, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 107 and the episode is 105 and the total_steps are 10930\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 3, 0, 2, 2, 1, 2, 1, 0, 1, 3, 1, 2, 2, 0, 3, 1, 0, 3, 2, 0, 0, 2, 2, 0, 3, 0, 2, 3, 1, 1, 3, 3, 3, 0, 0, 0, 3, 3, 2, 2, 1, 0, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 3, 0, 1, 2, 2, 1, 0, 0, 1, 3, 0, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 81 and the episode is 106 and the total_steps are 11011\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 3, 3, 1, 1, 3, 1, 3, 3, 0, 1, 3, 0, 0, 3, 0, 1, 2, 0, 2, 3, 0, 3, 3, 0, 2, 1, 1, 1, 3, 2, 2, 2, 1, 1, 0, 0, 3, 3, 1, 2, 1, 0, 1, 0, 2, 2, 2, 2, 0, 1, 0, 3, 3, 2, 0, 3, 2, 2, 3, 3, 1, 2, 3, 3, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -951. And steps were 71 and the episode is 107 and the total_steps are 11082\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 1, 3, 1, 2, 3, 1, 0, 0, 1, 3, 3, 2, 2, 1, 0, 3, 2, 1, 2, 1, 2, 2, 2, 1, 3, 0, 0, 0, 3, 2, 3, 0, 1, 3, 3, 3, 1, 3, 3, 2, 3, 1, 2, 1, 2, 2, 2, 2, 1, 0, 1, 3, 0, 3, 2, 3, 2, 0, 1, 0, 1, 2, 0, 1, 0, 3, 2, 2, 3, 2, 0, 3, 1, 2, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 82 and the episode is 108 and the total_steps are 11164\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -778     |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 11164    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 1, 1, 1, 3, 3, 3, 1, 3, 2, 2, 3, 1, 2, 3, 1, 3, 0, 0, 2, 0, 1, 0, 3, 3, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 1, 0, 2, 0, 2, 3, 3, 2, 3, 0, 1, 3, 0, 3, 1, 0, 1, 1, 3, 0, 1, 1, 2, 1, 2, 1, 0, 1, 2, 1, 2, 0, 2, 1, 0, 3, 2, 1, 2, 1, 0, 1, 2, 1, 3, 2, 0, 1, 2, 3, 0, 0, 2, 2, 3, 1, 0, 3, 1, 1, 3, 3, 2, 1, 1, 1, 2, 3, 3, 2, 0, 1, 1, 3, 2, 0, 1, 2, 3, 1, 0, 2, 1, 0, 1, 0, 2, 1, 3, 1, 1, 3, 3, 1, 0, 2, 0, 1, 3, 0, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1056. And steps were 144 and the episode is 109 and the total_steps are 11308\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 0, 2, 3, 1, 3, 1, 2, 2, 1, 1, 3, 0, 3, 2, 2, 0, 0, 3, 1, 1, 2, 0, 1, 3, 3, 3, 1, 1, 1, 0, 0, 0, 3, 1, 0, 1, 3, 0, 0, 2, 3, 1, 2, 3, 1, 0, 3, 1, 0, 2, 1, 3, 3, 2, 2, 2, 0, 2, 1, 1, 0, 2, 3, 1, 1, 0, 3, 3, 3, 1, 2, 2, 1, 0, 0, 0, 0, 0, 3, 2, 0, 1, 2, 2, 0, 2, 1, 0, 3, 1, 2, 3, 1, 2, 0, 3, 2, 3, 0, 2, 2, 0, 3, 2, 3, 0, 2, 0, 3, 2, 1, 2, 1, 0, 1, 3, 0, 1, 3, 1, 0, 3, 3, 3, 2, 1, 3, 2, 1, 3, 1, 0, 3, 2, 1, 3, 3, 2, 1, 0, 1, 3, 3, 2, 0, 1, 3, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 2, 2, 0, 0, 0, 2, 3, 1, 0, 0, 2, 1, 0, 2, 2, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1180. And steps were 182 and the episode is 110 and the total_steps are 11490\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 1, 0, 1, 2, 0, 0, 2, 3, 2, 3, 1, 3, 1, 2, 2, 3, 1, 3, 0, 0, 1, 2, 3, 3, 1, 3, 3, 1, 3, 0, 0, 2, 2, 0, 2, 2, 3, 2, 3, 0, 1, 3, 3, 0, 0, 3, 2, 2, 3, 0, 1, 3, 0, 2, 2, 1, 0, 3, 2, 2, 0, 0, 0, 0, 1, 3, 3, 3, 3, 2, 3, 0, 0, 2, 2, 0, 0, 2, 0, 1, 0, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1087. And steps were 89 and the episode is 111 and the total_steps are 11579\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 2, 0, 2, 0, 1, 3, 2, 0, 1, 1, 0, 0, 0, 1, 2, 1, 3, 3, 2, 0, 3, 2, 2, 0, 0, 3, 0, 0, 3, 1, 0, 1, 1, 3, 2, 0, 0, 0, 3, 3, 3, 0, 0, 0, 3, 0, 2, 1, 1, 2, 0, 0, 0, 1, 2, 0, 0, 2, 0, 0, 1, 2, 1, 3, 2, 2, 0, 2, 2, 2, 3, 3, 0, 2, 3, 1, 3, 2, 0, 1, 3, 2, 2, 0, 3, 1, 1, 2, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -932. And steps were 96 and the episode is 112 and the total_steps are 11675\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -783     |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 11675    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 2, 0, 2, 0, 0, 0, 0, 3, 2, 2, 1, 2, 3, 1, 2, 3, 3, 0, 1, 2, 3, 0, 0, 0, 0, 1, 3, 2, 3, 1, 1, 3, 1, 0, 2, 3, 2, 0, 2, 0, 1, 2, 1, 2, 2, 3, 3, 3, 1, 1, 0, 3, 2, 3, 3, 3, 2, 0, 0, 0, 0, 2, 0, 0, 3, 1, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 74 and the episode is 113 and the total_steps are 11749\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 1, 3, 1, 3, 0, 0, 3, 2, 1, 2, 1, 2, 0, 3, 2, 1, 1, 1, 1, 3, 1, 3, 0, 1, 3, 1, 2, 1, 0, 0, 3, 1, 1, 1, 1, 0, 1, 2, 2, 2, 0, 2, 1, 3, 2, 1, 1, 3, 0, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was 1054. And steps were 55 and the episode is 114 and the total_steps are 11804\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 2, 3, 3, 3, 0, 3, 0, 1, 2, 2, 2, 1, 1, 3, 1, 3, 2, 3, 3, 1, 2, 1, 3, 0, 2, 0, 1, 2, 1, 3, 3, 2, 0, 3, 3, 3, 2, 3, 1, 2, 0, 2, 2, 1, 3, 3, 3, 1, 1, 2, 1, 3, 0, 2, 2, 1, 0, 3, 3, 1, 0, 2, 3, 3, 3, 3, 2, 2, 2, 2, 0, 2, 0, 3, 3, 3, 3, 1, 0, 2, 2, 0, 1, 3, 0, 1, 2, 2, 1, 3, 0, 2, 2, 1, 1, 2, 0, 2, 1, 3, 0, 0, 3, 3, 0, 2, 1, 1, 0, 3, 1, 3, 2, 3, 2, 2, 3, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -927. And steps were 125 and the episode is 115 and the total_steps are 11929\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 0, 3, 2, 2, 2, 2, 0, 3, 0, 3, 0, 0, 2, 1, 2, 0, 1, 1, 2, 3, 1, 1, 3, 1, 3, 2, 1, 2, 3, 2, 0, 3, 0, 3, 0, 0, 1, 1, 2, 0, 0, 2, 2, 1, 0, 1, 2, 2, 3, 1, 3, 3, 3, 2, 1, 1, 3, 0, 2, 2, 2, 3, 1, 1, 3, 3, 3, 0, 1, 1, 3, 1, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 2, 2, 2, 3, 1, 1, 1, 3, 1, 3, 1, 0, 1, 3, 3, 0, 3, 2, 0, 1, 0, 3, 0, 3, 3, 3, 2, 0, 3, 2, 2, 3, 2, 2, 3, 1, 1, 1, 3, 2, 3, 1, 3, 3, 1, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1055. And steps were 135 and the episode is 116 and the total_steps are 12064\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -782     |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 12064    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 3, 1, 3, 3, 2, 1, 0, 0, 2, 0, 2, 1, 2, 0, 0, 2, 0, 3, 2, 0, 1, 2, 3, 3, 2, 1, 3, 2, 2, 0, 2, 2, 1, 3, 2, 2, 2, 1, 2, 0, 0, 1, 2, 3, 3, 3, 0, 1, 2, 3, 0, 1, 3, 2, 2, 0, 2, 3, 0, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 67 and the episode is 117 and the total_steps are 12131\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 0, 0, 2, 3, 0, 1, 1, 2, 2, 1, 1, 2, 2, 3, 0, 3, 3, 3, 1, 2, 2, 2, 0, 1, 1, 1, 3, 3, 1, 1, 1, 0, 0, 3, 1, 0, 2, 3, 0, 1, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1043. And steps were 46 and the episode is 118 and the total_steps are 12177\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 1, 1, 1, 1, 3, 1, 2, 0, 0, 0, 3, 1, 1, 2, 1, 0, 0, 3, 2, 0, 1, 0, 2, 0, 3, 1, 1, 1, 0, 2, 2, 3, 0, 1, 3, 3, 1, 1, 3, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 3, 3, 2, 3, 3, 0, 2, 1, 1, 3, 0, 3, 0, 3, 3, 2, 2, 2, 0, 3, 3, 1, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -939. And steps were 79 and the episode is 119 and the total_steps are 12256\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 0, 1, 3, 3, 3, 3, 0, 0, 0, 1, 1, 2, 3, 0, 3, 3, 2, 3, 2, 2, 1, 2, 3, 0, 3, 1, 2, 0, 3, 0, 1, 2, 2, 0, 3, 3, 0, 1, 0, 1, 3, 3, 2, 1, 3, 3, 2, 2, 1, 3, 2, 2, 3, 0, 0, 1, 2, 1, 3, 2, 0, 3, 0, 3, 0, 0, 2, 2, 2, 1, 2, 3, 2, 1, 3, 3, 2, 0, 1, 0, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 87 and the episode is 120 and the total_steps are 12343\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -761     |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 12343    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 2, 3, 3, 1, 2, 1, 1, 0, 0, 2, 2, 2, 2, 1, 2, 1, 3, 0, 2, 0, 1, 0, 1, 0, 3, 0, 1, 2, 1, 2, 0, 1, 3, 2, 3, 3, 3, 2, 1, 0, 2, 1, 2, 3, 0, 1, 3, 3, 1, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1054. And steps were 55 and the episode is 121 and the total_steps are 12398\n",
      "Done condition: collision\n",
      "[3, 0, 0, 1, 1, 3, 2, 3, 1, 0, 3, 1, 1, 0, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 3, 2, 3, 0, 1, 1, 1, 2, 2, 3, 1, 2, 3, 3, 2, 1, 2, 2, 0, 1, 3, 2, 3, 3, 0, 3, 2, 1, 2, 0, 1, 0, 2, 2, 1, 3, 1, 2, 1, 1, 2, 1, 1, 0, 3, 1, 1, 1, 1, 2, 0, 0, 2, 2, 1, 0, 0, 2, 0, 1, 0, 2, 1, 0, 3, 3, 3, 0, 1, 1, 0, 3, 3, 0, 2, 0, 1, 3, 1, 0, 3, 1, 1, 2, 0, 1, 1, 2, 1, 3, 1, 2, 1, 2, 2, 0, 1, 3, 0, 2, 0, 0, 0, 1, 1, 2, 3, 1, 3, 2, 1, 0, 0, 3, 2, 1, 3, 0, 2, 3, 1, 1, 0, 2, 1, 2, 3, 2, 2, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -904. And steps were 158 and the episode is 122 and the total_steps are 12556\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 3, 0, 1, 3, 1, 3, 2, 0, 0, 3, 3, 3, 0, 2, 1, 0, 2, 2, 0, 3, 3, 2, 1, 2, 1, 0, 1, 1, 2, 1, 1, 2, 1, 3, 1, 2, 1, 3, 3, 3, 0, 3, 0, 2, 3, 3, 0, 3, 0, 0, 2, 2, 2, 0, 0, 1, 3, 2, 3, 1, 2, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 1, 2, 0, 0, 0, 3, 1, 0, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 3, 3, 0, 3, 2, 0, 3, 3, 0, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -926. And steps were 106 and the episode is 123 and the total_steps are 12662\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 3, 3, 1, 3, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 3, 3, 1, 1, 2, 2, 3, 1, 2, 0, 1, 3, 3, 2, 3, 1, 3, 2, 2, 0, 2, 1, 0, 0, 2, 3, 2, 2, 0, 3, 0, 0, 3, 2, 3, 0, 0, 3, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3, 3, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 71 and the episode is 124 and the total_steps are 12733\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -740     |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 12733    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 0, 1, 3, 2, 3, 2, 1, 1, 1, 0, 1, 0, 2, 3, 1, 3, 0, 3, 2, 2, 1, 3, 3, 0, 1, 2, 0, 2, 3, 1, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 3, 3, 3, 1, 1, 0, 2, 3, 2, 2, 0, 3, 2, 2, 2, 1, 1, 0, 1, 2, 0, 3, 3, 3, 2, 1, 0, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -947. And steps were 75 and the episode is 125 and the total_steps are 12808\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 1, 3, 3, 3, 2, 1, 1, 3, 3, 3, 0, 1, 1, 3, 2, 1, 2, 3, 0, 0, 3, 1, 2, 0, 0, 2, 2, 0, 0, 0, 1, 3, 0, 2, 2, 0, 0, 1, 3, 3, 2, 3, 0, 0, 0, 2, 1, 1, 2, 1, 2, 2, 1, 3, 2, 2, 0, 3, 3, 3, 2, 1, 2, 3, 0, 2, 0, 1, 1, 0, 2, 0, 0, 3, 2, 0, 0, 2, 2, 2, 3, 2, 1, 2, 1, 1, 2, 3, 0, 3, 3, 2, 2, 2, 3, 1, 2, 3, 0, 2, 3, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 3, 1, 0, 2, 1, 2, 0, 1, 2, 2, 3, 2, 3, 0, 3, 3, 2, 0, 1, 3, 2, 1, 3, 3, 0, 2, 2, 2, 1, 3, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 149 and the episode is 126 and the total_steps are 12957\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 0, 3, 3, 1, 0, 3, 3, 3, 0, 0, 3, 0, 2, 3, 2, 2, 2, 0, 2, 3, 3, 1, 1, 2, 2, 3, 0, 2, 3, 0, 0, 1, 1, 3, 1, 3, 0, 1, 2, 2, 0, 1, 0, 2, 2, 1, 3, 0, 0, 0, 2, 1, 1, 3, 0, 1, 3, 1, 3, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2, 1, 3, 0, 3, 3, 2, 0, 2, 3, 2, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1085. And steps were 87 and the episode is 127 and the total_steps are 13044\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 2, 1, 3, 3, 1, 3, 1, 1, 2, 0, 0, 0, 3, 3, 0, 0, 3, 1, 1, 0, 0, 2, 2, 2, 2, 2, 1, 3, 0, 1, 3, 3, 2, 0, 0, 2, 3, 0, 2, 2, 3, 2, 1, 2, 0, 2, 2, 1, 3, 0, 2, 1, 1, 3, 3, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 1, 2, 2, 1, 1, 3, 0, 1, 1, 0, 1, 2, 2, 0, 2, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -924. And steps were 88 and the episode is 128 and the total_steps are 13132\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -760     |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 13132    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 2, 3, 2, 0, 0, 3, 3, 0, 2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 3, 3, 0, 3, 0, 2, 3, 0, 3, 0, 2, 2, 1, 2, 0, 1, 3, 0, 2, 0, 1, 3, 0, 0, 3, 1, 1, 3, 0, 1, 3, 1, 0, 2, 0, 2, 0, 2, 0, 0, 3, 0, 0, 3, 2, 0, 3, 0, 3, 2, 3, 1, 2, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 0, 1, 2, 0, 2, 1, 1, 1, 2, 3, 0, 0, 0, 2, 3, 2, 0, 0, 1, 3, 1, 0, 2, 0, 2, 0, 3, 0, 0, 0, 3, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 2, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 136 and the episode is 129 and the total_steps are 13268\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 1, 1, 1, 2, 2, 2, 0, 3, 2, 2, 3, 2, 1, 1, 3, 2, 1, 1, 0, 1, 0, 0, 3, 1, 1, 1, 0, 1, 3, 2, 3, 1, 0, 3, 1, 1, 3, 0, 3, 0, 3, 3, 1, 3, 3, 2, 2, 1, 0, 2, 2, 2, 1, 3, 0, 3, 1, 1, 3, 3, 3, 1, 0, 2, 1, 3, 0, 3, 1, 0, 0, 0, 2, 3, 3, 0, 1, 1, 3, 3, 2, 2, 3, 0, 1, 0, 0, 1, 3, 1, 3, 3, 2, 3, 0, 3, 1, 3, 1, 3, 1, 0, 2, 1, 3, 3, 0, 2, 3, 3, 1, 3, 1, 3, 1, 1, 3, 0, 0, 0, 0, 2, 2, 1, 3, 3, 0, 3, 1, 1, 2, 0, 1, 2, 3, 2, 2, 3, 2, 3, 0, 3, 3, 0, 1, 0, 3, 2, 3, 1, 1, 1, 3, 2, 0, 2, 2, 0, 3, 1, 3, 3, 1, 3, 2, 2, 0, 3, 0, 2, 0, 2, 1, 0, 2, 0, 2, 2, 2, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -841. And steps were 187 and the episode is 130 and the total_steps are 13455\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 2, 2, 1, 2, 0, 2, 1, 0, 2, 2, 3, 0, 1, 1, 1, 2, 0, 2, 1, 3, 0, 2, 3, 3, 3, 1, 2, 0, 0, 2, 0, 2, 3, 2, 3, 0, 3, 0, 1, 3, 0, 3, 3, 0, 2, 2, 3, 1, 0, 3, 3, 2, 3, 1, 3, 2, 1, 0, 3, 0, 1, 3, 0, 0, 2, 1, 2, 2, 0, 0, 0, 2, 1, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1079. And steps were 81 and the episode is 131 and the total_steps are 13536\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 0, 2, 2, 2, 1, 1, 2, 1, 1, 0, 2, 2, 2, 2, 3, 2, 1, 3, 1, 0, 0, 2, 2, 1, 1, 3, 3, 3, 1, 3, 0, 1, 2, 0, 0, 1, 3, 2, 3, 1, 0, 3, 2, 1, 0, 1, 3, 0, 3, 1, 2, 3, 3, 2, 2, 2, 3, 2, 0, 1, 0, 0, 1, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -951. And steps were 71 and the episode is 132 and the total_steps are 13607\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -761     |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 13607    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 2, 3, 2, 3, 1, 0, 0, 1, 2, 1, 1, 3, 2, 1, 0, 1, 0, 2, 3, 0, 3, 1, 0, 2, 1, 3, 3, 0, 0, 0, 2, 3, 1, 2, 2, 3, 1, 0, 1, 2, 3, 1, 3, 1, 0, 0, 1, 2, 3, 3, 1, 1, 3, 2, 0, 0, 2, 1, 3, 3, 1, 0, 3, 2, 3, 0, 3, 1, 2, 0, 1, 3, 1, 1, 1, 1, 3, 3, 2, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -953. And steps were 87 and the episode is 133 and the total_steps are 13694\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 0, 0, 0, 1, 0, 2, 0, 1, 0, 2, 0, 2, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 0, 0, 0, 1, 0, 1, 3, 2, 0, 3, 2, 3, 3, 1, 0, 0, 2, 3, 1, 1, 3, 0, 1, 1, 0, 3, 3, 2, 1, 3, 0, 1, 0, 3, 1, 3, 3, 1, 0, 0, 3, 0, 0, 1, 2, 3, 1, 1, 3, 3, 2, 1, 3, 3, 3, 0, 1, 0, 0, 2, 3, 3, 3, 0, 3, 0, 0, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 0, 1, 3, 0, 0, 2, 1, 3, 2, 1, 0, 1, 2, 1, 2, 3, 3, 3, 2, 1, 1, 3, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -892. And steps were 138 and the episode is 134 and the total_steps are 13832\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 2, 0, 1, 3, 3, 2, 2, 2, 0, 1, 2, 0, 0, 1, 3, 0, 1, 0, 0, 3, 0, 3, 3, 3, 0, 1, 1, 2, 2, 0, 3, 3, 3, 3, 3, 3, 2, 1, 2, 0, 1, 3, 0, 0, 0, 3, 0, 0, 2, 3, 1, 0, 1, 2, 2, 3, 1, 0, 2, 2, 0, 3, 3, 1, 3, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 81 and the episode is 135 and the total_steps are 13913\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 0, 3, 3, 1, 2, 2, 0, 2, 0, 0, 2, 0, 2, 1, 3, 3, 3, 3, 0, 2, 2, 3, 0, 2, 1, 2, 2, 2, 2, 2, 0, 3, 2, 1, 2, 1, 1, 2, 0, 1, 3, 3, 2, 2, 0, 1, 0, 0, 2, 0, 2, 3, 1, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 61 and the episode is 136 and the total_steps are 13974\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -780     |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 13974    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 0, 1, 3, 0, 0, 2, 1, 2, 2, 3, 2, 3, 3, 2, 1, 0, 0, 2, 1, 3, 2, 1, 3, 0, 0, 2, 0, 1, 3, 1, 1, 1, 0, 3, 3, 1, 2, 3, 0, 1, 0, 2, 0, 2, 1, 2, 0, 0, 0, 0, 2, 1, 3, 3, 1, 3, 2, 3, 0, 3, 2, 0, 1, 3, 0, 0, 1, 0, 3, 0, 3, 3, 1, 2, 3, 1, 0, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1083. And steps were 85 and the episode is 137 and the total_steps are 14059\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 3, 1, 1, 0, 3, 0, 0, 2, 0, 2, 0, 0, 3, 2, 1, 0, 1, 1, 0, 0, 3, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 0, 1, 2, 1, 3, 3, 1, 0, 2, 2, 3, 3, 2, 1, 0, 3, 1, 3, 0, 3, 2, 0, 0, 2, 2, 1, 1, 2, 3, 2, 1, 3, 2, 2, 1, 1, 2, 2, 0, 2, 1, 1, 3, 2, 1, 2, 2, 1, 2, 3, 1, 2, 2, 3, 1, 2, 1, 3, 1, 1, 3, 0, 3, 0, 2, 1, 1, 3, 2, 2, 1, 1, 0, 3, 0, 3, 2, 3, 3, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 120 and the episode is 138 and the total_steps are 14179\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 3, 2, 1, 3, 2, 0, 0, 3, 1, 1, 3, 3, 3, 2, 3, 0, 1, 3, 2, 1, 2, 0, 0, 3, 3, 2, 3, 3, 1, 0, 3, 3, 1, 2, 1, 3, 1, 0, 0, 2, 3, 0, 2, 2, 3, 3, 2, 2, 1, 1, 3, 0, 1, 2, 0, 3, 2, 3, 1, 2, 2, 1, 3, 2, 1, 2, 0, 2, 0, 2, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -945. And steps were 85 and the episode is 139 and the total_steps are 14264\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 1, 0, 0, 3, 3, 3, 3, 3, 1, 1, 2, 0, 0, 0, 1, 3, 3, 1, 2, 0, 2, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 0, 1, 3, 3, 1, 1, 3, 2, 2, 0, 0, 3, 1, 3, 3, 3, 1, 0, 0, 2, 2, 0, 1, 1, 0, 0, 2, 3, 3, 2, 2, 1, 2, 3, 0, 3, 3, 2, 2, 1, 1, 0, 0, 1, 2, 0, 0, 0, 2, 2, 3, 1, 1, 1, 2, 0, 0, 2, 3, 0, 1, 1, 3, 3, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1102. And steps were 104 and the episode is 140 and the total_steps are 14368\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -783     |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 14368    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 0, 0, 3, 2, 2, 3, 0, 3, 0, 3, 1, 3, 1, 0, 0, 1, 2, 2, 1, 1, 2, 1, 2, 1, 0, 3, 1, 2, 0, 1, 1, 3, 1, 2, 3, 0, 1, 2, 3, 2, 2, 2, 1, 2, 3, 1, 1, 0, 3, 1, 1, 0, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1058. And steps were 60 and the episode is 141 and the total_steps are 14428\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 0, 2, 2, 1, 2, 3, 0, 2, 2, 2, 3, 2, 0, 2, 2, 3, 1, 1, 0, 2, 1, 0, 1, 0, 2, 0, 0, 1, 2, 3, 2, 0, 0, 3, 1, 3, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 1, 2, 0, 0, 0, 2, 0, 0, 1, 3, 0, 2, 2, 1, 1, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1067. And steps were 69 and the episode is 142 and the total_steps are 14497\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 2, 0, 1, 0, 1, 3, 1, 1, 2, 1, 2, 3, 0, 0, 1, 2, 1, 2, 2, 3, 1, 0, 2, 0, 2, 2, 0, 0, 2, 1, 3, 2, 2, 1, 3, 0, 1, 3, 2, 1, 1, 2, 1, 2, 0, 3, 3, 2, 3, 1, 1, 2, 1, 2, 2, 3, 3, 1, 0, 0, 1, 3, 1, 1, 2, 0, 2, 0, 3, 1, 2, 2, 1, 3, 1, 0, 0, 2, 1, 1, 3, 2, 1, 0, 1, 0, 2, 1, 1, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 97 and the episode is 143 and the total_steps are 14594\n",
      "Done condition: max time steps reached\n",
      "[3, 0, 0, 2, 0, 0, 2, 0, 3, 3, 2, 3, 2, 2, 1, 2, 1, 1, 2, 1, 2, 3, 2, 0, 0, 3, 3, 0, 2, 0, 1, 0, 3, 1, 0, 2, 0, 0, 2, 3, 2, 1, 1, 3, 0, 1, 2, 3, 0, 3, 2, 1, 3, 1, 3, 2, 2, 3, 0, 2, 0, 3, 3, 2, 1, 3, 1, 0, 1, 2, 1, 0, 1, 3, 0, 1, 3, 0, 1, 1, 0, 0, 1, 0, 1, 2, 2, 2, 3, 1, 1, 1, 0, 3, 2, 0, 1, 1, 0, 3, 3, 0, 0, 2, 1, 3, 0, 1, 2, 2, 2, 0, 0, 0, 1, 0, 3, 3, 3, 1, 3, 3, 1, 3, 0, 1, 2, 0, 1, 1, 1, 0, 0, 2, 3, 0, 2, 0, 0, 3, 1, 1, 1, 2, 3, 0, 0, 2, 2, 1, 3, 1, 3, 3, 1, 3, 1, 3, 3, 0, 0, 3, 1, 1, 0, 1, 1, 0, 2, 2, 0, 3, 0, 3, 3, 3, 0, 2, 0, 1, 3, 2, 2, 0, 1, 1, 3, 2, 1, 3, 1, 3, 3, 2, 1, 0, 1, 0, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 202 and the episode is 144 and the total_steps are 14796\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.9     |\n",
      "|    ep_rew_mean      | -784     |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 14796    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 2, 2, 0, 2, 1, 2, 2, 3, 3, 1, 2, 0, 0, 3, 1, 1, 0, 2, 0, 0, 3, 2, 1, 0, 0, 0, 3, 3, 1, 2, 2, 1, 3, 0, 0, 1, 2, 0, 3, 3, 1, 3, 0, 1, 2, 3, 2, 2, 3, 0, 3, 0, 2, 0, 0, 3, 1, 0, 1, 1, 3, 3, 2, 0, 0, 3, 1, 1, 1, 2, 0, 2, 0, 2, 2, 3, 2, 1, 2, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 87 and the episode is 145 and the total_steps are 14883\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 3, 1, 1, 1, 0, 1, 0, 1, 0, 2, 3, 3, 2, 2, 0, 1, 1, 3, 1, 3, 0, 1, 0, 1, 3, 2, 1, 0, 1, 0, 2, 3, 3, 3, 1, 0, 1, 3, 0, 1, 3, 0, 1, 1, 1, 0, 3, 1, 0, 0, 2, 2, 2, 1, 0, 0, 1, 0, 1, 0, 0, 2, 2, 0, 3, 2, 0, 2, 0, 1, 0, 0, 0, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1079. And steps were 81 and the episode is 146 and the total_steps are 14964\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 0, 1, 1, 3, 1, 3, 0, 2, 1, 3, 1, 1, 1, 2, 3, 1, 2, 1, 2, 3, 0, 0, 3, 3, 1, 0, 0, 2, 1, 2, 2, 2, 2, 1, 3, 2, 3, 1, 0, 2, 1, 3, 2, 0, 0, 1, 0, 2, 0, 1, 2, 0, 1, 1, 1, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 63 and the episode is 147 and the total_steps are 15027\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 0, 1, 3, 3, 1, 0, 0, 3, 2, 1, 0, 1, 3, 2, 1, 1, 3, 2, 0, 3, 3, 1, 3, 1, 2, 2, 3, 2, 3, 2, 3, 3, 1, 1, 0, 3, 3, 0, 3, 0, 3, 3, 2, 1, 2, 0, 3, 0, 0, 1, 3, 0, 2, 3, 2, 0, 3, 2, 1, 0, 3, 0, 2, 2, 3, 0, 3, 3, 2, 1, 0, 3, 0, 1, 2, 2, 3, 3, 1, 0, 1, 1, 2, 2, 2, 3, 1, 0, 1, 1, 1, 2, 3, 1, 0, 1, 3, 1, 2, 1, 0, 0, 2, 3, 3, 0, 3, 3, 0, 3, 2, 2, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 120 and the episode is 148 and the total_steps are 15147\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.4     |\n",
      "|    ep_rew_mean      | -803     |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 15147    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 2, 1, 1, 2, 3, 2, 1, 3, 1, 2, 1, 0, 0, 2, 2, 0, 1, 3, 0, 0, 0, 0, 0, 1, 2, 0, 0, 3, 1, 1, 3, 2, 0, 0, 0, 0, 2, 2, 1, 2, 3, 0, 2, 1, 3, 2, 3, 1, 1, 0, 1, 3, 1, 1, 3, 1, 1, 1, 2, 1, 2, 2, 2, 0, 2, 1, 1, 1, 2, 1, 1, 1, 3, 3, 0, 1, 2, 2, 3, 2, 2, 3, 2, 1, 1, 0, 0, 0, 3, 0, 2, 3, 2, 1, 2, 3, 0, 0, 3, 3, 1, 1, 1, 1, 1, 0, 0, 3, 1, 2, 2, 2, 0, 1, 1, 3, 2, 3, 3, 2, 0, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 140 and the episode is 149 and the total_steps are 15287\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 3, 1, 2, 3, 2, 1, 3, 2, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 3, 1, 3, 3, 2, 3, 0, 0, 1, 2, 1, 0, 3, 2, 3, 2, 0, 2, 3, 0, 3, 0, 3, 2, 2, 0, 2, 3, 0, 1, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -950. And steps were 62 and the episode is 150 and the total_steps are 15349\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 3, 3, 3, 0, 3, 2, 2, 3, 0, 1, 1, 3, 3, 1, 1, 3, 3, 1, 2, 2, 1, 0, 3, 0, 3, 3, 1, 0, 1, 3, 3, 2, 2, 0, 0, 2, 1, 0, 1, 0, 2, 0, 0, 1, 2, 1, 1, 1, 3, 1, 3, 0, 0, 1, 2, 1, 1, 1, 2, 1, 0, 2, 2, 3, 2, 0, 0, 2, 0, 1, 2, 3, 1, 0, 1, 3, 3, 3, 3, 3, 1, 0, 1, 1, 2, 3, 2, 0, 0, 3, 3, 2, 3, 1, 1, 2, 1, 2, 2, 3, 0, 1, 3, 3, 1, 1, 0, 2, 2, 0, 0, 0, 2, 3, 1, 3, 0, 0, 2, 2, 0, 2, 3, 0, 1, 3, 1, 2, 1, 2, 3, 3, 3, 1, 2, 3, 2, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 2, 2, 2, 2, 0, 1, 1, 3, 0, 2, 2, 1, 0, 0, 2, 3, 0, 1, 0, 0, 3, 3, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -869. And steps were 177 and the episode is 151 and the total_steps are 15526\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 1, 1, 3, 0, 1, 1, 3, 1, 3, 0, 2, 1, 0, 1, 2, 1, 0, 2, 3, 3, 1, 1, 0, 1, 2, 1, 3, 2, 0, 3, 3, 0, 1, 2, 3, 3, 2, 1, 1, 0, 0, 2, 2, 1, 0, 0, 2, 1, 0, 3, 0, 2, 2, 2, 1, 3, 0, 3, 3, 3, 1, 1, 1, 2, 2, 2, 3, 3, 1, 2, 1, 2, 0, 1, 3, 2, 0, 2, 3, 0, 2, 3, 2, 3, 3, 2, 2, 3, 0, 1, 0, 3, 0, 3, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -928. And steps were 102 and the episode is 152 and the total_steps are 15628\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.9     |\n",
      "|    ep_rew_mean      | -801     |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 15628    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 0, 2, 3, 3, 2, 1, 3, 3, 2, 3, 2, 2, 0, 1, 0, 1, 2, 1, 1, 2, 0, 0, 3, 3, 0, 1, 0, 1, 3, 0, 1, 1, 2, 2, 2, 3, 3, 3, 2, 1, 2, 1, 0, 0, 3, 2, 3, 3, 2, 3, 0, 2, 0, 1, 3, 1, 0, 3, 1, 1, 3, 0, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1068. And steps were 70 and the episode is 153 and the total_steps are 15698\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 0, 0, 0, 2, 2, 1, 3, 3, 0, 3, 3, 2, 2, 2, 1, 0, 3, 2, 2, 1, 2, 3, 2, 3, 3, 1, 2, 2, 2, 0, 3, 3, 0, 1, 3, 2, 0, 1, 3, 0, 3, 1, 2, 1, 1, 3, 1, 0, 1, 1, 3, 3, 3, 2, 1, 3, 2, 2, 2, 3, 0, 2, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 70 and the episode is 154 and the total_steps are 15768\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 0, 0, 3, 0, 0, 0, 0, 2, 2, 1, 3, 0, 2, 2, 2, 1, 2, 3, 2, 0, 1, 2, 2, 1, 2, 2, 1, 3, 1, 0, 2, 1, 0, 2, 0, 3, 1, 0, 2, 2, 2, 0, 0, 3, 2, 0, 0, 2, 0, 3, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1055. And steps were 56 and the episode is 155 and the total_steps are 15824\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 0, 3, 1, 2, 3, 1, 2, 2, 3, 0, 2, 2, 1, 0, 1, 0, 0, 3, 1, 3, 2, 2, 1, 0, 3, 3, 2, 3, 0, 2, 2, 3, 0, 3, 3, 0, 0, 2, 2, 2, 3, 2, 1, 3, 3, 2, 0, 1, 1, 0, 1, 3, 0, 2, 0, 2, 3, 3, 3, 0, 0, 2, 3, 0, 0, 2, 3, 0, 1, 0, 3, 0, 3, 2, 3, 0, 0, 0, 2, 3, 1, 0, 0, 2, 0, 3, 1, 3, 1, 1, 1, 1, 2, 0, 1, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -943. And steps were 103 and the episode is 156 and the total_steps are 15927\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -781     |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total_timesteps  | 15927    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 3, 1, 0, 2, 3, 3, 1, 2, 1, 1, 2, 3, 3, 3, 3, 2, 0, 1, 2, 0, 3, 2, 0, 3, 3, 0, 2, 3, 3, 0, 0, 3, 2, 0, 3, 2, 1, 2, 2, 0, 0, 2, 0, 1, 0, 2, 3, 0, 0, 3, 0, 1, 2, 2, 1, 0, 2, 2, 0, 2, 3, 3, 2, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 72 and the episode is 157 and the total_steps are 15999\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 3, 2, 1, 0, 2, 0, 0, 0, 1, 1, 3, 2, 3, 3, 1, 1, 2, 1, 1, 2, 2, 0, 3, 0, 0, 1, 0, 1, 2, 3, 2, 1, 0, 3, 2, 0, 1, 1, 0, 0, 1, 1, 1, 2, 0, 0, 2, 0, 3, 3, 0, 3, 3, 1, 0, 3, 0, 1, 2, 3, 2, 2, 0, 0, 2, 3, 0, 1, 2, 0, 3, 2, 0, 0, 0, 2, 2, 3, 1, 1, 3, 1, 2, 0, 1, 3, 0, 1, 2, 0, 3, 1, 2, 2, 3, 1, 1, 2, 1, 1, 3, 3, 2, 3, 3, 0, 0, 3, 1, 1, 2, 1, 3, 2, 1, 3, 0, 0, 3, 3, 1, 2, 3, 2, 0, 2, 2, 3, 0, 0, 1, 0, 3, 1, 3, 3, 1, 0, 3, 1, 2, 2, 0, 1, 3, 3, 0, 1, 2, 2, 3, 0, 1, 3, 3, 2, 2, 0, 3, 0, 3, 2, 3, 2, 2, 1, 0, 3, 0, 1, 2, 0, 0, 3, 3, 2, 0, 0, 2, 3, 0, 0, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -844. And steps were 190 and the episode is 158 and the total_steps are 16189\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 0, 0, 3, 3, 0, 0, 1, 3, 2, 2, 3, 0, 0, 1, 0, 3, 3, 3, 0, 1, 0, 0, 0, 0, 3, 2, 3, 0, 1, 3, 1, 2, 1, 0, 2, 2, 2, 3, 0, 3, 0, 2, 2, 3, 0, 2, 0, 1, 3, 0, 0, 3, 2, 2, 0, 0, 0, 2, 3, 2, 3, 1, 0, 2, 0, 0, 1, 3, 0, 0, 0, 0, 1, 0, 0, 1, 2, 1, 3, 1, 2, 3, 2, 2, 3, 0, 3, 0, 1, 0, 2, 3, 1, 3, 2, 3, 2, 2, 1, 0, 3, 2, 0, 3, 2, 0, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 114 and the episode is 159 and the total_steps are 16303\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 1, 0, 3, 0, 3, 1, 1, 1, 0, 1, 0, 0, 2, 1, 2, 3, 3, 3, 3, 2, 0, 2, 0, 1, 1, 1, 1, 2, 1, 3, 3, 3, 2, 1, 2, 3, 2, 1, 3, 3, 2, 2, 1, 0, 2, 2, 0, 0, 0, 1, 2, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 59 and the episode is 160 and the total_steps are 16362\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -800     |\n",
      "|    exploration_rate | 0.984    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 16362    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 2, 1, 3, 0, 3, 2, 1, 2, 2, 1, 3, 2, 2, 3, 2, 0, 1, 3, 1, 3, 3, 2, 1, 0, 1, 3, 1, 1, 3, 3, 3, 1, 3, 0, 2, 2, 0, 3, 0, 3, 2, 1, 1, 3, 2, 1, 0, 1, 0, 2, 3, 2, 3, 1, 1, 3, 1, 0, 3, 2, 3, 2, 1, 1, 2, 3, 1, 3, 1, 0, 1, 1, 2, 0, 1, 1, 3, 1, 2, 1, 3, 1, 1, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 3, 2, 0, 3, 0, 3, 2, 1, 1, 3, 1, 3, 2, 1, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1113. And steps were 115 and the episode is 161 and the total_steps are 16477\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 2, 3, 3, 2, 2, 3, 0, 2, 3, 1, 2, 3, 0, 2, 1, 2, 3, 3, 3, 2, 3, 3, 3, 1, 1, 0, 2, 3, 0, 2, 2, 2, 2, 1, 3, 3, 2, 2, 0, 1, 1, 3, 1, 0, 1, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1050. And steps were 51 and the episode is 162 and the total_steps are 16528\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 3, 2, 0, 0, 2, 1, 1, 2, 3, 3, 3, 1, 1, 3, 1, 3, 0, 1, 1, 2, 2, 3, 0, 2, 0, 2, 1, 1, 3, 0, 2, 0, 0, 3, 2, 0, 3, 3, 3, 1, 1, 3, 1, 0, 3, 3, 1, 0, 2, 1, 3, 2, 3, 2, 2, 1, 2, 1, 1, 0, 3, 0, 3, 2, 1, 1, 3, 1, 0, 3, 1, 2, 3, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -945. And steps were 81 and the episode is 163 and the total_steps are 16609\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 1, 3, 2, 1, 2, 1, 2, 0, 2, 1, 0, 1, 1, 3, 2, 3, 1, 0, 1, 0, 1, 3, 2, 1, 0, 1, 3, 3, 3, 3, 3, 1, 3, 2, 3, 0, 3, 3, 2, 1, 1, 0, 2, 3, 0, 3, 0, 0, 3, 1, 3, 2, 3, 1, 2, 1, 2, 2, 2, 2, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 68 and the episode is 164 and the total_steps are 16677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -800     |\n",
      "|    exploration_rate | 0.984    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 16677    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 1, 0, 3, 0, 0, 2, 1, 1, 1, 3, 0, 0, 1, 1, 1, 2, 2, 2, 3, 2, 0, 0, 3, 1, 0, 0, 1, 2, 2, 2, 0, 0, 0, 1, 0, 3, 1, 3, 0, 3, 0, 1, 0, 0, 0, 2, 0, 3, 0, 3, 3, 0, 2, 3, 0, 2, 1, 0, 0, 2, 1, 3, 3, 3, 3, 2, 3, 1, 0, 1, 0, 3, 3, 3, 0, 2, 3, 0, 0, 1, 0, 0, 3, 3, 2, 0, 3, 1, 3, 3, 3, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 3, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -941. And steps were 111 and the episode is 165 and the total_steps are 16788\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 2, 1, 2, 3, 3, 3, 1, 0, 3, 0, 0, 1, 1, 1, 3, 1, 1, 1, 2, 0, 3, 1, 1, 0, 0, 3, 1, 3, 0, 1, 0, 3, 2, 0, 3, 0, 0, 1, 0, 3, 0, 0, 3, 1, 3, 3, 3, 0, 0, 1, 2, 3, 1, 3, 2, 1, 1, 0, 1, 3, 2, 1, 2, 2, 0, 0, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 74 and the episode is 166 and the total_steps are 16862\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 1, 1, 3, 1, 3, 1, 0, 2, 0, 2, 0, 0, 0, 2, 0, 3, 1, 0, 2, 1, 1, 2, 3, 0, 1, 3, 3, 0, 1, 3, 3, 1, 1, 0, 0, 2, 0, 2, 1, 3, 2, 2, 1, 0, 3, 3, 1, 3, 1, 3, 3, 2, 3, 3, 3, 1, 2, 1, 1, 2, 0, 0, 2, 1, 2, 0, 1, 2, 2, 1, 1, 0, 3, 2, 1, 0, 2, 2, 0, 2, 3, 1, 1, 0, 1, 2, 1, 2, 3, 2, 3, 1, 0, 1, 3, 1, 2, 0, 0, 0, 2, 1, 3, 2, 3, 2, 0, 1, 3, 3, 3, 3, 1, 2, 0, 1, 3, 1, 1, 1, 1, 2, 1, 0, 2, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 133 and the episode is 167 and the total_steps are 16995\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 3, 1, 0, 1, 3, 3, 2, 2, 0, 3, 0, 0, 3, 1, 0, 3, 3, 3, 2, 0, 1, 2, 1, 2, 0, 0, 2, 1, 0, 3, 1, 3, 3, 2, 1, 1, 1, 2, 3, 1, 2, 3, 0, 2, 2, 2, 2, 0, 2, 3, 0, 1, 2, 1, 1, 3, 3, 0, 0, 3, 3, 3, 0, 1, 2, 2, 3, 2, 0, 0, 2, 2, 1, 0, 3, 1, 0, 0, 0, 0, 1, 0, 0, 3, 2, 3, 0, 2, 3, 2, 3, 1, 2, 2, 3, 1, 3, 1, 0, 0, 1, 1, 0, 3, 2, 2, 0, 2, 0, 2, 1, 0, 0, 2, 0, 1, 0, 1, 0, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -933. And steps were 127 and the episode is 168 and the total_steps are 17122\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -841     |\n",
      "|    exploration_rate | 0.984    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 17122    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 0, 0, 3, 2, 0, 2, 2, 0, 3, 2, 2, 1, 2, 3, 1, 1, 1, 0, 1, 3, 0, 3, 2, 0, 1, 1, 3, 3, 2, 0, 2, 0, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 1, 3, 0, 0, 0, 3, 2, 2, 2, 2, 3, 1, 1, 1, 1, 3, 0, 0, 0, 1, 3, 3, 0, 0, 0, 0, 0, 3, 3, 2, 0, 2, 1, 2, 3, 3, 2, 2, 0, 1, 1, 0, 0, 2, 3, 1, 0, 1, 3, 3, 3, 3, 2, 2, 2, 1, 2, 1, 0, 0, 1, 3, 0, 3, 2, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1, 3, 0, 1, 1, 1, 0, 3, 1, 3, 0, 2, 2, 0, 3, 0, 2, 3, 1, 1, 1, 2, 3, 0, 2, 3, 3, 1, 1, 3, 2, 0, 3, 0, 3, 3, 3, 2, 0, 1, 3, 3, 1, 2, 0, 2, 1, 2, 3, 3, 2, 3, 2, 2, 3, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 178 and the episode is 169 and the total_steps are 17300\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 0, 0, 2, 2, 0, 1, 1, 0, 3, 1, 0, 1, 1, 3, 3, 0, 0, 1, 1, 0, 1, 3, 0, 1, 0, 0, 2, 2, 2, 0, 1, 2, 3, 3, 0, 0, 1, 2, 1, 3, 3, 2, 3, 2, 0, 3, 0, 1, 1, 3, 2, 1, 0, 3, 2, 3, 1, 2, 1, 1, 3, 0, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1068. And steps were 70 and the episode is 170 and the total_steps are 17370\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 0, 0, 3, 0, 2, 0, 0, 0, 2, 0, 2, 2, 1, 3, 1, 3, 3, 3, 3, 0, 1, 3, 1, 1, 1, 1, 1, 2, 2, 0, 0, 2, 2, 3, 3, 2, 2, 0, 2, 0, 2, 1, 0, 2, 1, 0, 2, 1, 1, 3, 2, 3, 2, 1, 1, 0, 1, 2, 2, 1, 3, 2, 0, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -947. And steps were 71 and the episode is 171 and the total_steps are 17441\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 0, 0, 2, 3, 0, 2, 0, 3, 2, 1, 3, 2, 3, 2, 2, 1, 2, 0, 1, 1, 1, 3, 1, 1, 3, 3, 0, 1, 1, 2, 2, 2, 3, 1, 1, 0, 1, 2, 1, 0, 1, 1, 0, 0, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1049. And steps were 50 and the episode is 172 and the total_steps are 17491\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -821     |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 17491    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 3, 3, 1, 1, 2, 3, 0, 1, 1, 2, 2, 2, 1, 0, 1, 1, 1, 0, 2, 1, 0, 1, 1, 2, 3, 3, 3, 0, 3, 2, 1, 3, 2, 2, 1, 0, 1, 3, 2, 3, 3, 3, 0, 1, 1, 2, 1, 2, 3, 1, 2, 2, 1, 2, 3, 2, 3, 3, 3, 2, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1066. And steps were 68 and the episode is 173 and the total_steps are 17559\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 1, 0, 0, 2, 3, 1, 3, 2, 2, 1, 3, 1, 0, 1, 3, 3, 1, 3, 0, 3, 0, 3, 0, 3, 2, 1, 3, 0, 3, 3, 2, 1, 1, 1, 0, 2, 1, 1, 3, 1, 3, 0, 1, 0, 0, 3, 2, 1, 0, 3, 2, 1, 0, 0, 3, 0, 0, 3, 1, 2, 0, 1, 3, 3, 0, 3, 3, 3, 3, 2, 0, 2, 0, 3, 0, 1, 2, 0, 2, 2, 2, 1, 3, 2, 0, 2, 3, 2, 2, 1, 1, 0, 2, 1, 0, 1, 2, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -933. And steps were 105 and the episode is 174 and the total_steps are 17664\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 2, 1, 1, 2, 2, 2, 1, 0, 2, 3, 2, 0, 0, 2, 3, 3, 0, 1, 0, 1, 2, 0, 1, 3, 3, 2, 3, 0, 1, 2, 0, 0, 0, 0, 0, 2, 3, 1, 2, 2, 3, 0, 0, 2, 2, 3, 1, 2, 0, 3, 2, 0, 3, 2, 3, 1, 3, 2, 1, 2, 3, 1, 3, 0, 0, 1, 2, 2, 3, 3, 0, 2, 2, 3, 3, 2, 1, 1, 3, 2, 2, 2, 3, 1, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 92 and the episode is 175 and the total_steps are 17756\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 1, 2, 2, 0, 0, 2, 2, 3, 2, 0, 3, 3, 1, 1, 1, 2, 1, 0, 2, 2, 2, 2, 0, 0, 0, 2, 3, 1, 1, 0, 2, 2, 0, 3, 1, 0, 0, 0, 1, 1, 2, 3, 0, 3, 3, 1, 3, 1, 0, 2, 3, 1, 1, 0, 2, 1, 3, 3, 3, 1, 1, 1, 3, 1, 1, 0, 3, 2, 0, 3, 3, 3, 1, 1, 1, 1, 0, 2, 3, 1, 2, 1, 2, 1, 3, 3, 1, 0, 1, 3, 3, 1, 2, 0, 2, 0, 1, 0, 3, 2, 3, 3, 0, 3, 1, 3, 2, 2, 1, 1, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 1, 1, 3, 2, 3, 0, 3, 0, 2, 3, 3, 1, 3, 3, 1, 0, 0, 1, 1, 2, 3, 1, 2, 2, 0, 1, 0, 2, 1, 3, 0, 0, 1, 0, 0, 3, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 165 and the episode is 176 and the total_steps are 17921\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -820     |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total_timesteps  | 17921    |\n",
      "----------------------------------\n",
      "Done condition: max time steps reached\n",
      "[0, 3, 3, 1, 2, 1, 1, 0, 1, 2, 2, 3, 3, 1, 1, 2, 0, 1, 0, 3, 0, 2, 3, 1, 2, 0, 1, 0, 3, 0, 1, 2, 3, 1, 1, 3, 3, 0, 2, 1, 0, 2, 0, 0, 0, 2, 0, 2, 1, 2, 1, 0, 3, 0, 0, 3, 1, 3, 3, 2, 3, 1, 3, 3, 2, 3, 2, 2, 3, 1, 3, 1, 1, 1, 3, 1, 3, 3, 3, 3, 0, 3, 2, 1, 1, 2, 1, 1, 2, 3, 1, 0, 1, 2, 0, 2, 1, 1, 0, 3, 0, 3, 3, 1, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3, 1, 0, 2, 2, 0, 0, 0, 0, 3, 3, 2, 1, 2, 2, 2, 2, 2, 3, 1, 2, 0, 0, 1, 1, 1, 0, 0, 2, 1, 2, 1, 3, 2, 3, 2, 2, 3, 1, 3, 0, 0, 0, 1, 3, 3, 0, 2, 3, 0, 2, 3, 1, 1, 3, 3, 3, 1, 1, 1, 0, 0, 3, 1, 1, 0, 1, 3, 0, 1, 1, 2, 2, 0, 3, 0, 1, 3, 0, 2, 1, 2, 2, 3, 1, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 202 and the episode is 177 and the total_steps are 18123\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 2, 3, 2, 0, 0, 2, 2, 2, 0, 1, 2, 2, 0, 3, 1, 2, 2, 0, 0, 0, 3, 2, 3, 3, 2, 1, 1, 0, 1, 1, 3, 1, 2, 3, 2, 2, 1, 2, 2, 0, 3, 2, 3, 1, 2, 1, 3, 2, 3, 3, 0, 1, 1, 0, 0, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 63 and the episode is 178 and the total_steps are 18186\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 0, 3, 3, 0, 0, 2, 3, 3, 1, 0, 2, 2, 3, 2, 3, 1, 1, 1, 0, 0, 3, 0, 3, 0, 0, 3, 3, 1, 2, 2, 2, 0, 1, 0, 1, 0, 1, 3, 3, 1, 3, 1, 2, 1, 2, 0, 0, 3, 3, 3, 0, 2, 0, 3, 3, 0, 3, 2, 0, 3, 1, 1, 3, 0, 0, 1, 1, 1, 2, 3, 3, 0, 0, 3, 1, 0, 3, 1, 0, 0, 1, 2, 1, 3, 1, 2, 2, 1, 2, 1, 0, 2, 2, 0, 0, 2, 3, 1, 2, 0, 0, 0, 3, 0, 0, 3, 1, 2, 2, 2, 3, 1, 3, 2, 0, 2, 2, 2, 1, 2, 0, 3, 3, 3, 1, 3, 2, 2, 0, 0, 1, 3, 3, 3, 1, 3, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -885. And steps were 145 and the episode is 179 and the total_steps are 18331\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 1, 3, 0, 3, 2, 1, 0, 2, 2, 3, 1, 2, 1, 2, 2, 2, 0, 3, 3, 0, 0, 1, 0, 0, 2, 1, 0, 0, 2, 3, 2, 2, 3, 3, 3, 0, 2, 0, 0, 0, 0, 3, 2, 3, 0, 3, 0, 0, 3, 3, 0, 0, 3, 1, 0, 3, 1, 1, 2, 3, 2, 0, 0, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 71 and the episode is 180 and the total_steps are 18402\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -819     |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 18402    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1, 0, 1, 3, 0, 2, 1, 2, 3, 3, 3, 0, 2, 1, 3, 3, 2, 0, 1, 1, 0, 3, 3, 1, 3, 0, 2, 3, 1, 0, 3, 2, 3, 3, 0, 0, 1, 1, 1, 3, 2, 3, 1, 0, 1, 2, 3, 2, 3, 2, 2, 3, 0, 3, 0, 1, 0, 0, 1, 3, 0, 1, 0, 3, 1, 3, 2, 0, 1, 2, 0, 1, 1, 3, 3, 2, 0, 3, 0, 2, 2, 1, 1, 1, 3, 0, 2, 1, 1, 2, 3, 2, 3, 2, 0, 2, 0, 2, 2, 0, 2, 3, 1, 1, 1, 0, 3, 1, 3, 3, 3, 0, 2, 1, 0, 1, 3, 1, 2, 1, 2, 2, 2, 1, 3, 0, 1, 0, 3, 2, 1, 1, 2, 1, 3, 1, 1, 1, 1, 2, 2, 1, 2, 3, 2, 0, 3, 2, 1, 0, 1, 0, 2, 0, 1, 1, 1, 1, 3, 1, 3, 0, 3, 2, 0, 0, 2, 3, 3, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -906. And steps were 186 and the episode is 181 and the total_steps are 18588\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 0, 1, 0, 0, 1, 1, 1, 3, 0, 0, 2, 3, 2, 3, 0, 2, 1, 3, 2, 3, 3, 3, 3, 2, 1, 2, 2, 3, 3, 0, 2, 3, 1, 1, 2, 3, 3, 3, 1, 0, 0, 0, 3, 0, 3, 1, 2, 1, 1, 0, 2, 0, 3, 1, 3, 2, 0, 0, 1, 0, 1, 1, 0, 1, 2, 1, 3, 2, 2, 2, 0, 2, 0, 0, 2, 3, 1, 3, 1, 2, 2, 0, 2, 0, 3, 0, 0, 0, 3, 3, 0, 1, 3, 2, 0, 1, 3, 2, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -902. And steps were 106 and the episode is 182 and the total_steps are 18694\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 2, 3, 1, 1, 3, 0, 3, 2, 1, 2, 1, 1, 1, 3, 2, 0, 2, 1, 1, 3, 1, 2, 0, 0, 3, 0, 1, 1, 0, 3, 0, 0, 0, 3, 1, 0, 0, 1, 3, 2, 1, 3, 3, 0, 2, 3, 3, 2, 2, 1, 2, 1, 1, 3, 0, 0, 3, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 1, 0, 3, 3, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 80 and the episode is 183 and the total_steps are 18774\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 2, 0, 1, 3, 1, 1, 2, 2, 3, 3, 1, 0, 1, 0, 1, 0, 1, 3, 3, 1, 2, 2, 0, 0, 1, 3, 2, 0, 2, 1, 0, 3, 3, 3, 1, 0, 1, 0, 0, 3, 1, 0, 2, 0, 0, 2, 2, 1, 1, 3, 0, 3, 1, 3, 1, 2, 3, 1, 0, 2, 3, 0, 3, 2, 3, 0, 0, 2, 2, 3, 1, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 0, 1, 1, 3, 3, 3, 0, 2, 2, 0, 0, 0, 3, 3, 0, 0, 0, 2, 3, 0, 3, 2, 0, 3, 1, 3, 3, 2, 1, 1, 3, 3, 1, 2, 2, 0, 1, 1, 0, 0, 1, 3, 2, 3, 1, 1, 2, 3, 3, 2, 2, 3, 0, 1, 2, 2, 0, 3, 3, 0, 1, 2, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 152 and the episode is 184 and the total_steps are 18926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -819     |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total_timesteps  | 18926    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 3, 1, 1, 1, 2, 2, 2, 1, 1, 1, 3, 0, 0, 1, 3, 2, 0, 1, 1, 2, 2, 1, 0, 0, 2, 3, 0, 3, 2, 3, 1, 3, 1, 1, 2, 0, 3, 3, 2, 0, 1, 3, 0, 3, 2, 2, 2, 1, 2, 0, 2, 1, 2, 1, 2, 3, 2, 3, 2, 3, 2, 1, 3, 2, 3, 1, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1072. And steps were 74 and the episode is 185 and the total_steps are 19000\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 1, 3, 2, 1, 3, 0, 3, 3, 0, 1, 1, 3, 0, 3, 2, 0, 1, 3, 0, 3, 3, 0, 1, 1, 2, 2, 0, 2, 2, 1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 2, 1, 1, 0, 0, 1, 1, 3, 1, 2, 1, 1, 0, 2, 0, 3, 2, 1, 0, 2, 0, 0, 0, 0, 3, 0, 3, 0, 0, 1, 0, 2, 0, 0, 1, 2, 1, 1, 3, 3, 0, 2, 2, 2, 2, 1, 0, 3, 0, 2, 1, 3, 2, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 100 and the episode is 186 and the total_steps are 19100\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 0, 2, 2, 0, 1, 1, 2, 3, 3, 1, 2, 0, 1, 0, 0, 2, 2, 1, 2, 3, 2, 1, 1, 1, 2, 3, 1, 1, 0, 0, 0, 3, 3, 0, 2, 3, 3, 2, 2, 3, 2, 3, 0, 1, 2, 3, 3, 3, 2, 1, 0, 0, 3, 1, 0, 2, 2, 1, 1, 3, 3, 1, 0, 1, 2, 1, 0, 2, 2, 0, 2, 2, 0, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 82 and the episode is 187 and the total_steps are 19182\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 2, 0, 1, 3, 3, 2, 0, 0, 1, 1, 3, 1, 2, 3, 3, 1, 0, 0, 2, 2, 2, 3, 0, 0, 1, 3, 2, 1, 3, 3, 0, 2, 2, 1, 2, 1, 0, 1, 1, 2, 1, 0, 3, 2, 1, 1, 3, 2, 3, 3, 1, 0, 2, 1, 2, 0, 2, 0, 0, 3, 1, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 69 and the episode is 188 and the total_steps are 19251\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -821     |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 19251    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 1, 3, 2, 2, 3, 1, 3, 0, 2, 0, 0, 1, 1, 2, 3, 2, 0, 1, 0, 1, 1, 2, 2, 2, 2, 0, 3, 3, 1, 3, 2, 3, 1, 0, 3, 3, 3, 2, 3, 0, 2, 0, 3, 2, 2, 2, 2, 1, 3, 2, 1, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 59 and the episode is 189 and the total_steps are 19310\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 1, 1, 2, 0, 3, 1, 2, 3, 2, 0, 1, 0, 0, 2, 0, 0, 1, 2, 2, 3, 0, 0, 1, 2, 2, 0, 1, 3, 2, 0, 2, 2, 2, 0, 1, 1, 3, 1, 3, 3, 2, 3, 2, 0, 1, 2, 3, 3, 0, 0, 3, 2, 3, 3, 1, 1, 0, 2, 1, 2, 0, 2, 1, 1, 3, 1, 2, 2, 1, 3, 1, 3, 2, 0, 3, 2, 1, 1, 2, 1, 2, 0, 1, 3, 2, 1, 2, 3, 0, 0, 3, 3, 0, 0, 1, 2, 3, 2, 3, 1, 2, 3, 1, 3, 3, 0, 3, 3, 0, 3, 2, 2, 1, 0, 1, 3, 2, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 2, 3, 2, 0, 0, 1, 2, 0, 1, 0, 1, 2, 1, 1, 2, 3, 3, 1, 2, 2, 1, 1, 1, 3, 3, 2, 0, 3, 1, 1, 0, 2, 0, 3, 0, 0, 2, 3, 0, 2, 3, 1, 0, 1, 0, 3, 1, 0, 1, 0, 1, 0, 2, 3, 2, 0, 2, 1, 2, 2, 1, 2, 0, 1, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 199 and the episode is 190 and the total_steps are 19509\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 1, 2, 3, 1, 3, 0, 0, 2, 3, 0, 0, 1, 1, 3, 1, 3, 3, 0, 0, 2, 2, 3, 3, 1, 0, 1, 0, 3, 1, 0, 2, 1, 2, 2, 2, 1, 1, 2, 3, 3, 2, 0, 3, 2, 1, 2, 3, 1, 3, 2, 0, 1, 2, 0, 1, 0, 2, 0, 0, 1, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 68 and the episode is 191 and the total_steps are 19577\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 2, 1, 0, 0, 1, 0, 1, 3, 0, 1, 1, 2, 2, 3, 2, 2, 3, 2, 0, 3, 0, 3, 3, 3, 2, 3, 2, 2, 2, 3, 0, 3, 0, 1, 0, 3, 1, 1, 1, 3, 3, 1, 2, 3, 3, 2, 2, 2, 1, 3, 1, 3, 2, 3, 2, 1, 2, 0, 0, 1, 1, 2, 3, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 71 and the episode is 192 and the total_steps are 19648\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -841     |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 19648    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 0, 3, 2, 3, 3, 2, 0, 1, 2, 2, 0, 3, 1, 1, 2, 0, 1, 2, 1, 3, 3, 3, 1, 0, 0, 2, 3, 1, 2, 0, 0, 2, 3, 1, 3, 2, 2, 1, 0, 0, 2, 0, 3, 0, 2, 1, 0, 0, 3, 0, 2, 0, 0, 3, 2, 0, 1, 2, 1, 3, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 3, 2, 1, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 81 and the episode is 193 and the total_steps are 19729\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 2, 1, 1, 2, 0, 3, 3, 1, 3, 1, 1, 0, 1, 2, 0, 0, 1, 0, 1, 0, 1, 3, 2, 1, 2, 1, 2, 1, 1, 1, 2, 0, 1, 2, 2, 2, 2, 0, 3, 3, 3, 0, 3, 2, 0, 3, 3, 0, 1, 0, 0, 0, 1, 2, 2, 0, 2, 2, 3, 2, 1, 2, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 70 and the episode is 194 and the total_steps are 19799\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 0, 1, 2, 1, 1, 2, 0, 2, 0, 0, 1, 2, 1, 3, 2, 2, 0, 3, 0, 0, 3, 2, 3, 2, 0, 3, 0, 2, 3, 0, 2, 0, 1, 0, 0, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 1, 0, 2, 1, 2, 0, 0, 0, 3, 3, 1, 2, 2, 0, 3, 2, 2, 1, 2, 3, 3, 2, 3, 2, 0, 0, 0, 3, 3, 2, 2, 2, 0, 2, 2, 2, 1, 0, 2, 2, 2, 0, 0, 2, 3, 2, 2, 1, 1, 2, 3, 3, 1, 1, 3, 1, 3, 3, 2, 3, 3, 1, 1, 1, 3, 0, 0, 2, 3, 0, 3, 3, 2, 3, 0, 0, 2, 2, 0, 2, 1, 1, 2, 0, 0, 2, 1, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -878. And steps were 140 and the episode is 195 and the total_steps are 19939\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 2, 2, 1, 2, 2, 0, 3, 1, 2, 0, 2, 0, 3, 3, 1, 0, 1, 0, 2, 3, 3, 3, 1, 2, 2, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 3, 3, 0, 0, 3, 2, 1, 1, 2, 2, 2, 3, 1, 1, 0, 3, 1, 3, 0, 0, 2, 2, 1, 3, 1, 1, 1, 0, 2, 2, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 73 and the episode is 196 and the total_steps are 20012\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -837     |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 20012    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 3, 1, 0, 2, 1, 1, 0, 3, 3, 1, 2, 0, 0, 1, 0, 2, 2, 1, 2, 3, 3, 2, 1, 3, 3, 1, 0, 0, 0, 0, 0, 1, 2, 1, 2, 3, 2, 3, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 1, 2, 3, 1, 1, 3, 1, 1, 0, 1, 0, 3, 3, 1, 3, 0, 0, 3, 0, 2, 2, 0, 0, 2, 3, 0, 1, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 83 and the episode is 197 and the total_steps are 20095\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 1, 1, 0, 3, 2, 1, 2, 2, 2, 0, 3, 0, 2, 0, 1, 0, 3, 3, 2, 0, 3, 2, 3, 3, 0, 3, 3, 2, 3, 0, 2, 2, 3, 3, 0, 0, 0, 1, 1, 0, 2, 0, 0, 3, 1, 2, 2, 0, 2, 1, 0, 2, 1, 3, 0, 2, 3, 3, 1, 1, 2, 3, 1, 0, 0, 2, 2, 2, 1, 3, 3, 3, 2, 3, 0, 3, 3, 0, 1, 2, 1, 3, 3, 2, 3, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -937. And steps were 93 and the episode is 198 and the total_steps are 20188\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 1, 0, 3, 3, 2, 3, 1, 3, 2, 0, 0, 1, 0, 3, 0, 0, 1, 3, 0, 0, 2, 2, 2, 1, 1, 3, 3, 1, 2, 3, 2, 0, 0, 2, 2, 1, 3, 3, 1, 3, 1, 1, 3, 0, 1, 2, 3, 2, 1, 3, 0, 3, 1, 3, 3, 0, 3, 2, 0, 3, 1, 0, 3, 1, 0, 2, 3, 3, 0, 3, 1, 1, 0, 1, 1, 2, 0, 2, 0, 3, 2, 1, 0, 0, 2, 0, 3, 3, 2, 2, 0, 1, 3, 2, 1, 0, 2, 0, 3, 1, 2, 1, 0, 2, 1, 1, 0, 2, 3, 0, 2, 3, 2, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -929. And steps were 121 and the episode is 199 and the total_steps are 20309\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 0, 2, 3, 0, 2, 2, 0, 2, 1, 2, 2, 0, 2, 3, 1, 0, 2, 2, 1, 3, 2, 2, 2, 1, 2, 0, 3, 0, 3, 3, 0, 3, 1, 2, 1, 3, 0, 1, 3, 3, 2, 0, 1, 2, 3, 0, 2, 1, 1, 0, 1, 0, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 60 and the episode is 200 and the total_steps are 20369\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 20369    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 2, 2, 2, 0, 1, 3, 2, 1, 0, 2, 2, 1, 1, 1, 0, 0, 3, 3, 1, 1, 1, 1, 3, 1, 3, 1, 2, 1, 3, 1, 0, 2, 3, 2, 3, 2, 0, 1, 3, 1, 2, 0, 0, 0, 2, 2, 3, 2, 0, 3, 1, 2, 1, 2, 1, 1, 0, 3, 1, 2, 1, 3, 1, 2, 0, 1, 3, 2, 2, 3, 2, 2, 3, 0, 2, 1, 0, 1, 3, 3, 2, 3, 1, 2, 1, 0, 3, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 95 and the episode is 201 and the total_steps are 20464\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 1, 2, 3, 1, 1, 0, 0, 3, 1, 2, 3, 3, 0, 2, 1, 2, 0, 2, 3, 0, 0, 3, 1, 2, 1, 1, 1, 1, 3, 3, 0, 1, 0, 0, 2, 1, 1, 3, 2, 0, 3, 0, 2, 0, 1, 2, 3, 0, 1, 1, 3, 0, 1, 1, 0, 2, 0, 3, 2, 0, 1, 0, 1, 0, 3, 3, 0, 2, 0, 1, 3, 2, 3, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1079. And steps were 81 and the episode is 202 and the total_steps are 20545\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 3, 2, 0, 2, 1, 2, 3, 3, 2, 0, 0, 0, 2, 1, 3, 3, 2, 3, 2, 1, 3, 3, 0, 2, 3, 2, 0, 1, 0, 0, 0, 1, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 1, 2, 1, 1, 3, 0, 1, 1, 3, 2, 2, 0, 0, 1, 1, 2, 1, 2, 3, 3, 2, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -941. And steps were 71 and the episode is 203 and the total_steps are 20616\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 3, 2, 0, 1, 2, 0, 3, 1, 1, 2, 3, 0, 2, 0, 3, 3, 0, 2, 1, 1, 3, 2, 2, 0, 1, 0, 3, 3, 0, 0, 0, 1, 3, 3, 0, 3, 3, 3, 2, 2, 2, 2, 0, 1, 1, 0, 0, 3, 1, 3, 1, 3, 0, 2, 0, 2, 1, 2, 2, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1065. And steps were 67 and the episode is 204 and the total_steps are 20683\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.6     |\n",
      "|    ep_rew_mean      | -859     |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 20683    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 2, 2, 2, 3, 2, 2, 0, 3, 1, 2, 2, 0, 2, 1, 0, 1, 3, 0, 2, 2, 2, 1, 1, 0, 1, 0, 3, 1, 0, 1, 3, 3, 1, 2, 0, 2, 1, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 0, 2, 3, 3, 1, 0, 1, 1, 0, 1, 0, 0, 3, 0, 3, 3, 3, 2, 1, 0, 2, 3, 1, 2, 3, 1, 1, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1081. And steps were 83 and the episode is 205 and the total_steps are 20766\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 3, 3, 0, 1, 3, 3, 1, 0, 3, 2, 1, 1, 0, 0, 0, 3, 0, 3, 2, 0, 0, 1, 1, 3, 3, 3, 3, 2, 0, 0, 0, 0, 3, 3, 0, 1, 2, 3, 0, 1, 3, 0, 3, 2, 3, 0, 3, 0, 1, 2, 3, 0, 0, 3, 3, 3, 3, 0, 2, 0, 1, 2, 2, 3, 2, 2, 1, 0, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 76 and the episode is 206 and the total_steps are 20842\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 3, 1, 1, 0, 0, 1, 3, 1, 3, 3, 2, 1, 2, 2, 3, 2, 2, 0, 1, 1, 1, 3, 3, 1, 2, 3, 3, 0, 0, 1, 1, 1, 3, 2, 3, 3, 0, 1, 3, 1, 2, 2, 0, 0, 1, 2, 2, 1, 1, 2, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 58 and the episode is 207 and the total_steps are 20900\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 2, 3, 3, 1, 1, 3, 3, 1, 1, 1, 0, 1, 0, 0, 0, 3, 0, 3, 1, 1, 0, 3, 2, 3, 1, 0, 1, 2, 2, 1, 0, 1, 3, 0, 0, 2, 2, 0, 1, 1, 1, 2, 0, 0, 1, 3, 1, 0, 3, 1, 1, 3, 3, 2, 2, 3, 2, 2, 0, 1, 3, 0, 1, 2, 0, 3, 3, 3, 2, 1, 2, 1, 1, 3, 3, 1, 2, 2, 0, 2, 3, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 89 and the episode is 208 and the total_steps are 20989\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -861     |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 20989    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 0, 0, 1, 2, 1, 1, 0, 0, 1, 3, 0, 0, 2, 1, 0, 0, 3, 3, 0, 3, 1, 1, 0, 1, 1, 3, 2, 0, 2, 2, 3, 0, 1, 1, 2, 0, 2, 3, 3, 3, 0, 3, 3, 2, 3, 0, 0, 3, 2, 1, 3, 1, 3, 3, 3, 0, 2, 2, 0, 3, 2, 3, 2, 1, 0, 2, 2, 1, 1, 0, 2, 3, 3, 2, 1, 3, 0, 0, 0, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 87 and the episode is 209 and the total_steps are 21076\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 1, 0, 1, 1, 0, 0, 3, 2, 0, 2, 1, 0, 2, 1, 3, 0, 2, 3, 2, 1, 3, 1, 2, 3, 2, 3, 2, 2, 3, 0, 1, 1, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 1, 1, 0, 3, 2, 1, 1, 2, 3, 2, 2, 3, 1, 2, 0, 1, 3, 3, 0, 2, 3, 3, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 72 and the episode is 210 and the total_steps are 21148\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 2, 1, 1, 1, 3, 2, 0, 2, 1, 0, 1, 1, 3, 1, 2, 3, 1, 1, 3, 2, 2, 1, 1, 3, 3, 3, 1, 1, 2, 2, 0, 2, 2, 1, 2, 2, 1, 3, 0, 3, 0, 0, 2, 2, 3, 3, 0, 3, 2, 1, 3, 1, 2, 0, 2, 3, 0, 1, 0, 0, 0, 1, 0, 0, 3, 3, 1, 3, 1, 3, 3, 3, 2, 0, 3, 2, 1, 1, 1, 0, 3, 2, 2, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 91 and the episode is 211 and the total_steps are 21239\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 2, 2, 3, 3, 3, 1, 0, 0, 1, 2, 2, 0, 0, 2, 1, 3, 0, 3, 2, 0, 1, 3, 2, 1, 2, 3, 1, 0, 1, 1, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 0, 3, 1, 3, 2, 3, 2, 0, 2, 3, 2, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1067. And steps were 69 and the episode is 212 and the total_steps are 21308\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.3     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 21308    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 1, 2, 2, 0, 3, 3, 1, 3, 1, 0, 0, 3, 0, 1, 0, 3, 0, 0, 0, 0, 3, 2, 1, 2, 2, 1, 2, 0, 3, 0, 2, 3, 3, 2, 1, 2, 3, 1, 3, 0, 1, 1, 2, 0, 1, 0, 2, 1, 3, 3, 0, 1, 2, 0, 0, 0, 1, 1, 3, 0, 2, 0, 3, 0, 0, 0, 0, 0, 1, 3, 3, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 79 and the episode is 213 and the total_steps are 21387\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 1, 2, 3, 0, 3, 2, 2, 3, 2, 0, 0, 0, 0, 2, 0, 0, 3, 1, 1, 3, 3, 2, 2, 2, 1, 2, 3, 0, 2, 1, 2, 3, 3, 0, 2, 0, 2, 1, 0, 1, 2, 2, 1, 2, 3, 1, 1, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 55 and the episode is 214 and the total_steps are 21442\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 3, 0, 0, 2, 2, 3, 2, 3, 0, 0, 1, 2, 0, 3, 3, 0, 1, 1, 2, 1, 3, 2, 2, 3, 0, 0, 3, 0, 0, 1, 0, 3, 0, 2, 2, 1, 2, 1, 2, 3, 0, 2, 3, 3, 0, 3, 2, 2, 2, 0, 3, 0, 1, 0, 1, 1, 1, 2, 3, 3, 3, 0, 3, 1, 2, 3, 1, 2, 1, 3, 1, 2, 3, 2, 1, 0, 1, 1, 3, 1, 0, 3, 2, 1, 0, 3, 0, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1093. And steps were 95 and the episode is 215 and the total_steps are 21537\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 1, 1, 0, 3, 1, 0, 1, 0, 3, 2, 2, 3, 0, 3, 0, 1, 0, 1, 1, 1, 2, 2, 1, 0, 2, 2, 0, 3, 0, 3, 3, 0, 1, 2, 0, 3, 2, 0, 0, 0, 3, 1, 3, 0, 3, 0, 3, 0, 3, 0, 0, 1, 2, 3, 3, 1, 0, 3, 3, 2, 0, 0, 3, 3, 2, 2, 0, 0, 2, 2, 0, 2, 1, 2, 1, 3, 1, 1, 1, 2, 2, 2, 3, 2, 2, 3, 3, 1, 0, 3, 3, 0, 0, 3, 2, 0, 1, 3, 1, 2, 3, 1, 0, 2, 0, 1, 2, 0, 0, 3, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -894. And steps were 118 and the episode is 216 and the total_steps are 21655\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.9     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 21655    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 0, 1, 0, 2, 0, 2, 2, 0, 0, 3, 3, 0, 0, 2, 1, 3, 2, 1, 3, 3, 0, 3, 2, 0, 2, 3, 1, 1, 0, 2, 3, 2, 3, 1, 2, 0, 1, 0, 2, 3, 1, 2, 0, 1, 0, 1, 2, 3, 1, 3, 2, 3, 0, 0, 3, 0, 3, 1, 2, 0, 2, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 69 and the episode is 217 and the total_steps are 21724\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 1, 2, 2, 1, 3, 2, 0, 1, 3, 3, 3, 1, 3, 2, 3, 2, 1, 2, 2, 2, 1, 1, 2, 2, 0, 3, 2, 1, 3, 1, 2, 3, 1, 2, 0, 0, 0, 3, 3, 1, 2, 1, 3, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 0, 2, 2, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 64 and the episode is 218 and the total_steps are 21788\n",
      "Done condition: max time steps reached\n",
      "[2, 2, 1, 3, 3, 3, 1, 0, 0, 1, 1, 2, 1, 1, 3, 2, 3, 0, 1, 0, 1, 1, 2, 2, 0, 0, 0, 1, 3, 3, 2, 3, 2, 3, 3, 3, 2, 1, 1, 0, 3, 1, 0, 0, 0, 1, 3, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 2, 3, 0, 3, 0, 0, 2, 3, 0, 3, 1, 1, 3, 2, 2, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 1, 3, 3, 3, 0, 0, 2, 2, 1, 2, 1, 0, 3, 2, 3, 1, 2, 3, 3, 3, 2, 1, 1, 3, 1, 3, 3, 0, 0, 3, 1, 3, 1, 2, 3, 1, 0, 3, 0, 2, 3, 3, 2, 2, 2, 1, 1, 1, 0, 3, 1, 0, 1, 3, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 0, 0, 3, 2, 0, 3, 2, 1, 3, 0, 2, 1, 1, 2, 3, 0, 1, 1, 3, 2, 0, 3, 0, 0, 3, 3, 3, 1, 2, 3, 3, 0, 2, 1, 0, 1, 2, 3, 3, 2, 3, 2, 1, 1, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1399. And steps were 202 and the episode is 219 and the total_steps are 21990\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 2, 2, 1, 2, 0, 3, 2, 1, 1, 2, 0, 1, 2, 0, 3, 3, 0, 2, 3, 2, 0, 2, 2, 2, 0, 3, 2, 1, 3, 2, 2, 3, 2, 3, 0, 1, 1, 2, 3, 1, 1, 2, 3, 0, 0, 1, 2, 1, 2, 3, 2, 2, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 60 and the episode is 220 and the total_steps are 22050\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.1     |\n",
      "|    ep_rew_mean      | -903     |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 22050    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 0, 0, 0, 2, 3, 2, 2, 2, 3, 2, 3, 3, 3, 3, 0, 3, 2, 2, 0, 2, 0, 3, 3, 3, 3, 3, 1, 0, 3, 1, 0, 2, 1, 0, 1, 2, 1, 3, 0, 2, 0, 2, 1, 3, 0, 2, 0, 2, 0, 2, 2, 0, 2, 1, 2, 3, 3, 2, 0, 3, 0, 3, 0, 2, 1, 0, 1, 0, 1, 2, 3, 0, 2, 1, 1, 0, 2, 2, 3, 0, 3, 1, 0, 0, 1, 2, 3, 3, 1, 3, 3, 0, 1, 1, 0, 0, 1, 2, 3, 3, 2, 1, 1, 1, 3, 1, 1, 2, 1, 0, 3, 3, 3, 2, 1, 3, 3, 1, 2, 1, 3, 0, 0, 3, 3, 0, 0, 1, 3, 1, 3, 3, 0, 3, 0, 0, 0, 0, 0, 3, 2, 3, 0, 1, 1, 0, 3, 1, 0, 1, 1, 2, 1, 0, 3, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -887. And steps were 163 and the episode is 221 and the total_steps are 22213\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 2, 1, 0, 1, 3, 0, 3, 0, 0, 3, 1, 0, 3, 0, 3, 0, 2, 1, 3, 3, 1, 2, 3, 2, 1, 2, 0, 2, 3, 2, 2, 2, 1, 2, 3, 3, 3, 2, 0, 1, 3, 1, 3, 0, 3, 2, 2, 0, 0, 0, 3, 0, 3, 3, 2, 2, 2, 0, 2, 2, 1, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1067. And steps were 69 and the episode is 222 and the total_steps are 22282\n",
      "Done condition: collision\n",
      "[1, 1, 3, 0, 0, 3, 3, 2, 1, 2, 3, 3, 3, 0, 3, 1, 1, 3, 3, 1, 0, 0, 1, 0, 3, 2, 2, 2, 1, 3, 3, 1, 0, 1, 2, 3, 0, 2, 1, 2, 3, 0, 0, 1, 2, 3, 0, 3, 3, 2, 0, 0, 1, 2, 2, 3, 2, 3, 1, 3, 3, 3, 1, 3, 1, 2, 1, 2, 2, 0, 3, 1, 3, 1, 2, 1, 0, 3, 0, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 83 and the episode is 223 and the total_steps are 22365\n",
      "Skiping this step\n",
      "Done condition: max time steps reached\n",
      "[0, 3, 1, 3, 3, 0, 1, 1, 1, 1, 0, 3, 1, 3, 3, 0, 3, 1, 0, 0, 0, 2, 1, 0, 1, 1, 0, 3, 0, 0, 0, 3, 0, 3, 2, 1, 1, 2, 1, 3, 1, 0, 3, 2, 2, 3, 1, 3, 2, 0, 1, 0, 1, 1, 3, 3, 0, 1, 0, 1, 1, 0, 0, 2, 0, 3, 0, 3, 0, 0, 3, 2, 2, 2, 2, 0, 1, 3, 3, 2, 1, 0, 3, 2, 0, 2, 1, 3, 3, 1, 3, 3, 2, 2, 3, 3, 2, 2, 0, 2, 2, 2, 3, 1, 1, 2, 2, 2, 2, 3, 2, 0, 0, 3, 1, 2, 2, 3, 0, 1, 0, 2, 3, 1, 3, 3, 1, 1, 2, 0, 1, 1, 3, 2, 0, 2, 3, 0, 1, 0, 0, 0, 2, 3, 2, 2, 1, 1, 3, 2, 3, 3, 3, 1, 0, 3, 0, 2, 2, 3, 0, 2, 0, 0, 1, 1, 0, 0, 3, 1, 1, 0, 0, 0, 2, 2, 1, 3, 1, 1, 1, 1, 3, 2, 3, 1, 2, 1, 0, 2, 3, 3, 0, 1, 0, 0, 1, 0, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1399. And steps were 202 and the episode is 224 and the total_steps are 22567\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.3     |\n",
      "|    ep_rew_mean      | -929     |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 370      |\n",
      "|    total_timesteps  | 22567    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 0, 1, 1, 1, 2, 1, 1, 1, 3, 3, 3, 2, 2, 1, 1, 3, 0, 1, 1, 3, 0, 1, 0, 1, 0, 1, 3, 3, 0, 1, 1, 3, 2, 0, 0, 0, 0, 2, 0, 3, 2, 3, 2, 3, 1, 0, 3, 0, 0, 1, 0, 0, 2, 1, 2, 3, 3, 3, 2, 1, 3, 2, 1, 0, 2, 1, 3, 1, 3, 2, 0, 1, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 80 and the episode is 225 and the total_steps are 22647\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 2, 0, 3, 2, 1, 0, 3, 1, 1, 3, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 3, 3, 2, 2, 2, 0, 3, 3, 1, 0, 1, 1, 2, 2, 0, 2, 3, 2, 3, 3, 2, 0, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 50 and the episode is 226 and the total_steps are 22697\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 0, 1, 3, 3, 3, 2, 2, 1, 2, 0, 1, 3, 2, 3, 0, 3, 0, 1, 2, 0, 1, 3, 1, 2, 2, 0, 0, 0, 1, 1, 3, 2, 0, 0, 0, 1, 3, 2, 2, 0, 3, 2, 1, 2, 3, 2, 2, 2, 0, 1, 0, 2, 2, 2, 3, 2, 0, 3, 2, 0, 2, 2, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 70 and the episode is 227 and the total_steps are 22767\n",
      "Done condition: max time steps reached\n",
      "[0, 2, 1, 1, 2, 2, 2, 1, 0, 2, 2, 0, 1, 1, 3, 0, 1, 1, 1, 3, 3, 2, 3, 2, 2, 1, 2, 0, 0, 0, 3, 2, 3, 2, 1, 1, 1, 2, 0, 0, 2, 0, 2, 1, 1, 2, 2, 0, 0, 2, 1, 3, 0, 0, 3, 0, 0, 2, 2, 1, 3, 3, 1, 1, 2, 2, 0, 1, 1, 1, 0, 0, 0, 1, 0, 2, 0, 1, 0, 2, 2, 0, 1, 2, 0, 1, 1, 2, 0, 3, 3, 0, 2, 3, 0, 1, 3, 1, 1, 2, 2, 0, 0, 2, 2, 2, 0, 0, 1, 2, 3, 3, 0, 1, 0, 2, 0, 3, 3, 2, 2, 0, 0, 1, 1, 2, 0, 3, 3, 2, 0, 2, 3, 0, 3, 2, 1, 3, 1, 1, 1, 0, 2, 3, 3, 3, 2, 0, 0, 2, 3, 2, 2, 0, 3, 1, 1, 1, 3, 3, 3, 3, 2, 2, 0, 3, 3, 3, 2, 3, 0, 3, 0, 1, 3, 0, 1, 2, 1, 1, 1, 2, 0, 1, 3, 0, 1, 0, 3, 0, 1, 0, 0, 2, 1, 0, 1, 0, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 202 and the episode is 228 and the total_steps are 22969\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -929     |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 376      |\n",
      "|    total_timesteps  | 22969    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 1, 1, 1, 0, 1, 2, 3, 3, 3, 2, 3, 0, 3, 3, 2, 3, 1, 2, 2, 2, 1, 3, 2, 2, 3, 0, 0, 3, 1, 2, 3, 2, 1, 3, 0, 2, 2, 1, 2, 2, 0, 0, 1, 0, 2, 3, 3, 1, 0, 2, 1, 1, 2, 1, 3, 3, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1062. And steps were 64 and the episode is 229 and the total_steps are 23033\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 0, 1, 3, 3, 3, 3, 3, 2, 2, 2, 0, 1, 2, 2, 1, 2, 3, 0, 3, 3, 0, 1, 1, 0, 3, 3, 1, 0, 0, 2, 0, 2, 2, 2, 1, 1, 2, 2, 3, 3, 1, 2, 1, 0, 3, 1, 0, 0, 1, 3, 2, 1, 1, 2, 3, 1, 1, 0, 2, 2, 3, 0, 3, 0, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 72 and the episode is 230 and the total_steps are 23105\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 2, 2, 2, 3, 2, 3, 1, 2, 2, 3, 3, 1, 0, 1, 2, 1, 3, 1, 1, 1, 1, 0, 0, 0, 3, 1, 3, 3, 0, 3, 3, 1, 2, 1, 1, 0, 2, 3, 3, 3, 0, 2, 0, 1, 3, 3, 3, 2, 0, 0, 0, 0, 2, 2, 2, 1, 2, 1, 3, 0, 2, 1, 1, 3, 2, 2, 1, 1, 1, 2, 3, 3, 1, 3, 1, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 83 and the episode is 231 and the total_steps are 23188\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 3, 0, 0, 3, 1, 3, 1, 2, 2, 0, 3, 2, 3, 3, 3, 3, 2, 1, 3, 1, 0, 1, 0, 1, 0, 0, 3, 0, 0, 0, 3, 2, 2, 2, 1, 0, 0, 0, 1, 3, 2, 0, 0, 1, 2, 3, 2, 1, 0, 3, 0, 0, 1, 1, 2, 0, 0, 0, 1, 0, 1, 1, 2, 0, 2, 0, 2, 3, 1, 1, 3, 2, 2, 3, 0, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 83 and the episode is 232 and the total_steps are 23271\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.6     |\n",
      "|    ep_rew_mean      | -930     |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 381      |\n",
      "|    total_timesteps  | 23271    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 1, 2, 1, 3, 0, 0, 0, 1, 0, 2, 3, 1, 2, 1, 3, 3, 1, 0, 3, 3, 3, 3, 2, 2, 1, 2, 1, 2, 0, 3, 3, 3, 2, 1, 0, 0, 0, 3, 3, 3, 0, 3, 1, 2, 3, 1, 2, 0, 1, 2, 1, 0, 2, 1, 3, 1, 1, 1, 0, 1, 3, 3, 1, 1, 2, 3, 0, 2, 1, 3, 1, 2, 0, 0, 2, 3, 3, 3, 0, 0, 1, 0, 1, 0, 1, 3, 2, 3, 1, 0, 2, 0, 3, 1, 3, 0, 0, 0, 3, 3, 1, 3, 1, 2, 0, 0, 3, 3, 2, 1, 3, 3, 0, 2, 0, 1, 1, 3, 3, 2, 1, 3, 2, 0, 3, 2, 2, 0, 3, 1, 2, 3, 0, 0, 0, 2, 1, 0, 3, 2, 2, 1, 3, 2, 1, 3, 3, 2, 0, 3, 0, 1, 2, 0, 0, 2, 3, 2, 0, 3, 1, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -919. And steps were 169 and the episode is 233 and the total_steps are 23440\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 3, 3, 0, 2, 0, 2, 3, 0, 2, 0, 3, 3, 0, 2, 3, 2, 2, 3, 1, 0, 1, 1, 1, 3, 3, 3, 3, 0, 3, 3, 2, 1, 0, 2, 1, 2, 1, 3, 1, 0, 3, 1, 2, 1, 1, 2, 3, 1, 2, 0, 2, 0, 1, 2, 0, 3, 2, 3, 2, 3, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 68 and the episode is 234 and the total_steps are 23508\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 2, 1, 3, 1, 2, 2, 1, 2, 2, 1, 3, 0, 1, 2, 3, 2, 2, 3, 1, 0, 2, 0, 0, 2, 1, 0, 3, 1, 2, 1, 0, 0, 2, 3, 0, 3, 1, 0, 1, 3, 2, 1, 1, 0, 1, 1, 1, 1, 3, 2, 3, 1, 3, 0, 0, 2, 1, 3, 2, 3, 3, 2, 1, 1, 1, 0, 3, 3, 0, 2, 3, 2, 0, 3, 0, 2, 2, 3, 3, 2, 1, 2, 0, 3, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -916. And steps were 92 and the episode is 235 and the total_steps are 23600\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 3, 1, 2, 3, 3, 2, 2, 3, 0, 2, 1, 2, 0, 3, 1, 1, 0, 2, 1, 1, 3, 2, 2, 2, 2, 3, 0, 2, 1, 3, 3, 1, 0, 3, 0, 0, 2, 1, 2, 2, 3, 2, 3, 0, 1, 0, 2, 3, 3, 3, 0, 0, 1, 2, 3, 3, 0, 3, 0, 0, 0, 2, 0, 1, 1, 0, 3, 2, 2, 0, 3, 2, 0, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 81 and the episode is 236 and the total_steps are 23681\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.1     |\n",
      "|    ep_rew_mean      | -930     |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 388      |\n",
      "|    total_timesteps  | 23681    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 2, 3, 1, 3, 2, 1, 2, 3, 0, 2, 2, 0, 2, 3, 1, 0, 1, 0, 2, 2, 1, 3, 2, 3, 3, 2, 2, 2, 3, 0, 2, 1, 0, 0, 1, 0, 1, 2, 3, 2, 3, 3, 0, 2, 3, 0, 2, 3, 3, 3, 3, 0, 2, 3, 1, 0, 1, 2, 0, 0, 3, 2, 2, 2, 3, 2, 3, 3, 2, 1, 2, 3, 2, 2, 3, 2, 3, 2, 1, 0, 1, 0, 0, 2, 3, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -931. And steps were 93 and the episode is 237 and the total_steps are 23774\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 0, 2, 3, 0, 2, 0, 3, 0, 1, 1, 2, 3, 0, 2, 0, 0, 2, 3, 3, 0, 0, 2, 1, 0, 1, 3, 1, 2, 1, 1, 0, 3, 1, 2, 3, 2, 2, 0, 0, 1, 3, 3, 0, 2, 3, 0, 0, 2, 1, 2, 1, 2, 1, 1, 2, 3, 2, 2, 1, 3, 3, 0, 0, 3, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 3, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1081. And steps were 83 and the episode is 238 and the total_steps are 23857\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 2, 3, 2, 0, 0, 0, 3, 1, 2, 1, 3, 0, 2, 0, 2, 0, 3, 3, 1, 2, 3, 0, 3, 2, 0, 2, 0, 1, 1, 3, 2, 3, 0, 2, 3, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 1, 1, 3, 1, 1, 2, 1, 0, 0, 0, 1, 0, 3, 3, 0, 1, 2, 3, 1, 3, 0, 3, 1, 0, 2, 1, 0, 1, 0, 2, 2, 1, 3, 2, 0, 3, 1, 3, 1, 3, 0, 0, 1, 0, 3, 1, 2, 0, 3, 3, 1, 2, 1, 3, 0, 0, 0, 0, 1, 0, 2, 2, 1, 3, 1, 3, 3, 3, 0, 3, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -927. And steps were 123 and the episode is 239 and the total_steps are 23980\n",
      "Done condition: collision\n",
      "[1, 1, 3, 0, 0, 2, 0, 0, 2, 2, 3, 3, 1, 3, 2, 1, 3, 0, 2, 2, 0, 0, 3, 0, 2, 2, 1, 0, 3, 0, 3, 2, 3, 3, 3, 2, 0, 3, 3, 2, 1, 0, 2, 0, 2, 3, 1, 1, 0, 3, 2, 1, 1, 0, 2, 0, 3, 0, 0, 0, 2, 0, 3, 1, 3, 1, 2, 1, 1, 0, 2, 0, 2, 3, 2, 3, 1, 3, 2, 1, 0, 2, 3, 3, 3, 3, 2, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1089. And steps were 91 and the episode is 240 and the total_steps are 24071\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -929     |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 395      |\n",
      "|    total_timesteps  | 24071    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 0, 3, 3, 3, 3, 2, 3, 3, 0, 1, 2, 2, 2, 2, 2, 3, 2, 3, 3, 1, 0, 1, 2, 0, 1, 2, 1, 1, 0, 2, 3, 0, 0, 3, 0, 0, 0, 0, 1, 2, 0, 2, 1, 1, 2, 0, 0, 3, 2, 3, 1, 0, 2, 1, 2, 3, 3, 1, 2, 0, 2, 0, 0, 3, 0, 1, 3, 3, 3, 0, 3, 0, 0, 1, 0, 0, 0, 0, 3, 1, 2, 0, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 90 and the episode is 241 and the total_steps are 24161\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 1, 3, 1, 2, 3, 3, 0, 3, 2, 1, 3, 0, 1, 2, 2, 3, 0, 0, 3, 1, 3, 2, 2, 1, 3, 2, 2, 2, 2, 3, 1, 1, 3, 2, 0, 1, 1, 0, 3, 1, 2, 1, 0, 0, 2, 2, 0, 2, 1, 2, 1, 3, 0, 3, 0, 2, 1, 3, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1064. And steps were 66 and the episode is 242 and the total_steps are 24227\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 3, 1, 0, 2, 3, 2, 3, 2, 0, 1, 3, 1, 3, 3, 1, 1, 3, 3, 1, 2, 3, 3, 1, 2, 2, 2, 0, 3, 2, 2, 1, 2, 1, 3, 0, 0, 1, 2, 1, 3, 0, 3, 2, 0, 3, 1, 2, 0, 1, 1, 1, 3, 0, 3, 3, 1, 1, 3, 1, 2, 1, 0, 1, 0, 0, 2, 0, 0, 1, 1, 0, 1, 1, 2, 0, 3, 3, 3, 0, 3, 3, 0, 0, 3, 2, 0, 2, 0, 2, 1, 1, 3, 2, 3, 3, 1, 2, 3, 1, 0, 3, 3, 3, 2, 0, 2, 3, 2, 0, 0, 1, 2, 2, 2, 0, 3, 0, 1, 3, 1, 2, 3, 3, 0, 1, 2, 0, 0, 3, 2, 3, 0, 2, 2, 3, 0, 1, 0, 2, 2, 3, 2, 0, 3, 0, 2, 3, 1, 2, 0, 2, 1, 3, 3, 2, 0, 0, 2, 0, 0, 2, 2, 3, 2, 3, 0, 3, 0, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -867. And steps were 177 and the episode is 243 and the total_steps are 24404\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 3, 1, 2, 2, 3, 1, 3, 2, 2, 2, 0, 1, 3, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1, 2, 0, 3, 3, 0, 1, 0, 1, 3, 0, 3, 2, 1, 0, 2, 1, 3, 2, 3, 1, 1, 3, 0, 2, 2, 1, 1, 0, 2, 3, 0, 1, 3, 1, 0, 2, 3, 2, 1, 2, 1, 1, 1, 3, 1, 3, 1, 2, 2, 0, 0, 1, 3, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 1, 0, 0, 1, 0, 1, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 102 and the episode is 244 and the total_steps are 24506\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.1     |\n",
      "|    ep_rew_mean      | -927     |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 401      |\n",
      "|    total_timesteps  | 24506    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: max time steps reached\n",
      "[3, 1, 0, 3, 2, 1, 1, 1, 2, 3, 2, 2, 3, 1, 0, 2, 2, 3, 2, 2, 1, 2, 0, 3, 1, 1, 2, 1, 2, 1, 0, 0, 1, 1, 3, 1, 2, 2, 3, 1, 1, 2, 0, 3, 2, 1, 1, 1, 1, 0, 2, 0, 0, 3, 2, 1, 2, 0, 2, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 1, 1, 2, 3, 1, 1, 3, 0, 1, 2, 1, 0, 0, 3, 1, 1, 3, 3, 3, 0, 0, 3, 1, 3, 2, 3, 1, 0, 3, 3, 2, 1, 0, 2, 0, 1, 0, 0, 3, 0, 1, 0, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 1, 0, 3, 2, 3, 1, 0, 3, 0, 2, 3, 3, 0, 0, 3, 3, 0, 0, 0, 2, 3, 1, 1, 3, 2, 3, 3, 3, 3, 1, 0, 3, 1, 3, 2, 2, 2, 3, 0, 1, 3, 2, 0, 0, 2, 2, 0, 0, 2, 3, 0, 2, 3, 0, 3, 2, 0, 2, 2, 0, 1, 3, 3, 3, 2, 0, 2, 2, 3, 3, 3, 2, 0, 3, 3, 2, 2, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1077. And steps were 202 and the episode is 245 and the total_steps are 24708\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 0, 0, 2, 2, 3, 2, 3, 0, 0, 1, 1, 0, 1, 3, 3, 0, 1, 0, 2, 3, 2, 0, 2, 0, 0, 0, 2, 3, 1, 2, 1, 0, 2, 2, 0, 2, 3, 0, 1, 1, 2, 2, 0, 0, 0, 0, 3, 2, 2, 1, 3, 1, 1, 0, 3, 1, 1, 3, 3, 0, 2, 1, 3, 2, 0, 3, 3, 3, 2, 2, 3, 2, 1, 1, 0, 3, 1, 2, 2, 2, 2, 0, 2, 1, 2, 0, 0, 1, 3, 0, 1, 1, 1, 3, 0, 2, 3, 2, 0, 1, 2, 2, 1, 0, 3, 1, 0, 3, 3, 1, 1, 1, 1, 2, 2, 3, 0, 0, 0, 1, 2, 1, 0, 2, 1, 3, 2, 2, 0, 1, 2, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 139 and the episode is 246 and the total_steps are 24847\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 0, 1, 0, 3, 0, 0, 0, 1, 1, 0, 2, 2, 2, 0, 1, 2, 3, 3, 1, 2, 3, 2, 3, 3, 2, 0, 0, 0, 0, 0, 2, 3, 2, 3, 1, 1, 1, 1, 3, 0, 0, 1, 1, 1, 1, 2, 3, 0, 3, 1, 2, 0, 1, 0, 0, 1, 1, 1, 0, 1, 2, 1, 0, 2, 3, 0, 3, 3, 3, 0, 1, 1, 1, 2, 1, 1, 2, 3, 0, 1, 0, 3, 0, 2, 3, 1, 0, 2, 0, 3, 0, 2, 0, 3, 1, 0, 1, 0, 1, 1, 3, 0, 0, 2, 3, 0, 3, 2, 2, 1, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1079. And steps were 127 and the episode is 247 and the total_steps are 24974\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 2, 2, 2, 2, 2, 0, 2, 2, 1, 3, 0, 0, 0, 3, 0, 3, 1, 2, 1, 0, 1, 3, 0, 1, 2, 3, 3, 2, 1, 0, 3, 3, 2, 2, 3, 3, 0, 1, 3, 1, 3, 0, 1, 1, 1, 1, 1, 3, 0, 1, 2, 1, 0, 2, 1, 0, 2, 3, 1, 0, 2, 0, 2, 2, 2, 1, 1, 1, 2, 0, 3, 1, 1, 2, 3, 0, 0, 1, 2, 3, 2, 3, 0, 3, 3, 2, 2, 2, 0, 3, 1, 1, 3, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1099. And steps were 101 and the episode is 248 and the total_steps are 25075\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -929     |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 410      |\n",
      "|    total_timesteps  | 25075    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 1, 0, 0, 0, 1, 3, 2, 3, 2, 0, 0, 0, 0, 2, 2, 2, 2, 3, 0, 0, 2, 1, 2, 0, 3, 1, 1, 0, 1, 1, 2, 3, 1, 1, 2, 2, 0, 0, 0, 2, 3, 2, 2, 2, 2, 3, 2, 2, 0, 3, 1, 2, 3, 3, 0, 0, 1, 0, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 66 and the episode is 249 and the total_steps are 25141\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 0, 0, 1, 0, 2, 2, 2, 2, 3, 0, 1, 0, 2, 0, 2, 3, 2, 0, 0, 3, 3, 2, 2, 3, 1, 0, 0, 0, 1, 3, 2, 0, 0, 3, 3, 3, 3, 3, 2, 3, 3, 0, 3, 3, 2, 1, 1, 0, 3, 2, 2, 1, 0, 1, 1, 3, 3, 0, 2, 1, 3, 1, 3, 3, 0, 1, 3, 3, 1, 3, 3, 0, 0, 0, 2, 3, 2, 1, 3, 2, 3, 3, 1, 3, 2, 0, 1, 1, 0, 3, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1049. And steps were 97 and the episode is 250 and the total_steps are 25238\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 0, 0, 1, 0, 0, 1, 2, 0, 3, 3, 0, 1, 0, 1, 1, 1, 3, 3, 3, 2, 0, 3, 2, 2, 0, 3, 1, 1, 3, 3, 2, 3, 1, 3, 2, 2, 3, 1, 2, 0, 1, 3, 1, 3, 1, 0, 0, 3, 3, 2, 2, 0, 3, 0, 2, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1061. And steps were 63 and the episode is 251 and the total_steps are 25301\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 1, 3, 3, 2, 2, 1, 0, 0, 2, 0, 3, 3, 0, 3, 2, 0, 1, 2, 3, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 2, 0, 2, 2, 1, 0, 1, 2, 0, 0, 1, 2, 3, 3, 0, 3, 0, 0, 3, 2, 1, 3, 2, 0, 3, 1, 1, 3, 2, 0, 3, 2, 3, 1, 3, 0, 1, 3, 2, 0, 2, 2, 1, 0, 0, 1, 3, 0, 3, 2, 1, 0, 3, 2, 3, 0, 2, 0, 1, 3, 3, 1, 0, 0, 3, 1, 1, 2, 1, 0, 2, 0, 3, 1, 1, 1, 3, 2, 2, 3, 3, 1, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 2, 2, 1, 0, 3, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -920. And steps were 140 and the episode is 252 and the total_steps are 25441\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.1     |\n",
      "|    ep_rew_mean      | -932     |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 416      |\n",
      "|    total_timesteps  | 25441    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 0, 2, 1, 0, 2, 2, 1, 0, 0, 3, 3, 0, 0, 2, 2, 2, 0, 0, 2, 3, 0, 1, 3, 0, 2, 2, 2, 1, 3, 3, 0, 3, 0, 0, 1, 2, 0, 0, 0, 3, 1, 0, 0, 0, 3, 3, 1, 3, 1, 3, 1, 3, 3, 1, 3, 1, 2, 2, 2, 0, 3, 0, 2, 2, 0, 2, 3, 1, 0, 0, 1, 2, 2, 0, 2, 3, 2, 1, 3, 2, 2, 3, 3, 2, 2, 0, 1, 2, 1, 0, 2, 1, 3, 1, 1, 1, 0, 2, 2, 3, 2, 1, 2, 2, 2, 2, 0, 1, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 116 and the episode is 253 and the total_steps are 25557\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 2, 2, 1, 3, 2, 1, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 1, 0, 0, 0, 2, 0, 3, 1, 1, 0, 0, 2, 2, 3, 3, 0, 0, 2, 3, 2, 2, 0, 3, 0, 1, 3, 0, 1, 3, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 59 and the episode is 254 and the total_steps are 25616\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 2, 1, 2, 2, 0, 3, 1, 2, 2, 1, 0, 0, 0, 2, 2, 1, 3, 1, 0, 2, 2, 1, 3, 0, 3, 0, 1, 3, 1, 2, 1, 0, 0, 2, 1, 3, 1, 1, 0, 3, 2, 3, 1, 3, 3, 0, 2, 3, 0, 0, 0, 1, 3, 2, 3, 2, 2, 3, 1, 2, 2, 3, 0, 3, 3, 1, 2, 1, 1, 2, 2, 3, 0, 0, 1, 0, 1, 0, 3, 3, 1, 1, 3, 1, 3, 2, 2, 2, 2, 1, 3, 3, 1, 0, 1, 2, 2, 0, 3, 1, 1, 1, 3, 0, 3, 2, 0, 1, 0, 2, 0, 0, 1, 1, 2, 3, 2, 1, 3, 0, 2, 1, 2, 3, 0, 3, 0, 3, 2, 3, 3, 0, 3, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -889. And steps were 141 and the episode is 255 and the total_steps are 25757\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 1, 3, 2, 2, 2, 0, 0, 0, 3, 2, 3, 1, 1, 3, 0, 0, 3, 0, 0, 3, 3, 1, 2, 2, 2, 3, 0, 3, 3, 0, 0, 3, 2, 3, 3, 3, 1, 2, 3, 3, 1, 0, 2, 2, 0, 0, 2, 2, 3, 0, 3, 2, 2, 1, 1, 2, 3, 2, 0, 1, 0, 2, 3, 2, 2, 2, 2, 2, 3, 0, 2, 2, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 80 and the episode is 256 and the total_steps are 25837\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -950     |\n",
      "|    exploration_rate | 0.975    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 423      |\n",
      "|    total_timesteps  | 25837    |\n",
      "----------------------------------\n",
      "Done condition: max time steps reached\n",
      "[0, 1, 2, 0, 0, 0, 2, 2, 2, 0, 0, 3, 2, 2, 1, 1, 1, 1, 1, 0, 3, 2, 3, 2, 2, 0, 1, 2, 0, 1, 1, 1, 0, 3, 3, 0, 0, 1, 3, 2, 3, 1, 0, 2, 0, 3, 1, 0, 3, 3, 1, 0, 0, 2, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 3, 3, 0, 0, 2, 3, 0, 1, 1, 3, 1, 0, 1, 1, 3, 2, 3, 3, 1, 0, 2, 3, 1, 2, 3, 3, 3, 1, 3, 2, 1, 3, 0, 1, 0, 0, 1, 3, 0, 3, 1, 3, 3, 2, 2, 2, 3, 1, 2, 1, 3, 3, 3, 2, 0, 0, 1, 1, 0, 1, 2, 1, 2, 1, 0, 1, 2, 0, 3, 2, 1, 3, 2, 2, 1, 3, 0, 0, 3, 1, 2, 1, 2, 2, 1, 3, 1, 3, 2, 1, 1, 2, 0, 3, 0, 0, 3, 1, 2, 1, 3, 1, 3, 1, 3, 2, 0, 0, 3, 3, 3, 0, 2, 3, 2, 2, 0, 2, 0, 1, 1, 0, 2, 3, 1, 1, 2, 1, 3, 2, 2, 1, 3, 2, 3, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1285. And steps were 202 and the episode is 257 and the total_steps are 26039\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 1, 2, 3, 3, 1, 2, 0, 0, 2, 3, 3, 0, 2, 1, 0, 3, 3, 2, 1, 2, 1, 2, 0, 1, 1, 2, 3, 3, 2, 3, 0, 1, 2, 3, 2, 1, 3, 0, 1, 3, 2, 0, 3, 0, 3, 1, 1, 2, 1, 1, 3, 1, 3, 2, 2, 2, 3, 3, 1, 0, 1, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1067. And steps were 69 and the episode is 258 and the total_steps are 26108\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 3, 1, 1, 3, 1, 2, 0, 3, 3, 1, 2, 1, 2, 0, 3, 2, 0, 1, 2, 2, 2, 1, 2, 3, 0, 3, 3, 1, 3, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 1, 2, 1, 0, 3, 1, 3, 1, 1, 2, 1, 3, 3, 3, 0, 3, 1, 1, 2, 0, 2, 1, 0, 2, 0, 2, 2, 0, 2, 1, 0, 0, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -936. And steps were 80 and the episode is 259 and the total_steps are 26188\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 1, 3, 0, 0, 3, 1, 3, 1, 0, 0, 2, 2, 1, 0, 0, 2, 0, 2, 3, 2, 1, 2, 2, 0, 2, 3, 3, 1, 0, 2, 1, 1, 3, 3, 3, 3, 0, 0, 0, 1, 1, 3, 0, 2, 1, 2, 2, 1, 0, 1, 3, 0, 3, 3, 2, 2, 2, 0, 2, 1, 1, 1, 0, 3, 3, 2, 2, 1, 2, 1, 0, 2, 2, 2, 1, 0, 0, 1, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 86 and the episode is 260 and the total_steps are 26274\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.975    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 430      |\n",
      "|    total_timesteps  | 26274    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 1, 2, 1, 0, 3, 3, 2, 2, 0, 0, 1, 0, 2, 3, 2, 3, 3, 2, 1, 3, 3, 3, 3, 0, 2, 0, 0, 1, 0, 2, 2, 2, 1, 3, 2, 3, 2, 1, 1, 1, 1, 0, 1, 0, 0, 1, 2, 2, 1, 3, 1, 1, 3, 0, 3, 3, 3, 2, 2, 0, 0, 3, 0, 3, 0, 1, 0, 1, 3, 2, 2, 1, 3, 3, 3, 1, 3, 0, 3, 3, 2, 0, 1, 3, 0, 2, 3, 2, 0, 0, 3, 0, 1, 0, 1, 3, 0, 2, 3, 3, 0, 3, 1, 1, 0, 2, 2, 2, 2, 1, 2, 0, 0, 2, 0, 2, 3, 1, 3, 3, 2, 3, 1, 3, 2, 0, 2, 1, 2, 3, 2, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -871. And steps were 139 and the episode is 261 and the total_steps are 26413\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 2, 2, 1, 0, 1, 3, 1, 2, 2, 3, 0, 3, 2, 2, 3, 1, 1, 1, 0, 3, 0, 3, 2, 2, 3, 1, 1, 1, 1, 3, 3, 2, 0, 1, 0, 2, 1, 0, 1, 2, 0, 0, 0, 3, 0, 0, 1, 2, 3, 1, 1, 2, 3, 2, 1, 3, 0, 2, 0, 2, 0, 2, 0, 2, 3, 0, 0, 0, 2, 3, 3, 1, 3, 3, 1, 2, 2, 3, 2, 2, 3, 3, 0, 2, 1, 1, 3, 2, 2, 0, 3, 3, 0, 2, 1, 2, 1, 0, 2, 2, 0, 3, 3, 1, 3, 2, 1, 1, 1, 1, 1, 1, 3, 1, 3, 2, 3, 3, 3, 1, 3, 1, 2, 0, 1, 3, 3, 2, 3, 0, 0, 0, 3, 1, 0, 1, 0, 3, 0, 3, 1, 3, 1, 1, 3, 0, 2, 1, 0, 0, 3, 1, 1, 3, 3, 3, 0, 3, 1, 2, 1, 2, 1, 3, 3, 1, 2, 1, 1, 3, 0, 2, 3, 1, 0, 2, 3, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -871. And steps were 185 and the episode is 262 and the total_steps are 26598\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 0, 3, 3, 3, 1, 0, 2, 2, 0, 0, 1, 2, 2, 1, 1, 1, 0, 2, 3, 0, 1, 1, 2, 1, 1, 3, 3, 0, 1, 3, 3, 3, 0, 3, 3, 1, 0, 3, 3, 2, 0, 1, 2, 3, 0, 3, 0, 0, 3, 2, 3, 2, 1, 1, 0, 1, 2, 3, 1, 2, 3, 1, 3, 0, 0, 0, 2, 2, 3, 1, 2, 3, 1, 1, 1, 3, 0, 1, 2, 1, 3, 1, 3, 0, 3, 1, 2, 1, 0, 2, 1, 3, 0, 1, 1, 3, 1, 2, 2, 0, 1, 1, 3, 0, 1, 0, 3, 1, 2, 2, 2, 2, 1, 0, 2, 2, 2, 0, 1, 3, 0, 1, 2, 1, 2, 1, 1, 2, 0, 1, 3, 0, 3, 0, 0, 3, 2, 2, 3, 3, 2, 2, 3, 1, 1, 0, 1, 0, 2, 1, 3, 3, 2, 0, 2, 3, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 181 and the episode is 263 and the total_steps are 26779\n",
      "Done condition: max time steps reached\n",
      "[3, 1, 3, 2, 3, 0, 3, 1, 3, 1, 0, 2, 1, 3, 1, 1, 2, 0, 1, 2, 0, 0, 3, 0, 0, 2, 1, 1, 1, 0, 2, 3, 0, 2, 0, 3, 1, 1, 2, 1, 3, 2, 2, 2, 1, 2, 3, 0, 2, 3, 0, 3, 0, 2, 3, 3, 2, 3, 2, 1, 1, 1, 2, 0, 0, 1, 0, 3, 2, 3, 3, 3, 0, 2, 0, 0, 0, 2, 1, 2, 0, 3, 1, 3, 2, 1, 2, 2, 2, 1, 2, 0, 2, 1, 3, 1, 2, 0, 3, 3, 3, 0, 3, 1, 3, 1, 1, 0, 0, 1, 3, 0, 2, 2, 2, 0, 1, 3, 0, 0, 2, 0, 1, 2, 3, 0, 1, 3, 1, 3, 3, 1, 1, 2, 1, 3, 1, 3, 3, 3, 2, 1, 3, 2, 0, 1, 1, 0, 1, 2, 1, 0, 0, 1, 1, 1, 0, 3, 1, 0, 2, 1, 1, 2, 0, 0, 0, 3, 0, 2, 0, 0, 3, 1, 3, 3, 3, 2, 1, 3, 2, 0, 3, 1, 2, 0, 0, 0, 2, 0, 3, 0, 3, 0, 3, 3, 2, 0, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1399. And steps were 202 and the episode is 264 and the total_steps are 26981\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 441      |\n",
      "|    total_timesteps  | 26981    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 3, 0, 0, 3, 1, 2, 0, 2, 2, 0, 0, 0, 2, 1, 2, 3, 1, 2, 0, 3, 2, 0, 1, 0, 1, 1, 1, 0, 0, 1, 3, 3, 2, 2, 0, 1, 0, 0, 3, 2, 3, 0, 0, 1, 0, 0, 3, 3, 2, 0, 1, 2, 2, 1, 1, 1, 3, 0, 3, 3, 2, 2, 2, 2, 2, 3, 3, 1, 1, 2, 0, 3, 1, 0, 1, 1, 2, 1, 3, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -929. And steps were 87 and the episode is 265 and the total_steps are 27068\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 2, 1, 1, 3, 1, 0, 3, 1, 3, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 0, 1, 3, 2, 1, 0, 1, 0, 0, 0, 1, 2, 3, 2, 1, 3, 3, 0, 3, 2, 3, 1, 0, 2, 0, 1, 3, 0, 2, 0, 3, 1, 3, 0, 2, 2, 3, 3, 3, 0, 2, 3, 3, 1, 1, 2, 3, 0, 1, 3, 2, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 81 and the episode is 266 and the total_steps are 27149\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 1, 1, 1, 3, 3, 0, 3, 3, 3, 0, 2, 1, 2, 3, 0, 0, 3, 1, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 3, 2, 0, 1, 0, 3, 0, 2, 3, 1, 2, 3, 2, 3, 3, 2, 1, 1, 3, 2, 0, 1, 3, 1, 2, 3, 0, 1, 1, 2, 1, 0, 0, 0, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 74 and the episode is 267 and the total_steps are 27223\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 0, 3, 2, 1, 1, 1, 2, 3, 2, 0, 1, 2, 3, 2, 0, 3, 2, 2, 2, 3, 2, 0, 3, 1, 0, 1, 3, 0, 0, 1, 3, 0, 1, 2, 3, 0, 3, 1, 3, 3, 1, 1, 1, 2, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 0, 3, 0, 3, 1, 3, 2, 0, 2, 2, 0, 3, 2, 0, 0, 2, 1, 2, 2, 1, 2, 0, 3, 0, 0, 0, 0, 2, 2, 2, 2, 1, 3, 3, 1, 1, 0, 0, 3, 0, 0, 1, 1, 0, 1, 2, 1, 3, 1, 2, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 112 and the episode is 268 and the total_steps are 27335\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 446      |\n",
      "|    total_timesteps  | 27335    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 2, 1, 1, 3, 0, 0, 0, 2, 3, 1, 2, 1, 0, 3, 2, 1, 3, 3, 3, 1, 2, 1, 2, 0, 3, 0, 2, 1, 2, 1, 1, 2, 0, 0, 0, 3, 2, 2, 1, 1, 1, 2, 2, 1, 1, 0, 3, 2, 1, 0, 0, 0, 0, 3, 2, 3, 2, 3, 0, 2, 0, 2, 3, 2, 0, 0, 1, 3, 0, 2, 3, 0, 1, 1, 1, 2, 0, 3, 0, 2, 2, 0, 1, 2, 3, 3, 2, 0, 0, 3, 2, 3, 1, 3, 1, 3, 1, 1, 2, 2, 2, 2, 3, 3, 0, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 113 and the episode is 269 and the total_steps are 27448\n",
      "Done condition: max time steps reached\n",
      "[3, 1, 0, 1, 0, 2, 3, 2, 3, 3, 2, 0, 0, 2, 3, 1, 1, 0, 1, 3, 3, 2, 2, 3, 3, 1, 0, 0, 0, 0, 2, 3, 1, 0, 1, 1, 2, 0, 3, 3, 3, 0, 0, 1, 1, 3, 0, 1, 1, 3, 0, 3, 1, 0, 2, 1, 2, 3, 0, 3, 3, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 0, 3, 0, 0, 3, 1, 2, 3, 0, 2, 2, 3, 1, 1, 2, 0, 3, 2, 1, 0, 1, 3, 0, 0, 1, 0, 3, 0, 1, 0, 2, 0, 3, 0, 1, 0, 2, 2, 2, 1, 1, 1, 0, 2, 1, 3, 0, 2, 3, 3, 3, 2, 1, 0, 2, 3, 2, 2, 0, 0, 1, 1, 3, 3, 0, 0, 1, 3, 0, 0, 0, 3, 0, 1, 0, 0, 1, 0, 1, 2, 0, 2, 2, 0, 0, 0, 1, 3, 0, 3, 0, 3, 0, 2, 0, 1, 1, 3, 3, 3, 3, 1, 0, 1, 1, 3, 0, 1, 1, 2, 2, 0, 3, 3, 0, 1, 3, 2, 1, 2, 2, 1, 2, 0, 2, 0, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1399. And steps were 202 and the episode is 270 and the total_steps are 27650\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 0, 1, 3, 2, 0, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 0, 0, 2, 2, 2, 3, 2, 2, 1, 1, 2, 2, 2, 3, 3, 1, 0, 0, 1, 2, 3, 0, 0, 0, 1, 0, 0, 1, 0, 2, 3, 3, 2, 1, 2, 1, 1, 0, 1, 3, 0, 3, 2, 2, 1, 2, 3, 0, 3, 3, 3, 2, 2, 2, 0, 1, 0, 0, 0, 2, 2, 3, 1, 0, 0, 3, 3, 1, 3, 2, 2, 3, 0, 0, 1, 1, 2, 0, 3, 0, 1, 1, 1, 2, 0, 0, 1, 0, 0, 2, 0, 3, 3, 3, 0, 3, 1, 2, 2, 2, 2, 0, 0, 2, 0, 1, 3, 3, 0, 0, 0, 1, 3, 1, 2, 1, 1, 1, 1, 3, 3, 2, 3, 1, 2, 3, 3, 3, 3, 3, 2, 3, 0, 3, 3, 1, 0, 3, 3, 1, 0, 1, 0, 3, 0, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 168 and the episode is 271 and the total_steps are 27818\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 3, 3, 2, 2, 3, 1, 0, 2, 3, 0, 3, 2, 1, 3, 1, 2, 0, 2, 0, 0, 1, 2, 0, 1, 3, 2, 1, 0, 2, 1, 3, 1, 0, 3, 0, 0, 2, 1, 1, 3, 2, 0, 2, 3, 2, 3, 3, 3, 2, 3, 1, 0, 1, 3, 1, 0, 1, 1, 3, 1, 2, 1, 3, 0, 2, 2, 0, 0, 2, 2, 1, 3, 0, 2, 0, 0, 3, 2, 2, 3, 3, 2, 3, 2, 0, 3, 3, 0, 1, 0, 1, 0, 3, 2, 3, 2, 0, 0, 0, 0, 1, 0, 1, 2, 2, 0, 3, 1, 2, 3, 1, 3, 0, 3, 1, 3, 1, 0, 2, 3, 1, 1, 1, 0, 0, 3, 3, 3, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -938. And steps were 136 and the episode is 272 and the total_steps are 27954\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -1e+03   |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 456      |\n",
      "|    total_timesteps  | 27954    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 1, 0, 2, 1, 1, 1, 2, 3, 0, 2, 1, 0, 2, 0, 1, 2, 3, 2, 1, 0, 2, 2, 3, 3, 2, 0, 1, 0, 2, 3, 1, 0, 3, 2, 0, 2, 3, 3, 2, 3, 0, 2, 1, 1, 2, 0, 2, 2, 1, 1, 3, 1, 1, 2, 2, 3, 0, 3, 2, 3, 1, 2, 2, 0, 2, 1, 0, 0, 2, 2, 2, 2, 0, 1, 3, 3, 2, 2, 2, 3, 1, 0, 3, 0, 2, 2, 0, 0, 1, 0, 0, 2, 2, 3, 1, 2, 1, 1, 2, 3, 3, 1, 3, 0, 3, 1, 2, 1, 1, 1, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 118 and the episode is 273 and the total_steps are 28072\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 2, 2, 2, 2, 0, 1, 3, 1, 0, 3, 1, 0, 1, 3, 3, 1, 3, 2, 3, 2, 3, 3, 0, 0, 2, 2, 0, 2, 0, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 3, 3, 2, 1, 3, 0, 2, 0, 1, 0, 3, 2, 3, 0, 0, 2, 3, 0, 1, 3, 3, 2, 0, 0, 2, 1, 0, 3, 1, 3, 3, 1, 1, 0, 3, 1, 1, 3, 1, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1085. And steps were 87 and the episode is 274 and the total_steps are 28159\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 1, 1, 1, 0, 2, 3, 3, 2, 0, 0, 3, 0, 0, 0, 0, 2, 0, 3, 3, 1, 1, 0, 1, 0, 3, 1, 2, 0, 2, 0, 0, 2, 2, 1, 0, 3, 3, 3, 2, 2, 0, 0, 2, 0, 2, 3, 1, 1, 0, 0, 1, 3, 3, 2, 2, 0, 2, 2, 1, 0, 0, 1, 2, 3, 3, 3, 2, 1, 0, 0, 2, 0, 2, 2, 2, 1, 0, 1, 3, 3, 1, 1, 0, 1, 0, 2, 2, 0, 3, 0, 3, 0, 2, 0, 1, 2, 0, 1, 1, 3, 3, 2, 2, 2, 1, 3, 3, 1, 0, 2, 1, 3, 0, 3, 3, 3, 0, 1, 0, 0, 0, 2, 3, 0, 2, 1, 3, 3, 1, 3, 3, 3, 3, 0, 1, 0, 0, 3, 3, 2, 1, 0, 3, 1, 3, 3, 1, 1, 1, 3, 3, 1, 0, 0, 2, 1, 3, 2, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1164. And steps were 166 and the episode is 275 and the total_steps are 28325\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 1, 2, 3, 1, 2, 0, 0, 0, 3, 1, 0, 2, 0, 3, 0, 2, 2, 2, 2, 0, 0, 3, 0, 1, 0, 1, 2, 2, 1, 0, 3, 0, 0, 1, 3, 2, 0, 2, 3, 0, 0, 1, 3, 1, 3, 0, 0, 2, 0, 0, 2, 2, 2, 1, 1, 0, 2, 0, 3, 1, 2, 0, 3, 2, 0, 3, 2, 0, 0, 2, 1, 3, 3, 0, 2, 1, 3, 1, 0, 2, 3, 3, 0, 3, 3, 2, 3, 1, 3, 2, 1, 0, 0, 1, 0, 1, 0, 3, 1, 1, 2, 1, 0, 3, 1, 3, 2, 2, 0, 0, 3, 2, 2, 2, 2, 0, 0, 3, 2, 2, 1, 2, 3, 2, 1, 1, 1, 1, 2, 3, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 0, 1, 3, 1, 2, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1051. And steps were 155 and the episode is 276 and the total_steps are 28480\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | -1e+03   |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 464      |\n",
      "|    total_timesteps  | 28480    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 3, 1, 1, 3, 1, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 1, 0, 2, 1, 1, 0, 0, 2, 0, 1, 1, 2, 2, 1, 0, 3, 0, 1, 3, 3, 3, 0, 3, 3, 2, 0, 1, 2, 2, 1, 1, 1, 1, 3, 0, 2, 2, 3, 2, 0, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 1, 0, 2, 3, 2, 0, 1, 3, 3, 2, 1, 1, 1, 1, 0, 3, 1, 0, 3, 3, 0, 3, 0, 3, 1, 2, 1, 3, 2, 1, 1, 3, 3, 3, 2, 2, 1, 2, 2, 3, 3, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 2, 0, 0, 2, 1, 0, 0, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -900. And steps were 142 and the episode is 277 and the total_steps are 28622\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 0, 0, 3, 1, 0, 0, 0, 1, 3, 1, 0, 2, 3, 0, 3, 3, 1, 3, 2, 2, 2, 0, 0, 3, 3, 0, 2, 3, 0, 3, 3, 0, 0, 3, 2, 3, 2, 3, 0, 0, 3, 0, 1, 1, 0, 0, 2, 0, 1, 2, 3, 0, 0, 2, 3, 2, 2, 3, 2, 2, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 2, 0, 0, 2, 1, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 83 and the episode is 278 and the total_steps are 28705\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 0, 2, 0, 2, 1, 2, 1, 3, 1, 0, 0, 1, 3, 2, 0, 0, 1, 2, 0, 2, 3, 0, 3, 1, 1, 2, 1, 2, 3, 2, 1, 3, 0, 2, 3, 2, 1, 3, 1, 1, 3, 1, 3, 1, 1, 3, 0, 1, 2, 2, 2, 0, 1, 1, 2, 0, 2, 0, 2, 2, 2, 1, 1, 2, 1, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 73 and the episode is 279 and the total_steps are 28778\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 0, 2, 2, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 3, 1, 0, 3, 2, 2, 0, 1, 3, 3, 0, 0, 1, 0, 1, 2, 0, 2, 1, 0, 1, 3, 2, 0, 1, 3, 1, 0, 2, 3, 3, 0, 1, 3, 3, 3, 2, 1, 3, 2, 0, 0, 0, 2, 2, 0, 1, 2, 1, 2, 3, 3, 1, 0, 0, 1, 3, 2, 3, 3, 2, 3, 3, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -942. And steps were 84 and the episode is 280 and the total_steps are 28862\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -1e+03   |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 470      |\n",
      "|    total_timesteps  | 28862    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 2, 1, 0, 3, 2, 3, 2, 0, 2, 2, 3, 3, 1, 2, 2, 2, 0, 3, 1, 1, 2, 2, 2, 1, 3, 1, 3, 1, 0, 0, 0, 2, 2, 0, 0, 0, 2, 3, 0, 3, 2, 3, 2, 1, 2, 1, 0, 1, 1, 0, 1, 2, 0, 2, 0, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 3, 0, 0, 0, 1, 2, 0, 3, 2, 2, 3, 2, 3, 2, 2, 2, 0, 0, 0, 3, 0, 1, 3, 1, 2, 1, 3, 3, 3, 2, 1, 3, 0, 1, 3, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1109. And steps were 111 and the episode is 281 and the total_steps are 28973\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 0, 3, 0, 1, 3, 0, 2, 3, 0, 3, 3, 0, 0, 3, 0, 0, 3, 3, 1, 2, 0, 3, 3, 3, 3, 0, 0, 1, 0, 1, 2, 3, 3, 0, 0, 3, 1, 2, 3, 1, 0, 3, 1, 3, 1, 1, 3, 0, 0, 1, 3, 3, 3, 1, 0, 3, 0, 0, 3, 1, 1, 1, 3, 3, 1, 3, 2, 2, 0, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 77 and the episode is 282 and the total_steps are 29050\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 1, 2, 2, 0, 2, 2, 2, 3, 0, 3, 3, 2, 3, 3, 0, 0, 2, 2, 0, 0, 0, 2, 1, 2, 1, 1, 3, 2, 1, 3, 1, 0, 3, 1, 0, 0, 3, 3, 1, 0, 3, 2, 1, 2, 3, 3, 1, 1, 2, 0, 2, 0, 0, 2, 0, 1, 2, 3, 3, 3, 3, 0, 3, 2, 3, 3, 1, 3, 0, 3, 1, 3, 3, 2, 0, 2, 0, 1, 2, 3, 0, 3, 3, 3, 1, 2, 1, 0, 2, 3, 2, 3, 2, 3, 2, 0, 1, 1, 0, 3, 0, 2, 1, 0, 0, 3, 2, 0, 0, 1, 2, 3, 0, 0, 0, 1, 3, 2, 1, 3, 0, 2, 3, 2, 2, 2, 0, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 135 and the episode is 283 and the total_steps are 29185\n",
      "Done condition: collision\n",
      "[1, 1, 3, 0, 1, 1, 3, 1, 2, 3, 0, 2, 0, 0, 2, 2, 0, 1, 0, 3, 2, 2, 1, 2, 0, 0, 1, 0, 2, 0, 3, 2, 1, 0, 2, 1, 3, 2, 3, 1, 3, 1, 3, 0, 0, 2, 0, 0, 0, 2, 0, 0, 3, 1, 0, 2, 2, 1, 3, 3, 0, 2, 1, 0, 1, 1, 3, 3, 2, 3, 3, 3, 3, 2, 2, 3, 1, 2, 0, 2, 0, 3, 3, 0, 3, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 89 and the episode is 284 and the total_steps are 29274\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 103       |\n",
      "|    ep_rew_mean      | -1.01e+03 |\n",
      "|    exploration_rate | 0.972     |\n",
      "| time/               |           |\n",
      "|    episodes         | 284       |\n",
      "|    fps              | 61        |\n",
      "|    time_elapsed     | 477       |\n",
      "|    total_timesteps  | 29274     |\n",
      "-----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 3, 2, 0, 2, 2, 1, 1, 3, 3, 1, 1, 2, 1, 1, 2, 1, 1, 3, 0, 0, 2, 2, 3, 0, 0, 0, 2, 1, 2, 0, 3, 3, 3, 1, 3, 0, 2, 3, 1, 3, 3, 1, 0, 1, 1, 0, 0, 0, 0, 3, 3, 0, 2, 2, 2, 3, 1, 1, 3, 1, 1, 2, 2, 2, 2, 0, 1, 3, 3, 0, 1, 0, 0, 0, 3, 1, 2, 2, 0, 2, 3, 1, 0, 0, 1, 1, 2, 1, 0, 0, 0, 3, 2, 3, 3, 2, 2, 1, 0, 1, 3, 2, 2, 2, 3, 2, 1, 3, 2, 3, 3, 3, 0, 3, 3, 0, 2, 1, 0, 2, 0, 1, 2, 3, 2, 2, 2, 2, 1, 1, 3, 1, 2, 2, 2, 1, 2, 1, 2, 1, 0, 3, 1, 2, 0, 0, 1, 0, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -858. And steps were 156 and the episode is 285 and the total_steps are 29430\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 1, 2, 2, 3, 3, 1, 0, 3, 2, 0, 1, 3, 3, 2, 1, 3, 0, 1, 1, 3, 0, 3, 1, 1, 0, 0, 0, 1, 0, 3, 0, 3, 2, 0, 0, 0, 0, 0, 2, 3, 1, 0, 3, 2, 3, 0, 1, 0, 0, 3, 2, 2, 2, 3, 1, 0, 1, 1, 3, 0, 1, 0, 3, 0, 0, 3, 0, 3, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 76 and the episode is 286 and the total_steps are 29506\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 3, 1, 3, 2, 2, 2, 1, 1, 2, 0, 1, 2, 0, 1, 1, 2, 1, 1, 1, 3, 2, 2, 2, 0, 1, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 2, 2, 3, 0, 1, 0, 2, 0, 2, 1, 3, 3, 1, 2, 2, 3, 0, 1, 1, 2, 2, 2, 2, 3, 0, 3, 1, 1, 2, 3, 2, 1, 1, 3, 3, 2, 0, 2, 3, 2, 1, 0, 1, 3, 3, 3, 1, 2, 1, 2, 2, 3, 2, 2, 3, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 2, 2, 2, 0, 3, 1, 3, 3, 0, 1, 2, 1, 2, 1, 2, 1, 3, 3, 2, 0, 2, 1, 2, 3, 1, 3, 1, 1, 2, 3, 1, 0, 0, 0, 1, 1, 0, 0, 2, 3, 2, 2, 3, 3, 0, 2, 3, 1, 0, 0, 0, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -885. And steps were 167 and the episode is 287 and the total_steps are 29673\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 3, 1, 2, 2, 3, 0, 0, 1, 2, 2, 3, 0, 0, 1, 0, 0, 3, 3, 1, 3, 1, 2, 0, 1, 1, 3, 1, 0, 3, 3, 2, 2, 3, 3, 3, 0, 2, 1, 1, 0, 1, 0, 1, 1, 2, 0, 1, 3, 3, 1, 2, 0, 0, 0, 2, 3, 3, 1, 2, 2, 0, 1, 1, 0, 3, 0, 0, 2, 2, 2, 2, 0, 3, 1, 1, 1, 2, 2, 2, 2, 3, 0, 3, 3, 3, 2, 2, 3, 0, 0, 2, 3, 0, 3, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -924. And steps were 102 and the episode is 288 and the total_steps are 29775\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -1e+03   |\n",
      "|    exploration_rate | 0.972    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 485      |\n",
      "|    total_timesteps  | 29775    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 3, 3, 0, 0, 3, 2, 0, 2, 3, 2, 1, 1, 1, 1, 1, 0, 2, 1, 0, 2, 3, 3, 1, 2, 0, 1, 0, 0, 2, 1, 0, 2, 3, 2, 2, 0, 1, 0, 0, 2, 3, 3, 3, 0, 3, 3, 0, 0, 1, 3, 1, 3, 0, 1, 0, 1, 0, 2, 3, 1, 2, 0, 2, 1, 3, 3, 1, 3, 3, 1, 1, 3, 0, 2, 2, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 83 and the episode is 289 and the total_steps are 29858\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 1, 2, 3, 0, 3, 1, 1, 0, 3, 0, 0, 0, 3, 0, 2, 2, 3, 0, 1, 2, 0, 3, 1, 0, 0, 0, 2, 2, 1, 2, 3, 3, 2, 1, 2, 0, 3, 0, 1, 3, 2, 2, 1, 3, 0, 1, 2, 1, 0, 3, 3, 1, 1, 2, 0, 2, 0, 1, 1, 2, 2, 3, 0, 2, 1, 3, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 74 and the episode is 290 and the total_steps are 29932\n",
      "Done condition: max time steps reached\n",
      "[2, 1, 2, 3, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 2, 0, 3, 0, 3, 3, 1, 1, 3, 1, 0, 3, 0, 2, 1, 1, 1, 1, 2, 0, 1, 1, 2, 0, 3, 1, 2, 1, 2, 2, 1, 0, 0, 0, 2, 0, 3, 2, 0, 2, 1, 3, 2, 3, 2, 1, 1, 0, 2, 2, 2, 2, 3, 3, 1, 0, 2, 1, 0, 1, 1, 3, 1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 2, 3, 0, 0, 1, 1, 3, 1, 0, 0, 0, 2, 3, 1, 3, 0, 1, 0, 1, 0, 3, 3, 0, 0, 1, 0, 1, 3, 0, 1, 2, 0, 0, 1, 3, 3, 0, 1, 2, 3, 1, 3, 1, 3, 2, 2, 3, 2, 0, 1, 3, 3, 3, 0, 0, 0, 1, 0, 3, 1, 3, 3, 1, 0, 0, 3, 1, 2, 0, 2, 1, 1, 0, 2, 3, 3, 1, 2, 0, 3, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2, 2, 1, 3, 3, 1, 1, 3, 2, 2, 2, 0, 1, 0, 1, 0, 0, 1, 0, 3, 2, 1, 1, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1205. And steps were 202 and the episode is 291 and the total_steps are 30134\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 1, 3, 0, 2, 2, 2, 2, 1, 2, 0, 0, 1, 0, 1, 0, 0, 2, 3, 1, 1, 1, 0, 0, 2, 2, 3, 2, 3, 0, 1, 1, 0, 1, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 2, 3, 2, 0, 2, 0, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1048. And steps were 55 and the episode is 292 and the total_steps are 30189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -985     |\n",
      "|    exploration_rate | 0.971    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 491      |\n",
      "|    total_timesteps  | 30189    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 3, 3, 0, 1, 0, 2, 1, 2, 3, 2, 2, 0, 2, 0, 2, 0, 2, 0, 3, 2, 2, 3, 1, 2, 0, 2, 3, 2, 3, 3, 1, 3, 2, 0, 3, 2, 0, 1, 2, 2, 2, 2, 1, 3, 2, 3, 2, 0, 3, 2, 3, 3, 1, 0, 0, 3, 0, 2, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1064. And steps were 66 and the episode is 293 and the total_steps are 30255\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 1, 1, 2, 2, 1, 0, 3, 1, 3, 1, 2, 1, 2, 0, 2, 2, 0, 1, 3, 1, 0, 0, 2, 0, 1, 1, 0, 0, 0, 3, 3, 1, 0, 3, 2, 3, 2, 0, 1, 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 1, 3, 2, 3, 3, 0, 3, 1, 0, 1, 0, 0, 2, 3, 2, 3, 2, 2, 3, 0, 3, 2, 3, 3, 3, 2, 3, 0, 3, 1, 2, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1086. And steps were 88 and the episode is 294 and the total_steps are 30343\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 2, 0, 3, 1, 1, 3, 3, 2, 0, 1, 2, 1, 2, 3, 1, 1, 0, 0, 2, 0, 1, 0, 2, 1, 1, 1, 2, 2, 1, 3, 2, 3, 3, 2, 3, 0, 1, 2, 0, 1, 1, 0, 2, 2, 2, 2, 2, 3, 0, 0, 3, 0, 2, 1, 0, 1, 3, 0, 2, 1, 3, 2, 3, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 71 and the episode is 295 and the total_steps are 30414\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 1, 2, 1, 0, 0, 3, 3, 3, 3, 2, 1, 3, 0, 2, 1, 3, 1, 2, 0, 2, 0, 3, 2, 0, 2, 3, 3, 0, 1, 0, 3, 2, 0, 1, 3, 1, 3, 1, 3, 3, 1, 2, 3, 3, 0, 1, 1, 3, 0, 1, 1, 2, 2, 0, 0, 0, 3, 3, 0, 2, 2, 0, 2, 0, 3, 2, 3, 3, 3, 0, 2, 3, 0, 3, 1, 3, 0, 3, 3, 0, 0, 1, 1, 3, 2, 2, 2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 0, 2, 2, 2, 1, 3, 1, 1, 1, 0, 2, 3, 1, 1, 2, 2, 0, 1, 2, 3, 2, 1, 3, 1, 3, 3, 0, 2, 3, 0, 2, 2, 2, 1, 0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1052. And steps were 150 and the episode is 296 and the total_steps are 30564\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | -989     |\n",
      "|    exploration_rate | 0.971    |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 497      |\n",
      "|    total_timesteps  | 30564    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 2, 0, 3, 3, 0, 2, 3, 1, 0, 3, 2, 0, 2, 2, 0, 3, 2, 1, 1, 3, 3, 2, 0, 1, 3, 0, 3, 0, 1, 0, 2, 0, 0, 2, 1, 0, 0, 3, 0, 2, 0, 0, 3, 0, 0, 1, 0, 2, 1, 3, 2, 2, 3, 3, 3, 1, 1, 1, 3, 3, 1, 3, 2, 2, 2, 1, 2, 0, 1, 2, 2, 3, 3, 1, 1, 0, 0, 0, 3, 2, 2, 0, 3, 2, 2, 3, 0, 3, 2, 3, 3, 0, 2, 0, 3, 2, 3, 1, 0, 1, 2, 3, 2, 1, 2, 1, 3, 1, 0, 1, 3, 0, 2, 0, 3, 1, 2, 2, 2, 1, 3, 3, 3, 2, 1, 2, 0, 3, 0, 1, 0, 2, 3, 0, 1, 0, 3, 2, 1, 3, 2, 2, 0, 3, 1, 3, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1078. And steps were 154 and the episode is 297 and the total_steps are 30718\n",
      "Skiping this step\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 0, 0, 2, 3, 1, 1, 3, 2, 3, 2, 1, 3, 0, 2, 0, 3, 0, 1, 1, 3, 2, 0, 2, 1, 3, 3, 3, 0, 2, 0, 2, 0, 1, 3, 2, 1, 1, 0, 2, 3, 0, 0, 1, 2, 2, 3, 3, 0, 3, 0, 2, 1, 3, 0, 3, 3, 3, 3, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 939. And steps were 64 and the episode is 298 and the total_steps are 30782\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 2, 3, 3, 0, 3, 0, 2, 1, 3, 1, 2, 1, 2, 2, 3, 0, 3, 3, 2, 0, 2, 3, 3, 2, 0, 1, 0, 0, 2, 2, 2, 3, 0, 2, 1, 0, 2, 2, 2, 2, 0, 3, 0, 3, 3, 0, 3, 2, 2, 1, 2, 3, 1, 1, 0, 3, 1, 2, 2, 1, 3, 1, 0, 2, 0, 2, 2, 1, 2, 1, 0, 1, 2, 0, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 82 and the episode is 299 and the total_steps are 30864\n",
      "Done condition: max time steps reached\n",
      "[2, 0, 2, 0, 1, 1, 0, 0, 0, 2, 0, 2, 1, 3, 0, 2, 0, 3, 0, 0, 1, 1, 1, 0, 2, 0, 3, 1, 1, 1, 2, 1, 1, 0, 0, 3, 2, 3, 1, 3, 1, 0, 3, 1, 0, 3, 2, 3, 0, 0, 3, 2, 3, 1, 2, 0, 2, 2, 1, 1, 0, 0, 0, 2, 0, 2, 3, 0, 0, 2, 0, 0, 1, 3, 1, 1, 1, 1, 3, 2, 0, 1, 2, 3, 2, 1, 1, 2, 1, 0, 2, 2, 2, 0, 1, 3, 0, 2, 2, 2, 1, 0, 2, 2, 3, 0, 2, 2, 1, 1, 0, 2, 1, 0, 0, 3, 1, 2, 1, 3, 1, 2, 3, 0, 1, 3, 3, 1, 0, 0, 3, 3, 2, 2, 2, 3, 1, 0, 0, 2, 2, 0, 3, 2, 0, 3, 0, 2, 0, 3, 0, 1, 0, 3, 3, 0, 2, 2, 2, 3, 1, 3, 0, 0, 3, 0, 3, 1, 1, 2, 2, 2, 0, 2, 3, 3, 2, 3, 1, 2, 2, 1, 3, 2, 3, 0, 2, 0, 3, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1123. And steps were 202 and the episode is 300 and the total_steps are 31066\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | -973     |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 505      |\n",
      "|    total_timesteps  | 31066    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 1, 0, 1, 2, 2, 2, 0, 2, 1, 0, 3, 0, 1, 1, 3, 0, 3, 0, 1, 2, 3, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 3, 0, 1, 0, 1, 3, 0, 2, 3, 1, 1, 3, 2, 2, 2, 3, 1, 2, 0, 2, 1, 0, 2, 3, 1, 0, 0, 0, 0, 3, 2, 2, 2, 2, 3, 1, 1, 1, 1, 0, 2, 2, 2, 1, 1, 2, 0, 3, 3, 1, 3, 2, 3, 0, 1, 3, 2, 2, 3, 0, 0, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 100 and the episode is 301 and the total_steps are 31166\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 3, 0, 3, 3, 0, 1, 3, 3, 0, 0, 2, 2, 3, 1, 2, 3, 1, 0, 0, 2, 1, 1, 1, 3, 1, 0, 2, 3, 1, 2, 3, 1, 3, 1, 1, 3, 2, 1, 0, 2, 3, 2, 1, 0, 2, 2, 1, 3, 3, 3, 2, 1, 0, 0, 1, 3, 0, 1, 1, 2, 3, 1, 3, 3, 1, 1, 3, 2, 1, 3, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1076. And steps were 78 and the episode is 302 and the total_steps are 31244\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 1, 2, 1, 1, 0, 0, 1, 0, 2, 3, 3, 2, 3, 0, 3, 1, 2, 2, 0, 1, 2, 0, 1, 2, 2, 3, 2, 3, 3, 2, 2, 0, 2, 3, 2, 2, 3, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 53 and the episode is 303 and the total_steps are 31297\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 1, 3, 2, 2, 2, 3, 0, 3, 3, 1, 1, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 3, 3, 2, 2, 0, 1, 2, 2, 3, 0, 1, 3, 3, 3, 0, 2, 3, 2, 3, 1, 3, 3, 1, 0, 3, 0, 3, 3, 1, 2, 1, 0, 3, 3, 3, 1, 3, 3, 1, 2, 1, 2, 2, 3, 0, 2, 2, 3, 3, 3, 0, 1, 0, 1, 2, 2, 2, 3, 2, 3, 1, 1, 2, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 92 and the episode is 304 and the total_steps are 31389\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | -972     |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 511      |\n",
      "|    total_timesteps  | 31389    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 0, 1, 0, 0, 3, 1, 1, 3, 2, 2, 1, 3, 0, 0, 2, 1, 0, 0, 3, 3, 2, 2, 1, 3, 3, 1, 3, 1, 0, 3, 1, 3, 3, 0, 1, 0, 0, 3, 0, 0, 0, 1, 0, 0, 2, 3, 3, 2, 2, 2, 0, 0, 0, 2, 0, 3, 0, 2, 0, 3, 3, 3, 2, 3, 1, 2, 2, 0, 1, 3, 3, 2, 1, 2, 1, 1, 1, 0, 2, 3, 2, 1, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 90 and the episode is 305 and the total_steps are 31479\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 1, 3, 1, 1, 0, 3, 3, 0, 0, 3, 1, 2, 2, 0, 1, 2, 1, 3, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 1, 1, 2, 0, 2, 0, 2, 2, 3, 0, 1, 3, 2, 3, 2, 1, 2, 2, 1, 2, 2, 3, 3, 3, 2, 2, 3, 1, 2, 3, 2, 0, 0, 0, 1, 0, 3, 1, 2, 1, 0, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -953. And steps were 77 and the episode is 306 and the total_steps are 31556\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 1, 0, 2, 3, 0, 2, 1, 0, 3, 2, 0, 3, 3, 3, 1, 2, 3, 2, 2, 3, 3, 3, 3, 1, 0, 3, 0, 0, 1, 1, 3, 1, 0, 2, 2, 3, 1, 2, 2, 0, 3, 1, 0, 3, 2, 1, 1, 3, 2, 3, 0, 2, 1, 3, 0, 1, 3, 0, 0, 3, 0, 0, 3, 3, 2, 0, 3, 3, 0, 2, 1, 1, 0, 1, 2, 3, 2, 2, 3, 0, 1, 0, 3, 2, 2, 1, 1, 0, 0, 0, 3, 1, 3, 1, 0, 2, 3, 2, 3, 1, 3, 0, 2, 0, 1, 2, 2, 3, 1, 1, 0, 2, 2, 1, 2, 0, 3, 2, 0, 3, 1, 2, 0, 3, 1, 3, 0, 2, 2, 1, 2, 2, 3, 3, 3, 2, 3, 0, 3, 2, 1, 2, 2, 0, 1, 0, 3, 2, 0, 3, 0, 3, 0, 3, 3, 1, 2, 2, 3, 1, 3, 3, 1, 1, 2, 0, 3, 2, 0, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -881. And steps were 177 and the episode is 307 and the total_steps are 31733\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 0, 1, 2, 2, 3, 1, 1, 1, 2, 1, 0, 2, 3, 2, 2, 0, 1, 0, 0, 1, 1, 2, 2, 2, 2, 1, 2, 0, 0, 3, 2, 2, 2, 1, 2, 2, 3, 3, 0, 2, 3, 2, 3, 0, 1, 1, 0, 3, 2, 1, 1, 2, 3, 2, 3, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 63 and the episode is 308 and the total_steps are 31796\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | -969     |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 517      |\n",
      "|    total_timesteps  | 31796    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 3, 2, 0, 3, 1, 0, 1, 0, 0, 3, 0, 2, 3, 3, 0, 1, 0, 3, 2, 1, 1, 1, 3, 1, 1, 0, 2, 2, 2, 2, 3, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 2, 2, 2, 3, 0, 2, 3, 3, 0, 3, 0, 1, 0, 3, 0, 3, 2, 2, 1, 1, 0, 3, 1, 2, 0, 2, 0, 0, 0, 3, 2, 3, 3, 1, 2, 0, 1, 3, 1, 2, 2, 2, 1, 3, 0, 1, 1, 0, 2, 2, 1, 0, 3, 3, 2, 1, 1, 1, 1, 0, 2, 3, 3, 3, 1, 0, 3, 3, 1, 3, 0, 1, 2, 1, 0, 2, 1, 3, 1, 2, 1, 3, 2, 2, 1, 0, 1, 2, 2, 2, 0, 2, 0, 3, 0, 3, 0, 3, 3, 0, 2, 2, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1149. And steps were 151 and the episode is 309 and the total_steps are 31947\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 0, 3, 1, 1, 0, 2, 1, 3, 2, 0, 3, 2, 1, 1, 3, 0, 2, 1, 0, 0, 1, 3, 0, 0, 3, 0, 2, 0, 3, 3, 1, 1, 3, 1, 1, 2, 0, 0, 1, 3, 0, 0, 2, 1, 3, 0, 0, 2, 1, 1, 1, 1, 1, 2, 3, 3, 3, 2, 1, 3, 3, 1, 2, 1, 2, 2, 2, 1, 0, 0, 3, 2, 1, 2, 3, 1, 1, 1, 0, 1, 3, 2, 0, 1, 0, 0, 0, 3, 1, 1, 1, 2, 0, 2, 1, 3, 2, 1, 2, 3, 3, 3, 0, 1, 2, 3, 3, 0, 2, 1, 2, 1, 0, 2, 3, 3, 2, 0, 2, 3, 2, 0, 3, 3, 3, 0, 0, 3, 0, 1, 0, 0, 0, 0, 2, 1, 2, 1, 0, 2, 0, 2, 3, 1, 0, 0, 0, 2, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1056. And steps were 156 and the episode is 310 and the total_steps are 32103\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 3, 0, 3, 1, 2, 2, 3, 2, 2, 0, 1, 1, 3, 0, 2, 3, 1, 3, 0, 2, 3, 2, 0, 3, 2, 3, 1, 2, 2, 1, 3, 0, 2, 1, 1, 3, 1, 2, 0, 3, 0, 1, 3, 0, 3, 2, 2, 0, 0, 0, 2, 1, 1, 0, 2, 3, 2, 0, 3, 1, 1, 3, 0, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 71 and the episode is 311 and the total_steps are 32174\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 1, 0, 1, 0, 0, 1, 0, 1, 0, 2, 0, 3, 2, 1, 2, 2, 1, 2, 1, 3, 2, 1, 0, 0, 1, 3, 2, 3, 2, 2, 3, 1, 2, 0, 0, 3, 2, 0, 1, 2, 3, 3, 0, 3, 2, 0, 0, 3, 2, 1, 0, 0, 3, 0, 3, 0, 0, 3, 0, 1, 1, 2, 1, 0, 3, 2, 0, 0, 1, 0, 2, 0, 3, 3, 2, 0, 2, 0, 2, 2, 2, 2, 1, 3, 2, 2, 3, 2, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 96 and the episode is 312 and the total_steps are 32270\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | -971     |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 525      |\n",
      "|    total_timesteps  | 32270    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 0, 3, 1, 1, 2, 1, 2, 2, 3, 1, 0, 0, 1, 0, 2, 1, 2, 1, 3, 3, 3, 0, 0, 1, 3, 2, 2, 0, 2, 2, 1, 3, 2, 1, 3, 2, 2, 0, 0, 3, 0, 3, 3, 3, 3, 0, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 3, 0, 3, 0, 2, 1, 1, 2, 0, 0, 2, 2, 2, 2, 1, 1, 3, 2, 3, 3, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 95 and the episode is 313 and the total_steps are 32365\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 2, 1, 3, 1, 3, 1, 0, 0, 1, 3, 2, 2, 3, 0, 3, 3, 1, 1, 2, 3, 0, 2, 2, 3, 1, 3, 3, 0, 2, 0, 1, 2, 2, 3, 0, 0, 2, 3, 0, 2, 0, 2, 1, 1, 3, 3, 2, 3, 1, 3, 3, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 1, 0, 2, 3, 3, 3, 3, 0, 3, 1, 2, 1, 2, 3, 0, 2, 0, 2, 0, 0, 1, 1, 1, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 94 and the episode is 314 and the total_steps are 32459\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 1, 0, 1, 2, 2, 0, 1, 2, 0, 3, 0, 1, 0, 0, 2, 2, 2, 1, 3, 3, 0, 1, 1, 0, 3, 0, 1, 3, 3, 0, 0, 1, 1, 1, 2, 2, 3, 0, 3, 2, 2, 1, 1, 1, 2, 2, 0, 0, 0, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1054. And steps were 55 and the episode is 315 and the total_steps are 32514\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 1, 1, 3, 0, 1, 0, 3, 1, 2, 2, 3, 2, 1, 2, 2, 3, 2, 1, 2, 3, 3, 3, 0, 2, 0, 0, 0, 3, 1, 2, 2, 2, 2, 0, 2, 0, 2, 0, 3, 3, 3, 1, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 60 and the episode is 316 and the total_steps are 32574\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | -950     |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 530      |\n",
      "|    total_timesteps  | 32574    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 2, 3, 2, 0, 2, 3, 0, 3, 2, 2, 0, 2, 1, 2, 0, 2, 1, 3, 3, 0, 1, 1, 2, 1, 3, 3, 1, 3, 1, 3, 2, 1, 3, 2, 1, 1, 0, 1, 3, 0, 3, 0, 0, 0, 0, 2, 2, 1, 3, 1, 0, 2, 1, 3, 1, 0, 1, 1, 2, 1, 2, 1, 1, 3, 1, 2, 2, 0, 2, 1, 3, 2, 3, 0, 2, 0, 0, 1, 3, 0, 3, 1, 2, 0, 0, 2, 3, 0, 0, 1, 2, 1, 3, 1, 0, 0, 1, 3, 1, 2, 1, 2, 1, 3, 2, 0, 1, 1, 3, 1, 2, 3, 2, 1, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 122 and the episode is 317 and the total_steps are 32696\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 2, 3, 0, 3, 1, 0, 3, 1, 3, 3, 3, 0, 3, 0, 1, 2, 0, 0, 0, 2, 1, 1, 3, 3, 2, 0, 3, 1, 1, 0, 1, 2, 3, 3, 0, 0, 1, 0, 3, 2, 0, 2, 1, 0, 0, 0, 2, 3, 0, 0, 2, 0, 2, 2, 3, 1, 0, 0, 0, 0, 1, 3, 3, 3, 1, 2, 3, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1073. And steps were 75 and the episode is 318 and the total_steps are 32771\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 1, 0, 1, 1, 2, 0, 1, 1, 2, 1, 1, 0, 1, 2, 0, 1, 3, 1, 2, 3, 3, 2, 3, 1, 3, 3, 3, 2, 0, 2, 2, 1, 3, 1, 0, 2, 1, 2, 3, 0, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1057. And steps were 59 and the episode is 319 and the total_steps are 32830\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 3, 2, 2, 1, 2, 0, 3, 2, 3, 1, 2, 0, 0, 2, 0, 0, 3, 0, 3, 3, 1, 3, 1, 0, 0, 3, 3, 2, 2, 1, 3, 3, 2, 1, 1, 1, 3, 3, 3, 0, 3, 0, 2, 2, 3, 3, 3, 1, 2, 1, 2, 2, 3, 3, 1, 2, 2, 3, 1, 1, 1, 1, 2, 0, 2, 1, 1, 3, 1, 3, 2, 3, 1, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -925. And steps were 81 and the episode is 320 and the total_steps are 32911\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | -948     |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 535      |\n",
      "|    total_timesteps  | 32911    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 0, 3, 3, 3, 3, 0, 1, 0, 2, 3, 2, 3, 0, 1, 3, 2, 1, 1, 3, 0, 0, 1, 3, 2, 1, 0, 0, 1, 2, 2, 0, 1, 1, 2, 2, 0, 3, 3, 0, 3, 1, 2, 0, 1, 0, 2, 0, 0, 3, 0, 2, 0, 3, 0, 1, 2, 3, 3, 3, 3, 2, 0, 0, 1, 3, 0, 1, 3, 0, 1, 3, 3, 0, 1, 0, 0, 0, 1, 3, 2, 0, 2, 1, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 1, 2, 3, 0, 2, 2, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 107 and the episode is 321 and the total_steps are 33018\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 3, 2, 0, 2, 0, 1, 2, 1, 1, 3, 2, 1, 3, 3, 3, 0, 1, 0, 0, 0, 0, 3, 2, 2, 1, 2, 3, 1, 2, 2, 0, 1, 2, 2, 0, 1, 2, 1, 3, 2, 2, 3, 0, 3, 3, 3, 0, 1, 3, 3, 0, 1, 2, 1, 0, 3, 1, 0, 3, 0, 2, 3, 3, 1, 0, 3, 1, 2, 1, 0, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 0, 2, 0, 2, 0, 2, 1, 2, 2, 2, 2, 0, 2, 1, 0, 1, 3, 2, 3, 2, 2, 1, 1, 3, 1, 1, 3, 0, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -912. And steps were 126 and the episode is 322 and the total_steps are 33144\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 3, 3, 3, 3, 2, 3, 0, 0, 1, 3, 2, 3, 1, 1, 3, 1, 3, 0, 0, 1, 3, 0, 2, 0, 2, 1, 2, 3, 1, 3, 3, 2, 0, 3, 0, 2, 2, 0, 1, 0, 1, 0, 3, 1, 3, 3, 3, 3, 2, 0, 2, 1, 0, 0, 0, 3, 0, 2, 2, 2, 2, 1, 0, 3, 3, 0, 2, 2, 1, 3, 1, 1, 3, 0, 0, 2, 1, 0, 3, 0, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 88 and the episode is 323 and the total_steps are 33232\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 1, 3, 3, 2, 3, 1, 0, 1, 2, 2, 1, 0, 1, 3, 3, 1, 1, 1, 3, 3, 0, 0, 0, 1, 2, 2, 2, 3, 1, 2, 2, 2, 0, 2, 2, 0, 2, 1, 1, 1, 3, 2, 0, 2, 0, 2, 2, 1, 0, 2, 3, 1, 2, 0, 0, 3, 0, 2, 2, 3, 3, 3, 3, 0, 2, 1, 1, 2, 0, 1, 2, 2, 0, 1, 1, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 3, 1, 2, 0, 1, 3, 2, 3, 1, 1, 2, 3, 0, 1, 2, 0, 3, 3, 3, 3, 1, 3, 3, 3, 0, 2, 3, 0, 0, 0, 1, 1, 3, 2, 1, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -918. And steps were 138 and the episode is 324 and the total_steps are 33370\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 542      |\n",
      "|    total_timesteps  | 33370    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 3, 3, 1, 1, 3, 0, 2, 0, 1, 0, 2, 1, 2, 2, 0, 0, 1, 1, 2, 2, 0, 1, 3, 2, 2, 2, 3, 0, 2, 0, 0, 2, 0, 3, 1, 0, 0, 3, 1, 2, 0, 0, 2, 0, 1, 0, 0, 1, 1, 2, 3, 2, 1, 3, 2, 2, 0, 3, 3, 3, 0, 1, 3, 1, 3, 3, 1, 3, 1, 2, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -934. And steps were 78 and the episode is 325 and the total_steps are 33448\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 1, 3, 0, 3, 3, 1, 3, 1, 2, 3, 2, 2, 1, 2, 2, 1, 3, 0, 1, 3, 3, 3, 1, 0, 2, 2, 1, 0, 1, 2, 0, 3, 2, 2, 1, 3, 3, 3, 2, 0, 3, 0, 0, 3, 3, 0, 0, 0, 3, 2, 3, 3, 1, 3, 1, 1, 0, 0, 0, 1, 2, 2, 1, 2, 0, 2, 1, 3, 2, 2, 1, 2, 0, 0, 1, 0, 2, 0, 0, 3, 0, 2, 2, 3, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 3, 1, 1, 2, 1, 3, 0, 3, 3, 2, 1, 3, 3, 0, 0, 2, 3, 2, 1, 2, 0, 1, 3, 1, 0, 3, 2, 2, 1, 1, 1, 0, 0, 2, 3, 1, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 0, 0, 3, 1, 1, 1, 2, 2, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 1, 3, 3, 1, 1, 0, 1, 1, 0, 0, 2, 0, 1, 3, 2, 0, 2, 1, 1, 1, 0, 3, 2, 1, 2, 3, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -854. And steps were 192 and the episode is 326 and the total_steps are 33640\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 0, 1, 3, 0, 3, 1, 0, 3, 0, 0, 2, 2, 2, 3, 3, 2, 0, 3, 3, 1, 1, 0, 0, 2, 3, 3, 3, 1, 1, 1, 0, 2, 0, 0, 3, 0, 0, 2, 2, 2, 2, 2, 0, 1, 2, 0, 0, 1, 0, 2, 0, 2, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1057. And steps were 58 and the episode is 327 and the total_steps are 33698\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 3, 3, 1, 3, 0, 2, 1, 2, 3, 2, 0, 0, 3, 1, 3, 0, 0, 2, 2, 0, 0, 0, 1, 2, 1, 3, 2, 0, 1, 2, 2, 3, 1, 3, 2, 1, 0, 0, 3, 3, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1041. And steps were 46 and the episode is 328 and the total_steps are 33744\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 548      |\n",
      "|    total_timesteps  | 33744    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 0, 1, 3, 3, 1, 2, 2, 3, 0, 2, 2, 2, 3, 1, 2, 1, 3, 2, 1, 3, 2, 2, 1, 2, 0, 3, 0, 1, 3, 3, 2, 0, 2, 2, 3, 0, 0, 3, 3, 3, 2, 3, 2, 3, 1, 0, 3, 3, 2, 1, 1, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 59 and the episode is 329 and the total_steps are 33803\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 1, 1, 2, 2, 3, 3, 3, 0, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 0, 2, 2, 2, 2, 1, 2, 0, 3, 1, 0, 2, 0, 0, 1, 3, 0, 3, 1, 0, 1, 1, 2, 0, 1, 3, 1, 3, 1, 1, 2, 1, 3, 2, 1, 3, 3, 1, 1, 1, 3, 2, 3, 3, 1, 2, 2, 1, 1, 3, 3, 2, 2, 0, 3, 1, 3, 2, 2, 0, 3, 3, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 88 and the episode is 330 and the total_steps are 33891\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 3, 3, 2, 3, 2, 3, 2, 0, 3, 0, 0, 0, 0, 1, 3, 0, 1, 2, 1, 2, 1, 2, 0, 3, 0, 0, 1, 0, 0, 3, 0, 3, 1, 3, 2, 3, 3, 2, 0, 3, 1, 1, 2, 3, 2, 1, 0, 3, 1, 1, 3, 0, 1, 3, 2, 1, 3, 0, 2, 1, 1, 1, 0, 2, 1, 2, 3, 0, 1, 3, 2, 1, 0, 1, 0, 1, 1, 3, 2, 3, 3, 3, 1, 3, 1, 2, 2, 1, 3, 0, 0, 0, 2, 2, 1, 2, 1, 0, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 106 and the episode is 331 and the total_steps are 33997\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 0, 2, 1, 3, 0, 0, 3, 0, 1, 1, 1, 1, 0, 2, 0, 0, 2, 0, 3, 3, 2, 3, 3, 3, 0, 1, 3, 1, 2, 3, 2, 3, 3, 1, 3, 1, 2, 1, 1, 0, 3, 1, 3, 0, 2, 2, 2, 2, 3, 0, 2, 3, 1, 3, 0, 2, 0, 0, 2, 0, 0, 3, 3, 1, 0, 3, 1, 1, 3, 2, 2, 3, 1, 1, 0, 0, 1, 3, 3, 1, 1, 3, 2, 1, 2, 0, 3, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, 2, 1, 3, 0, 1, 3, 3, 0, 0, 2, 1, 0, 3, 1, 0, 1, 0, 2, 1, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -925. And steps were 125 and the episode is 332 and the total_steps are 34122\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 555      |\n",
      "|    total_timesteps  | 34122    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 0, 0, 2, 0, 3, 1, 2, 3, 0, 0, 1, 3, 1, 2, 0, 3, 3, 3, 0, 2, 1, 0, 1, 2, 2, 0, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1, 2, 3, 1, 1, 3, 2, 3, 0, 1, 3, 1, 3, 3, 2, 0, 1, 0, 3, 3, 2, 2, 3, 0, 0, 1, 2, 2, 0, 0, 0, 3, 1, 1, 0, 2, 0, 3, 0, 3, 2, 3, 0, 3, 2, 1, 3, 0, 2, 0, 3, 2, 0, 1, 2, 0, 3, 1, 3, 3, 1, 0, 2, 2, 3, 3, 3, 3, 3, 1, 0, 2, 1, 3, 3, 0, 2, 2, 1, 0, 3, 1, 0, 3, 1, 0, 1, 0, 3, 0, 1, 2, 0, 1, 2, 3, 3, 1, 2, 0, 2, 2, 1, 1, 2, 3, 2, 1, 3, 3, 3, 0, 3, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 156 and the episode is 333 and the total_steps are 34278\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 3, 0, 0, 2, 0, 3, 1, 2, 3, 2, 2, 2, 3, 3, 2, 3, 0, 2, 2, 3, 0, 2, 3, 2, 3, 3, 3, 0, 1, 3, 0, 2, 2, 2, 1, 2, 2, 3, 3, 0, 0, 3, 3, 0, 3, 0, 1, 3, 3, 2, 0, 0, 1, 2, 1, 1, 0, 3, 3, 1, 3, 1, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 70 and the episode is 334 and the total_steps are 34348\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 0, 0, 3, 3, 0, 1, 1, 2, 3, 0, 2, 2, 3, 1, 2, 3, 1, 0, 2, 2, 1, 1, 3, 3, 0, 3, 1, 0, 3, 0, 0, 2, 1, 3, 1, 1, 0, 0, 2, 3, 1, 2, 1, 2, 0, 2, 2, 0, 2, 1, 0, 3, 1, 0, 3, 2, 0, 0, 0, 2, 2, 2, 2, 3, 0, 3, 1, 1, 3, 0, 2, 3, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 80 and the episode is 335 and the total_steps are 34428\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 1, 3, 0, 1, 1, 0, 0, 3, 2, 1, 2, 2, 0, 0, 2, 0, 1, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 1, 3, 1, 0, 3, 3, 2, 2, 0, 2, 3, 2, 3, 0, 3, 2, 2, 0, 1, 1, 0, 1, 2, 1, 2, 3, 0, 0, 2, 3, 1, 0, 0, 0, 3, 3, 1, 1, 0, 0, 0, 3, 2, 3, 2, 3, 0, 1, 3, 3, 0, 1, 3, 3, 0, 0, 0, 2, 0, 1, 0, 0, 1, 2, 0, 3, 3, 0, 1, 1, 2, 3, 2, 2, 1, 0, 0, 2, 3, 1, 0, 0, 1, 1, 2, 1, 3, 0, 3, 3, 1, 3, 3, 1, 2, 0, 1, 2, 3, 3, 0, 2, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -903. And steps were 137 and the episode is 336 and the total_steps are 34565\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 562      |\n",
      "|    total_timesteps  | 34565    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 2, 0, 3, 3, 2, 3, 1, 3, 2, 0, 0, 2, 3, 0, 3, 0, 2, 1, 3, 0, 2, 1, 0, 1, 2, 2, 3, 3, 3, 3, 0, 2, 2, 0, 0, 3, 3, 3, 0, 0, 1, 2, 0, 0, 2, 3, 1, 3, 3, 2, 1, 0, 2, 1, 0, 3, 3, 2, 2, 0, 1, 3, 0, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -943. And steps were 71 and the episode is 337 and the total_steps are 34636\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 2, 3, 2, 3, 3, 1, 1, 3, 2, 3, 0, 2, 0, 0, 1, 0, 2, 0, 0, 2, 1, 2, 0, 2, 3, 2, 3, 0, 0, 3, 2, 3, 2, 0, 1, 1, 2, 0, 2, 2, 0, 0, 1, 0, 3, 0, 2, 0, 0, 3, 3, 3, 2, 3, 0, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was 1060. And steps were 61 and the episode is 338 and the total_steps are 34697\n",
      "Skiping this step\n",
      "Done condition: max time steps reached\n",
      "[0, 2, 3, 1, 3, 1, 2, 1, 2, 1, 0, 2, 0, 3, 1, 3, 1, 2, 2, 1, 2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 1, 1, 3, 0, 2, 0, 1, 2, 1, 1, 0, 2, 2, 0, 1, 0, 3, 3, 2, 1, 1, 2, 2, 2, 1, 3, 1, 1, 1, 1, 0, 2, 0, 3, 1, 1, 1, 1, 2, 3, 0, 2, 3, 0, 1, 0, 1, 0, 3, 0, 0, 1, 0, 1, 0, 3, 3, 3, 1, 2, 0, 1, 3, 2, 3, 0, 0, 2, 0, 0, 0, 2, 2, 3, 2, 0, 1, 3, 0, 0, 1, 3, 1, 0, 3, 3, 3, 3, 0, 1, 0, 1, 2, 2, 1, 1, 0, 2, 3, 0, 0, 1, 0, 0, 2, 0, 1, 2, 3, 2, 0, 2, 2, 2, 0, 1, 2, 2, 0, 2, 1, 3, 3, 1, 1, 3, 2, 2, 0, 0, 0, 1, 2, 2, 1, 1, 0, 3, 0, 1, 1, 3, 0, 0, 1, 2, 3, 2, 0, 1, 1, 2, 3, 0, 1, 0, 0, 3, 3, 1, 2, 3, 1, 1, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1305. And steps were 202 and the episode is 339 and the total_steps are 34899\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 1, 0, 0, 1, 1, 2, 2, 0, 1, 3, 3, 2, 3, 3, 0, 2, 2, 2, 2, 0, 2, 2, 2, 3, 0, 3, 2, 0, 2, 0, 1, 0, 2, 0, 3, 0, 3, 3, 2, 0, 2, 0, 2, 1, 3, 1, 0, 1, 1, 3, 0, 1, 1, 0, 0, 2, 0, 3, 3, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 67 and the episode is 340 and the total_steps are 34966\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 568      |\n",
      "|    total_timesteps  | 34966    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 1, 2, 3, 2, 0, 0, 3, 1, 1, 3, 3, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3, 2, 2, 2, 0, 2, 0, 2, 3, 3, 2, 3, 3, 2, 1, 2, 3, 2, 0, 1, 2, 2, 2, 3, 2, 2, 1, 1, 0, 3, 2, 3, 0, 3, 0, 0, 3, 2, 2, 1, 1, 3, 3, 3, 2, 2, 3, 0, 0, 2, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 86 and the episode is 341 and the total_steps are 35052\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 0, 0, 2, 2, 1, 1, 0, 1, 0, 3, 0, 2, 1, 2, 2, 1, 0, 1, 0, 0, 3, 2, 1, 0, 2, 0, 1, 3, 3, 0, 3, 0, 2, 2, 1, 2, 3, 3, 1, 3, 1, 1, 3, 0, 1, 1, 1, 3, 3, 1, 1, 3, 2, 3, 3, 2, 3, 0, 2, 3, 3, 3, 1, 3, 0, 2, 0, 1, 1, 1, 3, 2, 1, 2, 2, 3, 2, 2, 0, 0, 3, 2, 1, 2, 0, 3, 1, 0, 1, 3, 3, 0, 1, 3, 2, 0, 0, 3, 3, 3, 3, 1, 1, 3, 2, 2, 1, 0, 0, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -895. And steps were 117 and the episode is 342 and the total_steps are 35169\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 0, 1, 2, 3, 2, 2, 0, 1, 3, 3, 0, 0, 3, 1, 2, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3, 3, 3, 0, 2, 0, 3, 1, 0, 1, 2, 2, 1, 1, 2, 3, 3, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1056. And steps were 58 and the episode is 343 and the total_steps are 35227\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 3, 3, 3, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 3, 1, 0, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 0, 2, 1, 3, 2, 2, 2, 2, 0, 1, 1, 1, 1, 0, 3, 1, 0, 3, 1, 2, 1, 1, 1, 3, 2, 2, 3, 3, 0, 1, 1, 3, 2, 3, 2, 0, 2, 2, 2, 0, 0, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -931. And steps were 81 and the episode is 344 and the total_steps are 35308\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 574      |\n",
      "|    total_timesteps  | 35308    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 1, 1, 3, 3, 3, 3, 0, 2, 1, 3, 0, 1, 2, 2, 1, 0, 3, 0, 0, 0, 0, 1, 0, 0, 3, 2, 3, 3, 3, 1, 1, 3, 0, 0, 3, 0, 3, 3, 3, 2, 2, 1, 3, 1, 3, 0, 3, 0, 0, 1, 0, 0, 2, 1, 2, 0, 0, 2, 3, 1, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 69 and the episode is 345 and the total_steps are 35377\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 2, 3, 1, 2, 3, 1, 2, 2, 3, 2, 1, 3, 2, 1, 0, 3, 2, 3, 1, 1, 2, 2, 3, 1, 0, 1, 0, 1, 3, 2, 1, 0, 2, 0, 1, 2, 2, 3, 2, 1, 1, 2, 2, 2, 3, 2, 3, 1, 3, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1055. And steps were 57 and the episode is 346 and the total_steps are 35434\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 1, 3, 1, 2, 0, 1, 3, 0, 0, 2, 1, 2, 2, 3, 3, 1, 1, 1, 1, 1, 2, 2, 1, 3, 3, 0, 2, 1, 0, 2, 2, 0, 3, 2, 2, 3, 1, 2, 3, 0, 3, 0, 3, 2, 0, 2, 2, 2, 1, 3, 1, 1, 0, 3, 1, 3, 2, 3, 0, 1, 0, 2, 3, 3, 0, 1, 0, 1, 1, 0, 0, 0, 3, 1, 3, 3, 1, 0, 3, 3, 0, 1, 3, 2, 3, 2, 2, 0, 0, 2, 3, 1, 1, 0, 2, 0, 2, 2, 1, 1, 2, 2, 2, 3, 2, 1, 0, 0, 3, 1, 0, 1, 3, 0, 2, 1, 2, 0, 1, 1, 1, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1127. And steps were 129 and the episode is 347 and the total_steps are 35563\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 2, 1, 1, 2, 2, 0, 3, 0, 2, 2, 0, 2, 2, 3, 2, 1, 0, 2, 0, 0, 1, 3, 1, 1, 1, 2, 1, 2, 3, 2, 2, 3, 1, 3, 1, 0, 0, 0, 2, 3, 2, 2, 0, 3, 3, 3, 2, 3, 2, 3, 1, 1, 1, 0, 1, 0, 3, 2, 2, 2, 0, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 69 and the episode is 348 and the total_steps are 35632\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 579      |\n",
      "|    total_timesteps  | 35632    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 3, 1, 1, 2, 1, 2, 1, 3, 3, 0, 0, 1, 2, 0, 2, 2, 1, 0, 2, 2, 1, 3, 0, 0, 1, 0, 3, 1, 0, 0, 1, 0, 1, 3, 1, 3, 0, 1, 3, 2, 3, 1, 0, 3, 3, 3, 1, 2, 2, 1, 3, 1, 3, 0, 3, 2, 0, 2, 0, 1, 0, 2, 3, 2, 2, 2, 1, 1, 3, 3, 2, 3, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 80 and the episode is 349 and the total_steps are 35712\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 1, 1, 1, 1, 1, 0, 3, 1, 2, 0, 2, 0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 2, 2, 2, 1, 1, 2, 0, 3, 0, 1, 1, 1, 1, 2, 3, 3, 0, 2, 0, 3, 3, 0, 0, 3, 1, 2, 2, 1, 0, 2, 2, 2, 1, 3, 3, 1, 1, 0, 1, 1, 3, 2, 1, 0, 3, 0, 0, 2, 3, 2, 1, 0, 2, 0, 3, 0, 1, 0, 1, 0, 3, 1, 2, 2, 1, 1, 3, 1, 0, 2, 0, 3, 2, 2, 2, 3, 0, 1, 1, 3, 1, 2, 3, 2, 1, 3, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -918. And steps were 116 and the episode is 350 and the total_steps are 35828\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 3, 3, 2, 1, 3, 0, 3, 3, 1, 3, 1, 1, 1, 0, 1, 0, 0, 3, 2, 3, 1, 1, 3, 3, 0, 2, 1, 1, 2, 3, 0, 1, 1, 2, 2, 0, 2, 3, 1, 1, 0, 0, 3, 1, 1, 1, 0, 3, 2, 2, 2, 2, 1, 3, 0, 2, 2, 0, 0, 3, 0, 1, 2, 2, 3, 1, 3, 2, 1, 1, 1, 0, 3, 2, 1, 3, 0, 3, 2, 0, 2, 1, 0, 3, 2, 2, 2, 3, 3, 1, 3, 1, 2, 0, 1, 1, 0, 1, 0, 1, 2, 1, 1, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 111 and the episode is 351 and the total_steps are 35939\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 3, 2, 2, 1, 0, 3, 3, 1, 3, 2, 1, 2, 1, 0, 1, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 0, 3, 2, 3, 2, 2, 2, 2, 2, 1, 0, 2, 2, 3, 3, 0, 1, 3, 1, 1, 3, 2, 2, 3, 3, 0, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1058. And steps were 60 and the episode is 352 and the total_steps are 35999\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 585      |\n",
      "|    total_timesteps  | 35999    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 3, 3, 3, 0, 0, 0, 0, 2, 2, 3, 1, 1, 1, 3, 1, 1, 0, 1, 3, 1, 3, 1, 1, 1, 2, 1, 3, 1, 1, 3, 1, 1, 1, 3, 3, 0, 0, 0, 1, 3, 1, 2, 0, 1, 0, 1, 1, 3, 1, 1, 0, 0, 1, 1, 3, 2, 3, 1, 0, 3, 0, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 76 and the episode is 353 and the total_steps are 36075\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 2, 3, 1, 3, 1, 1, 1, 1, 0, 3, 1, 2, 0, 2, 3, 3, 1, 2, 3, 2, 1, 1, 3, 3, 1, 1, 0, 3, 0, 2, 3, 2, 3, 2, 1, 0, 0, 3, 1, 2, 1, 0, 0, 3, 2, 1, 0, 1, 1, 0, 1, 2, 2, 3, 0, 0, 3, 1, 2, 2, 3, 1, 3, 0, 2, 0, 1, 2, 3, 2, 0, 1, 2, 1, 1, 1, 0, 3, 3, 0, 1, 0, 0, 3, 0, 3, 1, 1, 0, 3, 0, 1, 3, 0, 1, 3, 2, 3, 3, 3, 1, 2, 0, 3, 2, 2, 3, 1, 3, 2, 2, 1, 1, 2, 2, 1, 1, 2, 3, 3, 0, 1, 2, 0, 3, 1, 3, 3, 0, 1, 3, 0, 3, 2, 0, 0, 0, 3, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 146 and the episode is 354 and the total_steps are 36221\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 0, 0, 2, 3, 0, 0, 2, 2, 2, 0, 3, 0, 1, 1, 2, 3, 1, 2, 0, 2, 3, 0, 3, 3, 2, 0, 3, 3, 3, 3, 0, 2, 1, 3, 1, 0, 1, 1, 3, 1, 2, 1, 2, 3, 1, 0, 1, 2, 2, 3, 1, 3, 2, 3, 1, 3, 3, 1, 0, 2, 2, 3, 3, 2, 1, 2, 1, 1, 3, 3, 1, 0, 2, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 81 and the episode is 355 and the total_steps are 36302\n",
      "Done condition: max time steps reached\n",
      "[1, 2, 1, 1, 0, 1, 0, 0, 3, 0, 3, 0, 0, 3, 3, 3, 0, 3, 2, 3, 0, 0, 2, 2, 0, 0, 2, 2, 0, 3, 2, 3, 3, 3, 3, 1, 3, 1, 0, 0, 1, 2, 0, 1, 3, 3, 1, 3, 0, 2, 1, 2, 3, 1, 0, 0, 2, 3, 2, 2, 1, 1, 0, 2, 3, 1, 1, 2, 1, 3, 1, 0, 1, 0, 1, 2, 2, 2, 0, 3, 0, 2, 2, 3, 2, 1, 2, 0, 2, 3, 3, 1, 0, 0, 3, 0, 2, 1, 2, 2, 2, 3, 0, 1, 1, 0, 2, 3, 0, 0, 1, 1, 3, 0, 1, 1, 1, 0, 0, 0, 3, 0, 0, 2, 2, 2, 2, 0, 3, 1, 0, 2, 3, 3, 0, 1, 1, 1, 1, 3, 1, 3, 3, 0, 2, 3, 2, 3, 3, 1, 3, 3, 2, 1, 3, 2, 0, 0, 3, 0, 0, 0, 1, 2, 1, 3, 3, 3, 3, 2, 2, 3, 0, 2, 3, 0, 0, 3, 3, 0, 0, 3, 3, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 1, 2, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 202 and the episode is 356 and the total_steps are 36504\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 593      |\n",
      "|    total_timesteps  | 36504    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 3, 1, 2, 2, 1, 3, 3, 1, 1, 2, 0, 2, 0, 3, 2, 2, 3, 3, 1, 3, 0, 2, 2, 3, 3, 1, 0, 1, 2, 1, 3, 3, 3, 1, 2, 2, 1, 3, 3, 2, 2, 0, 1, 3, 3, 3, 3, 1, 0, 3, 2, 3, 1, 2, 2, 0, 2, 3, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 66 and the episode is 357 and the total_steps are 36570\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 1, 3, 0, 3, 2, 1, 2, 2, 0, 0, 2, 3, 1, 1, 2, 3, 3, 2, 0, 0, 0, 1, 2, 0, 1, 2, 3, 2, 3, 1, 0, 2, 0, 0, 1, 0, 1, 1, 2, 2, 3, 3, 0, 2, 0, 1, 3, 3, 3, 0, 2, 2, 2, 0, 3, 0, 3, 2, 3, 1, 3, 0, 1, 2, 1, 3, 2, 2, 2, 0, 0, 0, 1, 2, 0, 2, 0, 0, 3, 2, 0, 3, 0, 0, 3, 3, 0, 3, 0, 1, 0, 2, 1, 0, 1, 2, 2, 1, 3, 0, 0, 2, 3, 3, 0, 3, 0, 1, 1, 3, 3, 0, 1, 3, 2, 3, 0, 0, 1, 2, 0, 0, 1, 1, 3, 0, 2, 2, 3, 0, 3, 2, 1, 1, 0, 1, 0, 0, 3, 3, 2, 3, 0, 1, 2, 2, 3, 2, 2, 0, 3, 0, 2, 2, 0, 0, 3, 1, 1, 1, 2, 2, 2, 3, 0, 0, 1, 2, 1, 1, 2, 2, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 180 and the episode is 358 and the total_steps are 36750\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 0, 2, 1, 1, 0, 1, 2, 3, 3, 1, 2, 1, 0, 2, 3, 2, 1, 2, 0, 2, 1, 3, 3, 2, 2, 2, 0, 3, 1, 1, 0, 1, 1, 2, 3, 1, 1, 0, 2, 0, 0, 0, 1, 2, 1, 0, 2, 0, 2, 2, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 58 and the episode is 359 and the total_steps are 36808\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 0, 2, 1, 2, 3, 1, 1, 0, 2, 2, 1, 0, 1, 1, 2, 3, 3, 2, 1, 0, 1, 0, 0, 0, 2, 0, 1, 3, 0, 0, 3, 1, 1, 0, 0, 1, 3, 3, 2, 2, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 3, 2, 3, 1, 0, 0, 1, 0, 1, 3, 2, 2, 1, 0, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 72 and the episode is 360 and the total_steps are 36880\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 599      |\n",
      "|    total_timesteps  | 36880    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 1, 2, 1, 2, 2, 0, 1, 2, 3, 0, 1, 3, 3, 1, 1, 3, 0, 3, 0, 2, 3, 2, 0, 1, 2, 0, 1, 2, 2, 3, 1, 3, 0, 3, 0, 2, 2, 1, 1, 2, 1, 3, 0, 0, 0, 3, 1, 3, 3, 2, 1, 3, 0, 3, 0, 3, 0, 2, 1, 3, 1, 0, 2, 0, 0, 2, 1, 0, 3, 1, 1, 0, 0, 3, 3, 1, 1, 0, 1, 3, 3, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 2, 2, 3, 1, 0, 0, 0, 0, 3, 0, 3, 0, 0, 1, 1, 1, 2, 2, 0, 1, 3, 1, 2, 1, 3, 2, 2, 1, 0, 0, 0, 2, 0, 3, 2, 2, 2, 1, 3, 0, 1, 1, 0, 1, 0, 2, 1, 1, 0, 1, 2, 2, 0, 3, 0, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 171 and the episode is 361 and the total_steps are 37051\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 3, 2, 0, 0, 0, 0, 2, 2, 3, 0, 3, 0, 1, 2, 3, 0, 1, 2, 3, 3, 2, 1, 0, 3, 1, 1, 2, 2, 3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 0, 3, 2, 1, 2, 2, 1, 3, 0, 0, 3, 3, 1, 2, 1, 0, 3, 1, 3, 1, 1, 2, 3, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -941. And steps were 69 and the episode is 362 and the total_steps are 37120\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 1, 1, 2, 2, 0, 0, 0, 1, 3, 3, 1, 0, 1, 3, 0, 0, 0, 3, 3, 3, 3, 0, 1, 0, 3, 1, 2, 2, 2, 2, 2, 0, 0, 3, 1, 1, 0, 2, 0, 0, 0, 3, 2, 0, 1, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1050. And steps were 51 and the episode is 363 and the total_steps are 37171\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 3, 2, 1, 2, 2, 3, 2, 0, 2, 1, 0, 2, 0, 2, 3, 2, 1, 3, 0, 3, 2, 1, 3, 0, 3, 0, 2, 0, 1, 2, 3, 2, 3, 2, 2, 2, 3, 2, 0, 2, 3, 2, 3, 0, 0, 3, 3, 2, 2, 0, 3, 2, 3, 1, 2, 2, 0, 1, 2, 1, 2, 1, 0, 3, 2, 0, 0, 3, 0, 0, 1, 0, 2, 1, 1, 0, 3, 2, 2, 0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 1, 3, 0, 2, 2, 1, 1, 1, 0, 1, 1, 0, 2, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 110 and the episode is 364 and the total_steps are 37281\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -855     |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 606      |\n",
      "|    total_timesteps  | 37281    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 3, 1, 1, 1, 3, 1, 0, 3, 0, 3, 0, 0, 1, 1, 2, 2, 2, 2, 0, 1, 2, 3, 0, 1, 2, 2, 0, 3, 0, 1, 1, 3, 0, 3, 0, 1, 1, 3, 3, 0, 3, 1, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1043. And steps were 48 and the episode is 365 and the total_steps are 37329\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 0, 0, 2, 1, 0, 0, 1, 0, 2, 3, 3, 3, 1, 3, 1, 2, 3, 0, 2, 2, 1, 2, 0, 0, 1, 2, 3, 0, 0, 2, 3, 1, 1, 3, 1, 0, 1, 1, 0, 2, 3, 1, 2, 0, 1, 0, 1, 1, 0, 2, 1, 0, 2, 0, 3, 1, 1, 1, 1, 0, 1, 0, 3, 0, 1, 3, 3, 3, 1, 1, 0, 2, 3, 1, 2, 0, 2, 2, 1, 3, 2, 3, 0, 0, 1, 2, 2, 2, 0, 3, 1, 0, 3, 0, 3, 1, 0, 3, 2, 3, 0, 1, 0, 2, 1, 0, 1, 2, 3, 2, 1, 1, 0, 2, 1, 2, 2, 2, 3, 2, 2, 2, 0, 2, 2, 0, 1, 0, 3, 2, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -912. And steps were 138 and the episode is 366 and the total_steps are 37467\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 0, 2, 3, 0, 1, 0, 3, 3, 1, 1, 3, 3, 3, 0, 1, 3, 3, 2, 3, 3, 1, 1, 3, 3, 0, 3, 2, 0, 1, 2, 0, 0, 3, 1, 3, 2, 1, 2, 3, 2, 3, 1, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 2, 1, 1, 3, 2, 1, 3, 1, 3, 3, 1, 0, 3, 0, 3, 1, 3, 0, 3, 2, 0, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 81 and the episode is 367 and the total_steps are 37548\n",
      "Done condition: max time steps reached\n",
      "[3, 1, 0, 2, 2, 1, 2, 0, 1, 1, 1, 0, 2, 0, 2, 3, 3, 1, 1, 0, 2, 3, 1, 3, 0, 1, 2, 1, 1, 3, 0, 0, 2, 2, 2, 0, 0, 2, 2, 3, 0, 0, 1, 0, 2, 0, 3, 2, 3, 1, 0, 2, 1, 2, 0, 3, 3, 1, 3, 3, 1, 0, 3, 1, 1, 3, 2, 1, 3, 3, 0, 0, 3, 2, 2, 2, 3, 1, 0, 3, 0, 3, 2, 1, 3, 3, 3, 3, 2, 2, 3, 2, 0, 2, 3, 3, 3, 1, 3, 3, 3, 1, 0, 2, 1, 3, 0, 1, 2, 0, 0, 2, 2, 1, 0, 2, 0, 2, 0, 1, 2, 0, 0, 0, 3, 1, 2, 0, 3, 2, 0, 0, 2, 3, 1, 2, 2, 1, 2, 1, 1, 1, 2, 3, 0, 3, 3, 3, 2, 3, 3, 2, 0, 0, 0, 0, 2, 0, 3, 1, 3, 2, 3, 3, 2, 1, 3, 3, 3, 3, 2, 0, 2, 3, 0, 1, 0, 1, 1, 1, 2, 2, 2, 3, 3, 2, 2, 3, 2, 3, 1, 1, 3, 0, 3, 3, 1, 0, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1399. And steps were 202 and the episode is 368 and the total_steps are 37750\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -839     |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 614      |\n",
      "|    total_timesteps  | 37750    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 3, 0, 3, 0, 3, 3, 2, 0, 3, 3, 0, 1, 3, 2, 3, 0, 3, 1, 1, 2, 0, 1, 3, 0, 1, 0, 0, 0, 1, 2, 1, 3, 0, 3, 2, 0, 3, 3, 3, 1, 0, 0, 2, 0, 0, 1, 3, 0, 3, 0, 0, 3, 2, 1, 2, 1, 0, 3, 1, 0, 1, 0, 2, 0, 1, 2, 2, 0, 1, 2, 3, 2, 0, 0, 1, 1, 1, 0, 1, 3, 0, 2, 1, 2, 2, 0, 0, 3, 3, 0, 2, 3, 1, 0, 1, 1, 1, 0, 2, 2, 2, 0, 2, 1, 3, 2, 0, 1, 0, 2, 2, 1, 3, 2, 0, 2, 1, 0, 1, 2, 1, 1, 2, 1, 3, 3, 0, 2, 0, 1, 2, 2, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -892. And steps were 140 and the episode is 369 and the total_steps are 37890\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 1, 3, 2, 1, 3, 1, 3, 3, 2, 2, 1, 2, 2, 1, 3, 0, 2, 0, 1, 0, 3, 2, 2, 1, 0, 1, 1, 3, 3, 2, 1, 3, 3, 0, 2, 3, 1, 3, 3, 1, 2, 3, 3, 0, 2, 1, 0, 1, 3, 0, 1, 2, 1, 1, 0, 1, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was 1061. And steps were 62 and the episode is 370 and the total_steps are 37952\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 3, 3, 3, 0, 0, 2, 2, 1, 2, 1, 2, 1, 2, 2, 0, 1, 1, 2, 0, 3, 1, 1, 2, 0, 2, 1, 2, 0, 3, 0, 2, 3, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 1, 3, 0, 3, 1, 3, 0, 0, 3, 1, 1, 0, 2, 0, 0, 0, 3, 1, 1, 2, 3, 1, 3, 2, 2, 0, 0, 2, 0, 1, 2, 0, 0, 2, 1, 2, 0, 0, 0, 0, 2, 3, 0, 0, 0, 2, 2, 0, 2, 3, 2, 0, 3, 2, 0, 1, 3, 3, 1, 2, 1, 3, 2, 3, 1, 0, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -936. And steps were 118 and the episode is 371 and the total_steps are 38070\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 3, 1, 0, 0, 2, 1, 2, 2, 3, 0, 3, 2, 0, 3, 3, 3, 0, 1, 2, 3, 1, 1, 1, 3, 1, 2, 1, 1, 3, 0, 3, 2, 0, 0, 0, 0, 1, 2, 2, 1, 1, 1, 3, 0, 1, 0, 0, 0, 1, 0, 1, 3, 0, 0, 0, 1, 0, 3, 0, 1, 0, 1, 1, 1, 0, 3, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 73 and the episode is 372 and the total_steps are 38143\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -813     |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 621      |\n",
      "|    total_timesteps  | 38143    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 1, 3, 1, 0, 0, 3, 0, 3, 3, 2, 0, 3, 1, 1, 0, 2, 2, 2, 0, 3, 3, 0, 0, 2, 1, 1, 0, 3, 1, 0, 2, 1, 2, 1, 1, 0, 3, 3, 3, 3, 0, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 3, 3, 3, 1, 0, 0, 0, 2, 3, 1, 1, 3, 3, 3, 2, 1, 2, 0, 3, 3, 3, 2, 2, 1, 2, 0, 0, 0, 2, 2, 1, 1, 3, 2, 0, 0, 2, 3, 1, 1, 1, 0, 0, 1, 2, 1, 1, 0, 0, 0, 2, 2, 0, 0, 0, 1, 2, 1, 0, 1, 3, 3, 3, 3, 2, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -880. And steps were 140 and the episode is 373 and the total_steps are 38283\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 2, 1, 2, 0, 2, 1, 2, 3, 3, 3, 1, 1, 3, 3, 0, 2, 0, 1, 1, 3, 2, 2, 0, 1, 0, 1, 1, 0, 0, 1, 3, 1, 2, 3, 3, 2, 1, 0, 1, 1, 1, 2, 0, 1, 3, 2, 1, 2, 2, 1, 2, 2, 0, 0, 3, 1, 1, 2, 0, 2, 1, 3, 1, 0, 1, 0, 1, 0, 3, 2, 2, 2, 3, 3, 0, 0, 3, 2, 1, 3, 1, 1, 1, 1, 2, 0, 0, 2, 3, 1, 1, 3, 1, 1, 1, 2, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1102. And steps were 104 and the episode is 374 and the total_steps are 38387\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 3, 3, 2, 0, 2, 0, 0, 3, 2, 2, 1, 1, 1, 0, 1, 2, 2, 1, 2, 1, 3, 0, 0, 0, 1, 0, 3, 3, 0, 3, 2, 0, 2, 0, 3, 3, 1, 3, 3, 1, 2, 1, 2, 3, 3, 2, 0, 2, 0, 1, 2, 2, 1, 0, 1, 2, 0, 0, 1, 3, 0, 1, 3, 0, 0, 0, 3, 1, 2, 0, 1, 3, 2, 3, 0, 2, 2, 1, 0, 1, 0, 1, 0, 3, 2, 2, 2, 1, 1, 2, 0, 0, 2, 2, 2, 0, 2, 3, 2, 0, 3, 3, 0, 3, 1, 0, 2, 1, 3, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1115. And steps were 117 and the episode is 375 and the total_steps are 38504\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 0, 0, 1, 3, 1, 2, 0, 3, 3, 0, 3, 1, 2, 3, 1, 2, 2, 0, 1, 1, 3, 1, 1, 0, 0, 2, 3, 1, 2, 2, 0, 2, 1, 3, 3, 3, 2, 1, 0, 1, 3, 1, 0, 3, 1, 0, 1, 3, 2, 1, 2, 1, 2, 0, 2, 3, 2, 3, 3, 0, 2, 2, 1, 2, 3, 3, 2, 0, 2, 3, 2, 3, 2, 2, 1, 1, 2, 3, 3, 1, 3, 3, 3, 1, 3, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 3, 1, 0, 2, 2, 2, 1, 0, 3, 1, 2, 2, 3, 0, 2, 1, 3, 2, 3, 1, 0, 2, 3, 3, 0, 2, 3, 2, 2, 0, 3, 1, 1, 3, 3, 0, 2, 0, 1, 0, 0, 1, 1, 1, 2, 0, 3, 0, 2, 3, 2, 2, 2, 3, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 159 and the episode is 376 and the total_steps are 38663\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -810     |\n",
      "|    exploration_rate | 0.963    |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 630      |\n",
      "|    total_timesteps  | 38663    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 1, 3, 0, 3, 0, 1, 0, 2, 1, 3, 1, 3, 2, 1, 2, 1, 1, 3, 2, 3, 0, 2, 0, 1, 0, 3, 3, 0, 3, 0, 0, 1, 2, 3, 1, 2, 0, 2, 0, 3, 2, 3, 1, 1, 3, 3, 0, 3, 3, 0, 0, 2, 1, 1, 1, 3, 2, 1, 2, 3, 0, 2, 3, 3, 1, 0, 1, 2, 2, 2, 2, 0, 0, 3, 2, 3, 0, 0, 0, 0, 3, 3, 0, 2, 1, 0, 3, 0, 2, 1, 3, 2, 1, 0, 1, 3, 3, 0, 2, 1, 3, 0, 2, 1, 1, 1, 1, 0, 1, 3, 1, 2, 1, 1, 2, 0, 3, 1, 3, 1, 1, 2, 2, 0, 3, 1, 0, 1, 0, 1, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 3, 2, 1, 0, 0, 3, 0, 3, 0, 1, 2, 2, 0, 3, 1, 0, 3, 2, 3, 0, 0, 1, 2, 0, 1, 0, 0, 3, 3, 0, 1, 1, 3, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -875. And steps were 181 and the episode is 377 and the total_steps are 38844\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 2, 3, 0, 2, 3, 3, 2, 0, 0, 2, 2, 3, 0, 0, 2, 1, 0, 2, 0, 0, 2, 2, 0, 0, 3, 3, 2, 0, 3, 3, 1, 1, 0, 0, 2, 0, 0, 2, 1, 1, 3, 2, 1, 3, 0, 0, 2, 1, 1, 0, 1, 1, 1, 3, 2, 2, 1, 2, 1, 3, 1, 3, 1, 3, 1, 3, 0, 3, 0, 0, 1, 2, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1078. And steps were 80 and the episode is 378 and the total_steps are 38924\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 3, 0, 0, 2, 2, 1, 1, 0, 2, 0, 3, 1, 3, 1, 3, 0, 0, 3, 0, 0, 0, 2, 3, 1, 0, 0, 0, 3, 3, 3, 2, 1, 3, 3, 0, 3, 2, 3, 0, 3, 1, 0, 3, 3, 0, 3, 3, 1, 0, 0, 0, 0, 3, 0, 3, 0, 1, 3, 0, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 67 and the episode is 379 and the total_steps are 38991\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 0, 2, 2, 3, 1, 1, 1, 2, 2, 1, 0, 3, 2, 3, 2, 1, 2, 0, 2, 1, 0, 3, 2, 2, 3, 3, 1, 2, 3, 1, 3, 1, 0, 3, 3, 3, 1, 0, 2, 0, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1043. And steps were 46 and the episode is 380 and the total_steps are 39037\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -792     |\n",
      "|    exploration_rate | 0.963    |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 636      |\n",
      "|    total_timesteps  | 39037    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 3, 0, 2, 3, 2, 0, 3, 1, 2, 2, 1, 2, 0, 3, 3, 2, 1, 1, 1, 2, 1, 0, 1, 2, 3, 1, 3, 0, 0, 1, 1, 1, 1, 3, 2, 1, 1, 2, 2, 2, 1, 3, 3, 2, 1, 3, 0, 1, 0, 0, 1, 2, 3, 1, 0, 1, 2, 0, 2, 1, 2, 3, 0, 3, 2, 1, 2, 2, 2, 0, 1, 2, 3, 0, 2, 1, 2, 0, 0, 3, 2, 3, 0, 0, 2, 3, 2, 0, 2, 2, 3, 0, 2, 0, 2, 0, 0, 0, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 2, 1, 0, 0, 3, 3, 3, 2, 0, 1, 2, 1, 1, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -929. And steps were 129 and the episode is 381 and the total_steps are 39166\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 0, 2, 2, 3, 0, 2, 0, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 0, 0, 2, 0, 0, 3, 3, 0, 0, 3, 0, 1, 0, 0, 3, 0, 3, 1, 3, 2, 1, 2, 3, 3, 3, 1, 3, 1, 1, 3, 3, 2, 0, 1, 0, 2, 3, 3, 2, 2, 0, 3, 2, 3, 1, 3, 0, 1, 1, 3, 0, 3, 1, 3, 2, 3, 3, 1, 3, 0, 0, 1, 1, 3, 0, 2, 0, 3, 3, 0, 0, 1, 2, 2, 3, 3, 3, 0, 0, 1, 3, 3, 3, 3, 2, 1, 1, 0, 2, 0, 0, 2, 2, 2, 1, 3, 2, 3, 2, 2, 2, 2, 3, 0, 1, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1059. And steps were 131 and the episode is 382 and the total_steps are 39297\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 3, 1, 1, 2, 0, 3, 3, 0, 3, 3, 3, 1, 1, 1, 3, 3, 0, 0, 1, 1, 0, 1, 1, 2, 0, 1, 3, 2, 1, 0, 0, 0, 0, 3, 2, 3, 0, 0, 1, 3, 2, 3, 1, 2, 2, 3, 2, 1, 2, 2, 2, 1, 2, 2, 0, 0, 1, 1, 0, 3, 0, 2, 3, 0, 2, 3, 3, 0, 2, 2, 3, 1, 3, 0, 3, 0, 0, 0, 1, 3, 1, 1, 2, 2, 3, 0, 1, 0, 2, 2, 3, 1, 2, 1, 3, 3, 0, 0, 0, 0, 3, 3, 1, 3, 0, 3, 1, 2, 1, 2, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 118 and the episode is 383 and the total_steps are 39415\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 3, 3, 2, 1, 3, 0, 0, 2, 1, 3, 3, 0, 0, 3, 2, 0, 0, 3, 1, 3, 0, 2, 1, 2, 3, 2, 2, 3, 1, 2, 2, 1, 3, 0, 1, 2, 1, 2, 0, 0, 3, 3, 0, 1, 3, 0, 2, 2, 1, 1, 0, 2, 0, 2, 0, 1, 3, 3, 3, 0, 0, 1, 3, 0, 3, 2, 2, 2, 3, 1, 3, 1, 3, 0, 3, 2, 3, 0, 1, 3, 2, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -931. And steps were 89 and the episode is 384 and the total_steps are 39504\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -790     |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 643      |\n",
      "|    total_timesteps  | 39504    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 1, 1, 1, 1, 3, 2, 2, 3, 0, 2, 0, 0, 0, 3, 1, 1, 3, 0, 0, 3, 3, 3, 1, 2, 3, 3, 0, 1, 3, 3, 0, 3, 1, 3, 0, 0, 0, 2, 0, 0, 1, 0, 1, 1, 3, 1, 1, 3, 1, 0, 0, 0, 3, 2, 2, 3, 0, 1, 3, 3, 2, 2, 0, 2, 1, 1, 2, 3, 1, 0, 3, 2, 3, 1, 1, 2, 1, 1, 3, 0, 3, 0, 2, 0, 3, 2, 1, 0, 3, 1, 3, 2, 2, 1, 3, 0, 3, 1, 2, 3, 3, 0, 1, 0, 2, 3, 0, 2, 2, 0, 1, 2, 2, 3, 3, 0, 1, 1, 2, 2, 1, 1, 1, 1, 3, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -898. And steps were 134 and the episode is 385 and the total_steps are 39638\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 1, 3, 1, 3, 1, 0, 0, 3, 3, 1, 0, 2, 2, 0, 1, 0, 1, 1, 0, 2, 2, 0, 0, 0, 0, 0, 3, 3, 3, 0, 2, 1, 3, 1, 2, 0, 2, 0, 0, 0, 3, 3, 3, 1, 3, 0, 3, 1, 0, 0, 0, 2, 0, 2, 2, 2, 3, 1, 2, 3, 2, 0, 2, 0, 1, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 73 and the episode is 386 and the total_steps are 39711\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 3, 1, 0, 3, 3, 3, 1, 2, 1, 1, 2, 2, 0, 3, 1, 3, 1, 2, 0, 1, 3, 3, 0, 1, 1, 3, 1, 2, 0, 2, 2, 3, 0, 3, 3, 2, 2, 3, 3, 1, 3, 2, 0, 3, 3, 2, 1, 3, 2, 0, 1, 0, 1, 2, 3, 1, 3, 2, 3, 3, 3, 1, 3, 3, 1, 3, 2, 1, 0, 3, 1, 3, 0, 2, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1080. And steps were 82 and the episode is 387 and the total_steps are 39793\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 0, 0, 2, 3, 2, 0, 3, 1, 3, 0, 3, 3, 3, 1, 1, 0, 1, 2, 3, 3, 0, 3, 3, 1, 3, 1, 2, 2, 2, 2, 3, 1, 3, 3, 1, 0, 3, 1, 1, 0, 2, 2, 0, 3, 3, 0, 1, 1, 0, 3, 0, 2, 3, 2, 3, 0, 2, 1, 3, 1, 1, 1, 2, 2, 3, 3, 1, 3, 2, 1, 0, 2, 0, 3, 3, 3, 1, 3, 0, 1, 2, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 89 and the episode is 388 and the total_steps are 39882\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -794     |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 649      |\n",
      "|    total_timesteps  | 39882    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 2, 3, 2, 0, 3, 2, 1, 0, 2, 0, 1, 3, 3, 2, 3, 1, 1, 3, 2, 1, 3, 0, 2, 0, 3, 2, 1, 3, 3, 2, 3, 2, 3, 2, 0, 0, 0, 1, 3, 0, 1, 0, 0, 0, 3, 1, 1, 2, 3, 0, 0, 2, 3, 0, 3, 2, 2, 2, 2, 3, 2, 3, 3, 2, 2, 0, 2, 3, 0, 0, 3, 0, 3, 2, 2, 2, 3, 1, 0, 0, 1, 0, 3, 3, 2, 2, 2, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -913. And steps were 95 and the episode is 389 and the total_steps are 39977\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 3, 2, 1, 0, 2, 3, 1, 2, 1, 1, 3, 0, 0, 3, 2, 1, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 0, 0, 2, 2, 0, 0, 1, 2, 3, 1, 0, 1, 0, 2, 2, 2, 0, 2, 0, 2, 2, 3, 3, 3, 0, 2, 0, 3, 3, 1, 3, 0, 0, 1, 1, 2, 0, 3, 3, 1, 2, 0, 0, 1, 2, 3, 1, 3, 2, 1, 0, 3, 0, 0, 1, 1, 2, 3, 1, 2, 3, 1, 2, 1, 1, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 99 and the episode is 390 and the total_steps are 40076\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 0, 1, 2, 2, 2, 2, 0, 3, 3, 2, 0, 1, 0, 2, 2, 1, 3, 3, 3, 3, 0, 0, 2, 2, 0, 1, 2, 3, 3, 2, 0, 3, 1, 3, 0, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was 1047. And steps were 48 and the episode is 391 and the total_steps are 40124\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 1, 3, 1, 2, 1, 0, 2, 0, 0, 0, 3, 1, 3, 1, 3, 2, 3, 3, 2, 1, 0, 2, 2, 3, 3, 3, 0, 1, 0, 2, 2, 3, 1, 3, 2, 0, 3, 1, 1, 2, 3, 2, 0, 3, 2, 2, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 54 and the episode is 392 and the total_steps are 40178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.9     |\n",
      "|    ep_rew_mean      | -791     |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 654      |\n",
      "|    total_timesteps  | 40178    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 0, 0, 0, 3, 3, 1, 1, 3, 1, 1, 2, 0, 0, 1, 2, 1, 0, 0, 2, 3, 0, 3, 1, 0, 0, 0, 3, 3, 2, 3, 3, 3, 3, 1, 2, 3, 2, 1, 2, 1, 3, 1, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 1, 3, 3, 3, 0, 0, 0, 2, 0, 0, 1, 0, 3, 2, 1, 3, 0, 0, 0, 2, 2, 3, 0, 1, 2, 3, 3, 1, 2, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 3, 3, 2, 2, 1, 3, 1, 2, 2, 3, 1, 3, 3, 1, 2, 2, 0, 0, 2, 3, 2, 2, 0, 2, 2, 3, 1, 2, 2, 2, 1, 2, 0, 3, 3, 3, 2, 2, 0, 2, 2, 3, 3, 3, 2, 3, 3, 3, 1, 2, 0, 2, 3, 2, 3, 3, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -885. And steps were 157 and the episode is 393 and the total_steps are 40335\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 2, 3, 3, 0, 1, 0, 3, 2, 2, 1, 1, 2, 0, 1, 0, 1, 1, 0, 2, 3, 0, 2, 0, 1, 0, 0, 0, 3, 2, 0, 0, 3, 0, 0, 0, 1, 0, 1, 2, 2, 3, 3, 1, 0, 3, 3, 1, 1, 1, 3, 1, 0, 3, 3, 2, 1, 2, 1, 3, 2, 1, 3, 2, 0, 2, 2, 0, 1, 3, 3, 2, 0, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 0, 3, 3, 2, 3, 3, 2, 2, 3, 0, 2, 2, 1, 0, 0, 3, 2, 1, 3, 0, 2, 3, 1, 0, 3, 0, 3, 3, 1, 0, 0, 2, 0, 3, 0, 3, 2, 0, 3, 0, 3, 3, 0, 0, 3, 2, 0, 3, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -928. And steps were 138 and the episode is 394 and the total_steps are 40473\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 1, 1, 1, 2, 1, 0, 0, 2, 1, 2, 3, 1, 3, 0, 2, 1, 0, 1, 0, 0, 0, 3, 3, 1, 2, 0, 3, 1, 3, 2, 3, 2, 0, 3, 2, 3, 2, 1, 2, 3, 3, 1, 2, 1, 0, 0, 0, 2, 0, 0, 3, 1, 1, 1, 3, 3, 1, 0, 2, 1, 1, 3, 2, 0, 3, 3, 1, 1, 0, 3, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 3, 0, 1, 2, 3, 0, 2, 3, 2, 0, 2, 2, 1, 3, 0, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -945. And steps were 105 and the episode is 395 and the total_steps are 40578\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 3, 3, 0, 1, 2, 3, 1, 2, 3, 3, 2, 0, 3, 0, 0, 3, 1, 0, 0, 0, 1, 3, 0, 2, 1, 0, 3, 2, 3, 0, 0, 1, 2, 3, 1, 3, 1, 2, 0, 3, 3, 0, 1, 1, 3, 0, 2, 1, 2, 1, 1, 1, 0, 3, 0, 1, 1, 2, 2, 2, 1, 2, 3, 3, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 0, 1, 3, 1, 0, 3, 3, 3, 3, 2, 2, 3, 0, 3, 1, 2, 2, 3, 1, 0, 2, 3, 3, 1, 3, 0, 2, 2, 2, 3, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -932. And steps were 112 and the episode is 396 and the total_steps are 40690\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -786     |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 662      |\n",
      "|    total_timesteps  | 40690    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 1, 0, 0, 3, 3, 0, 0, 1, 3, 3, 3, 0, 3, 3, 2, 2, 3, 0, 1, 0, 1, 3, 3, 3, 2, 2, 2, 0, 3, 1, 3, 3, 0, 3, 0, 2, 0, 1, 1, 1, 3, 0, 0, 1, 1, 1, 2, 2, 3, 1, 1, 3, 1, 2, 2, 0, 0, 2, 1, 1, 1, 0, 1, 3, 2, 2, 2, 1, 3, 3, 3, 0, 3, 0, 0, 1, 2, 0, 0, 2, 3, 2, 0, 2, 0, 1, 0, 1, 2, 2, 3, 2, 3, 2, 0, 1, 2, 0, 3, 2, 3, 1, 2, 2, 2, 0, 1, 3, 1, 0, 1, 3, 1, 0, 1, 2, 0, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1123. And steps were 125 and the episode is 397 and the total_steps are 40815\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 0, 3, 2, 2, 1, 1, 1, 3, 3, 2, 1, 0, 0, 3, 0, 1, 3, 2, 2, 1, 3, 1, 3, 3, 2, 3, 1, 3, 3, 1, 2, 3, 2, 1, 2, 0, 0, 0, 3, 1, 2, 2, 2, 2, 3, 2, 2, 0, 1, 0, 2, 2, 3, 3, 3, 1, 1, 1, 0, 2, 1, 3, 0, 2, 2, 1, 0, 1, 2, 0, 2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 3, 1, 3, 3, 0, 0, 0, 1, 3, 1, 1, 2, 1, 1, 1, 0, 2, 1, 1, 0, 0, 2, 0, 3, 2, 0, 0, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1113. And steps were 115 and the episode is 398 and the total_steps are 40930\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 1, 3, 2, 1, 2, 0, 1, 1, 1, 0, 2, 1, 0, 3, 2, 1, 2, 1, 2, 1, 3, 1, 2, 0, 0, 2, 1, 3, 1, 0, 1, 0, 3, 0, 3, 0, 3, 3, 0, 3, 2, 0, 1, 2, 2, 1, 0, 0, 2, 1, 3, 1, 2, 3, 1, 1, 0, 3, 3, 2, 2, 0, 0, 1, 0, 2, 0, 0, 1, 2, 3, 3, 1, 1, 3, 3, 0, 0, 3, 2, 0, 1, 3, 2, 3, 3, 0, 1, 1, 2, 0, 2, 1, 1, 0, 3, 2, 2, 2, 2, 1, 3, 3, 0, 0, 1, 0, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1113. And steps were 115 and the episode is 399 and the total_steps are 41045\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 0, 1, 1, 0, 3, 0, 2, 2, 2, 2, 3, 1, 1, 3, 2, 2, 0, 1, 3, 2, 2, 2, 1, 3, 2, 0, 1, 1, 3, 1, 2, 2, 1, 0, 0, 3, 3, 2, 1, 0, 2, 3, 0, 1, 2, 1, 1, 0, 2, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was 1054. And steps were 55 and the episode is 400 and the total_steps are 41100\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -787     |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 669      |\n",
      "|    total_timesteps  | 41100    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 1, 2, 1, 1, 2, 3, 0, 1, 3, 0, 0, 3, 2, 0, 2, 1, 3, 0, 2, 2, 0, 0, 3, 3, 3, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 2, 3, 1, 2, 1, 0, 1, 0, 0, 2, 3, 3, 3, 3, 0, 0, 3, 3, 0, 3, 2, 0, 1, 2, 3, 0, 3, 1, 3, 2, 3, 1, 2, 1, 0, 1, 2, 3, 1, 1, 3, 1, 3, 1, 3, 1, 3, 2, 0, 1, 3, 3, 2, 1, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -931. And steps were 97 and the episode is 401 and the total_steps are 41197\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 1, 2, 2, 3, 0, 3, 3, 2, 3, 1, 2, 0, 0, 0, 3, 0, 3, 2, 3, 2, 0, 3, 3, 1, 0, 1, 2, 1, 2, 2, 0, 3, 2, 0, 3, 2, 3, 3, 1, 3, 3, 0, 0, 3, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 1, 3, 0, 1, 0, 2, 1, 2, 0, 2, 3, 1, 1, 2, 1, 0, 3, 1, 3, 2, 0, 0, 0, 2, 2, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 87 and the episode is 402 and the total_steps are 41284\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 0, 3, 1, 2, 2, 2, 3, 1, 3, 1, 2, 0, 3, 0, 2, 1, 0, 2, 2, 0, 1, 2, 1, 1, 3, 0, 1, 2, 0, 3, 1, 0, 0, 1, 3, 0, 0, 0, 2, 1, 0, 1, 0, 0, 1, 0, 0, 2, 2, 2, 2, 3, 3, 3, 3, 1, 0, 0, 1, 2, 1, 0, 0, 3, 2, 2, 0, 2, 1, 0, 0, 3, 2, 0, 0, 3, 1, 1, 3, 2, 3, 3, 1, 3, 3, 3, 0, 3, 2, 3, 3, 1, 2, 0, 3, 2, 2, 3, 2, 2, 2, 1, 3, 1, 1, 0, 3, 3, 1, 2, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 118 and the episode is 403 and the total_steps are 41402\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 0, 3, 0, 0, 2, 0, 3, 2, 1, 3, 3, 2, 1, 0, 1, 3, 1, 1, 1, 1, 0, 3, 2, 2, 3, 2, 2, 1, 2, 0, 3, 2, 1, 0, 1, 0, 0, 2, 3, 1, 1, 3, 0, 0, 1, 1, 2, 2, 3, 2, 2, 3, 2, 0, 2, 1, 3, 1, 3, 0, 1, 1, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 70 and the episode is 404 and the total_steps are 41472\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -786     |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 675      |\n",
      "|    total_timesteps  | 41472    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 3, 0, 3, 2, 0, 0, 0, 2, 0, 3, 3, 3, 0, 0, 1, 3, 0, 1, 3, 0, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 3, 3, 2, 3, 2, 3, 3, 2, 3, 1, 0, 1, 3, 0, 2, 2, 1, 2, 3, 0, 3, 1, 2, 3, 3, 1, 1, 3, 0, 0, 1, 3, 1, 2, 1, 0, 1, 3, 2, 0, 2, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 79 and the episode is 405 and the total_steps are 41551\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 1, 2, 3, 1, 1, 3, 0, 3, 1, 1, 2, 1, 3, 0, 0, 3, 2, 1, 1, 0, 2, 3, 2, 3, 2, 1, 3, 0, 0, 0, 2, 3, 0, 3, 2, 3, 1, 1, 1, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 3, 0, 2, 0, 2, 2, 3, 2, 1, 0, 2, 1, 2, 3, 3, 0, 2, 0, 3, 2, 1, 2, 2, 0, 1, 1, 2, 1, 3, 1, 2, 3, 0, 3, 0, 2, 1, 2, 1, 1, 0, 0, 3, 0, 3, 1, 0, 0, 3, 3, 1, 3, 2, 2, 2, 2, 0, 2, 1, 0, 0, 3, 0, 1, 3, 0, 1, 1, 1, 3, 0, 3, 2, 2, 3, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 132 and the episode is 406 and the total_steps are 41683\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 2, 0, 3, 1, 2, 1, 0, 0, 0, 1, 1, 3, 2, 0, 1, 0, 2, 0, 2, 0, 2, 3, 0, 0, 3, 1, 0, 3, 2, 0, 1, 3, 2, 1, 1, 1, 2, 0, 0, 0, 2, 0, 2, 1, 3, 1, 1, 3, 3, 2, 2, 3, 3, 0, 1, 2, 0, 1, 3, 1, 1, 0, 2, 1, 1, 2, 2, 3, 3, 0, 3, 2, 1, 0, 0, 2, 1, 0, 0, 0, 0, 2, 2, 0, 0, 3, 0, 3, 3, 3, 1, 0, 3, 2, 0, 3, 0, 0, 2, 1, 2, 2, 3, 3, 3, 3, 3, 1, 1, 3, 1, 1, 1, 2, 1, 2, 2, 3, 0, 2, 2, 0, 3, 1, 3, 3, 3, 1, 1, 1, 2, 2, 0, 1, 3, 0, 1, 2, 3, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1144. And steps were 145 and the episode is 407 and the total_steps are 41828\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 3, 2, 1, 3, 3, 1, 1, 0, 0, 1, 0, 0, 2, 0, 2, 2, 3, 3, 3, 3, 2, 0, 3, 0, 2, 2, 1, 3, 0, 0, 3, 2, 0, 0, 0, 0, 1, 2, 1, 3, 1, 0, 3, 1, 0, 1, 3, 2, 2, 3, 0, 1, 3, 3, 2, 0, 0, 0, 0, 3, 0, 3, 2, 3, 0, 0, 2, 2, 0, 0, 0, 1, 3, 1, 0, 3, 3, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1083. And steps were 85 and the episode is 408 and the total_steps are 41913\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -767     |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 682      |\n",
      "|    total_timesteps  | 41913    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 2, 0, 0, 3, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 2, 0, 1, 2, 3, 1, 3, 3, 0, 3, 0, 3, 0, 3, 2, 1, 2, 1, 3, 3, 3, 3, 3, 1, 1, 2, 3, 0, 3, 3, 0, 2, 2, 3, 0, 3, 0, 2, 2, 1, 1, 2, 3, 1, 0, 3, 1, 0, 2, 1, 2, 0, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1082. And steps were 84 and the episode is 409 and the total_steps are 41997\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 0, 2, 0, 2, 1, 0, 2, 2, 3, 0, 1, 3, 3, 3, 2, 2, 1, 2, 3, 1, 1, 2, 0, 1, 2, 3, 2, 0, 1, 2, 2, 0, 1, 3, 1, 2, 3, 3, 1, 2, 1, 2, 0, 0, 0, 0, 3, 2, 1, 2, 3, 1, 2, 0, 3, 1, 0, 2, 2, 1, 0, 1, 3, 2, 0, 1, 1, 0, 0, 2, 1, 3, 3, 0, 0, 0, 0, 1, 2, 1, 0, 2, 1, 0, 0, 1, 3, 1, 3, 3, 0, 3, 0, 2, 3, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 103 and the episode is 410 and the total_steps are 42100\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 2, 2, 1, 0, 0, 0, 0, 3, 3, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 0, 0, 3, 2, 1, 2, 0, 1, 3, 2, 2, 1, 0, 3, 3, 3, 2, 2, 1, 3, 2, 3, 1, 0, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 3, 1, 0, 2, 3, 2, 1, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 68 and the episode is 411 and the total_steps are 42168\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 3, 2, 0, 1, 3, 1, 2, 0, 1, 0, 1, 0, 0, 3, 3, 0, 0, 1, 3, 2, 2, 0, 2, 3, 0, 0, 1, 2, 0, 2, 2, 3, 0, 1, 2, 1, 2, 3, 2, 3, 2, 2, 3, 3, 2, 0, 0, 3, 0, 0, 1, 1, 1, 0, 3, 1, 3, 2, 0, 2, 0, 2, 1, 2, 0, 2, 3, 0, 3, 2, 2, 2, 2, 2, 3, 3, 0, 0, 2, 3, 0, 0, 2, 1, 3, 0, 1, 3, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 1, 3, 0, 3, 2, 2, 2, 0, 0, 3, 2, 3, 3, 0, 2, 3, 0, 1, 3, 2, 1, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1035. And steps were 127 and the episode is 412 and the total_steps are 42295\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -766     |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 688      |\n",
      "|    total_timesteps  | 42295    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 3, 1, 1, 0, 1, 3, 2, 1, 1, 3, 1, 2, 0, 2, 2, 2, 2, 0, 0, 1, 0, 2, 3, 0, 3, 0, 1, 2, 1, 2, 3, 3, 1, 3, 1, 0, 3, 3, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1041. And steps were 44 and the episode is 413 and the total_steps are 42339\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 1, 0, 1, 0, 3, 3, 0, 1, 3, 2, 0, 3, 3, 1, 0, 0, 1, 2, 1, 2, 0, 2, 1, 0, 3, 2, 1, 1, 3, 1, 2, 3, 1, 2, 1, 0, 0, 1, 2, 2, 1, 0, 2, 0, 3, 2, 0, 0, 0, 1, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 0, 0, 1, 1, 3, 3, 3, 0, 0, 0, 0, 2, 0, 3, 2, 3, 1, 3, 0, 2, 3, 3, 2, 3, 2, 3, 1, 1, 2, 2, 1, 2, 1, 2, 3, 0, 1, 1, 0, 2, 1, 3, 0, 0, 3, 3, 0, 3, 0, 0, 1, 2, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 121 and the episode is 414 and the total_steps are 42460\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 1, 0, 0, 3, 2, 2, 0, 2, 0, 2, 0, 1, 0, 0, 1, 0, 0, 3, 1, 2, 0, 1, 2, 3, 2, 0, 0, 0, 1, 0, 3, 1, 1, 2, 2, 1, 2, 0, 2, 1, 3, 0, 2, 1, 0, 2, 3, 3, 1, 2, 1, 2, 0, 2, 0, 0, 1, 1, 2, 0, 3, 1, 3, 3, 3, 0, 0, 1, 3, 0, 2, 0, 3, 0, 3, 2, 2, 0, 0, 1, 0, 2, 2, 3, 3, 0, 0, 0, 1, 1, 2, 2, 3, 2, 3, 0, 2, 0, 2, 0, 2, 2, 1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 3, 3, 0, 0, 2, 0, 1, 3, 3, 2, 3, 0, 1, 0, 2, 3, 0, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -907. And steps were 141 and the episode is 415 and the total_steps are 42601\n",
      "Done condition: collision\n",
      "[3, 3, 3, 3, 1, 0, 1, 2, 0, 3, 0, 0, 0, 2, 0, 3, 2, 2, 0, 0, 0, 1, 1, 2, 0, 1, 1, 3, 3, 2, 2, 2, 0, 3, 2, 3, 0, 1, 0, 2, 3, 2, 2, 2, 3, 1, 3, 1, 2, 2, 2, 1, 3, 1, 2, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1057. And steps were 59 and the episode is 416 and the total_steps are 42660\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -766     |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 694      |\n",
      "|    total_timesteps  | 42660    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 3, 3, 3, 3, 2, 2, 0, 3, 1, 3, 2, 3, 1, 0, 1, 2, 0, 0, 0, 2, 3, 1, 3, 1, 0, 3, 2, 3, 0, 0, 1, 1, 0, 3, 1, 1, 0, 3, 2, 1, 1, 1, 1, 0, 3, 2, 0, 2, 1, 0, 1, 0, 3, 3, 1, 2, 1, 1, 2, 2, 3, 0, 3, 3, 0, 2, 2, 3, 1, 0, 1, 2, 1, 0, 3, 1, 1, 2, 2, 2, 1, 0, 3, 1, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 1, 1, 2, 2, 1, 1, 2, 0, 1, 3, 3, 3, 0, 0, 0, 2, 2, 2, 0, 2, 1, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -935. And steps were 123 and the episode is 417 and the total_steps are 42783\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 3, 2, 2, 0, 3, 0, 1, 1, 1, 0, 2, 1, 2, 3, 1, 3, 3, 1, 1, 1, 2, 3, 3, 1, 3, 0, 1, 0, 3, 0, 1, 1, 0, 2, 0, 1, 1, 2, 1, 0, 3, 1, 3, 1, 3, 0, 2, 2, 3, 1, 1, 3, 1, 0, 1, 3, 0, 1, 2, 2, 1, 1, 1, 3, 1, 3, 3, 3, 1, 0, 3, 1, 3, 0, 2, 3, 1, 2, 3, 0, 1, 3, 2, 1, 1, 2, 3, 0, 3, 0, 3, 2, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 100 and the episode is 418 and the total_steps are 42883\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 3, 2, 2, 1, 2, 1, 0, 1, 0, 0, 3, 2, 2, 3, 1, 0, 3, 1, 3, 2, 0, 0, 0, 0, 0, 0, 3, 3, 1, 0, 3, 1, 1, 2, 2, 1, 0, 1, 0, 2, 0, 2, 3, 2, 0, 2, 3, 3, 2, 3, 2, 3, 0, 2, 1, 3, 2, 3, 1, 1, 1, 2, 1, 2, 3, 0, 1, 0, 2, 0, 2, 1, 1, 3, 1, 2, 1, 0, 1, 0, 3, 1, 1, 0, 2, 3, 2, 2, 3, 1, 2, 0, 0, 1, 2, 1, 3, 1, 2, 0, 3, 0, 3, 3, 3, 3, 2, 0, 2, 3, 3, 2, 0, 2, 3, 2, 0, 2, 2, 3, 1, 2, 3, 1, 3, 0, 3, 2, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1053. And steps were 149 and the episode is 419 and the total_steps are 43032\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 0, 1, 3, 3, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 0, 1, 0, 2, 1, 1, 3, 0, 1, 0, 2, 0, 0, 1, 0, 3, 1, 2, 2, 2, 0, 0, 3, 2, 0, 2, 2, 0, 1, 2, 1, 0, 0, 0, 2, 3, 0, 0, 3, 0, 1, 1, 3, 3, 2, 3, 3, 0, 3, 3, 2, 0, 3, 2, 2, 1, 1, 3, 1, 1, 1, 3, 0, 2, 1, 2, 1, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -933. And steps were 89 and the episode is 420 and the total_steps are 43121\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -764     |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 702      |\n",
      "|    total_timesteps  | 43121    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 3, 3, 0, 1, 2, 2, 3, 1, 0, 3, 0, 3, 1, 1, 0, 0, 1, 0, 0, 3, 2, 3, 2, 0, 1, 0, 1, 1, 2, 2, 3, 2, 0, 3, 1, 2, 0, 2, 2, 3, 3, 0, 0, 2, 3, 3, 2, 2, 0, 1, 1, 2, 3, 3, 3, 1, 3, 2, 3, 1, 2, 3, 2, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 71 and the episode is 421 and the total_steps are 43192\n",
      "Done condition: collision\n",
      "[0, 0, 1, 2, 0, 1, 1, 1, 0, 0, 1, 1, 3, 2, 3, 1, 1, 2, 1, 0, 0, 2, 3, 2, 2, 1, 0, 3, 3, 0, 2, 2, 0, 0, 2, 2, 2, 2, 1, 3, 2, 1, 2, 1, 1, 1, 0, 2, 0, 2, 3, 1, 1, 0, 1, 1, 3, 0, 1, 3, 1, 0, 2, 3, 0, 2, 3, 3, 2, 0, 2, 1, 1, 1, 2, 3, 2, 3, 2, 1, 3, 3, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -932. And steps were 86 and the episode is 422 and the total_steps are 43278\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 3, 3, 2, 0, 1, 0, 0, 2, 3, 1, 1, 0, 1, 3, 3, 1, 1, 0, 2, 2, 0, 0, 0, 3, 1, 1, 3, 2, 2, 0, 3, 0, 2, 0, 1, 1, 0, 1, 2, 3, 1, 3, 2, 1, 1, 3, 1, 2, 2, 3, 1, 3, 0, 3, 2, 2, 3, 1, 1, 3, 0, 1, 3, 3, 2, 0, 3, 2, 0, 3, 1, 3, 2, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 81 and the episode is 423 and the total_steps are 43359\n",
      "Done condition: max time steps reached\n",
      "[0, 1, 3, 0, 2, 0, 2, 3, 0, 1, 2, 3, 3, 3, 3, 3, 2, 3, 1, 1, 2, 0, 0, 0, 0, 1, 1, 0, 0, 3, 1, 2, 0, 0, 2, 3, 3, 0, 2, 2, 0, 2, 2, 2, 0, 3, 3, 2, 3, 2, 3, 2, 1, 2, 0, 1, 0, 0, 2, 0, 0, 3, 0, 3, 0, 0, 1, 0, 3, 1, 2, 3, 3, 3, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 3, 1, 3, 1, 1, 2, 3, 1, 2, 2, 3, 3, 2, 0, 0, 3, 3, 1, 0, 3, 2, 1, 3, 0, 2, 3, 0, 3, 3, 0, 2, 1, 0, 2, 0, 3, 3, 3, 3, 2, 3, 0, 0, 0, 1, 1, 0, 2, 2, 1, 2, 2, 3, 1, 2, 1, 1, 2, 0, 1, 3, 1, 3, 3, 2, 1, 2, 1, 3, 3, 2, 1, 0, 0, 3, 3, 2, 0, 1, 2, 1, 0, 3, 0, 2, 0, 0, 0, 2, 3, 2, 3, 2, 2, 0, 0, 2, 0, 0, 1, 3, 1, 2, 3, 0, 3, 1, 1, 0, 3, 0, 1, 2, 2, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 202 and the episode is 424 and the total_steps are 43561\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -765     |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 708      |\n",
      "|    total_timesteps  | 43561    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 0, 2, 1, 1, 0, 3, 3, 0, 1, 2, 2, 0, 3, 0, 0, 1, 3, 1, 2, 0, 1, 1, 2, 3, 3, 0, 0, 1, 3, 2, 3, 0, 2, 3, 1, 1, 1, 3, 0, 3, 0, 3, 0, 1, 3, 0, 0, 3, 2, 2, 1, 0, 3, 2, 2, 2, 0, 3, 2, 0, 2, 0, 2, 2, 2, 1, 1, 2, 2, 1, 3, 1, 1, 3, 2, 2, 1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 1, 3, 2, 2, 2, 2, 0, 0, 1, 2, 2, 1, 0, 2, 1, 1, 0, 0, 2, 0, 1, 1, 3, 2, 2, 3, 3, 1, 0, 2, 3, 2, 2, 3, 3, 0, 1, 0, 2, 1, 0, 1, 2, 0, 2, 1, 2, 3, 1, 1, 2, 3, 2, 2, 3, 0, 0, 0, 0, 2, 3, 0, 1, 2, 2, 1, 1, 3, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -916. And steps were 162 and the episode is 425 and the total_steps are 43723\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 3, 2, 1, 0, 0, 1, 3, 3, 2, 3, 1, 2, 3, 2, 1, 3, 3, 3, 3, 2, 3, 3, 0, 3, 1, 1, 2, 1, 2, 3, 2, 1, 2, 2, 1, 0, 0, 2, 3, 2, 0, 3, 2, 2, 0, 0, 3, 3, 3, 0, 3, 0, 3, 1, 1, 2, 3, 3, 0, 0, 2, 3, 0, 2, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 3, 1, 2, 0, 3, 3, 1, 2, 1, 0, 3, 0, 0, 1, 2, 3, 3, 1, 3, 2, 3, 1, 0, 1, 0, 2, 1, 3, 1, 2, 2, 3, 3, 2, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -914. And steps were 116 and the episode is 426 and the total_steps are 43839\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 2, 1, 1, 1, 2, 3, 2, 0, 0, 2, 3, 1, 0, 0, 1, 3, 1, 2, 3, 1, 1, 3, 2, 3, 1, 0, 0, 2, 2, 1, 3, 1, 2, 1, 2, 2, 2, 0, 3, 3, 0, 0, 0, 1, 0, 3, 1, 2, 2, 3, 0, 1, 2, 0, 1, 3, 1, 2, 2, 2, 0, 1, 3, 0, 0, 3, 3, 1, 3, 0, 0, 3, 1, 2, 0, 1, 0, 1, 1, 1, 3, 3, 2, 0, 3, 2, 0, 1, 1, 1, 1, 1, 3, 2, 2, 3, 0, 1, 0, 2, 2, 3, 2, 2, 0, 1, 2, 3, 3, 1, 0, 0, 0, 1, 2, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -905. And steps were 123 and the episode is 427 and the total_steps are 43962\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 3, 2, 0, 0, 2, 1, 1, 1, 2, 1, 2, 0, 1, 0, 2, 1, 0, 2, 3, 0, 1, 1, 2, 3, 1, 0, 1, 0, 3, 1, 1, 1, 1, 2, 3, 3, 3, 2, 0, 1, 0, 0, 2, 0, 3, 1, 3, 3, 1, 3, 1, 3, 2, 1, 1, 3, 3, 2, 2, 3, 3, 0, 1, 1, 3, 1, 3, 3, 3, 3, 1, 3, 2, 2, 3, 0, 0, 2, 1, 0, 0, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -919. And steps were 89 and the episode is 428 and the total_steps are 44051\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -805     |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 716      |\n",
      "|    total_timesteps  | 44051    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 1, 0, 2, 1, 2, 1, 3, 3, 1, 0, 2, 0, 1, 0, 0, 3, 1, 3, 1, 0, 3, 2, 2, 2, 3, 2, 3, 1, 1, 3, 0, 1, 3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 1, 2, 0, 2, 1, 2, 0, 0, 1, 1, 2, 3, 0, 2, 2, 1, 3, 2, 1, 3, 0, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 71 and the episode is 429 and the total_steps are 44122\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 2, 0, 1, 0, 1, 2, 2, 1, 3, 1, 3, 1, 2, 2, 3, 0, 1, 3, 2, 2, 1, 0, 0, 2, 3, 3, 2, 3, 1, 0, 1, 0, 3, 3, 3, 1, 3, 0, 3, 3, 0, 0, 3, 0, 1, 1, 2, 0, 3, 0, 2, 1, 3, 0, 1, 1, 0, 3, 2, 2, 2, 0, 1, 1, 0, 2, 0, 1, 0, 1, 3, 3, 0, 1, 1, 1, 0, 0, 2, 0, 2, 1, 0, 3, 0, 1, 1, 3, 3, 1, 3, 2, 3, 3, 2, 2, 2, 0, 1, 1, 3, 1, 3, 1, 1, 3, 1, 1, 3, 0, 0, 3, 0, 3, 0, 3, 0, 3, 2, 2, 0, 0, 2, 3, 1, 1, 0, 2, 3, 1, 2, 1, 2, 0, 0, 2, 1, 2, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 154 and the episode is 430 and the total_steps are 44276\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 1, 3, 1, 3, 3, 0, 2, 1, 1, 2, 3, 1, 1, 2, 1, 1, 0, 3, 1, 2, 0, 3, 2, 1, 2, 2, 0, 2, 2, 3, 0, 1, 0, 0, 2, 1, 2, 2, 1, 1, 1, 2, 2, 0, 0, 3, 0, 3, 1, 2, 2, 2, 1, 0, 1, 2, 1, 2, 2, 3, 3, 2, 0, 1, 1, 2, 1, 1, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 76 and the episode is 431 and the total_steps are 44352\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 0, 0, 2, 0, 3, 2, 2, 3, 0, 3, 0, 1, 2, 3, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 3, 1, 1, 1, 2, 3, 3, 0, 2, 2, 3, 2, 3, 1, 0, 0, 2, 3, 2, 3, 1, 3, 0, 3, 2, 0, 3, 1, 3, 1, 1, 3, 2, 2, 1, 2, 3, 0, 1, 2, 1, 3, 1, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -939. And steps were 75 and the episode is 432 and the total_steps are 44427\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -805     |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 722      |\n",
      "|    total_timesteps  | 44427    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 0, 2, 2, 0, 3, 0, 2, 3, 3, 1, 0, 2, 2, 1, 3, 2, 0, 0, 0, 1, 2, 1, 0, 2, 1, 3, 3, 2, 0, 1, 2, 3, 0, 3, 3, 1, 1, 2, 2, 3, 0, 3, 2, 1, 1, 0, 3, 2, 2, 0, 1, 2, 3, 0, 3, 0, 2, 3, 3, 2, 3, 1, 1, 1, 3, 0, 3, 0, 2, 1, 0, 3, 0, 1, 3, 1, 1, 0, 1, 1, 0, 2, 1, 0, 1, 1, 2, 0, 1, 1, 0, 1, 1, 1, 2, 2, 0, 3, 1, 3, 0, 3, 0, 2, 3, 1, 0, 1, 3, 0, 1, 2, 3, 3, 0, 3, 2, 1, 1, 2, 1, 2, 0, 0, 0, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1052. And steps were 140 and the episode is 433 and the total_steps are 44567\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 3, 1, 2, 3, 3, 0, 1, 2, 3, 1, 1, 3, 0, 1, 3, 1, 0, 2, 0, 2, 2, 3, 1, 2, 1, 0, 1, 3, 2, 3, 0, 3, 2, 0, 1, 1, 2, 2, 3, 1, 1, 3, 3, 2, 2, 2, 3, 1, 1, 3, 3, 0, 3, 0, 2, 0, 2, 2, 0, 1, 2, 2, 0, 1, 1, 2, 3, 2, 1, 3, 3, 3, 3, 0, 2, 0, 2, 2, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 86 and the episode is 434 and the total_steps are 44653\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 0, 0, 2, 1, 3, 3, 0, 0, 1, 0, 3, 2, 3, 0, 1, 1, 2, 1, 1, 2, 1, 1, 3, 2, 2, 0, 1, 0, 2, 1, 1, 0, 0, 2, 3, 1, 3, 1, 1, 3, 3, 1, 1, 1, 0, 0, 0, 3, 2, 3, 2, 1, 3, 0, 2, 0, 1, 3, 2, 3, 3, 3, 3, 2, 3, 1, 0, 2, 0, 2, 2, 3, 2, 1, 3, 0, 3, 2, 1, 0, 0, 0, 1, 2, 1, 0, 0, 3, 2, 0, 1, 3, 0, 2, 3, 2, 2, 3, 1, 0, 0, 3, 0, 1, 3, 0, 0, 1, 0, 3, 1, 1, 0, 3, 2, 0, 2, 2, 0, 2, 3, 3, 2, 2, 2, 3, 2, 0, 3, 2, 3, 1, 3, 1, 0, 0, 3, 1, 3, 0, 1, 2, 2, 2, 1, 2, 2, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1159. And steps were 161 and the episode is 435 and the total_steps are 44814\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 2, 0, 1, 3, 3, 0, 3, 1, 3, 0, 1, 3, 2, 2, 0, 3, 3, 0, 3, 3, 0, 1, 3, 2, 1, 3, 0, 2, 1, 1, 1, 0, 1, 2, 2, 3, 1, 3, 1, 2, 1, 1, 3, 3, 2, 1, 1, 1, 2, 3, 0, 2, 1, 1, 0, 2, 0, 2, 1, 3, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 3, 3, 3, 2, 0, 1, 3, 1, 1, 3, 3, 2, 2, 1, 2, 1, 3, 0, 3, 0, 1, 0, 3, 0, 0, 2, 2, 0, 2, 1, 3, 3, 2, 0, 1, 1, 1, 0, 2, 3, 2, 1, 2, 1, 2, 0, 3, 0, 3, 1, 0, 0, 2, 2, 3, 3, 2, 0, 1, 0, 0, 0, 2, 1, 0, 3, 2, 3, 2, 2, 3, 1, 0, 2, 3, 3, 2, 3, 0, 2, 3, 2, 3, 2, 0, 1, 2, 1, 3, 2, 2, 3, 1, 0, 3, 0, 0, 2, 3, 1, 0, 1, 3, 0, 3, 2, 2, 1, 3, 1, 2, 1, 3, 0, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -872. And steps were 192 and the episode is 436 and the total_steps are 45006\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -807     |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 731      |\n",
      "|    total_timesteps  | 45006    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 1, 3, 1, 3, 1, 3, 2, 3, 0, 3, 2, 1, 2, 3, 3, 1, 2, 3, 3, 0, 2, 0, 1, 2, 3, 1, 0, 1, 0, 2, 0, 3, 2, 0, 3, 0, 2, 1, 2, 0, 3, 0, 3, 3, 3, 3, 2, 3, 1, 3, 1, 0, 3, 2, 3, 2, 1, 2, 2, 2, 3, 1, 3, 0, 3, 0, 2, 3, 3, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 0, 3, 1, 2, 3, 1, 2, 1, 3, 2, 2, 3, 2, 2, 0, 3, 2, 1, 3, 1, 3, 1, 0, 0, 1, 0, 2, 1, 2, 0, 1, 0, 1, 3, 2, 0, 3, 0, 2, 1, 0, 1, 1, 0, 2, 1, 2, 1, 2, 3, 0, 1, 0, 3, 0, 1, 3, 3, 3, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 146 and the episode is 437 and the total_steps are 45152\n",
      "Done condition: max time steps reached\n",
      "[3, 3, 0, 3, 2, 0, 1, 1, 2, 2, 2, 0, 3, 0, 0, 2, 0, 1, 0, 2, 3, 2, 1, 3, 1, 1, 0, 1, 2, 0, 3, 0, 1, 2, 3, 3, 3, 2, 1, 3, 0, 2, 2, 2, 3, 0, 0, 1, 2, 1, 2, 0, 3, 2, 0, 2, 1, 1, 0, 2, 1, 1, 3, 0, 1, 1, 3, 3, 0, 1, 3, 0, 1, 3, 0, 2, 1, 1, 3, 1, 2, 2, 0, 3, 1, 3, 0, 3, 3, 3, 0, 2, 1, 3, 2, 0, 1, 2, 2, 1, 3, 1, 1, 2, 3, 3, 0, 3, 0, 3, 0, 3, 0, 0, 2, 2, 1, 2, 0, 0, 0, 3, 0, 1, 3, 2, 1, 0, 0, 2, 3, 2, 1, 0, 0, 3, 1, 2, 3, 0, 0, 0, 2, 0, 1, 2, 3, 0, 3, 0, 3, 3, 2, 2, 2, 2, 1, 3, 2, 1, 0, 1, 0, 0, 2, 2, 3, 3, 1, 1, 3, 3, 3, 3, 0, 2, 1, 0, 1, 0, 2, 0, 2, 1, 1, 3, 3, 1, 1, 3, 2, 0, 3, 1, 1, 2, 2, 1, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1137. And steps were 202 and the episode is 438 and the total_steps are 45354\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 3, 0, 2, 0, 1, 0, 3, 0, 1, 3, 3, 2, 2, 3, 0, 1, 1, 2, 3, 3, 3, 1, 3, 0, 0, 3, 0, 1, 3, 2, 3, 1, 1, 2, 2, 2, 3, 2, 1, 0, 1, 0, 1, 2, 1, 2, 1, 2, 2, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 57 and the episode is 439 and the total_steps are 45411\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 3, 3, 3, 3, 0, 3, 1, 2, 0, 2, 2, 2, 3, 0, 1, 2, 0, 1, 0, 2, 2, 0, 2, 3, 3, 1, 2, 1, 1, 0, 1, 2, 2, 1, 1, 2, 0, 1, 0, 3, 1, 3, 2, 1, 2, 2, 1, 0, 3, 3, 2, 0, 3, 0, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 68 and the episode is 440 and the total_steps are 45479\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -827     |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 739      |\n",
      "|    total_timesteps  | 45479    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 3, 0, 3, 3, 0, 3, 3, 2, 2, 3, 0, 1, 2, 0, 0, 0, 0, 1, 1, 2, 3, 3, 3, 3, 1, 0, 2, 1, 0, 2, 3, 0, 0, 2, 1, 3, 2, 1, 3, 0, 0, 3, 2, 0, 3, 3, 3, 2, 1, 0, 3, 1, 1, 2, 3, 3, 3, 1, 0, 0, 3, 3, 0, 0, 2, 3, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 0, 3, 1, 0, 0, 0, 3, 1, 3, 0, 2, 1, 3, 3, 2, 2, 0, 2, 0, 0, 3, 3, 2, 2, 3, 2, 1, 2, 2, 1, 0, 3, 3, 0, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -934. And steps were 118 and the episode is 441 and the total_steps are 45597\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 3, 3, 1, 2, 3, 1, 1, 0, 1, 3, 2, 2, 3, 0, 1, 0, 1, 2, 0, 3, 3, 3, 2, 2, 0, 1, 2, 0, 1, 2, 3, 2, 0, 2, 1, 1, 3, 2, 0, 2, 0, 3, 3, 0, 0, 1, 2, 1, 3, 2, 3, 1, 2, 1, 1, 2, 3, 3, 3, 0, 1, 1, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 70 and the episode is 442 and the total_steps are 45667\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 0, 1, 3, 3, 2, 3, 1, 1, 3, 0, 2, 0, 2, 3, 2, 3, 0, 3, 3, 0, 1, 0, 0, 3, 2, 3, 3, 1, 2, 1, 3, 2, 0, 2, 1, 1, 3, 3, 0, 1, 3, 3, 2, 0, 0, 0, 1, 2, 2, 0, 2, 2, 1, 2, 0, 0, 3, 0, 1, 1, 1, 1, 3, 3, 3, 0, 0, 0, 1, 1, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 78 and the episode is 443 and the total_steps are 45745\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 0, 3, 2, 3, 0, 2, 1, 2, 0, 3, 0, 1, 3, 3, 2, 3, 3, 2, 0, 2, 2, 1, 3, 1, 3, 2, 1, 1, 2, 2, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 3, 1, 2, 2, 0, 3, 0, 3, 1, 3, 2, 2, 1, 0, 0, 2, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 3, 1, 2, 2, 1, 2, 0, 2, 0, 2, 3, 3, 2, 1, 1, 2, 0, 2, 0, 3, 0, 3, 3, 0, 0, 2, 2, 1, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 107 and the episode is 444 and the total_steps are 45852\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -827     |\n",
      "|    exploration_rate | 0.956    |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 745      |\n",
      "|    total_timesteps  | 45852    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 3, 1, 2, 0, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 0, 2, 3, 3, 2, 1, 1, 1, 1, 1, 2, 2, 2, 3, 0, 3, 2, 0, 2, 3, 3, 0, 3, 1, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was 1045. And steps were 46 and the episode is 445 and the total_steps are 45898\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 3, 2, 1, 3, 1, 1, 0, 2, 2, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 3, 3, 0, 2, 3, 0, 3, 3, 1, 1, 1, 0, 0, 0, 2, 0, 3, 1, 1, 1, 3, 1, 1, 0, 1, 2, 0, 1, 2, 3, 1, 2, 3, 1, 0, 2, 0, 0, 1, 0, 3, 0, 1, 2, 3, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 72 and the episode is 446 and the total_steps are 45970\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 1, 2, 1, 0, 3, 1, 0, 0, 2, 2, 2, 3, 2, 1, 3, 1, 3, 2, 2, 2, 2, 1, 3, 1, 2, 3, 2, 3, 1, 0, 1, 1, 0, 1, 1, 0, 3, 2, 1, 3, 0, 2, 0, 2, 0, 3, 2, 3, 3, 3, 2, 1, 3, 3, 3, 1, 3, 0, 3, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 67 and the episode is 447 and the total_steps are 46037\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 0, 3, 1, 3, 2, 3, 2, 1, 2, 0, 3, 1, 2, 2, 1, 3, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 1, 1, 1, 3, 2, 3, 2, 3, 3, 3, 3, 0, 0, 1, 1, 3, 3, 2, 3, 3, 0, 1, 2, 3, 2, 1, 2, 2, 0, 0, 0, 0, 1, 1, 3, 2, 2, 0, 0, 0, 0, 1, 3, 2, 1, 1, 3, 1, 3, 3, 2, 3, 0, 0, 2, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -939. And steps were 89 and the episode is 448 and the total_steps are 46126\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -804     |\n",
      "|    exploration_rate | 0.956    |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 749      |\n",
      "|    total_timesteps  | 46126    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 2, 1, 3, 2, 0, 3, 1, 1, 3, 3, 2, 0, 0, 2, 3, 2, 0, 2, 1, 2, 3, 0, 3, 3, 2, 1, 2, 0, 1, 1, 2, 0, 1, 3, 2, 0, 3, 0, 2, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 3, 3, 0, 2, 3, 0, 2, 2, 3, 1, 3, 1, 1, 1, 0, 0, 2, 1, 2, 0, 0, 1, 2, 0, 0, 1, 2, 0, 3, 3, 2, 1, 2, 2, 1, 0, 0, 1, 3, 2, 0, 3, 0, 2, 1, 3, 3, 1, 2, 3, 0, 3, 1, 1, 2, 3, 3, 3, 0, 3, 3, 2, 3, 3, 3, 2, 3, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1122. And steps were 124 and the episode is 449 and the total_steps are 46250\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 2, 0, 2, 1, 3, 2, 0, 3, 2, 0, 1, 2, 3, 0, 0, 3, 1, 0, 3, 0, 1, 2, 0, 2, 2, 1, 0, 2, 0, 3, 3, 3, 2, 2, 1, 2, 0, 2, 0, 3, 0, 3, 0, 3, 1, 3, 3, 2, 3, 3, 2, 1, 1, 3, 0, 2, 3, 1, 3, 1, 0, 2, 0, 2, 2, 2, 1, 3, 2, 3, 2, 2, 0, 0, 1, 1, 3, 0, 0, 3, 0, 3, 1, 0, 2, 3, 3, 3, 3, 3, 2, 2, 3, 0, 1, 3, 2, 3, 0, 1, 3, 1, 2, 1, 3, 0, 3, 1, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1114. And steps were 116 and the episode is 450 and the total_steps are 46366\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 3, 1, 3, 3, 2, 1, 1, 2, 2, 3, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 2, 2, 1, 3, 3, 3, 2, 0, 0, 3, 0, 1, 0, 0, 0, 3, 1, 0, 3, 2, 0, 2, 2, 2, 3, 1, 2, 0, 2, 1, 0, 3, 1, 3, 3, 0, 2, 0, 2, 2, 3, 2, 0, 3, 0, 2, 0, 3, 1, 1, 2, 2, 0, 2, 2, 2, 2, 0, 3, 3, 0, 0, 3, 0, 1, 2, 3, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 96 and the episode is 451 and the total_steps are 46462\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 0, 3, 3, 1, 3, 1, 2, 2, 1, 0, 3, 3, 1, 2, 0, 1, 3, 0, 1, 2, 1, 0, 2, 2, 3, 0, 3, 0, 1, 1, 3, 2, 3, 3, 1, 1, 1, 0, 1, 2, 0, 3, 2, 3, 0, 2, 3, 0, 2, 1, 1, 0, 1, 3, 1, 2, 2, 3, 2, 2, 1, 1, 3, 1, 0, 2, 2, 2, 1, 0, 0, 3, 3, 0, 0, 0, 2, 3, 0, 0, 1, 3, 3, 2, 3, 1, 0, 2, 1, 3, 2, 2, 3, 1, 0, 1, 2, 1, 3, 0, 2, 1, 0, 3, 0, 0, 2, 0, 2, 2, 1, 0, 1, 1, 0, 0, 0, 0, 0, 3, 3, 2, 1, 0, 3, 0, 2, 2, 2, 1, 2, 3, 2, 3, 1, 3, 1, 2, 2, 2, 0, 2, 3, 2, 0, 3, 1, 2, 3, 2, 3, 3, 2, 0, 0, 3, 2, 0, 1, 1, 1, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -861. And steps were 169 and the episode is 452 and the total_steps are 46631\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | -806     |\n",
      "|    exploration_rate | 0.956    |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 757      |\n",
      "|    total_timesteps  | 46631    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 0, 2, 0, 2, 0, 3, 2, 1, 0, 2, 3, 3, 2, 1, 1, 0, 0, 2, 3, 2, 1, 0, 3, 0, 0, 0, 3, 0, 3, 1, 3, 0, 0, 0, 3, 0, 2, 2, 1, 0, 0, 1, 3, 2, 0, 2, 0, 1, 2, 1, 3, 3, 0, 3, 1, 1, 1, 0, 2, 2, 2, 3, 2, 2, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 72 and the episode is 453 and the total_steps are 46703\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 1, 3, 1, 0, 2, 1, 2, 2, 0, 3, 3, 1, 1, 0, 2, 3, 2, 1, 2, 2, 1, 0, 0, 0, 2, 0, 3, 1, 0, 0, 2, 0, 1, 0, 3, 2, 1, 2, 3, 0, 3, 0, 0, 3, 1, 3, 3, 3, 0, 1, 1, 2, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 2, 2, 2, 1, 1, 0, 3, 1, 1, 3, 1, 3, 1, 3, 3, 3, 2, 0, 3, 0, 2, 3, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1047. And steps were 93 and the episode is 454 and the total_steps are 46796\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 2, 3, 2, 3, 2, 2, 0, 2, 1, 3, 3, 2, 1, 1, 2, 3, 3, 0, 2, 2, 3, 2, 3, 2, 0, 0, 0, 0, 2, 1, 3, 3, 0, 3, 2, 0, 1, 3, 3, 0, 2, 3, 3, 3, 2, 0, 3, 3, 1, 1, 1, 3, 3, 3, 3, 1, 2, 3, 3, 3, 0, 3, 2, 0, 2, 0, 0, 1, 3, 3, 2, 2, 3, 1, 3, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -925. And steps were 83 and the episode is 455 and the total_steps are 46879\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 2, 0, 3, 3, 0, 1, 0, 2, 1, 2, 3, 2, 0, 2, 3, 0, 0, 3, 1, 0, 2, 0, 1, 3, 2, 3, 3, 0, 0, 0, 2, 2, 2, 3, 2, 3, 1, 0, 1, 3, 3, 3, 2, 3, 0, 3, 1, 1, 3, 3, 1, 1, 2, 1, 3, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 2, 3, 3, 3, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 77 and the episode is 456 and the total_steps are 46956\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -805     |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 763      |\n",
      "|    total_timesteps  | 46956    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 3, 0, 0, 1, 2, 2, 1, 3, 2, 3, 3, 1, 2, 2, 3, 2, 3, 0, 0, 3, 3, 2, 3, 3, 0, 2, 1, 3, 2, 3, 2, 3, 3, 1, 3, 1, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1037. And steps were 42 and the episode is 457 and the total_steps are 46998\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 2, 2, 0, 0, 2, 0, 1, 1, 2, 3, 3, 0, 0, 3, 1, 0, 1, 2, 3, 1, 2, 2, 2, 0, 3, 3, 0, 1, 3, 0, 0, 1, 2, 1, 3, 1, 3, 1, 2, 0, 0, 2, 3, 1, 1, 3, 3, 3, 3, 1, 2, 0, 3, 2, 2, 3, 2, 3, 2, 1, 2, 2, 2, 2, 1, 2, 1, 0, 0, 2, 1, 2, 2, 2, 0, 2, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 85 and the episode is 458 and the total_steps are 47083\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 0, 2, 1, 1, 1, 2, 0, 2, 1, 1, 2, 2, 3, 1, 3, 3, 1, 2, 2, 1, 1, 0, 3, 1, 0, 2, 3, 3, 2, 2, 3, 0, 0, 1, 0, 0, 3, 1, 0, 0, 3, 2, 2, 2, 2, 3, 2, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 3, 1, 0, 1, 1, 1, 1, 2, 3, 2, 3, 0, 1, 0, 0, 1, 2, 2, 1, 2, 0, 0, 1, 1, 1, 0, 2, 2, 1, 0, 1, 3, 1, 0, 2, 2, 3, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -932. And steps were 104 and the episode is 459 and the total_steps are 47187\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 2, 1, 3, 0, 0, 1, 2, 3, 0, 0, 3, 2, 1, 3, 1, 2, 0, 0, 3, 0, 2, 0, 2, 3, 3, 2, 3, 1, 0, 2, 3, 0, 1, 3, 3, 3, 1, 1, 2, 2, 3, 2, 1, 0, 2, 3, 2, 2, 3, 0, 3, 1, 0, 1, 3, 2, 1, 1, 1, 0, 2, 3, 0, 0, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 72 and the episode is 460 and the total_steps are 47259\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -785     |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 768      |\n",
      "|    total_timesteps  | 47259    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 2, 1, 1, 3, 1, 0, 2, 1, 1, 3, 1, 2, 3, 1, 3, 1, 3, 1, 1, 2, 0, 1, 2, 0, 0, 0, 2, 3, 0, 3, 3, 0, 3, 0, 3, 3, 0, 1, 3, 3, 3, 2, 0, 3, 2, 1, 1, 2, 0, 3, 3, 3, 1, 2, 0, 0, 0, 3, 1, 1, 3, 3, 2, 2, 1, 1, 3, 3, 3, 3, 2, 1, 1, 0, 1, 1, 0, 3, 0, 0, 1, 3, 3, 2, 0, 0, 3, 2, 2, 2, 0, 2, 3, 2, 1, 2, 3, 3, 3, 2, 2, 2, 3, 1, 0, 2, 2, 2, 1, 2, 0, 3, 0, 0, 1, 2, 1, 2, 2, 0, 2, 0, 3, 0, 1, 3, 2, 1, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 136 and the episode is 461 and the total_steps are 47395\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 0, 1, 0, 0, 2, 2, 0, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 2, 1, 3, 0, 3, 2, 2, 1, 0, 2, 1, 0, 0, 3, 0, 0, 3, 3, 3, 2, 2, 3, 1, 3, 0, 2, 3, 0, 3, 2, 0, 2, 2, 1, 3, 0, 2, 1, 3, 3, 0, 0, 2, 1, 0, 3, 0, 2, 1, 0, 0, 1, 2, 0, 0, 0, 2, 1, 3, 0, 3, 0, 1, 1, 0, 2, 0, 0, 2, 2, 1, 0, 2, 2, 2, 0, 0, 1, 1, 2, 3, 1, 3, 2, 3, 3, 1, 2, 2, 0, 1, 0, 3, 3, 3, 0, 2, 1, 3, 2, 3, 0, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 127 and the episode is 462 and the total_steps are 47522\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 3, 0, 0, 3, 1, 1, 0, 2, 3, 0, 2, 0, 2, 3, 2, 2, 3, 0, 0, 0, 1, 1, 0, 3, 0, 3, 2, 2, 2, 3, 0, 3, 3, 2, 0, 3, 2, 2, 1, 2, 3, 2, 3, 0, 1, 1, 0, 3, 1, 3, 3, 2, 3, 1, 3, 1, 1, 2, 0, 0, 3, 0, 0, 3, 0, 2, 2, 2, 2, 3, 2, 3, 3, 0, 0, 2, 1, 1, 2, 1, 0, 3, 3, 0, 3, 0, 0, 0, 2, 3, 1, 0, 3, 2, 2, 0, 3, 3, 2, 2, 2, 3, 2, 3, 3, 2, 2, 1, 3, 1, 2, 3, 2, 3, 1, 1, 3, 2, 0, 3, 1, 2, 2, 3, 3, 0, 2, 0, 1, 0, 1, 1, 0, 3, 3, 0, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -888. And steps were 144 and the episode is 463 and the total_steps are 47666\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 3, 3, 0, 1, 3, 2, 2, 0, 2, 1, 2, 2, 0, 0, 1, 1, 1, 2, 1, 2, 2, 3, 2, 0, 1, 2, 2, 3, 2, 2, 3, 0, 2, 2, 3, 2, 2, 1, 3, 0, 2, 2, 3, 1, 3, 3, 2, 2, 0, 2, 2, 3, 0, 3, 1, 1, 3, 1, 3, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 67 and the episode is 464 and the total_steps are 47733\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -804     |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 775      |\n",
      "|    total_timesteps  | 47733    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 0, 1, 1, 0, 0, 0, 2, 0, 0, 3, 1, 0, 3, 3, 1, 1, 3, 3, 0, 3, 2, 1, 1, 2, 1, 1, 0, 1, 1, 2, 3, 0, 1, 1, 1, 2, 3, 1, 0, 0, 2, 3, 1, 1, 2, 2, 3, 1, 1, 3, 3, 0, 3, 0, 3, 2, 1, 0, 3, 0, 3, 1, 1, 2, 2, 0, 3, 2, 2, 3, 1, 3, 2, 3, 0, 3, 1, 0, 3, 3, 2, 1, 0, 2, 3, 2, 0, 2, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 96 and the episode is 465 and the total_steps are 47829\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 3, 3, 0, 2, 0, 0, 1, 1, 1, 0, 2, 3, 1, 2, 3, 2, 3, 0, 0, 0, 1, 2, 1, 2, 0, 0, 2, 0, 3, 0, 0, 3, 2, 1, 0, 1, 1, 1, 3, 2, 0, 0, 2, 2, 1, 3, 0, 1, 2, 0, 2, 3, 2, 1, 0, 3, 0, 0, 1, 2, 0, 0, 3, 3, 2, 1, 0, 2, 1, 2, 0, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 79 and the episode is 466 and the total_steps are 47908\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 3, 1, 0, 2, 2, 3, 0, 2, 0, 1, 3, 3, 0, 0, 1, 2, 3, 0, 3, 1, 0, 3, 3, 1, 1, 0, 0, 1, 0, 2, 1, 2, 0, 2, 2, 0, 3, 1, 3, 3, 0, 3, 1, 1, 0, 3, 3, 3, 0, 0, 0, 3, 2, 1, 3, 0, 2, 3, 0, 2, 2, 0, 0, 0, 2, 1, 3, 2, 0, 0, 0, 0, 1, 1, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 82 and the episode is 467 and the total_steps are 47990\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 2, 2, 0, 3, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 3, 0, 2, 2, 2, 3, 1, 2, 2, 0, 2, 3, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 1, 0, 2, 0, 3, 2, 0, 1, 0, 2, 0, 0, 1, 2, 2, 0, 2, 3, 3, 2, 1, 1, 2, 2, 2, 0, 0, 3, 2, 2, 2, 0, 1, 1, 0, 0, 0, 2, 3, 1, 0, 2, 2, 2, 2, 2, 1, 3, 3, 2, 0, 1, 3, 1, 1, 0, 2, 2, 1, 0, 0, 0, 1, 3, 0, 2, 3, 2, 0, 1, 3, 1, 0, 0, 0, 3, 0, 2, 2, 0, 1, 1, 3, 2, 1, 2, 2, 1, 1, 1, 1, 0, 0, 2, 0, 0, 1, 1, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 152 and the episode is 468 and the total_steps are 48142\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -821     |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 782      |\n",
      "|    total_timesteps  | 48142    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 0, 1, 1, 0, 1, 3, 3, 2, 1, 2, 3, 0, 3, 2, 3, 2, 1, 3, 3, 3, 2, 1, 3, 0, 0, 1, 3, 3, 0, 3, 1, 1, 0, 2, 1, 1, 0, 1, 2, 3, 0, 2, 3, 1, 0, 2, 2, 0, 0, 3, 2, 0, 1, 3, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was 1059. And steps were 60 and the episode is 469 and the total_steps are 48202\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 3, 0, 2, 1, 0, 1, 1, 0, 3, 0, 3, 0, 3, 1, 2, 2, 2, 3, 2, 3, 1, 1, 2, 0, 1, 3, 1, 3, 1, 3, 1, 3, 0, 1, 3, 0, 1, 1, 3, 3, 1, 2, 1, 0, 3, 1, 2, 3, 0, 3, 3, 1, 2, 2, 3, 3, 1, 0, 3, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 67 and the episode is 470 and the total_steps are 48269\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 0, 2, 0, 0, 0, 0, 2, 3, 2, 2, 2, 3, 1, 2, 1, 2, 0, 0, 3, 2, 0, 0, 0, 3, 1, 0, 1, 2, 2, 2, 0, 2, 1, 1, 1, 3, 0, 0, 3, 0, 3, 2, 3, 0, 3, 1, 2, 2, 3, 2, 3, 2, 1, 3, 0, 2, 2, 3, 0, 3, 0, 2, 2, 3, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 72 and the episode is 471 and the total_steps are 48341\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 1, 0, 1, 0, 2, 2, 0, 3, 2, 2, 3, 3, 0, 2, 2, 0, 2, 0, 1, 0, 1, 0, 2, 2, 2, 3, 1, 2, 3, 1, 1, 2, 2, 0, 2, 0, 2, 1, 1, 1, 3, 3, 1, 1, 2, 1, 1, 1, 2, 2, 3, 2, 1, 3, 1, 3, 2, 0, 1, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1065. And steps were 67 and the episode is 472 and the total_steps are 48408\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -822     |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 786      |\n",
      "|    total_timesteps  | 48408    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 1, 0, 3, 3, 2, 3, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 3, 1, 0, 0, 3, 1, 3, 1, 2, 1, 0, 0, 0, 2, 3, 3, 1, 3, 0, 1, 0, 0, 1, 2, 2, 3, 3, 2, 1, 2, 3, 1, 3, 0, 0, 1, 0, 1, 2, 3, 0, 0, 0, 0, 2, 2, 1, 3, 2, 1, 0, 2, 0, 3, 1, 3, 2, 0, 2, 0, 3, 3, 2, 0, 3, 3, 3, 1, 3, 0, 2, 2, 3, 0, 1, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 99 and the episode is 473 and the total_steps are 48507\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 1, 1, 0, 1, 3, 1, 0, 2, 1, 3, 2, 3, 3, 0, 0, 0, 2, 0, 2, 1, 2, 0, 0, 3, 3, 3, 3, 3, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 3, 2, 2, 0, 2, 0, 3, 3, 0, 0, 3, 2, 2, 3, 0, 3, 1, 3, 3, 2, 1, 3, 0, 2, 3, 0, 1, 3, 2, 2, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -936. And steps were 76 and the episode is 474 and the total_steps are 48583\n",
      "Done condition: collision\n",
      "[3, 0, 0, 3, 2, 2, 1, 1, 2, 3, 0, 2, 2, 2, 1, 3, 3, 3, 2, 1, 1, 2, 3, 3, 3, 0, 1, 0, 3, 0, 0, 1, 1, 0, 0, 3, 2, 1, 3, 1, 1, 3, 2, 2, 1, 0, 3, 1, 3, 0, 3, 2, 1, 3, 2, 1, 2, 0, 0, 1, 1, 0, 2, 2, 2, 0, 1, 0, 3, 1, 1, 3, 0, 3, 1, 0, 2, 3, 1, 1, 1, 3, 2, 3, 1, 2, 3, 0, 3, 0, 2, 1, 0, 0, 0, 0, 2, 1, 3, 3, 2, 3, 0, 0, 2, 3, 0, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1049. And steps were 111 and the episode is 475 and the total_steps are 48694\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 3, 1, 3, 0, 1, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 3, 3, 0, 2, 2, 2, 1, 2, 1, 3, 1, 3, 3, 1, 3, 1, 0, 0, 2, 0, 0, 2, 1, 3, 2, 2, 3, 1, 0, 2, 2, 3, 0, 0, 0, 0, 0, 2, 1, 0, 2, 1, 2, 0, 0, 2, 0, 1, 0, 3, 0, 0, 1, 0, 2, 2, 1, 3, 3, 3, 2, 0, 1, 0, 1, 1, 2, 3, 1, 3, 2, 2, 2, 0, 2, 3, 2, 3, 0, 1, 0, 1, 0, 3, 0, 2, 0, 0, 0, 1, 2, 2, 1, 2, 3, 1, 1, 0, 1, 0, 0, 0, 3, 3, 0, 1, 1, 1, 2, 1, 3, 0, 2, 2, 0, 1, 3, 1, 2, 3, 1, 3, 0, 0, 3, 2, 0, 2, 3, 1, 1, 0, 2, 3, 3, 1, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1157. And steps were 159 and the episode is 476 and the total_steps are 48853\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -823     |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 793      |\n",
      "|    total_timesteps  | 48853    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 2, 3, 0, 0, 2, 1, 3, 0, 2, 0, 2, 2, 1, 2, 3, 1, 3, 3, 2, 1, 3, 0, 0, 3, 2, 3, 3, 2, 3, 1, 1, 3, 0, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1034. And steps were 39 and the episode is 477 and the total_steps are 48892\n",
      "Done condition: max time steps reached\n",
      "[3, 3, 2, 2, 0, 3, 0, 1, 1, 0, 3, 1, 3, 0, 3, 0, 1, 0, 2, 0, 3, 2, 0, 2, 2, 0, 1, 3, 2, 0, 1, 0, 3, 0, 1, 1, 3, 1, 0, 0, 3, 2, 0, 3, 2, 3, 0, 1, 0, 2, 1, 1, 3, 3, 2, 0, 1, 1, 2, 0, 0, 3, 3, 0, 3, 2, 1, 1, 3, 1, 1, 2, 0, 0, 0, 2, 3, 0, 1, 1, 1, 3, 0, 0, 1, 1, 2, 1, 2, 1, 2, 3, 2, 0, 3, 2, 3, 2, 1, 1, 1, 0, 2, 1, 0, 0, 1, 3, 2, 3, 2, 2, 0, 3, 1, 2, 3, 1, 2, 1, 0, 3, 1, 3, 1, 2, 1, 2, 0, 1, 0, 2, 0, 0, 3, 2, 0, 0, 2, 1, 0, 1, 0, 3, 2, 0, 2, 3, 3, 3, 3, 3, 3, 2, 1, 2, 2, 2, 2, 0, 2, 2, 3, 1, 0, 2, 2, 2, 3, 3, 3, 2, 3, 1, 3, 3, 1, 2, 3, 0, 3, 3, 2, 3, 0, 3, 0, 2, 2, 2, 0, 1, 2, 2, 2, 1, 0, 2, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 202 and the episode is 478 and the total_steps are 49094\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 3, 2, 0, 1, 3, 3, 3, 0, 1, 1, 1, 2, 0, 0, 1, 2, 0, 1, 1, 0, 3, 3, 2, 3, 1, 0, 3, 0, 3, 3, 1, 0, 2, 3, 2, 3, 0, 3, 0, 3, 1, 3, 0, 3, 3, 3, 1, 3, 3, 3, 1, 0, 0, 2, 1, 0, 3, 2, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 66 and the episode is 479 and the total_steps are 49160\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 1, 0, 2, 1, 0, 3, 1, 0, 0, 2, 1, 3, 2, 3, 1, 1, 1, 3, 1, 1, 0, 3, 3, 0, 1, 1, 3, 3, 3, 3, 0, 0, 2, 3, 1, 0, 3, 2, 0, 1, 3, 3, 2, 2, 3, 1, 0, 3, 1, 0, 2, 3, 3, 1, 1, 0, 1, 3, 1, 3, 0, 3, 3, 3, 3, 0, 3, 2, 1, 1, 3, 0, 2, 0, 3, 1, 0, 3, 2, 0, 1, 3, 0, 2, 3, 2, 3, 1, 1, 3, 3, 0, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 100 and the episode is 480 and the total_steps are 49260\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -824     |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 800      |\n",
      "|    total_timesteps  | 49260    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 0, 2, 1, 0, 1, 2, 1, 3, 2, 0, 2, 1, 3, 1, 2, 3, 0, 3, 2, 3, 2, 2, 2, 3, 3, 0, 2, 1, 0, 0, 1, 1, 3, 2, 3, 1, 2, 1, 3, 0, 3, 1, 2, 1, 0, 1, 3, 0, 3, 2, 0, 3, 0, 2, 3, 2, 1, 0, 2, 0, 3, 3, 2, 0, 0, 0, 2, 3, 0, 0, 1, 0, 3, 1, 1, 1, 0, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 92 and the episode is 481 and the total_steps are 49352\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 2, 1, 3, 3, 0, 2, 2, 0, 1, 1, 3, 2, 0, 2, 1, 3, 3, 1, 1, 0, 0, 2, 3, 2, 1, 0, 1, 0, 0, 1, 1, 2, 1, 3, 0, 2, 2, 0, 1, 1, 3, 3, 2, 0, 0, 3, 3, 3, 2, 1, 2, 0, 3, 2, 0, 1, 2, 3, 3, 3, 3, 0, 2, 1, 0, 2, 2, 0, 3, 2, 3, 1, 0, 0, 1, 3, 1, 1, 1, 0, 2, 3, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 3, 2, 3, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -937. And steps were 103 and the episode is 482 and the total_steps are 49455\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 2, 0, 2, 0, 3, 1, 2, 2, 0, 0, 2, 3, 2, 2, 1, 2, 3, 0, 3, 2, 3, 1, 1, 0, 2, 2, 3, 2, 1, 1, 2, 0, 2, 1, 3, 2, 2, 1, 2, 1, 2, 0, 3, 2, 3, 2, 2, 2, 1, 3, 0, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1057. And steps were 59 and the episode is 483 and the total_steps are 49514\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 2, 0, 3, 1, 1, 0, 2, 3, 1, 1, 1, 2, 1, 3, 0, 1, 1, 3, 1, 3, 1, 3, 0, 3, 2, 3, 1, 2, 2, 0, 1, 1, 1, 2, 0, 3, 0, 3, 2, 1, 0, 3, 2, 3, 2, 2, 1, 1, 3, 2, 3, 2, 3, 0, 3, 2, 2, 0, 1, 0, 2, 1, 3, 2, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1070. And steps were 72 and the episode is 484 and the total_steps are 49586\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -824     |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 805      |\n",
      "|    total_timesteps  | 49586    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 3, 3, 1, 3, 3, 3, 3, 1, 2, 1, 3, 3, 2, 1, 1, 2, 3, 1, 0, 3, 3, 0, 1, 2, 3, 0, 2, 2, 2, 2, 0, 2, 2, 3, 1, 2, 3, 2, 2, 1, 1, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1046. And steps were 47 and the episode is 485 and the total_steps are 49633\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 1, 2, 2, 3, 0, 0, 0, 3, 1, 3, 0, 1, 3, 0, 1, 2, 1, 3, 0, 3, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 3, 2, 0, 0, 0, 1, 1, 2, 3, 3, 3, 0, 3, 2, 3, 0, 2, 2, 1, 3, 1, 1, 1, 1, 2, 2, 2, 1, 0, 3, 1, 0, 2, 1, 3, 0, 0, 0, 3, 2, 3, 2, 0, 0, 2, 2, 1, 2, 1, 2, 0, 0, 3, 2, 2, 0, 2, 0, 3, 0, 0, 3, 1, 3, 1, 1, 0, 2, 1, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -925. And steps were 107 and the episode is 486 and the total_steps are 49740\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 2, 1, 3, 1, 1, 0, 1, 0, 2, 2, 0, 2, 2, 0, 3, 2, 3, 2, 3, 1, 3, 0, 3, 2, 2, 1, 3, 0, 0, 3, 3, 3, 2, 1, 1, 3, 3, 0, 0, 0, 1, 1, 3, 3, 3, 2, 3, 3, 2, 0, 3, 3, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 60 and the episode is 487 and the total_steps are 49800\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 3, 2, 0, 2, 3, 2, 2, 3, 0, 0, 3, 3, 0, 1, 1, 0, 0, 1, 0, 3, 0, 3, 0, 0, 0, 1, 0, 2, 2, 0, 3, 0, 3, 1, 0, 1, 3, 1, 0, 3, 1, 2, 2, 3, 1, 2, 0, 2, 0, 3, 3, 1, 3, 0, 0, 0, 3, 2, 0, 3, 1, 0, 2, 3, 0, 0, 1, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 75 and the episode is 488 and the total_steps are 49875\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.9     |\n",
      "|    ep_rew_mean      | -803     |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 810      |\n",
      "|    total_timesteps  | 49875    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 1, 0, 0, 2, 3, 2, 1, 3, 1, 0, 3, 1, 2, 0, 3, 2, 2, 0, 3, 1, 3, 0, 3, 3, 1, 1, 0, 2, 0, 3, 0, 1, 1, 0, 0, 1, 1, 1, 3, 2, 3, 0, 1, 0, 3, 2, 0, 2, 3, 0, 1, 1, 2, 1, 1, 0, 1, 3, 2, 0, 1, 2, 3, 3, 0, 1, 3, 2, 1, 1, 0, 3, 2, 0, 2, 3, 1, 2, 3, 3, 2, 2, 2, 0, 3, 3, 2, 2, 0, 0, 2, 1, 1, 0, 0, 1, 1, 1, 2, 3, 1, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -901. And steps were 109 and the episode is 489 and the total_steps are 49984\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 3, 0, 1, 1, 1, 1, 2, 0, 3, 0, 3, 3, 1, 2, 3, 3, 0, 3, 0, 0, 3, 1, 3, 2, 2, 0, 0, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 35 and the episode is 490 and the total_steps are 50019\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 0, 0, 0, 1, 2, 0, 1, 0, 2, 2, 1, 2, 0, 2, 0, 2, 3, 1, 2, 2, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 491 and the total_steps are 50045\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 1, 0, 3, 3, 2, 2, 3, 1, 2, 0, 1, 3, 1, 3, 1, 1, 1, 2, 1, 0, 1, 3, 1, 0, 0, 1, 1, 3, 3, 3, 0, 3, 0, 1, 3, 2, 3, 2, 2, 3, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 48 and the episode is 492 and the total_steps are 50093\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -803     |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 820      |\n",
      "|    total_timesteps  | 50093    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 23       |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 0, 3, 1, 2, 3, 0, 2, 1, 1, 3, 3, 1, 3, 2, 2, 1, 1, 2, 0, 1, 1, 2, 2, 3, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 36 and the episode is 493 and the total_steps are 50129\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 1, 3, 1, 2, 2, 0, 0, 3, 3, 3, 1, 3, 3, 1, 2, 3, 0, 3, 3, 0, 2, 3, 1, 0, 2, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 33 and the episode is 494 and the total_steps are 50162\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 1, 1, 3, 1, 2, 0, 2, 3, 3, 1, 2, 2, 2, 0, 0, 3, 0, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 3, 0, 3, 2, 3, 0, 2, 1, 3, 2, 2, 2, 0, 2, 0, 0, 3, 1, 3, 3, 0, 3, 2, 3, 2, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 60 and the episode is 495 and the total_steps are 50222\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 2, 3, 2, 3, 1, 3, 0, 0, 2, 1, 1, 3, 2, 0, 0, 3, 2, 0, 1, 1, 1, 0, 1, 2, 1, 2, 2, 3, 1, 0, 2, 3, 1, 1, 2, 3, 2, 1, 0, 1, 2, 3, 0, 2, 1, 1, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 54 and the episode is 496 and the total_steps are 50276\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.9     |\n",
      "|    ep_rew_mean      | -806     |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 827      |\n",
      "|    total_timesteps  | 50276    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.494    |\n",
      "|    n_updates        | 68       |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 3, 3, 1, 2, 0, 3, 1, 2, 0, 3, 1, 2, 3, 3, 0, 2, 3, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 497 and the total_steps are 50301\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 0, 2, 3, 3, 3, 0, 1, 3, 3, 0, 3, 2, 2, 3, 2, 3, 0, 2, 0, 1, 1, 0, 2, 1, 3, 3, 1, 1, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 36 and the episode is 498 and the total_steps are 50337\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 0, 3, 0, 2, 2, 1, 0, 0, 3, 0, 2, 1, 2, 2, 3, 0, 1, 1, 0, 2, 3, 2, 3, 0, 3, 1, 1, 3, 0, 2, 3, 2, 0, 3, 2, 3, 0, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 45 and the episode is 499 and the total_steps are 50382\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 1, 3, 3, 1, 0, 1, 3, 0, 3, 3, 3, 1, 2, 0, 3, 0, 2, 2, 0, 3, 2, 0, 3, 2, 1, 0, 3, 0, 2, 2, 2, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 39 and the episode is 500 and the total_steps are 50421\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.2     |\n",
      "|    ep_rew_mean      | -823     |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 833      |\n",
      "|    total_timesteps  | 50421    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.398    |\n",
      "|    n_updates        | 105      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 1, 1, 1, 1, 0, 0, 2, 1, 0, 1, 1, 3, 2, 2, 0, 1, 0, 2, 0, 3, 0, 3, 1, 1, 3, 0, 0, 0, 1, 2, 0, 1, 3, 3, 2, 0, 1, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 45 and the episode is 501 and the total_steps are 50466\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 1, 0, 1, 0, 1, 3, 1, 0, 1, 1, 3, 0, 1, 0, 3, 0, 2, 1, 1, 2, 3, 2, 1, 1, 1, 3, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 33 and the episode is 502 and the total_steps are 50499\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 2, 2, 2, 1, 0, 1, 1, 3, 0, 1, 3, 0, 0, 2, 0, 2, 3, 3, 1, 1, 2, 3, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 503 and the total_steps are 50529\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 2, 3, 2, 2, 2, 3, 2, 1, 2, 3, 0, 0, 0, 3, 2, 3, 0, 3, 0, 0, 1, 3, 1, 3, 0, 2, 3, 3, 2, 1, 1, 2, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 40 and the episode is 504 and the total_steps are 50569\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91       |\n",
      "|    ep_rew_mean      | -825     |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 838      |\n",
      "|    total_timesteps  | 50569    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 36.4     |\n",
      "|    n_updates        | 142      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 1, 2, 2, 0, 2, 3, 1, 3, 1, 3, 0, 2, 0, 2, 2, 3, 0, 1, 2, 3, 3, 1, 2, 3, 2, 2, 2, 1, 0, 1, 0, 0, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 40 and the episode is 505 and the total_steps are 50609\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 3, 2, 2, 2, 2, 2, 1, 3, 3, 0, 2, 1, 1, 1, 3, 3, 3, 2, 0, 2, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 506 and the total_steps are 50637\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 2, 1, 1, 2, 0, 2, 0, 2, 0, 2, 1, 3, 1, 2, 1, 3, 0, 3, 2, 2, 3, 0, 3, 0, 2, 3, 1, 1, 3, 2, 2, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 39 and the episode is 507 and the total_steps are 50676\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 1, 1, 1, 2, 0, 0, 1, 2, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 24 and the episode is 508 and the total_steps are 50700\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 87.9     |\n",
      "|    ep_rew_mean      | -846     |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 843      |\n",
      "|    total_timesteps  | 50700    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.74     |\n",
      "|    n_updates        | 174      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 1, 2, 1, 1, 0, 2, 2, 1, 3, 0, 2, 1, 0, 1, 3, 0, 1, 1, 0, 3, 1, 0, 0, 3, 0, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 33 and the episode is 509 and the total_steps are 50733\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 0, 2, 0, 3, 1, 0, 3, 0, 0, 3, 1, 1, 2, 3, 1, 3, 1, 0, 1, 1, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 510 and the total_steps are 50759\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 0, 3, 1, 0, 1, 1, 1, 0, 3, 1, 3, 3, 3, 1, 1, 0, 2, 2, 1, 2, 1, 3, 3, 3, 0, 1, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 34 and the episode is 511 and the total_steps are 50793\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 2, 2, 3, 3, 1, 1, 2, 1, 2, 1, 3, 2, 1, 2, 1, 1, 0, 3, 0, 2, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 512 and the total_steps are 50819\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 85.2     |\n",
      "|    ep_rew_mean      | -804     |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 848      |\n",
      "|    total_timesteps  | 50819    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.93     |\n",
      "|    n_updates        | 204      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 0, 1, 3, 1, 0, 3, 2, 2, 1, 3, 2, 3, 0, 2, 0, 1, 0, 1, 3, 0, 0, 3, 0, 1, 0, 2, 3, 3, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 46 and the episode is 513 and the total_steps are 50865\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 3, 2, 1, 1, 0, 2, 0, 1, 2, 1, 0, 3, 2, 2, 3, 1, 2, 3, 0, 1, 3, 3, 3, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1, 1, 3, 0, 2, 1, 0, 2, 1, 3, 2, 1, 2, 3, 1, 1, 1, 3, 0, 3, 0, 3, 3, 1, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 64 and the episode is 514 and the total_steps are 50929\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 3, 3, 2, 3, 0, 0, 1, 3, 3, 3, 3, 3, 1, 3, 3, 0, 1, 1, 3, 1, 2, 1, 2, 1, 0, 0, 2, 3, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 515 and the total_steps are 50965\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 1, 3, 1, 0, 3, 2, 0, 1, 2, 3, 3, 1, 0, 1, 1, 2, 0, 0, 1, 3, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 2, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 42 and the episode is 516 and the total_steps are 51007\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 83.5     |\n",
      "|    ep_rew_mean      | -825     |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 856      |\n",
      "|    total_timesteps  | 51007    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.368    |\n",
      "|    n_updates        | 251      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 2, 0, 3, 3, 1, 3, 1, 0, 3, 0, 0, 1, 3, 3, 1, 2, 2, 1, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 3, 0, 0, 0, 2, 3, 3, 1, 0, 2, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 47 and the episode is 517 and the total_steps are 51054\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 3, 1, 1, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 1, 0, 3, 2, 3, 0, 3, 1, 3, 1, 1, 0, 2, 3, 0, 0, 3, 3, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 39 and the episode is 518 and the total_steps are 51093\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 2, 1, 0, 0, 3, 3, 2, 3, 1, 3, 2, 2, 3, 1, 2, 3, 3, 3, 2, 3, 3, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 29 and the episode is 519 and the total_steps are 51122\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 1, 1, 1, 2, 1, 3, 3, 1, 0, 3, 0, 1, 0, 3, 3, 0, 2, 2, 1, 0, 0, 1, 1, 3, 0, 3, 1, 3, 2, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 43 and the episode is 520 and the total_steps are 51165\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 80.4     |\n",
      "|    ep_rew_mean      | -827     |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 862      |\n",
      "|    total_timesteps  | 51165    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.294    |\n",
      "|    n_updates        | 291      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 1, 2, 1, 2, 1, 0, 3, 0, 0, 2, 2, 0, 3, 3, 3, 1, 0, 1, 3, 1, 2, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 29 and the episode is 521 and the total_steps are 51194\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 0, 0, 2, 0, 1, 1, 1, 3, 3, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 0, 2, 3, 2, 1, 0, 2, 1, 3, 0, 2, 3, 2, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 47 and the episode is 522 and the total_steps are 51241\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 0, 2, 2, 0, 3, 2, 1, 3, 1, 1, 3, 3, 0, 3, 3, 3, 1, 3, 1, 1, 1, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 29 and the episode is 523 and the total_steps are 51270\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 3, 1, 3, 2, 1, 3, 0, 2, 1, 3, 1, 3, 3, 1, 3, 2, 3, 3, 2, 2, 1, 3, 0, 1, 1, 3, 0, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 35 and the episode is 524 and the total_steps are 51305\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 77.4     |\n",
      "|    ep_rew_mean      | -828     |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 867      |\n",
      "|    total_timesteps  | 51305    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0854   |\n",
      "|    n_updates        | 326      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 1, 3, 0, 0, 1, 2, 2, 2, 2, 0, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 18 and the episode is 525 and the total_steps are 51323\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 3, 0, 3, 1, 3, 3, 1, 0, 0, 2, 3, 1, 0, 1, 2, 3, 3, 2, 0, 1, 2, 0, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 526 and the total_steps are 51353\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 2, 3, 1, 1, 3, 1, 2, 3, 1, 3, 2, 0, 2, 2, 1, 0, 2, 1, 3, 1, 1, 3, 3, 0, 3, 1, 2, 2, 0, 0, 2, 1, 1, 3, 2, 2, 0, 1, 2, 3, 2, 2, 0, 2, 2, 0, 1, 3, 0, 0, 3, 3, 2, 1, 2, 0, 3, 1, 3, 2, 0, 3, 1, 2, 1, 1, 1, 1, 3, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 77 and the episode is 527 and the total_steps are 51430\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 1, 1, 3, 0, 0, 1, 3, 1, 0, 3, 1, 1, 1, 1, 3, 1, 0, 2, 2, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 528 and the total_steps are 51457\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 74.1     |\n",
      "|    ep_rew_mean      | -831     |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 58       |\n",
      "|    time_elapsed     | 873      |\n",
      "|    total_timesteps  | 51457    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.62     |\n",
      "|    n_updates        | 364      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 1, 2, 1, 2, 3, 3, 2, 0, 3, 3, 1, 2, 3, 2, 1, 2, 3, 2, 0, 2, 1, 3, 1, 2, 3, 2, 3, 2, 3, 0, 0, 0, 2, 2, 0, 2, 1, 3, 2, 1, 2, 1, 0, 3, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 52 and the episode is 529 and the total_steps are 51509\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 1, 3, 2, 1, 0, 3, 3, 1, 0, 2, 1, 3, 2, 0, 3, 1, 3, 1, 1, 1, 3, 3, 1, 3, 3, 1, 0, 2, 0, 3, 1, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 39 and the episode is 530 and the total_steps are 51548\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 1, 0, 0, 2, 1, 3, 3, 3, 0, 3, 2, 0, 2, 1, 3, 0, 1, 3, 0, 3, 0, 1, 2, 0, 2, 1, 2, 1, 2, 1, 3, 0, 3, 0, 1, 1, 2, 0, 3, 1, 3, 3, 1, 2, 2, 3, 2, 2, 0, 3, 1, 3, 1, 1, 2, 3, 3, 1, 2, 2, 0, 2, 3, 3, 1, 1, 2, 3, 3, 2, 2, 1, 3, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1047. And steps were 81 and the episode is 531 and the total_steps are 51629\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 2, 0, 3, 1, 2, 1, 1, 1, 0, 3, 2, 2, 3, 3, 2, 2, 1, 0, 1, 1, 1, 0, 0, 2, 1, 3, 2, 0, 3, 1, 2, 2, 3, 1, 3, 0, 3, 3, 2, 2, 3, 3, 2, 3, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 52 and the episode is 532 and the total_steps are 51681\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.5     |\n",
      "|    ep_rew_mean      | -833     |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 58       |\n",
      "|    time_elapsed     | 882      |\n",
      "|    total_timesteps  | 51681    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.373    |\n",
      "|    n_updates        | 420      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 0, 3, 0, 1, 0, 3, 1, 3, 0, 1, 2, 3, 1, 0, 1, 3, 1, 0, 3, 1, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 533 and the total_steps are 51709\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 1, 0, 2, 0, 2, 3, 2, 2, 2, 3, 2, 2, 1, 2, 1, 3, 2, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 534 and the total_steps are 51734\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 0, 0, 2, 1, 0, 3, 2, 2, 1, 2, 0, 0, 1, 0, 2, 0, 3, 0, 3, 3, 3, 1, 2, 1, 2, 3, 3, 3, 2, 1, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 38 and the episode is 535 and the total_steps are 51772\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 1, 0, 1, 3, 3, 1, 3, 0, 3, 2, 3, 3, 3, 3, 2, 2, 0, 2, 2, 1, 1, 0, 1, 1, 1, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0, 2, 1, 3, 1, 1, 0, 1, 1, 2, 0, 0, 3, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -951. And steps were 55 and the episode is 536 and the total_steps are 51827\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.2     |\n",
      "|    ep_rew_mean      | -832     |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 58       |\n",
      "|    time_elapsed     | 888      |\n",
      "|    total_timesteps  | 51827    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 456      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 1, 0, 2, 0, 2, 2, 1, 2, 2, 1, 1, 2, 3, 3, 2, 2, 0, 1, 2, 1, 3, 2, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 30 and the episode is 537 and the total_steps are 51857\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 1, 1, 0, 3, 1, 0, 0, 2, 2, 3, 2, 3, 1, 1, 2, 1, 0, 0, 3, 2, 0, 2, 3, 3, 1, 3, 1, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 538 and the total_steps are 51893\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 0, 0, 0, 2, 2, 1, 1, 2, 2, 3, 2, 2, 1, 0, 0, 1, 2, 3, 2, 3, 2, 0, 1, 0, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 539 and the total_steps are 51925\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 0, 1, 2, 0, 1, 2, 1, 1, 3, 1, 3, 0, 3, 1, 3, 0, 1, 2, 1, 2, 1, 1, 0, 3, 1, 2, 2, 0, 0, 3, 2, 2, 2, 0, 1, 2, 2, 1, 1, 0, 3, 1, 2, 1, 2, 1, 3, 1, 2, 1, 0, 2, 2, 1, 1, 2, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 64 and the episode is 540 and the total_steps are 51989\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | -831     |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 58       |\n",
      "|    time_elapsed     | 894      |\n",
      "|    total_timesteps  | 51989    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.338    |\n",
      "|    n_updates        | 497      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 1, 0, 1, 0, 2, 0, 0, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 0, 1, 3, 0, 1, 0, 0, 3, 1, 0, 1, 2, 3, 3, 0, 2, 2, 2, 1, 0, 3, 1, 0, 1, 1, 1, 2, 2, 0, 3, 1, 2, 3, 1, 0, 2, 3, 2, 0, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 64 and the episode is 541 and the total_steps are 52053\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 3, 3, 3, 1, 0, 0, 2, 1, 2, 1, 1, 1, 0, 0, 1, 2, 1, 3, 0, 1, 0, 3, 0, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1028. And steps were 29 and the episode is 542 and the total_steps are 52082\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 1, 1, 1, 2, 3, 0, 1, 2, 1, 3, 1, 0, 2, 0, 1, 1, 1, 0, 1, 2, 2, 1, 1, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 31 and the episode is 543 and the total_steps are 52113\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 1, 1, 3, 0, 3, 1, 1, 3, 0, 0, 0, 3, 0, 3, 3, 1, 3, 1, 0, 0, 3, 0, 2, 3, 2, 3, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 34 and the episode is 544 and the total_steps are 52147\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | -813     |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 57       |\n",
      "|    time_elapsed     | 901      |\n",
      "|    total_timesteps  | 52147    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 536      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 1, 3, 1, 2, 1, 3, 1, 2, 1, 1, 3, 1, 1, 0, 3, 3, 0, 1, 0, 1, 1, 0, 3, 2, 2, 2, 3, 2, 3, 1, 2, 2, 0, 3, 3, 0, 0, 2, 2, 0, 0, 1, 0, 0, 1, 3, 1, 0, 2, 3, 3, 3, 3, 0, 3, 3, 1, 0, 1, 1, 0, 0, 3, 0, 2, 3, 0, 1, 2, 2, 2, 1, 1, 2, 1, 3, 1, 3, 1, 3, 0, 3, 3, 2, 2, 1, 3, 3, 2, 2, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 98 and the episode is 545 and the total_steps are 52245\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 2, 3, 0, 2, 3, 1, 0, 1, 0, 3, 0, 1, 0, 2, 3, 0, 3, 2, 1, 0, 0, 3, 3, 1, 0, 3, 0, 1, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 36 and the episode is 546 and the total_steps are 52281\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 1, 0, 2, 2, 2, 1, 1, 3, 2, 1, 1, 3, 3, 3, 0, 2, 3, 2, 1, 0, 0, 2, 1, 0, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 547 and the total_steps are 52313\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 2, 2, 0, 1, 0, 3, 2, 1, 1, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 17 and the episode is 548 and the total_steps are 52330\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | -834     |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 57       |\n",
      "|    time_elapsed     | 908      |\n",
      "|    total_timesteps  | 52330    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 582      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 1, 1, 2, 3, 1, 3, 1, 3, 0, 2, 1, 1, 1, 3, 2, 2, 2, 0, 3, 3, 0, 3, 3, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 31 and the episode is 549 and the total_steps are 52361\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 3, 3, 1, 3, 0, 1, 1, 2, 3, 2, 0, 1, 1, 3, 3, 0, 3, 3, 3, 2, 1, 3, 2, 1, 1, 1, 3, 1, 1, 0, 2, 3, 3, 1, 2, 0, 0, 2, 0, 3, 2, 3, 2, 3, 0, 1, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 54 and the episode is 550 and the total_steps are 52415\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 3, 2, 2, 3, 3, 1, 1, 0, 2, 2, 3, 3, 3, 1, 0, 1, 2, 3, 1, 1, 1, 0, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 551 and the total_steps are 52445\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 0, 2, 3, 0, 2, 1, 1, 3, 1, 2, 0, 3, 2, 2, 1, 2, 1, 3, 0, 3, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 552 and the total_steps are 52473\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | -834     |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 57       |\n",
      "|    time_elapsed     | 913      |\n",
      "|    total_timesteps  | 52473    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.329    |\n",
      "|    n_updates        | 618      |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 0, 3, 1, 1, 3, 1, 0, 2, 1, 2, 2, 3, 1, 3, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1018. And steps were 19 and the episode is 553 and the total_steps are 52492\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 0, 1, 0, 3, 1, 2, 1, 1, 2, 2, 0, 3, 0, 3, 0, 1, 1, 3, 3, 0, 3, 1, 2, 2, 3, 3, 2, 1, 2, 3, 2, 0, 3, 0, 2, 2, 1, 0, 3, 3, 3, 1, 2, 2, 3, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 53 and the episode is 554 and the total_steps are 52545\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 2, 2, 3, 1, 0, 3, 2, 3, 2, 2, 0, 0, 2, 0, 0, 2, 2, 1, 2, 0, 1, 0, 3, 1, 0, 3, 1, 2, 3, 3, 3, 2, 0, 2, 3, 0, 0, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 44 and the episode is 555 and the total_steps are 52589\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 0, 2, 0, 0, 0, 2, 3, 1, 0, 2, 0, 1, 3, 0, 2, 2, 1, 3, 0, 3, 3, 3, 0, 1, 0, 3, 3, 2, 2, 2, 2, 2, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 40 and the episode is 556 and the total_steps are 52629\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | -813     |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 57       |\n",
      "|    time_elapsed     | 920      |\n",
      "|    total_timesteps  | 52629    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 657      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 2, 2, 3, 1, 0, 2, 3, 2, 3, 0, 1, 0, 0, 2, 0, 0, 2, 1, 1, 3, 2, 1, 2, 3, 3, 0, 3, 1, 0, 2, 1, 1, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 557 and the total_steps are 52669\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 1, 2, 1, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 0, 0, 2, 3, 1, 1, 2, 1, 2, 1, 3, 3, 3, 0, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 40 and the episode is 558 and the total_steps are 52709\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 3, 1, 3, 0, 3, 1, 2, 1, 1, 3, 3, 1, 2, 0, 2, 1, 2, 1, 2, 2, 0, 0, 3, 2, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 32 and the episode is 559 and the total_steps are 52741\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 1, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 3, 1, 1, 3, 1, 1, 2, 1, 1, 2, 3, 1, 2, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 32 and the episode is 560 and the total_steps are 52773\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | -835     |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 56       |\n",
      "|    time_elapsed     | 925      |\n",
      "|    total_timesteps  | 52773    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.72     |\n",
      "|    n_updates        | 693      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 1, 2, 0, 3, 1, 1, 2, 0, 1, 0, 3, 1, 3, 3, 1, 1, 0, 0, 1, 3, 1, 3, 3, 2, 1, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 33 and the episode is 561 and the total_steps are 52806\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 1, 1, 3, 1, 0, 3, 1, 1, 3, 0, 1, 0, 0, 0, 3, 1, 3, 2, 3, 3, 1, 0, 3, 1, 1, 2, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 34 and the episode is 562 and the total_steps are 52840\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 0, 1, 0, 1, 2, 3, 3, 2, 1, 2, 1, 1, 1, 2, 0, 3, 0, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 25 and the episode is 563 and the total_steps are 52865\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 2, 2, 1, 3, 0, 3, 3, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 0, 2, 1, 3, 1, 0, 2, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 32 and the episode is 564 and the total_steps are 52897\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.6     |\n",
      "|    ep_rew_mean      | -836     |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 56       |\n",
      "|    time_elapsed     | 930      |\n",
      "|    total_timesteps  | 52897    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 100      |\n",
      "|    n_updates        | 724      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 0, 2, 1, 2, 3, 0, 0, 3, 3, 2, 2, 2, 2, 1, 0, 3, 3, 0, 2, 3, 1, 0, 2, 1, 1, 1, 2, 1, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 36 and the episode is 565 and the total_steps are 52933\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 2, 3, 3, 2, 3, 2, 3, 1, 2, 0, 3, 0, 1, 1, 1, 3, 1, 3, 3, 0, 2, 3, 1, 2, 3, 1, 3, 3, 0, 1, 0, 0, 3, 1, 3, 0, 3, 0, 1, 3, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 48 and the episode is 566 and the total_steps are 52981\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 0, 0, 2, 1, 1, 1, 1, 0, 1, 0, 3, 2, 2, 1, 0, 3, 3, 1, 2, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 27 and the episode is 567 and the total_steps are 53008\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 0, 1, 0, 1, 3, 1, 2, 0, 2, 0, 1, 1, 3, 2, 2, 0, 2, 2, 0, 1, 3, 2, 3, 0, 3, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 33 and the episode is 568 and the total_steps are 53041\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49       |\n",
      "|    ep_rew_mean      | -837     |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 56       |\n",
      "|    time_elapsed     | 936      |\n",
      "|    total_timesteps  | 53041    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.357    |\n",
      "|    n_updates        | 760      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 3, 2, 0, 3, 2, 1, 2, 2, 2, 2, 0, 0, 3, 3, 0, 1, 3, 1, 2, 0, 2, 2, 1, 2, 2, 3, 1, 2, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 569 and the total_steps are 53077\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 3, 0, 1, 3, 1, 1, 3, 2, 0, 2, 3, 1, 3, 3, 3, 1, 3, 1, 3, 3, 1, 2, 0, 3, 1, 0, 3, 1, 0, 2, 2, 0, 0, 3, 1, 2, 1, 1, 3, 3, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 52 and the episode is 570 and the total_steps are 53129\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 1, 0, 0, 3, 3, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 3, 2, 1, 2, 1, 2, 2, 1, 3, 2, 3, 2, 1, 2, 3, 3, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 40 and the episode is 571 and the total_steps are 53169\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 0, 3, 1, 0, 0, 3, 1, 1, 0, 0, 1, 0, 0, 0, 2, 3, 0, 0, 0, 3, 2, 3, 0, 3, 0, 0, 3, 3, 0, 0, 1, 1, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 572 and the total_steps are 53209\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48       |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 56       |\n",
      "|    time_elapsed     | 943      |\n",
      "|    total_timesteps  | 53209    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 36       |\n",
      "|    n_updates        | 802      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 2, 2, 3, 2, 2, 0, 2, 2, 3, 1, 3, 2, 2, 3, 3, 1, 1, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 25 and the episode is 573 and the total_steps are 53234\n",
      "Skiping this step\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 1, 1, 2, 3, 2, 2, 0, 1, 1, 3, 0, 0, 2, 2, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was 984. And steps were 19 and the episode is 574 and the total_steps are 53253\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 0, 2, 1, 2, 1, 1, 3, 1, 0, 0, 2, 2, 3, 1, 0, 1, 3, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 2, 1, 3, 2, 3, 1, 1, 0, 2, 1, 3, 1, 1, 0, 2, 3, 0, 3, 0, 1, 3, 3, 3, 2, 3, 1, 3, 1, 3, 2, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 65 and the episode is 575 and the total_steps are 53318\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 2, 2, 3, 2, 3, 0, 3, 1, 1, 2, 3, 1, 3, 3, 3, 2, 3, 1, 1, 1, 3, 1, 3, 2, 1, 1, 3, 0, 2, 2, 0, 1, 3, 3, 1, 0, 0, 2, 1, 2, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 576 and the total_steps are 53366\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.1     |\n",
      "|    ep_rew_mean      | -837     |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 56       |\n",
      "|    time_elapsed     | 949      |\n",
      "|    total_timesteps  | 53366    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 841      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 1, 2, 1, 2, 0, 0, 3, 0, 2, 0, 1, 3, 1, 3, 0, 0, 0, 2, 0, 3, 0, 2, 1, 1, 3, 3, 2, 1, 3, 0, 3, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 39 and the episode is 577 and the total_steps are 53405\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 0, 3, 3, 1, 3, 3, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 21 and the episode is 578 and the total_steps are 53426\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 2, 0, 0, 3, 2, 0, 3, 0, 3, 3, 1, 1, 2, 3, 0, 2, 0, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was 1022. And steps were 23 and the episode is 579 and the total_steps are 53449\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 2, 2, 1, 0, 3, 1, 2, 1, 1, 0, 1, 1, 3, 3, 3, 1, 1, 0, 0, 0, 0, 2, 3, 0, 3, 3, 2, 1, 1, 1, 3, 1, 1, 3, 0, 0, 0, 2, 0, 1, 0, 2, 3, 0, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 52 and the episode is 580 and the total_steps are 53501\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | -838     |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 56       |\n",
      "|    time_elapsed     | 954      |\n",
      "|    total_timesteps  | 53501    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.383    |\n",
      "|    n_updates        | 875      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 2, 0, 1, 2, 2, 2, 0, 2, 0, 0, 1, 1, 0, 3, 2, 1, 2, 2, 1, 3, 1, 2, 3, 1, 0, 0, 2, 1, 3, 3, 2, 0, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 40 and the episode is 581 and the total_steps are 53541\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 3, 1, 1, 3, 2, 0, 1, 0, 3, 2, 0, 0, 0, 1, 2, 3, 2, 3, 3, 1, 0, 0, 1, 1, 3, 0, 1, 2, 1, 0, 0, 2, 1, 0, 1, 2, 0, 3, 3, 1, 3, 1, 0, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 51 and the episode is 582 and the total_steps are 53592\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 1, 3, 3, 2, 2, 2, 3, 0, 1, 1, 0, 0, 2, 2, 3, 0, 3, 1, 2, 1, 0, 1, 1, 0, 3, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 583 and the total_steps are 53625\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 0, 3, 1, 1, 0, 1, 0, 0, 0, 0, 3, 3, 1, 2, 3, 1, 1, 2, 3, 2, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 584 and the total_steps are 53653\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -838     |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 55       |\n",
      "|    time_elapsed     | 960      |\n",
      "|    total_timesteps  | 53653    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 913      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 0, 1, 3, 2, 2, 0, 0, 0, 1, 0, 2, 0, 2, 0, 1, 3, 3, 2, 3, 3, 1, 0, 0, 0, 2, 1, 1, 2, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 585 and the total_steps are 53689\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 0, 3, 3, 2, 2, 0, 1, 1, 1, 2, 2, 3, 2, 0, 1, 0, 0, 3, 3, 1, 1, 2, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 586 and the total_steps are 53719\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 0, 0, 3, 3, 1, 2, 1, 3, 1, 2, 1, 1, 2, 1, 2, 2, 0, 1, 1, 3, 2, 1, 1, 1, 3, 2, 1, 1, 0, 2, 0, 1, 2, 1, 1, 2, 3, 1, 3, 0, 2, 0, 1, 1, 1, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 53 and the episode is 587 and the total_steps are 53772\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 2, 3, 2, 3, 1, 0, 2, 2, 0, 3, 0, 2, 1, 1, 0, 3, 0, 0, 2, 0, 1, 3, 3, 3, 2, 3, 0, 2, 0, 3, 0, 3, 3, 0, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 42 and the episode is 588 and the total_steps are 53814\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -859     |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 55       |\n",
      "|    time_elapsed     | 966      |\n",
      "|    total_timesteps  | 53814    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.966    |\n",
      "|    n_updates        | 953      |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 3, 2, 2, 0, 0, 3, 1, 1, 1, 2, 0, 2, 1, 3, 2, 1, 1, 3, 2, 3, 1, 0, 1, 0, 1, 3, 1, 1, 1, 3, 1, 2, 0, 0, 1, 3, 0, 1, 1, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 0, 2, 3, 1, 2, 2, 0, 1, 1, 3, 1, 2, 2, 2, 2, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1070. And steps were 72 and the episode is 589 and the total_steps are 53886\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 2, 0, 1, 2, 3, 2, 1, 2, 3, 1, 1, 2, 2, 0, 3, 1, 0, 0, 0, 0, 1, 1, 3, 1, 0, 3, 3, 2, 0, 2, 3, 3, 1, 1, 1, 2, 0, 2, 2, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 47 and the episode is 590 and the total_steps are 53933\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 2, 2, 0, 0, 2, 1, 2, 0, 0, 2, 0, 3, 2, 0, 1, 0, 0, 0, 1, 3, 3, 1, 0, 2, 2, 1, 2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 0, 3, 0, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 47 and the episode is 591 and the total_steps are 53980\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 3, 2, 1, 1, 1, 1, 3, 0, 1, 1, 3, 1, 1, 0, 2, 2, 2, 0, 1, 2, 0, 0, 3, 2, 2, 1, 0, 3, 1, 3, 1, 3, 0, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 41 and the episode is 592 and the total_steps are 54021\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 55       |\n",
      "|    time_elapsed     | 974      |\n",
      "|    total_timesteps  | 54021    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.402    |\n",
      "|    n_updates        | 1005     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 3, 1, 1, 2, 1, 1, 0, 0, 3, 1, 3, 1, 2, 0, 1, 3, 3, 1, 2, 2, 3, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 593 and the total_steps are 54049\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 2, 0, 2, 2, 2, 0, 2, 1, 1, 0, 1, 1, 2, 0, 2, 1, 1, 2, 2, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 27 and the episode is 594 and the total_steps are 54076\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 1, 2, 0, 1, 0, 3, 3, 1, 2, 0, 0, 0, 2, 3, 3, 0, 3, 0, 3, 1, 0, 0, 2, 3, 0, 2, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 34 and the episode is 595 and the total_steps are 54110\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 0, 0, 1, 3, 1, 2, 3, 1, 3, 1, 2, 1, 0, 2, 0, 3, 3, 0, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 596 and the total_steps are 54134\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -861     |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 55       |\n",
      "|    time_elapsed     | 979      |\n",
      "|    total_timesteps  | 54134    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.245    |\n",
      "|    n_updates        | 1033     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 1, 0, 3, 0, 1, 1, 1, 2, 0, 3, 0, 0, 1, 0, 0, 1, 1, 0, 3, 2, 0, 1, 0, 1, 1, 1, 3, 0, 1, 0, 0, 0, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 40 and the episode is 597 and the total_steps are 54174\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 3, 1, 1, 2, 2, 3, 2, 2, 3, 3, 1, 2, 1, 1, 1, 0, 1, 0, 0, 3, 2, 3, 1, 0, 1, 2, 1, 1, 1, 2, 3, 3, 2, 3, 2, 0, 0, 3, 3, 0, 3, 3, 2, 1, 1, 0, 1, 1, 0, 2, 3, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 59 and the episode is 598 and the total_steps are 54233\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 3, 2, 0, 0, 2, 1, 0, 3, 0, 3, 3, 3, 2, 0, 0, 1, 2, 3, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 599 and the total_steps are 54259\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 2, 1, 0, 3, 2, 3, 2, 2, 1, 1, 1, 2, 1, 2, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 22 and the episode is 600 and the total_steps are 54281\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -861     |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 55       |\n",
      "|    time_elapsed     | 985      |\n",
      "|    total_timesteps  | 54281    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.5     |\n",
      "|    n_updates        | 1070     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 3, 2, 2, 1, 0, 1, 0, 1, 1, 0, 2, 3, 0, 1, 3, 3, 2, 3, 2, 0, 2, 0, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 30 and the episode is 601 and the total_steps are 54311\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 0, 1, 1, 3, 1, 0, 0, 3, 3, 2, 3, 3, 1, 2, 3, 3, 3, 0, 3, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was 1031. And steps were 32 and the episode is 602 and the total_steps are 54343\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 1, 3, 0, 1, 3, 3, 3, 2, 2, 2, 0, 1, 3, 1, 2, 0, 2, 3, 3, 0, 2, 3, 0, 3, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 603 and the total_steps are 54375\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 3, 3, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 3, 0, 3, 3, 0, 1, 2, 3, 1, 2, 2, 2, 1, 2, 1, 0, 3, 0, 0, 1, 1, 2, 3, 0, 3, 1, 3, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1052. And steps were 54 and the episode is 604 and the total_steps are 54429\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -841     |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 991      |\n",
      "|    total_timesteps  | 54429    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 1107     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 1, 3, 3, 1, 1, 1, 0, 2, 0, 3, 3, 3, 2, 3, 2, 3, 1, 3, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was 979. And steps were 24 and the episode is 605 and the total_steps are 54453\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 1, 2, 0, 0, 3, 1, 0, 3, 3, 2, 0, 2, 3, 1, 0, 2, 1, 2, 1, 1, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 606 and the total_steps are 54481\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 2, 2, 0, 3, 0, 1, 3, 3, 3, 1, 3, 3, 0, 3, 1, 1, 0, 0, 3, 2, 3, 0, 0, 0, 3, 3, 3, 0, 3, 1, 1, 2, 1, 0, 2, 3, 0, 2, 3, 2, 0, 3, 2, 3, 0, 3, 2, 2, 0, 0, 2, 1, 1, 1, 2, 0, 0, 3, 3, 1, 1, 2, 0, 0, 1, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1071. And steps were 73 and the episode is 607 and the total_steps are 54554\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 0, 2, 2, 2, 3, 1, 3, 2, 1, 1, 3, 1, 2, 1, 3, 3, 2, 1, 0, 3, 1, 1, 2, 0, 0, 2, 1, 0, 2, 0, 0, 1, 3, 3, 1, 1, 3, 2, 0, 2, 1, 1, 0, 0, 3, 0, 2, 1, 1, 0, 0, 2, 0, 1, 0, 0, 3, 0, 0, 3, 2, 3, 1, 1, 3, 0, 2, 2, 3, 3, 2, 2, 3, 3, 2, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 83 and the episode is 608 and the total_steps are 54637\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -822     |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 998      |\n",
      "|    total_timesteps  | 54637    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.658    |\n",
      "|    n_updates        | 1159     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 2, 1, 2, 3, 3, 1, 2, 2, 1, 0, 3, 2, 2, 0, 0, 1, 3, 3, 2, 1, 0, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 29 and the episode is 609 and the total_steps are 54666\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 3, 3, 1, 1, 3, 2, 1, 1, 2, 3, 3, 3, 2, 0, 2, 2, 1, 0, 2, 3, 0, 0, 2, 2, 1, 1, 1, 1, 3, 1, 3, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 39 and the episode is 610 and the total_steps are 54705\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 1, 1, 0, 1, 3, 1, 3, 1, 1, 0, 2, 3, 1, 0, 3, 1, 3, 0, 2, 3, 2, 3, 1, 1, 0, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 33 and the episode is 611 and the total_steps are 54738\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 3, 0, 2, 0, 1, 3, 0, 2, 2, 0, 3, 1, 3, 2, 0, 1, 3, 3, 3, 3, 2, 2, 0, 0, 1, 0, 1, 2, 3, 3, 0, 1, 1, 0, 1, 2, 1, 1, 3, 2, 3, 0, 0, 1, 2, 0, 3, 1, 3, 1, 3, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 59 and the episode is 612 and the total_steps are 54797\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -863     |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 1005     |\n",
      "|    total_timesteps  | 54797    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.354    |\n",
      "|    n_updates        | 1199     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 0, 3, 1, 1, 1, 0, 3, 2, 0, 3, 1, 0, 0, 2, 0, 1, 1, 3, 1, 3, 0, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 613 and the total_steps are 54826\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 0, 3, 0, 2, 1, 0, 2, 3, 0, 3, 3, 2, 2, 2, 1, 2, 0, 2, 2, 2, 3, 2, 0, 3, 2, 2, 1, 3, 1, 2, 0, 0, 0, 2, 2, 1, 0, 1, 3, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 47 and the episode is 614 and the total_steps are 54873\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 2, 1, 3, 0, 1, 0, 1, 0, 2, 1, 3, 0, 1, 1, 2, 1, 2, 0, 2, 3, 3, 3, 3, 2, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 615 and the total_steps are 54905\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 2, 2, 2, 2, 0, 2, 3, 3, 1, 1, 0, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 0, 1, 0, 0, 1, 3, 1, 3, 0, 2, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 39 and the episode is 616 and the total_steps are 54944\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -862     |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 1011     |\n",
      "|    total_timesteps  | 54944    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 35.1     |\n",
      "|    n_updates        | 1235     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 3, 0, 0, 0, 0, 1, 2, 3, 3, 1, 1, 1, 0, 0, 3, 2, 3, 3, 0, 0, 1, 1, 3, 1, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 617 and the total_steps are 54976\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 0, 0, 3, 0, 0, 3, 2, 0, 0, 1, 1, 1, 3, 1, 3, 0, 1, 1, 2, 0, 3, 0, 2, 2, 3, 0, 3, 0, 1, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 37 and the episode is 618 and the total_steps are 55013\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 0, 1, 2, 3, 2, 1, 3, 0, 2, 3, 1, 3, 2, 0, 3, 0, 2, 3, 0, 3, 1, 3, 0, 2, 1, 0, 1, 0, 0, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 37 and the episode is 619 and the total_steps are 55050\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 1, 3, 3, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 26 and the episode is 620 and the total_steps are 55076\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -862     |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 1016     |\n",
      "|    total_timesteps  | 55076    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0637   |\n",
      "|    n_updates        | 1268     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 2, 1, 2, 0, 3, 0, 1, 0, 2, 1, 1, 0, 0, 1, 0, 0, 3, 3, 1, 2, 1, 3, 2, 2, 2, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 621 and the total_steps are 55109\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 1, 0, 0, 3, 2, 3, 2, 0, 3, 0, 2, 3, 3, 2, 3, 3, 1, 1, 3, 0, 3, 2, 3, 3, 1, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 622 and the total_steps are 55142\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 3, 3, 2, 3, 1, 0, 1, 2, 2, 2, 0, 3, 0, 3, 3, 0, 3, 1, 1, 3, 2, 1, 1, 1, 2, 0, 0, 3, 1, 1, 2, 2, 3, 2, 3, 0, 0, 3, 2, 2, 1, 1, 1, 3, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 623 and the total_steps are 55194\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 3, 1, 1, 3, 3, 0, 3, 2, 2, 0, 2, 0, 3, 0, 3, 0, 0, 1, 3, 2, 1, 3, 1, 0, 1, 1, 0, 1, 1, 0, 3, 2, 2, 0, 0, 0, 1, 3, 0, 0, 2, 3, 2, 0, 3, 2, 1, 3, 2, 1, 1, 0, 0, 0, 3, 2, 3, 2, 2, 1, 0, 1, 0, 3, 1, 1, 0, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 75 and the episode is 624 and the total_steps are 55269\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -864     |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 1023     |\n",
      "|    total_timesteps  | 55269    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.5     |\n",
      "|    n_updates        | 1317     |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 1, 0, 1, 2, 1, 2, 1, 0, 2, 2, 0, 3, 2, 2, 1, 0, 2, 3, 2, 1, 0, 0, 1, 0, 3, 0, 2, 0, 2, 2, 1, 2, 3, 0, 3, 3, 2, 0, 1, 1, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 48 and the episode is 625 and the total_steps are 55317\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 3, 0, 0, 0, 3, 1, 0, 2, 1, 2, 0, 1, 1, 2, 0, 0, 2, 2, 3, 1, 3, 0, 0, 0, 3, 1, 3, 0, 0, 3, 3, 1, 0, 3, 0, 2, 0, 0, 1, 1, 3, 3, 0, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 3, 1, 3, 2, 2, 1, 3, 0, 2, 0, 0, 2, 1, 3, 1, 0, 1, 2, 3, 3, 3, 1, 0, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -920. And steps were 84 and the episode is 626 and the total_steps are 55401\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 0, 3, 3, 0, 2, 2, 3, 3, 0, 2, 0, 2, 3, 0, 0, 1, 0, 1, 2, 1, 0, 0, 0, 0, 3, 2, 0, 2, 0, 1, 2, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 39 and the episode is 627 and the total_steps are 55440\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 0, 3, 0, 0, 0, 0, 3, 2, 0, 1, 2, 3, 1, 0, 3, 3, 0, 3, 1, 2, 2, 2, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 30 and the episode is 628 and the total_steps are 55470\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -863     |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 1031     |\n",
      "|    total_timesteps  | 55470    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.55     |\n",
      "|    n_updates        | 1367     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 1, 3, 1, 0, 1, 0, 3, 2, 3, 1, 1, 1, 1, 3, 1, 3, 1, 3, 0, 0, 1, 0, 2, 1, 2, 3, 2, 3, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 36 and the episode is 629 and the total_steps are 55506\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 1, 2, 0, 0, 2, 0, 3, 1, 1, 1, 3, 1, 1, 0, 1, 3, 3, 3, 2, 1, 3, 3, 2, 3, 3, 1, 2, 3, 1, 0, 2, 2, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 40 and the episode is 630 and the total_steps are 55546\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 2, 3, 0, 0, 0, 2, 2, 1, 3, 3, 3, 1, 2, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 631 and the total_steps are 55574\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 3, 2, 2, 2, 3, 0, 3, 0, 3, 2, 1, 1, 1, 3, 3, 1, 2, 3, 0, 2, 3, 0, 1, 1, 3, 1, 3, 1, 0, 3, 0, 0, 3, 0, 2, 3, 0, 2, 0, 0, 3, 2, 3, 3, 3, 2, 0, 0, 2, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was 948. And steps were 55 and the episode is 632 and the total_steps are 55629\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -843     |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 1037     |\n",
      "|    total_timesteps  | 55629    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.83     |\n",
      "|    n_updates        | 1407     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 1, 2, 3, 3, 3, 1, 1, 1, 0, 0, 0, 3, 2, 3, 1, 0, 1, 3, 3, 1, 2, 0, 1, 2, 3, 1, 3, 1, 2, 3, 3, 2, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 633 and the total_steps are 55669\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 1, 3, 2, 1, 3, 1, 3, 1, 2, 1, 0, 1, 2, 0, 2, 3, 1, 2, 2, 0, 0, 3, 2, 1, 2, 1, 3, 0, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 634 and the total_steps are 55705\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 3, 3, 2, 2, 3, 3, 1, 1, 0, 0, 1, 3, 3, 0, 2, 1, 2, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 25 and the episode is 635 and the total_steps are 55730\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 3, 2, 3, 3, 1, 0, 3, 3, 2, 1, 0, 1, 0, 2, 0, 1, 1, 0, 1, 2, 3, 1, 3, 2, 1, 2, 3, 0, 0, 0, 0, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 39 and the episode is 636 and the total_steps are 55769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -844     |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 1043     |\n",
      "|    total_timesteps  | 55769    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.151    |\n",
      "|    n_updates        | 1442     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 0, 3, 0, 3, 1, 0, 3, 0, 0, 2, 0, 0, 3, 3, 2, 0, 1, 1, 3, 3, 3, 3, 1, 0, 3, 0, 0, 1, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 637 and the total_steps are 55805\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 1, 2, 0, 3, 2, 0, 3, 2, 3, 3, 1, 2, 3, 3, 0, 3, 1, 3, 1, 3, 2, 3, 1, 1, 3, 2, 1, 3, 3, 0, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 38 and the episode is 638 and the total_steps are 55843\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 0, 0, 3, 3, 1, 2, 2, 0, 2, 2, 3, 3, 0, 1, 3, 0, 1, 0, 2, 0, 0, 1, 2, 3, 2, 2, 1, 2, 2, 3, 0, 2, 2, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 41 and the episode is 639 and the total_steps are 55884\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 0, 3, 3, 0, 1, 1, 0, 3, 3, 1, 3, 0, 0, 2, 0, 2, 1, 0, 2, 0, 3, 0, 1, 1, 3, 2, 1, 0, 1, 2, 2, 0, 2, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 41 and the episode is 640 and the total_steps are 55925\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -844     |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 1049     |\n",
      "|    total_timesteps  | 55925    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 1481     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 1, 3, 0, 3, 2, 2, 1, 1, 0, 1, 2, 0, 2, 0, 1, 0, 3, 3, 3, 2, 2, 0, 1, 1, 0, 3, 1, 0, 0, 1, 3, 1, 3, 3, 1, 1, 0, 2, 2, 1, 3, 0, 0, 0, 1, 2, 0, 3, 1, 0, 1, 0, 2, 0, 2, 3, 3, 3, 0, 2, 0, 3, 3, 1, 0, 0, 3, 3, 1, 1, 3, 1, 0, 3, 1, 3, 0, 1, 2, 2, 3, 0, 0, 1, 1, 1, 1, 3, 3, 1, 2, 1, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 100 and the episode is 641 and the total_steps are 56025\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 2, 2, 1, 3, 3, 3, 1, 2, 1, 3, 2, 1, 3, 1, 1, 0, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 24 and the episode is 642 and the total_steps are 56049\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 1, 3, 0, 3, 3, 0, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 0, 3, 2, 1, 2, 3, 0, 2, 3, 3, 2, 1, 1, 1, 3, 0, 0, 3, 3, 1, 3, 1, 0, 2, 1, 2, 0, 2, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 52 and the episode is 643 and the total_steps are 56101\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 0, 3, 0, 2, 1, 3, 3, 1, 2, 3, 0, 3, 2, 1, 0, 2, 1, 1, 0, 3, 0, 2, 0, 1, 0, 2, 2, 0, 2, 2, 0, 1, 3, 2, 2, 3, 0, 2, 1, 3, 3, 0, 1, 0, 2, 3, 3, 0, 3, 1, 0, 0, 2, 1, 3, 0, 1, 2, 3, 0, 1, 0, 3, 0, 0, 2, 3, 3, 3, 2, 0, 1, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1078. And steps were 80 and the episode is 644 and the total_steps are 56181\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -865     |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 1059     |\n",
      "|    total_timesteps  | 56181    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.539    |\n",
      "|    n_updates        | 1545     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 2, 3, 0, 3, 3, 3, 0, 0, 1, 2, 1, 2, 0, 3, 0, 3, 1, 3, 1, 3, 0, 2, 2, 3, 3, 3, 3, 0, 2, 0, 3, 2, 2, 0, 3, 1, 2, 2, 1, 1, 2, 2, 0, 2, 1, 1, 1, 2, 2, 1, 0, 3, 3, 2, 2, 2, 0, 2, 2, 1, 0, 3, 2, 1, 2, 1, 1, 1, 2, 0, 0, 3, 0, 0, 1, 2, 2, 3, 3, 2, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -918. And steps were 88 and the episode is 645 and the total_steps are 56269\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 1, 1, 3, 2, 0, 1, 3, 2, 0, 2, 1, 0, 1, 1, 0, 2, 1, 2, 3, 3, 1, 0, 2, 0, 3, 2, 3, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 35 and the episode is 646 and the total_steps are 56304\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 1, 1, 0, 1, 1, 3, 1, 1, 1, 1, 3, 2, 3, 1, 1, 0, 1, 2, 1, 2, 0, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 647 and the total_steps are 56333\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 1, 3, 3, 2, 2, 2, 0, 1, 1, 0, 3, 2, 0, 3, 3, 2, 0, 1, 0, 0, 0, 0, 3, 3, 1, 1, 3, 3, 3, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 37 and the episode is 648 and the total_steps are 56370\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -864     |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 52       |\n",
      "|    time_elapsed     | 1066     |\n",
      "|    total_timesteps  | 56370    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.132    |\n",
      "|    n_updates        | 1592     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 1, 2, 2, 3, 0, 3, 3, 1, 1, 2, 3, 0, 1, 1, 2, 1, 2, 0, 0, 0, 0, 3, 0, 3, 2, 0, 1, 1, 2, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 37 and the episode is 649 and the total_steps are 56407\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 0, 3, 2, 1, 0, 2, 1, 3, 3, 1, 1, 2, 1, 2, 2, 3, 0, 1, 1, 0, 0, 2, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 650 and the total_steps are 56437\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 2, 2, 3, 3, 0, 0, 3, 0, 0, 3, 3, 1, 1, 3, 0, 2, 0, 1, 1, 3, 1, 1, 3, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 31 and the episode is 651 and the total_steps are 56468\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 2, 3, 1, 3, 3, 0, 3, 1, 2, 2, 0, 3, 2, 2, 3, 0, 3, 0, 0, 0, 3, 1, 1, 1, 1, 3, 1, 1, 0, 2, 2, 0, 2, 0, 3, 2, 3, 1, 0, 0, 3, 2, 2, 1, 3, 3, 0, 1, 0, 1, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 58 and the episode is 652 and the total_steps are 56526\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -864     |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 52       |\n",
      "|    time_elapsed     | 1073     |\n",
      "|    total_timesteps  | 56526    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 1631     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 2, 0, 2, 2, 2, 0, 3, 1, 3, 3, 2, 3, 2, 1, 1, 1, 2, 1, 0, 3, 2, 2, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 653 and the total_steps are 56557\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 2, 2, 2, 1, 2, 2, 3, 0, 3, 2, 3, 0, 0, 3, 0, 0, 3, 2, 2, 2, 0, 3, 3, 2, 2, 3, 0, 0, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 654 and the total_steps are 56593\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 1, 0, 1, 0, 0, 1, 2, 1, 1, 1, 3, 0, 2, 0, 2, 2, 0, 0, 2, 3, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 28 and the episode is 655 and the total_steps are 56621\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 1, 2, 3, 1, 0, 2, 3, 0, 0, 0, 2, 2, 1, 3, 0, 2, 1, 3, 0, 0, 2, 2, 1, 2, 3, 1, 3, 0, 1, 1, 1, 2, 2, 3, 3, 1, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 44 and the episode is 656 and the total_steps are 56665\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -886     |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 52       |\n",
      "|    time_elapsed     | 1078     |\n",
      "|    total_timesteps  | 56665    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.4     |\n",
      "|    n_updates        | 1666     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1, 2, 1, 3, 3, 0, 2, 1, 1, 3, 2, 3, 2, 0, 3, 0, 0, 0, 3, 3, 1, 3, 1, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 40 and the episode is 657 and the total_steps are 56705\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 1, 2, 0, 2, 0, 2, 1, 1, 0, 1, 0, 2, 1, 1, 0, 3, 0, 1, 3, 3, 0, 2, 3, 0, 1, 3, 0, 0, 1, 2, 1, 2, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 40 and the episode is 658 and the total_steps are 56745\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 0, 0, 0, 1, 1, 1, 2, 3, 3, 2, 0, 1, 1, 0, 1, 0, 2, 2, 0, 1, 2, 3, 2, 2, 3, 3, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 34 and the episode is 659 and the total_steps are 56779\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 3, 2, 0, 2, 2, 1, 2, 3, 1, 0, 3, 1, 1, 2, 0, 1, 2, 0, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 26 and the episode is 660 and the total_steps are 56805\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -886     |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 52       |\n",
      "|    time_elapsed     | 1084     |\n",
      "|    total_timesteps  | 56805    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 1701     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 3, 1, 1, 1, 3, 0, 1, 0, 2, 1, 2, 3, 3, 0, 1, 3, 2, 0, 0, 1, 3, 2, 1, 2, 0, 3, 3, 1, 2, 3, 1, 0, 2, 0, 1, 0, 3, 0, 1, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 47 and the episode is 661 and the total_steps are 56852\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 2, 2, 3, 1, 3, 1, 3, 1, 0, 3, 0, 2, 3, 1, 0, 0, 2, 1, 0, 1, 2, 1, 3, 0, 2, 0, 0, 2, 3, 0, 0, 3, 1, 0, 2, 1, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 44 and the episode is 662 and the total_steps are 56896\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 2, 0, 3, 2, 0, 0, 0, 0, 3, 3, 2, 0, 2, 0, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 663 and the total_steps are 56925\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 3, 1, 2, 0, 1, 0, 0, 1, 2, 0, 1, 3, 0, 2, 3, 1, 0, 1, 1, 2, 2, 3, 1, 1, 1, 2, 3, 1, 1, 3, 1, 2, 3, 2, 3, 3, 2, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 45 and the episode is 664 and the total_steps are 56970\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -886     |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 52       |\n",
      "|    time_elapsed     | 1091     |\n",
      "|    total_timesteps  | 56970    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.7     |\n",
      "|    n_updates        | 1742     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 1, 0, 0, 2, 1, 2, 3, 3, 0, 0, 1, 0, 0, 0, 3, 2, 0, 3, 3, 1, 0, 2, 0, 1, 1, 3, 3, 1, 0, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 37 and the episode is 665 and the total_steps are 57007\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 0, 2, 0, 1, 2, 3, 0, 0, 1, 1, 2, 2, 1, 0, 3, 0, 2, 2, 1, 3, 3, 2, 3, 2, 1, 1, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 34 and the episode is 666 and the total_steps are 57041\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 3, 1, 3, 0, 1, 2, 1, 1, 1, 1, 1, 1, 0, 2, 3, 0, 0, 1, 3, 1, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 667 and the total_steps are 57069\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 0, 2, 2, 3, 3, 0, 1, 1, 3, 2, 2, 1, 2, 3, 3, 2, 2, 3, 2, 0, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 668 and the total_steps are 57097\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -886     |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 52       |\n",
      "|    time_elapsed     | 1096     |\n",
      "|    total_timesteps  | 57097    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.211    |\n",
      "|    n_updates        | 1774     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 2, 1, 3, 2, 1, 3, 3, 0, 3, 0, 1, 2, 3, 3, 2, 1, 1, 3, 1, 0, 3, 2, 1, 1, 3, 1, 2, 0, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 36 and the episode is 669 and the total_steps are 57133\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 1, 0, 1, 2, 2, 3, 0, 1, 1, 0, 2, 1, 2, 2, 2, 1, 0, 0, 0, 1, 0, 0, 2, 3, 2, 2, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was 1031. And steps were 32 and the episode is 670 and the total_steps are 57165\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 2, 1, 0, 3, 1, 1, 3, 2, 2, 0, 2, 3, 1, 0, 1, 1, 3, 2, 3, 3, 0, 0, 2, 2, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 32 and the episode is 671 and the total_steps are 57197\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 3, 3, 2, 1, 3, 2, 1, 3, 1, 1, 0, 3, 2, 0, 1, 0, 1, 1, 0, 2, 0, 2, 2, 0, 1, 2, 2, 2, 1, 0, 3, 2, 2, 3, 3, 3, 1, 3, 3, 2, 0, 1, 1, 0, 2, 1, 1, 0, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 56 and the episode is 672 and the total_steps are 57253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -864     |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 1102     |\n",
      "|    total_timesteps  | 57253    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 1813     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 1, 0, 2, 2, 0, 3, 1, 3, 2, 3, 0, 1, 3, 3, 1, 3, 0, 2, 2, 2, 1, 0, 2, 0, 2, 0, 0, 3, 0, 1, 1, 0, 2, 1, 0, 0, 3, 3, 3, 3, 2, 1, 3, 1, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 673 and the total_steps are 57305\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 0, 2, 3, 1, 3, 3, 3, 3, 3, 0, 2, 0, 1, 1, 0, 1, 3, 3, 0, 3, 3, 1, 1, 2, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 674 and the total_steps are 57337\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 3, 0, 0, 0, 0, 2, 0, 2, 3, 1, 1, 0, 2, 1, 3, 3, 0, 3, 0, 1, 1, 2, 2, 3, 1, 0, 1, 2, 2, 3, 3, 2, 3, 2, 3, 2, 1, 1, 0, 3, 3, 2, 1, 3, 2, 0, 2, 0, 1, 2, 1, 1, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 60 and the episode is 675 and the total_steps are 57397\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 1, 2, 3, 2, 1, 0, 1, 1, 2, 1, 3, 1, 2, 1, 0, 1, 3, 1, 2, 0, 3, 1, 2, 0, 1, 2, 1, 0, 2, 3, 1, 2, 1, 3, 2, 3, 2, 1, 2, 1, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 48 and the episode is 676 and the total_steps are 57445\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -883     |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 1109     |\n",
      "|    total_timesteps  | 57445    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 1861     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 2, 0, 0, 0, 2, 0, 3, 2, 2, 2, 0, 2, 1, 2, 0, 1, 2, 2, 2, 3, 3, 2, 2, 1, 2, 2, 2, 0, 2, 3, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 1, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 49 and the episode is 677 and the total_steps are 57494\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 1, 2, 2, 3, 1, 3, 2, 3, 1, 0, 0, 0, 1, 1, 1, 0, 2, 0, 3, 3, 1, 2, 3, 1, 2, 1, 0, 3, 0, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 37 and the episode is 678 and the total_steps are 57531\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 3, 1, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 2, 0, 0, 0, 3, 2, 2, 2, 2, 0, 1, 0, 0, 1, 1, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 35 and the episode is 679 and the total_steps are 57566\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 1, 3, 1, 2, 2, 2, 2, 2, 0, 0, 3, 1, 0, 1, 1, 2, 3, 2, 2, 0, 2, 3, 1, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 31 and the episode is 680 and the total_steps are 57597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -903     |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 1116     |\n",
      "|    total_timesteps  | 57597    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 1899     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 0, 3, 1, 0, 3, 0, 3, 3, 2, 3, 1, 3, 3, 1, 3, 1, 3, 1, 1, 0, 3, 2, 1, 2, 3, 1, 2, 0, 3, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 37 and the episode is 681 and the total_steps are 57634\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 0, 2, 1, 1, 2, 1, 1, 0, 0, 0, 1, 0, 2, 1, 1, 1, 3, 0, 1, 3, 3, 0, 2, 0, 1, 3, 1, 3, 3, 1, 0, 2, 1, 3, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 42 and the episode is 682 and the total_steps are 57676\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 2, 3, 2, 2, 0, 2, 1, 1, 1, 1, 3, 2, 1, 2, 1, 0, 0, 3, 3, 2, 3, 3, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 30 and the episode is 683 and the total_steps are 57706\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 1, 1, 0, 2, 0, 2, 2, 1, 0, 2, 3, 2, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 27 and the episode is 684 and the total_steps are 57733\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -903     |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 1121     |\n",
      "|    total_timesteps  | 57733    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 1933     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 2, 3, 0, 3, 2, 2, 3, 1, 2, 3, 0, 3, 3, 1, 0, 2, 1, 2, 2, 0, 2, 2, 3, 2, 0, 0, 0, 0, 2, 3, 1, 3, 0, 2, 3, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 43 and the episode is 685 and the total_steps are 57776\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 2, 3, 2, 2, 2, 2, 1, 0, 3, 2, 2, 0, 0, 0, 2, 3, 0, 2, 1, 0, 3, 0, 0, 2, 1, 3, 3, 1, 0, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 37 and the episode is 686 and the total_steps are 57813\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 3, 1, 1, 2, 0, 1, 3, 3, 3, 0, 1, 3, 1, 1, 1, 3, 3, 2, 2, 2, 2, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 29 and the episode is 687 and the total_steps are 57842\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 0, 1, 2, 0, 2, 0, 0, 2, 2, 1, 2, 0, 0, 3, 3, 3, 2, 0, 0, 3, 2, 3, 3, 1, 1, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 688 and the total_steps are 57875\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 1127     |\n",
      "|    total_timesteps  | 57875    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 1968     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 0, 2, 3, 0, 2, 1, 0, 3, 1, 2, 0, 1, 3, 1, 3, 3, 0, 1, 0, 0, 3, 3, 0, 3, 2, 3, 0, 1, 3, 3, 1, 0, 2, 3, 2, 0, 3, 3, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 46 and the episode is 689 and the total_steps are 57921\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 0, 0, 2, 3, 0, 2, 0, 2, 0, 0, 1, 3, 1, 1, 0, 3, 3, 1, 3, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 690 and the total_steps are 57946\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 2, 0, 1, 1, 1, 0, 1, 3, 0, 1, 3, 3, 2, 1, 2, 0, 2, 3, 3, 1, 3, 3, 1, 3, 2, 1, 0, 2, 0, 1, 2, 3, 1, 0, 2, 2, 3, 3, 3, 1, 2, 2, 0, 1, 2, 2, 1, 3, 3, 3, 0, 2, 0, 2, 0, 1, 3, 2, 3, 2, 2, 2, 1, 1, 1, 1, 3, 2, 2, 3, 3, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1077. And steps were 79 and the episode is 691 and the total_steps are 58025\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 3, 3, 1, 0, 2, 3, 0, 2, 3, 2, 3, 0, 0, 0, 1, 1, 2, 0, 1, 0, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 692 and the total_steps are 58053\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -883     |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 1134     |\n",
      "|    total_timesteps  | 58053    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.562    |\n",
      "|    n_updates        | 2013     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 2, 0, 2, 2, 3, 1, 1, 2, 1, 1, 0, 3, 0, 1, 2, 0, 0, 1, 3, 2, 2, 2, 2, 1, 3, 3, 1, 3, 0, 3, 0, 0, 1, 2, 2, 2, 0, 1, 3, 2, 3, 3, 0, 1, 2, 3, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 60 and the episode is 693 and the total_steps are 58113\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 0, 3, 2, 3, 2, 2, 3, 2, 2, 1, 2, 2, 0, 3, 3, 3, 3, 3, 2, 1, 2, 3, 1, 0, 1, 1, 0, 0, 3, 0, 2, 1, 2, 1, 0, 1, 1, 2, 0, 3, 0, 0, 2, 0, 2, 2, 2, 3, 2, 2, 0, 0, 0, 3, 2, 1, 2, 0, 2, 3, 0, 2, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 70 and the episode is 694 and the total_steps are 58183\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 1, 1, 2, 1, 0, 3, 2, 2, 0, 3, 0, 3, 0, 0, 0, 3, 2, 0, 3, 0, 0, 0, 1, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 31 and the episode is 695 and the total_steps are 58214\n",
      "Done condition: collision\n",
      "[1, 1, 3, 0, 3, 1, 1, 3, 0, 1, 2, 2, 1, 0, 0, 1, 2, 0, 1, 0, 2, 3, 2, 0, 2, 2, 3, 1, 1, 2, 2, 2, 1, 1, 2, 3, 2, 1, 3, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 43 and the episode is 696 and the total_steps are 58257\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 1142     |\n",
      "|    total_timesteps  | 58257    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 2064     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 2, 2, 2, 1, 1, 0, 1, 3, 0, 1, 2, 3, 0, 2, 1, 2, 2, 1, 1, 1, 2, 3, 1, 2, 2, 0, 3, 2, 3, 1, 2, 0, 1, 2, 2, 3, 1, 2, 3, 1, 0, 2, 2, 0, 1, 3, 2, 0, 1, 1, 3, 2, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 60 and the episode is 697 and the total_steps are 58317\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 1, 3, 3, 3, 3, 1, 3, 1, 3, 0, 1, 0, 3, 1, 2, 1, 3, 3, 2, 1, 3, 0, 3, 1, 1, 0, 0, 1, 3, 1, 2, 0, 2, 0, 3, 2, 2, 1, 0, 2, 1, 1, 2, 3, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 52 and the episode is 698 and the total_steps are 58369\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 3, 0, 3, 2, 2, 3, 0, 1, 1, 1, 2, 0, 1, 3, 3, 2, 0, 2, 0, 3, 1, 1, 3, 3, 0, 3, 3, 2, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 699 and the total_steps are 58405\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 2, 1, 3, 0, 0, 0, 1, 1, 3, 2, 1, 0, 1, 0, 0, 0, 3, 2, 3, 0, 1, 1, 2, 3, 2, 3, 0, 1, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 36 and the episode is 700 and the total_steps are 58441\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 1149     |\n",
      "|    total_timesteps  | 58441    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 2110     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 2, 3, 2, 1, 2, 0, 1, 1, 3, 0, 1, 3, 2, 0, 2, 1, 1, 1, 2, 2, 3, 1, 0, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 31 and the episode is 701 and the total_steps are 58472\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 0, 1, 1, 3, 3, 0, 3, 0, 1, 2, 2, 1, 1, 3, 2, 3, 2, 0, 0, 3, 2, 0, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 39 and the episode is 702 and the total_steps are 58511\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 3, 3, 2, 0, 3, 1, 1, 0, 0, 1, 2, 1, 2, 1, 0, 0, 3, 1, 3, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 703 and the total_steps are 58535\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 3, 3, 3, 1, 3, 3, 2, 1, 0, 1, 3, 3, 2, 0, 0, 3, 2, 3, 2, 1, 2, 3, 3, 2, 3, 3, 2, 1, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 36 and the episode is 704 and the total_steps are 58571\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 1155     |\n",
      "|    total_timesteps  | 58571    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.195    |\n",
      "|    n_updates        | 2142     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 2, 3, 2, 1, 3, 3, 2, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 2, 3, 2, 2, 0, 0, 3, 1, 3, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 34 and the episode is 705 and the total_steps are 58605\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 2, 1, 3, 0, 0, 1, 1, 3, 1, 2, 1, 3, 2, 1, 0, 2, 1, 3, 3, 3, 2, 2, 0, 0, 3, 3, 2, 0, 0, 2, 3, 1, 3, 1, 2, 3, 3, 2, 2, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 58 and the episode is 706 and the total_steps are 58663\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 0, 2, 0, 3, 1, 0, 3, 1, 1, 0, 1, 2, 2, 0, 1, 3, 3, 3, 1, 3, 0, 0, 3, 2, 0, 3, 1, 1, 1, 3, 3, 1, 1, 2, 2, 3, 2, 2, 3, 3, 1, 0, 1, 1, 1, 1, 2, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 2, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -938. And steps were 66 and the episode is 707 and the total_steps are 58729\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 1, 0, 2, 3, 1, 3, 3, 0, 0, 3, 1, 1, 2, 2, 2, 2, 1, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1022. And steps were 23 and the episode is 708 and the total_steps are 58752\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 1162     |\n",
      "|    total_timesteps  | 58752    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64       |\n",
      "|    n_updates        | 2187     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 2, 3, 2, 1, 0, 1, 1, 0, 1, 2, 2, 2, 0, 3, 1, 1, 0, 2, 0, 2, 2, 3, 0, 3, 2, 1, 2, 1, 0, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 37 and the episode is 709 and the total_steps are 58789\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 3, 1, 1, 3, 0, 2, 2, 2, 3, 3, 1, 1, 3, 2, 3, 0, 0, 1, 1, 3, 1, 2, 3, 0, 3, 2, 1, 1, 0, 0, 0, 0, 1, 1, 2, 2, 2, 0, 2, 1, 0, 2, 2, 2, 0, 2, 1, 0, 3, 0, 1, 1, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -944. And steps were 60 and the episode is 710 and the total_steps are 58849\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 1, 1, 1, 2, 3, 0, 2, 2, 0, 0, 0, 3, 2, 2, 0, 3, 3, 0, 0, 1, 3, 3, 2, 0, 0, 2, 3, 1, 3, 0, 0, 0, 1, 0, 2, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 43 and the episode is 711 and the total_steps are 58892\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 1, 3, 3, 0, 2, 1, 0, 1, 0, 0, 3, 1, 2, 1, 1, 2, 3, 0, 1, 0, 1, 3, 2, 1, 3, 0, 0, 3, 3, 3, 3, 2, 0, 0, 3, 2, 0, 2, 1, 3, 1, 1, 1, 2, 3, 2, 1, 1, 2, 3, 3, 3, 0, 2, 1, 1, 3, 3, 0, 2, 2, 3, 0, 2, 1, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 73 and the episode is 712 and the total_steps are 58965\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 1170     |\n",
      "|    total_timesteps  | 58965    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 2241     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 0, 2, 3, 0, 1, 2, 3, 1, 2, 3, 2, 1, 1, 2, 3, 1, 3, 3, 3, 1, 2, 2, 1, 3, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 32 and the episode is 713 and the total_steps are 58997\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 3, 1, 1, 3, 0, 2, 2, 2, 0, 3, 2, 0, 2, 1, 0, 2, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 22 and the episode is 714 and the total_steps are 59019\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 3, 1, 0, 3, 1, 3, 3, 2, 2, 0, 2, 1, 1, 3, 0, 1, 3, 3, 2, 2, 2, 0, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 30 and the episode is 715 and the total_steps are 59049\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 2, 3, 0, 0, 0, 1, 3, 2, 3, 0, 1, 3, 2, 2, 2, 0, 0, 0, 3, 2, 2, 0, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 28 and the episode is 716 and the total_steps are 59077\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 1175     |\n",
      "|    total_timesteps  | 59077    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.53     |\n",
      "|    n_updates        | 2269     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 0, 1, 1, 3, 3, 2, 2, 2, 3, 1, 2, 3, 3, 3, 0, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 717 and the total_steps are 59098\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 3, 1, 2, 2, 1, 2, 2, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 3, 2, 0, 3, 2, 3, 1, 1, 2, 1, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 35 and the episode is 718 and the total_steps are 59133\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 3, 3, 2, 2, 2, 2, 0, 3, 3, 2, 3, 1, 1, 3, 0, 2, 1, 1, 3, 2, 3, 0, 0, 1, 3, 2, 0, 1, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 719 and the total_steps are 59169\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 2, 1, 2, 0, 3, 3, 2, 0, 3, 2, 2, 3, 1, 3, 3, 0, 2, 2, 1, 2, 2, 2, 0, 3, 2, 1, 0, 3, 1, 0, 1, 1, 3, 0, 2, 0, 0, 1, 0, 0, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 48 and the episode is 720 and the total_steps are 59217\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -838     |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 1181     |\n",
      "|    total_timesteps  | 59217    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.7     |\n",
      "|    n_updates        | 2304     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 1, 2, 0, 0, 2, 3, 0, 1, 3, 0, 1, 1, 3, 2, 1, 1, 3, 2, 1, 2, 2, 3, 3, 2, 1, 3, 2, 0, 2, 0, 2, 3, 0, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 0, 3, 0, 1, 2, 0, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -951. And steps were 61 and the episode is 721 and the total_steps are 59278\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 2, 3, 2, 0, 0, 3, 1, 1, 0, 1, 3, 0, 2, 0, 0, 1, 2, 1, 3, 1, 3, 0, 3, 3, 1, 2, 3, 3, 3, 2, 1, 1, 3, 3, 1, 0, 3, 1, 3, 2, 3, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 3, 3, 0, 3, 2, 0, 3, 1, 1, 2, 1, 1, 3, 3, 2, 0, 1, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -933. And steps were 79 and the episode is 722 and the total_steps are 59357\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 0, 2, 3, 2, 0, 2, 3, 2, 2, 2, 2, 3, 3, 1, 3, 0, 3, 0, 3, 2, 2, 2, 3, 1, 0, 3, 1, 1, 2, 2, 3, 1, 3, 1, 0, 2, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 44 and the episode is 723 and the total_steps are 59401\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 3, 1, 0, 0, 1, 2, 1, 3, 0, 0, 3, 3, 3, 3, 1, 1, 1, 2, 0, 0, 1, 1, 3, 1, 2, 2, 1, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 35 and the episode is 724 and the total_steps are 59436\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -835     |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 1190     |\n",
      "|    total_timesteps  | 59436    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 2358     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 2, 1, 0, 0, 0, 3, 3, 0, 1, 2, 3, 0, 1, 3, 0, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was 1018. And steps were 21 and the episode is 725 and the total_steps are 59457\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 0, 2, 2, 0, 1, 0, 1, 0, 2, 2, 3, 1, 2, 1, 3, 0, 0, 1, 3, 3, 1, 2, 1, 1, 1, 3, 1, 0, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 36 and the episode is 726 and the total_steps are 59493\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 0, 2, 2, 3, 0, 0, 0, 2, 2, 0, 3, 2, 2, 3, 2, 2, 2, 3, 3, 1, 1, 2, 1, 3, 3, 3, 1, 1, 1, 1, 1, 2, 0, 2, 1, 1, 3, 0, 1, 1, 1, 1, 1, 0, 1, 3, 0, 0, 3, 1, 2, 2, 2, 3, 3, 1, 1, 1, 0, 3, 3, 0, 3, 0, 1, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1071. And steps were 73 and the episode is 727 and the total_steps are 59566\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 3, 3, 1, 1, 0, 2, 2, 2, 1, 1, 2, 3, 0, 2, 2, 0, 1, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was 1022. And steps were 23 and the episode is 728 and the total_steps are 59589\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -796     |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 1196     |\n",
      "|    total_timesteps  | 59589    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 2397     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 2, 2, 0, 3, 0, 3, 0, 2, 2, 0, 2, 2, 2, 2, 3, 3, 1, 0, 1, 2, 0, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 729 and the total_steps are 59618\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 1, 1, 3, 0, 3, 3, 3, 1, 2, 2, 2, 3, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 27 and the episode is 730 and the total_steps are 59645\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 0, 2, 0, 2, 3, 0, 3, 2, 0, 2, 3, 3, 3, 1, 3, 0, 2, 0, 1, 2, 2, 3, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 975. And steps were 28 and the episode is 731 and the total_steps are 59673\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 2, 1, 1, 2, 1, 3, 0, 0, 0, 0, 3, 2, 1, 0, 0, 0, 1, 2, 3, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 27 and the episode is 732 and the total_steps are 59700\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -796     |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 1201     |\n",
      "|    total_timesteps  | 59700    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 2424     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 3, 1, 3, 1, 2, 1, 2, 2, 2, 1, 3, 0, 1, 1, 0, 2, 1, 2, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 26 and the episode is 733 and the total_steps are 59726\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 1, 0, 0, 2, 0, 1, 2, 3, 2, 1, 3, 3, 1, 2, 1, 2, 3, 1, 0, 0, 0, 1, 2, 2, 3, 0, 0, 2, 1, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 37 and the episode is 734 and the total_steps are 59763\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 1, 3, 1, 2, 0, 1, 1, 0, 1, 2, 0, 2, 3, 1, 0, 1, 2, 1, 3, 3, 1, 1, 0, 2, 1, 2, 2, 3, 0, 3, 2, 0, 1, 2, 2, 3, 1, 1, 2, 0, 1, 1, 1, 1, 1, 3, 1, 0, 1, 1, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 58 and the episode is 735 and the total_steps are 59821\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 1, 2, 0, 0, 0, 0, 3, 2, 1, 2, 2, 1, 2, 1, 3, 0, 1, 0, 0, 1, 0, 0, 3, 3, 1, 2, 1, 2, 3, 2, 0, 1, 3, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 40 and the episode is 736 and the total_steps are 59861\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -794     |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 1207     |\n",
      "|    total_timesteps  | 59861    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.325    |\n",
      "|    n_updates        | 2465     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 1, 1, 1, 2, 0, 3, 3, 0, 2, 3, 1, 3, 3, 2, 3, 0, 0, 1, 3, 1, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 28 and the episode is 737 and the total_steps are 59889\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 3, 0, 3, 2, 2, 3, 2, 2, 3, 1, 1, 1, 0, 1, 3, 3, 1, 0, 3, 0, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 738 and the total_steps are 59917\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 1, 3, 0, 3, 1, 3, 3, 2, 1, 1, 2, 2, 0, 1, 0, 0, 3, 0, 2, 0, 0, 3, 3, 1, 3, 2, 2, 1, 2, 2, 3, 0, 2, 2, 0, 0, 3, 3, 1, 0, 2, 1, 1, 1, 3, 0, 3, 2, 0, 3, 0, 1, 3, 3, 2, 1, 2, 1, 2, 0, 2, 2, 1, 2, 1, 0, 3, 1, 0, 2, 2, 1, 3, 2, 3, 0, 0, 1, 1, 1, 0, 2, 3, 1, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1090. And steps were 92 and the episode is 739 and the total_steps are 60009\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 1, 1, 0, 3, 2, 0, 3, 3, 2, 2, 2, 1, 1, 3, 2, 3, 0, 0, 3, 0, 3, 1, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 30 and the episode is 740 and the total_steps are 60039\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -795     |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 1214     |\n",
      "|    total_timesteps  | 60039    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.4      |\n",
      "|    n_updates        | 2509     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 2, 2, 2, 3, 2, 1, 1, 1, 0, 0, 2, 0, 3, 1, 2, 1, 3, 3, 3, 1, 1, 3, 1, 2, 0, 3, 3, 2, 1, 1, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 38 and the episode is 741 and the total_steps are 60077\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 0, 1, 3, 0, 2, 0, 1, 2, 1, 3, 3, 0, 0, 2, 2, 2, 0, 1, 3, 2, 2, 3, 2, 3, 0, 2, 2, 3, 1, 2, 0, 3, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 40 and the episode is 742 and the total_steps are 60117\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 3, 1, 0, 3, 3, 2, 1, 1, 2, 3, 2, 1, 2, 2, 1, 1, 2, 1, 3, 1, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 743 and the total_steps are 60145\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 1, 3, 1, 3, 2, 1, 1, 2, 0, 3, 2, 1, 0, 3, 2, 0, 3, 3, 0, 1, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 744 and the total_steps are 60173\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -794     |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 1220     |\n",
      "|    total_timesteps  | 60173    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 2543     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 2, 2, 1, 1, 3, 2, 0, 2, 1, 2, 1, 3, 2, 3, 2, 0, 3, 0, 2, 2, 0, 2, 0, 3, 3, 0, 3, 1, 0, 3, 0, 2, 2, 0, 0, 1, 3, 0, 3, 3, 2, 3, 1, 3, 2, 3, 1, 3, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 56 and the episode is 745 and the total_steps are 60229\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 3, 3, 1, 3, 1, 3, 2, 1, 1, 2, 1, 0, 1, 1, 3, 2, 1, 1, 3, 1, 3, 0, 2, 2, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 32 and the episode is 746 and the total_steps are 60261\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 2, 3, 1, 3, 1, 0, 2, 3, 2, 2, 2, 1, 0, 2, 0, 2, 3, 2, 0, 3, 3, 0, 1, 2, 0, 1, 1, 1, 2, 0, 3, 0, 2, 0, 2, 0, 2, 3, 3, 3, 0, 2, 2, 1, 2, 3, 0, 0, 3, 1, 2, 2, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -950. And steps were 60 and the episode is 747 and the total_steps are 60321\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 2, 3, 2, 3, 0, 3, 3, 0, 1, 2, 1, 1, 2, 2, 2, 3, 2, 2, 3, 0, 0, 1, 1, 2, 3, 1, 3, 2, 1, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 37 and the episode is 748 and the total_steps are 60358\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -793     |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 1227     |\n",
      "|    total_timesteps  | 60358    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.1     |\n",
      "|    n_updates        | 2589     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 1, 0, 0, 3, 3, 0, 3, 3, 0, 3, 2, 0, 0, 2, 2, 2, 1, 0, 2, 1, 1, 1, 1, 1, 3, 1, 2, 3, 1, 3, 3, 0, 3, 1, 1, 1, 0, 3, 1, 1, 3, 1, 1, 1, 3, 0, 3, 2, 3, 0, 0, 1, 3, 3, 1, 3, 3, 3, 1, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1065. And steps were 67 and the episode is 749 and the total_steps are 60425\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 3, 2, 1, 1, 2, 1, 0, 3, 0, 3, 0, 0, 2, 1, 1, 2, 3, 3, 0, 0, 3, 2, 1, 2, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 750 and the total_steps are 60457\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 1, 0, 0, 1, 0, 1, 1, 2, 1, 3, 2, 0, 3, 2, 0, 0, 1, 1, 2, 0, 0, 0, 3, 0, 0, 0, 1, 3, 0, 1, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 38 and the episode is 751 and the total_steps are 60495\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 2, 3, 3, 2, 1, 0, 2, 3, 2, 2, 1, 1, 3, 0, 1, 0, 1, 3, 2, 1, 3, 0, 2, 2, 2, 0, 3, 0, 1, 0, 1, 0, 2, 2, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 752 and the total_steps are 60537\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -794     |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 1234     |\n",
      "|    total_timesteps  | 60537    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.7     |\n",
      "|    n_updates        | 2634     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 0, 2, 1, 1, 0, 3, 0, 0, 3, 3, 3, 1, 1, 1, 2, 3, 1, 0, 1, 2, 3, 3, 1, 3, 1, 1, 1, 0, 1, 0, 0, 0, 3, 2, 2, 3, 2, 0, 1, 2, 0, 2, 3, 3, 3, 3, 2, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -951. And steps were 55 and the episode is 753 and the total_steps are 60592\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 0, 2, 0, 3, 0, 1, 3, 3, 0, 2, 2, 3, 3, 3, 2, 2, 1, 0, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 754 and the total_steps are 60616\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 3, 2, 2, 1, 2, 3, 1, 3, 2, 1, 3, 0, 3, 0, 0, 3, 3, 0, 0, 1, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 755 and the total_steps are 60644\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 2, 1, 2, 1, 3, 3, 0, 3, 2, 1, 0, 0, 1, 1, 0, 3, 2, 2, 2, 1, 0, 3, 3, 3, 2, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 2, 3, 2, 3, 2, 2, 1, 1, 3, 0, 3, 3, 2, 3, 0, 2, 3, 3, 2, 2, 3, 1, 0, 3, 0, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -949. And steps were 69 and the episode is 756 and the total_steps are 60713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -772     |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 1241     |\n",
      "|    total_timesteps  | 60713    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.2     |\n",
      "|    n_updates        | 2678     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 3, 2, 2, 2, 0, 1, 0, 1, 3, 0, 1, 0, 0, 3, 3, 2, 1, 0, 2, 3, 2, 1, 1, 0, 3, 0, 2, 2, 0, 2, 0, 0, 1, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 40 and the episode is 757 and the total_steps are 60753\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 3, 1, 3, 2, 2, 0, 1, 3, 0, 0, 1, 0, 1, 1, 0, 2, 1, 0, 2, 2, 3, 2, 0, 1, 2, 3, 2, 1, 3, 3, 0, 2, 2, 0, 1, 0, 3, 2, 2, 0, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 48 and the episode is 758 and the total_steps are 60801\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 0, 2, 1, 3, 3, 1, 2, 2, 0, 0, 1, 3, 1, 3, 3, 3, 3, 3, 3, 1, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 759 and the total_steps are 60829\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 3, 3, 0, 2, 3, 3, 3, 1, 3, 1, 0, 3, 3, 3, 1, 3, 3, 0, 2, 2, 1, 3, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 30 and the episode is 760 and the total_steps are 60859\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -771     |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 1247     |\n",
      "|    total_timesteps  | 60859    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 2714     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 1, 3, 3, 2, 1, 0, 0, 3, 3, 3, 3, 2, 0, 1, 3, 3, 2, 2, 2, 2, 3, 1, 3, 0, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 761 and the total_steps are 60891\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 3, 3, 1, 2, 1, 1, 2, 1, 2, 3, 3, 1, 1, 2, 2, 1, 1, 2, 0, 1, 0, 2, 2, 2, 0, 3, 1, 1, 3, 0, 2, 0, 2, 3, 1, 3, 2, 2, 3, 2, 3, 1, 2, 2, 0, 1, 2, 3, 3, 1, 1, 3, 3, 3, 0, 0, 0, 3, 3, 2, 2, 0, 2, 2, 2, 1, 3, 1, 2, 1, 1, 0, 1, 0, 3, 1, 2, 0, 2, 0, 0, 3, 0, 2, 1, 0, 1, 3, 2, 2, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -942. And steps were 98 and the episode is 762 and the total_steps are 60989\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 2, 0, 0, 2, 2, 1, 2, 3, 2, 1, 0, 3, 1, 2, 2, 0, 0, 2, 2, 1, 2, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 29 and the episode is 763 and the total_steps are 61018\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 3, 1, 0, 1, 2, 3, 3, 2, 0, 1, 0, 1, 0, 2, 0, 3, 2, 0, 3, 1, 3, 1, 3, 3, 1, 3, 2, 1, 2, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 37 and the episode is 764 and the total_steps are 61055\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -771     |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 1254     |\n",
      "|    total_timesteps  | 61055    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.698    |\n",
      "|    n_updates        | 2763     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 1, 1, 0, 3, 2, 0, 2, 0, 2, 0, 3, 2, 3, 0, 3, 0, 3, 0, 1, 3, 2, 3, 1, 2, 3, 0, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 34 and the episode is 765 and the total_steps are 61089\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 0, 1, 2, 1, 2, 2, 1, 2, 3, 1, 0, 0, 2, 1, 3, 1, 3, 2, 0, 2, 1, 2, 0, 2, 0, 1, 1, 2, 0, 2, 3, 1, 2, 2, 0, 1, 1, 2, 3, 0, 1, 3, 1, 3, 0, 0, 1, 1, 2, 0, 3, 0, 1, 3, 3, 0, 2, 0, 0, 3, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -944. And steps were 68 and the episode is 766 and the total_steps are 61157\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 2, 2, 3, 1, 0, 3, 3, 2, 1, 0, 1, 1, 2, 0, 3, 0, 3, 2, 0, 3, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 2, 1, 0, 3, 3, 3, 2, 3, 0, 0, 2, 3, 3, 3, 0, 1, 1, 1, 3, 2, 3, 2, 2, 2, 1, 2, 3, 2, 2, 1, 3, 2, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 70 and the episode is 767 and the total_steps are 61227\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 3, 0, 0, 3, 1, 1, 0, 1, 2, 0, 1, 3, 1, 3, 0, 0, 1, 1, 0, 3, 0, 0, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 31 and the episode is 768 and the total_steps are 61258\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -770     |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 1262     |\n",
      "|    total_timesteps  | 61258    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.744    |\n",
      "|    n_updates        | 2814     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 1, 0, 0, 0, 1, 3, 1, 2, 2, 0, 1, 2, 0, 1, 1, 1, 2, 3, 3, 1, 1, 0, 0, 3, 1, 3, 3, 0, 0, 1, 1, 1, 1, 2, 1, 2, 0, 3, 2, 2, 0, 1, 1, 2, 2, 1, 0, 1, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1054. And steps were 56 and the episode is 769 and the total_steps are 61314\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 0, 3, 1, 0, 1, 2, 3, 3, 2, 2, 2, 2, 1, 2, 1, 0, 0, 2, 1, 1, 2, 3, 1, 2, 0, 3, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 34 and the episode is 770 and the total_steps are 61348\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 3, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 3, 0, 1, 3, 2, 3, 3, 2, 0, 2, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 29 and the episode is 771 and the total_steps are 61377\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 1, 0, 3, 3, 2, 3, 3, 0, 1, 1, 3, 1, 3, 3, 0, 0, 2, 2, 2, 1, 0, 1, 2, 1, 3, 1, 0, 1, 2, 1, 3, 2, 2, 2, 3, 1, 3, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1052. And steps were 54 and the episode is 772 and the total_steps are 61431\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -792     |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 1269     |\n",
      "|    total_timesteps  | 61431    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.437    |\n",
      "|    n_updates        | 2857     |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 1, 2, 1, 3, 1, 2, 3, 3, 0, 3, 2, 0, 0, 2, 0, 1, 3, 3, 3, 3, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 2, 3, 3, 3, 1, 2, 0, 2, 1, 3, 3, 1, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 50 and the episode is 773 and the total_steps are 61481\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 3, 3, 3, 2, 2, 0, 2, 2, 2, 3, 2, 1, 1, 0, 1, 1, 0, 1, 3, 1, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 28 and the episode is 774 and the total_steps are 61509\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 3, 1, 1, 2, 3, 1, 1, 0, 2, 3, 0, 2, 3, 2, 1, 3, 1, 2, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 775 and the total_steps are 61533\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 1, 1, 2, 3, 0, 0, 3, 2, 1, 0, 2, 3, 3, 1, 3, 2, 3, 0, 2, 2, 2, 3, 2, 0, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 776 and the total_steps are 61565\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -772     |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 1275     |\n",
      "|    total_timesteps  | 61565    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 2891     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 3, 3, 1, 3, 3, 2, 1, 2, 0, 0, 2, 0, 2, 1, 0, 2, 1, 1, 1, 3, 0, 1, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1027. And steps were 28 and the episode is 777 and the total_steps are 61593\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 0, 0, 3, 3, 1, 1, 3, 0, 3, 3, 2, 2, 0, 1, 3, 0, 1, 1, 3, 1, 3, 1, 2, 1, 3, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 778 and the total_steps are 61633\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 0, 1, 3, 2, 3, 1, 2, 2, 3, 2, 1, 1, 1, 3, 2, 1, 3, 1, 0, 3, 3, 0, 2, 0, 2, 3, 2, 1, 2, 2, 3, 3, 3, 3, 1, 1, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 779 and the total_steps are 61677\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 2, 1, 2, 3, 0, 0, 3, 1, 0, 3, 0, 3, 0, 1, 1, 3, 2, 1, 0, 0, 2, 2, 0, 1, 0, 1, 0, 1, 3, 2, 3, 2, 1, 0, 1, 1, 1, 0, 1, 0, 3, 0, 1, 2, 3, 3, 1, 2, 0, 3, 2, 0, 2, 3, 0, 2, 2, 2, 0, 2, 3, 2, 0, 0, 0, 1, 2, 1, 1, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 78 and the episode is 780 and the total_steps are 61755\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -753     |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 1282     |\n",
      "|    total_timesteps  | 61755    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65.8     |\n",
      "|    n_updates        | 2938     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 1, 1, 2, 0, 2, 0, 2, 0, 2, 0, 0, 3, 0, 1, 1, 3, 2, 0, 0, 1, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 28 and the episode is 781 and the total_steps are 61783\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 0, 2, 0, 3, 0, 3, 0, 3, 3, 2, 0, 2, 1, 3, 3, 2, 0, 3, 0, 2, 0, 1, 2, 0, 2, 1, 3, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 0, 1, 3, 0, 1, 0, 1, 0, 3, 1, 3, 0, 0, 3, 2, 3, 0, 2, 0, 1, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 66 and the episode is 782 and the total_steps are 61849\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 1, 0, 0, 1, 2, 3, 0, 0, 1, 1, 0, 3, 2, 3, 1, 1, 1, 1, 3, 2, 1, 2, 3, 2, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 783 and the total_steps are 61881\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 2, 3, 1, 0, 0, 0, 0, 0, 2, 1, 3, 3, 1, 3, 2, 1, 1, 2, 1, 3, 3, 0, 1, 3, 2, 1, 1, 1, 1, 2, 0, 1, 1, 3, 0, 3, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 0, 2, 0, 2, 0, 3, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1058. And steps were 60 and the episode is 784 and the total_steps are 61941\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -754     |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 1289     |\n",
      "|    total_timesteps  | 61941    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 2985     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 3, 3, 1, 0, 2, 2, 1, 3, 0, 1, 1, 1, 0, 0, 3, 1, 0, 1, 0, 3, 0, 1, 2, 3, 0, 1, 1, 2, 3, 2, 0, 3, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 40 and the episode is 785 and the total_steps are 61981\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 0, 1, 1, 1, 0, 1, 1, 2, 2, 2, 2, 0, 3, 0, 1, 0, 1, 1, 2, 1, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 786 and the total_steps are 62009\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 3, 3, 3, 2, 0, 3, 2, 3, 3, 1, 2, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 19 and the episode is 787 and the total_steps are 62028\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 1, 2, 3, 2, 1, 2, 2, 1, 3, 2, 2, 2, 2, 3, 1, 3, 1, 1, 2, 1, 1, 1, 0, 0, 2, 3, 0, 1, 1, 1, 2, 0, 3, 1, 0, 2, 2, 0, 2, 2, 2, 1, 3, 3, 3, 2, 0, 1, 3, 1, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1056. And steps were 58 and the episode is 788 and the total_steps are 62086\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -755     |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1295     |\n",
      "|    total_timesteps  | 62086    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.897    |\n",
      "|    n_updates        | 3021     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 2, 3, 2, 1, 0, 2, 0, 0, 3, 1, 2, 3, 2, 3, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 789 and the total_steps are 62117\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 2, 3, 2, 2, 3, 1, 1, 2, 3, 1, 2, 0, 3, 1, 3, 1, 2, 0, 2, 0, 3, 2, 1, 0, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 32 and the episode is 790 and the total_steps are 62149\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 1, 1, 2, 0, 2, 3, 3, 1, 3, 2, 0, 0, 2, 2, 1, 2, 3, 1, 1, 3, 1, 2, 0, 3, 2, 1, 3, 1, 1, 2, 2, 3, 2, 1, 1, 2, 3, 3, 2, 3, 2, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 49 and the episode is 791 and the total_steps are 62198\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 0, 0, 3, 1, 3, 3, 0, 2, 1, 1, 2, 0, 0, 2, 0, 0, 0, 0, 3, 0, 1, 1, 2, 0, 2, 2, 2, 2, 0, 0, 2, 1, 2, 3, 2, 2, 2, 1, 3, 2, 2, 0, 3, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 51 and the episode is 792 and the total_steps are 62249\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | -775     |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1302     |\n",
      "|    total_timesteps  | 62249    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.946    |\n",
      "|    n_updates        | 3062     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 2, 1, 2, 1, 1, 1, 0, 2, 0, 3, 0, 3, 2, 0, 1, 0, 2, 1, 3, 2, 0, 1, 3, 2, 1, 3, 3, 3, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 3, 0, 3, 3, 1, 1, 1, 2, 1, 3, 0, 2, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 64 and the episode is 793 and the total_steps are 62313\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 1, 3, 2, 3, 0, 2, 0, 1, 3, 1, 1, 0, 1, 1, 1, 3, 1, 3, 0, 1, 1, 2, 0, 0, 0, 1, 2, 2, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 36 and the episode is 794 and the total_steps are 62349\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 2, 0, 0, 2, 1, 0, 3, 1, 1, 0, 0, 0, 1, 1, 3, 3, 3, 0, 1, 2, 1, 0, 1, 1, 3, 1, 2, 3, 0, 3, 0, 0, 2, 0, 1, 0, 3, 3, 3, 2, 3, 0, 2, 1, 0, 1, 0, 3, 0, 2, 2, 3, 2, 2, 2, 2, 0, 1, 2, 1, 2, 0, 2, 3, 2, 0, 3, 1, 2, 0, 1, 3, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 80 and the episode is 795 and the total_steps are 62429\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 2, 0, 3, 2, 1, 0, 3, 2, 1, 2, 1, 0, 0, 1, 2, 2, 0, 1, 0, 2, 0, 3, 3, 0, 1, 2, 0, 2, 1, 1, 2, 2, 3, 0, 3, 0, 1, 1, 0, 0, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 48 and the episode is 796 and the total_steps are 62477\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -775     |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1310     |\n",
      "|    total_timesteps  | 62477    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.9      |\n",
      "|    n_updates        | 3119     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 3, 0, 1, 2, 2, 0, 2, 1, 1, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 3, 0, 3, 0, 0, 0, 2, 2, 1, 2, 0, 2, 0, 0, 3, 3, 0, 0, 2, 3, 1, 2, 3, 1, 1, 3, 0, 1, 2, 0, 1, 0, 3, 1, 3, 0, 3, 3, 2, 0, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 67 and the episode is 797 and the total_steps are 62544\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 2, 1, 2, 0, 0, 1, 2, 2, 1, 0, 2, 2, 2, 0, 2, 3, 0, 2, 2, 2, 3, 2, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 30 and the episode is 798 and the total_steps are 62574\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 1, 3, 1, 0, 1, 1, 0, 1, 3, 1, 3, 1, 1, 2, 2, 1, 0, 2, 1, 2, 3, 3, 3, 3, 3, 2, 2, 0, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 799 and the total_steps are 62610\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 3, 0, 3, 3, 0, 1, 1, 1, 3, 3, 3, 2, 3, 1, 2, 3, 3, 0, 3, 1, 0, 2, 2, 0, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 32 and the episode is 800 and the total_steps are 62642\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | -775     |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1317     |\n",
      "|    total_timesteps  | 62642    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 3160     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 1, 1, 3, 3, 3, 1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 3, 3, 2, 2, 3, 0, 3, 3, 2, 2, 2, 2, 1, 0, 2, 1, 1, 3, 1, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 43 and the episode is 801 and the total_steps are 62685\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 3, 3, 3, 1, 0, 3, 2, 2, 1, 3, 1, 0, 1, 1, 3, 0, 0, 1, 0, 3, 2, 3, 0, 1, 2, 0, 3, 1, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 802 and the total_steps are 62721\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 1, 3, 1, 3, 1, 1, 1, 2, 2, 0, 1, 1, 1, 1, 3, 2, 0, 0, 3, 0, 2, 1, 0, 1, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 803 and the total_steps are 62753\n",
      "Done condition: collision\n",
      "[3, 1, 3, 1, 2, 3, 3, 0, 2, 1, 1, 0, 0, 1, 0, 3, 0, 3, 2, 2, 0, 1, 1, 0, 3, 0, 2, 0, 2, 0, 1, 0, 0, 0, 2, 1, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 40 and the episode is 804 and the total_steps are 62793\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -796     |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1323     |\n",
      "|    total_timesteps  | 62793    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.211    |\n",
      "|    n_updates        | 3198     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 2, 3, 1, 3, 3, 1, 3, 2, 2, 1, 1, 0, 2, 0, 0, 2, 0, 0, 3, 2, 0, 3, 1, 1, 2, 0, 0, 1, 3, 1, 2, 2, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 40 and the episode is 805 and the total_steps are 62833\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 0, 2, 1, 3, 0, 1, 3, 2, 0, 2, 0, 3, 1, 1, 3, 2, 3, 2, 1, 3, 2, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 3, 2, 0, 1, 3, 0, 3, 3, 2, 3, 0, 1, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 51 and the episode is 806 and the total_steps are 62884\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 0, 0, 2, 3, 0, 3, 2, 0, 2, 1, 3, 1, 3, 3, 3, 3, 1, 2, 3, 0, 3, 3, 3, 0, 2, 0, 3, 2, 0, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 37 and the episode is 807 and the total_steps are 62921\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 1, 1, 2, 1, 0, 3, 2, 0, 2, 3, 1, 3, 0, 0, 3, 1, 2, 3, 3, 0, 3, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 808 and the total_steps are 62950\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | -817     |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1329     |\n",
      "|    total_timesteps  | 62950    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 3237     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 2, 2, 2, 1, 0, 1, 2, 2, 1, 0, 1, 0, 0, 3, 3, 0, 0, 2, 3, 3, 3, 1, 2, 0, 0, 1, 2, 1, 1, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 37 and the episode is 809 and the total_steps are 62987\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 0, 0, 3, 3, 3, 1, 1, 2, 3, 0, 1, 0, 0, 2, 3, 3, 2, 0, 3, 3, 1, 1, 1, 3, 1, 2, 2, 1, 3, 1, 1, 2, 0, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 810 and the total_steps are 63028\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 1, 1, 3, 1, 0, 2, 2, 0, 0, 3, 0, 0, 0, 2, 1, 2, 1, 3, 0, 3, 3, 1, 1, 3, 3, 2, 2, 2, 3, 1, 0, 2, 0, 1, 0, 1, 1, 2, 0, 0, 0, 2, 0, 1, 2, 3, 1, 2, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 56 and the episode is 811 and the total_steps are 63084\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 1, 3, 2, 2, 2, 1, 3, 0, 1, 1, 1, 1, 1, 2, 2, 1, 3, 3, 1, 0, 2, 1, 0, 3, 2, 1, 3, 2, 2, 0, 3, 3, 1, 1, 1, 0, 3, 3, 3, 1, 1, 2, 1, 1, 2, 3, 1, 3, 1, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 57 and the episode is 812 and the total_steps are 63141\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -818     |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1336     |\n",
      "|    total_timesteps  | 63141    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 3285     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 2, 3, 0, 3, 2, 3, 3, 2, 0, 1, 2, 0, 2, 2, 3, 2, 2, 3, 0, 3, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 28 and the episode is 813 and the total_steps are 63169\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 1, 0, 0, 0, 2, 3, 2, 2, 2, 2, 0, 0, 1, 2, 3, 1, 1, 3, 2, 0, 0, 0, 3, 3, 0, 1, 1, 0, 1, 1, 2, 3, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 40 and the episode is 814 and the total_steps are 63209\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 3, 2, 3, 3, 0, 3, 0, 0, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 3, 3, 1, 1, 0, 0, 1, 0, 2, 3, 1, 2, 2, 0, 1, 3, 0, 3, 1, 3, 1, 1, 0, 3, 0, 3, 2, 3, 0, 0, 3, 0, 3, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 0, 3, 0, 0, 0, 3, 1, 0, 3, 0, 2, 2, 3, 0, 0, 0, 1, 0, 0, 3, 1, 1, 0, 1, 1, 2, 3, 1, 3, 0, 1, 3, 1, 0, 2, 3, 1, 3, 1, 3, 1, 1, 2, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -900. And steps were 112 and the episode is 815 and the total_steps are 63321\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 3, 3, 1, 1, 3, 0, 1, 2, 2, 0, 0, 3, 1, 0, 2, 0, 0, 1, 3, 2, 1, 2, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 30 and the episode is 816 and the total_steps are 63351\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1344     |\n",
      "|    total_timesteps  | 63351    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 93.2     |\n",
      "|    n_updates        | 3337     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 3, 3, 2, 2, 0, 0, 0, 0, 3, 3, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 26 and the episode is 817 and the total_steps are 63377\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 1, 1, 0, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 0, 3, 0, 2, 0, 0, 0, 3, 1, 2, 3, 3, 1, 3, 1, 1, 1, 3, 0, 3, 2, 3, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 44 and the episode is 818 and the total_steps are 63421\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 3, 1, 3, 0, 1, 0, 0, 1, 2, 3, 0, 2, 1, 2, 2, 2, 1, 2, 0, 0, 3, 3, 2, 1, 1, 3, 0, 0, 0, 1, 1, 3, 2, 3, 2, 0, 0, 0, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 46 and the episode is 819 and the total_steps are 63467\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 0, 2, 3, 2, 2, 1, 1, 3, 2, 1, 3, 2, 0, 3, 1, 0, 1, 1, 1, 0, 2, 3, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 30 and the episode is 820 and the total_steps are 63497\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.8     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 1350     |\n",
      "|    total_timesteps  | 63497    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 3374     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 1, 2, 0, 2, 0, 1, 2, 1, 0, 2, 2, 0, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 20 and the episode is 821 and the total_steps are 63517\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 2, 2, 3, 3, 2, 3, 0, 1, 0, 3, 3, 2, 2, 1, 0, 1, 0, 0, 1, 2, 0, 3, 1, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 822 and the total_steps are 63548\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 2, 1, 2, 0, 1, 1, 0, 1, 3, 1, 0, 2, 0, 3, 3, 2, 3, 0, 0, 0, 2, 3, 0, 2, 3, 1, 2, 0, 0, 0, 3, 3, 0, 3, 1, 1, 3, 0, 2, 3, 1, 1, 1, 0, 0, 3, 1, 3, 3, 3, 3, 2, 1, 0, 0, 3, 3, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 65 and the episode is 823 and the total_steps are 63613\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 3, 2, 3, 0, 3, 2, 2, 2, 2, 1, 3, 0, 0, 1, 3, 2, 1, 1, 1, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 824 and the total_steps are 63640\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1356     |\n",
      "|    total_timesteps  | 63640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.281    |\n",
      "|    n_updates        | 3409     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 0, 2, 2, 2, 1, 2, 0, 3, 2, 3, 2, 0, 1, 3, 2, 1, 1, 2, 3, 0, 1, 2, 2, 0, 0, 3, 1, 1, 3, 1, 2, 2, 1, 1, 1, 3, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 825 and the total_steps are 63684\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 3, 3, 3, 3, 1, 1, 0, 0, 2, 3, 1, 0, 2, 1, 2, 3, 0, 2, 2, 1, 1, 2, 1, 0, 2, 2, 0, 1, 1, 3, 3, 0, 2, 3, 2, 0, 3, 3, 2, 0, 1, 2, 0, 1, 2, 2, 3, 3, 1, 3, 2, 3, 2, 3, 2, 1, 3, 3, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 66 and the episode is 826 and the total_steps are 63750\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 3, 0, 2, 0, 0, 2, 0, 1, 0, 1, 0, 3, 3, 1, 1, 2, 3, 3, 2, 2, 2, 0, 0, 3, 2, 3, 2, 1, 3, 2, 2, 2, 2, 0, 0, 1, 1, 1, 3, 2, 2, 2, 3, 1, 3, 1, 1, 1, 0, 2, 0, 3, 0, 3, 1, 3, 1, 3, 0, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 67 and the episode is 827 and the total_steps are 63817\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 1, 1, 2, 0, 3, 3, 0, 0, 0, 3, 0, 2, 2, 3, 1, 1, 3, 3, 0, 0, 3, 1, 2, 2, 2, 0, 3, 2, 1, 1, 2, 1, 1, 1, 0, 0, 2, 1, 3, 1, 0, 0, 3, 2, 3, 2, 1, 2, 1, 3, 0, 3, 1, 3, 1, 3, 0, 0, 2, 1, 2, 2, 0, 0, 1, 3, 3, 3, 0, 3, 3, 1, 0, 0, 1, 0, 0, 0, 2, 2, 1, 3, 0, 2, 3, 2, 1, 1, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 96 and the episode is 828 and the total_steps are 63913\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.2     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1366     |\n",
      "|    total_timesteps  | 63913    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.2     |\n",
      "|    n_updates        | 3478     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 0, 1, 1, 2, 3, 1, 1, 0, 2, 1, 1, 2, 0, 3, 3, 0, 0, 2, 1, 1, 2, 3, 0, 3, 2, 0, 0, 1, 3, 1, 2, 1, 1, 0, 1, 3, 0, 2, 1, 1, 2, 1, 1, 3, 2, 2, 2, 0, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 56 and the episode is 829 and the total_steps are 63969\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 0, 2, 0, 1, 2, 3, 2, 2, 2, 1, 3, 0, 1, 3, 0, 3, 2, 3, 0, 3, 1, 2, 1, 1, 2, 2, 3, 1, 1, 0, 3, 0, 3, 0, 0, 2, 1, 1, 1, 3, 3, 2, 3, 3, 3, 3, 0, 3, 1, 1, 2, 2, 1, 2, 0, 1, 1, 1, 3, 2, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 68 and the episode is 830 and the total_steps are 64037\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 2, 1, 2, 2, 2, 2, 3, 2, 0, 0, 3, 3, 0, 0, 0, 3, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 3, 1, 0, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 40 and the episode is 831 and the total_steps are 64077\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 1, 2, 0, 0, 3, 0, 2, 3, 1, 3, 1, 1, 3, 2, 2, 3, 2, 3, 2, 2, 2, 1, 3, 0, 2, 2, 1, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 35 and the episode is 832 and the total_steps are 64112\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.1     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1375     |\n",
      "|    total_timesteps  | 64112    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 3527     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 1, 1, 3, 2, 0, 0, 1, 1, 0, 3, 1, 2, 0, 2, 1, 2, 3, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 25 and the episode is 833 and the total_steps are 64137\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 2, 2, 1, 0, 3, 2, 1, 0, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 29 and the episode is 834 and the total_steps are 64166\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 1, 2, 1, 0, 1, 0, 0, 3, 0, 1, 3, 0, 3, 0, 0, 3, 2, 2, 1, 3, 3, 0, 3, 0, 2, 2, 3, 1, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 36 and the episode is 835 and the total_steps are 64202\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 0, 1, 3, 0, 3, 1, 3, 3, 3, 0, 0, 2, 1, 1, 3, 3, 3, 3, 3, 1, 2, 2, 1, 3, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 31 and the episode is 836 and the total_steps are 64233\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.7     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1380     |\n",
      "|    total_timesteps  | 64233    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.4     |\n",
      "|    n_updates        | 3558     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 3, 0, 2, 1, 3, 3, 2, 0, 2, 1, 3, 3, 1, 2, 1, 0, 2, 0, 0, 3, 1, 3, 0, 2, 2, 1, 0, 1, 2, 0, 2, 3, 0, 2, 2, 0, 0, 2, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 46 and the episode is 837 and the total_steps are 64279\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 1, 1, 2, 1, 1, 2, 3, 3, 2, 2, 0, 2, 2, 3, 0, 2, 2, 1, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 26 and the episode is 838 and the total_steps are 64305\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 2, 2, 0, 1, 2, 3, 0, 0, 0, 2, 2, 0, 0, 0, 3, 2, 0, 0, 3, 2, 2, 2, 0, 0, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 32 and the episode is 839 and the total_steps are 64337\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 1, 3, 0, 0, 1, 2, 3, 3, 2, 2, 1, 2, 3, 3, 2, 0, 0, 3, 1, 3, 1, 0, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 28 and the episode is 840 and the total_steps are 64365\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.3     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1386     |\n",
      "|    total_timesteps  | 64365    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.24     |\n",
      "|    n_updates        | 3591     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 3, 2, 1, 0, 0, 1, 3, 3, 1, 2, 3, 2, 2, 2, 3, 1, 1, 0, 0, 1, 1, 3, 2, 3, 3, 0, 2, 2, 0, 3, 2, 2, 0, 3, 3, 0, 1, 3, 2, 0, 2, 0, 3, 3, 0, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 53 and the episode is 841 and the total_steps are 64418\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 0, 2, 2, 3, 2, 1, 2, 0, 1, 1, 1, 3, 1, 0, 2, 3, 2, 3, 2, 1, 1, 3, 2, 3, 1, 3, 3, 2, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 3, 0, 3, 3, 0, 1, 3, 3, 2, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 55 and the episode is 842 and the total_steps are 64473\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 3, 3, 2, 0, 0, 3, 2, 1, 3, 0, 0, 2, 2, 0, 0, 3, 0, 1, 0, 0, 2, 1, 1, 1, 3, 1, 3, 2, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 843 and the total_steps are 64509\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 1, 3, 3, 3, 1, 1, 1, 0, 0, 0, 1, 3, 2, 2, 1, 3, 0, 2, 3, 2, 3, 3, 1, 0, 2, 0, 0, 0, 1, 0, 1, 3, 2, 0, 3, 0, 3, 3, 0, 1, 2, 2, 0, 1, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 844 and the total_steps are 64561\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.9     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1393     |\n",
      "|    total_timesteps  | 64561    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.29     |\n",
      "|    n_updates        | 3640     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 2, 1, 0, 3, 1, 2, 3, 0, 1, 1, 3, 3, 3, 2, 3, 0, 0, 2, 0, 2, 1, 0, 3, 3, 2, 0, 3, 0, 3, 1, 3, 2, 1, 3, 3, 2, 2, 0, 3, 2, 2, 3, 0, 2, 2, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 53 and the episode is 845 and the total_steps are 64614\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 1, 3, 1, 2, 3, 1, 2, 0, 1, 0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 846 and the total_steps are 64641\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 1, 2, 2, 1, 2, 1, 3, 3, 1, 2, 3, 3, 2, 3, 0, 0, 0, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 22 and the episode is 847 and the total_steps are 64663\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 1, 3, 2, 0, 2, 3, 0, 1, 2, 1, 3, 1, 0, 0, 3, 1, 2, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 25 and the episode is 848 and the total_steps are 64688\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.3     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1399     |\n",
      "|    total_timesteps  | 64688    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.886    |\n",
      "|    n_updates        | 3671     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 0, 0, 2, 0, 1, 0, 2, 1, 1, 3, 0, 1, 1, 3, 3, 2, 1, 3, 0, 2, 1, 3, 2, 3, 2, 3, 2, 3, 1, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 37 and the episode is 849 and the total_steps are 64725\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 0, 3, 3, 1, 2, 0, 0, 2, 1, 3, 0, 2, 0, 3, 0, 1, 1, 2, 3, 2, 2, 0, 0, 0, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 32 and the episode is 850 and the total_steps are 64757\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 1, 1, 0, 0, 3, 0, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 3, 0, 2, 0, 1, 2, 3, 0, 2, 3, 1, 1, 0, 1, 0, 0, 2, 3, 2, 0, 3, 2, 3, 3, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 49 and the episode is 851 and the total_steps are 64806\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 1, 1, 0, 1, 2, 3, 2, 0, 3, 1, 3, 1, 1, 3, 3, 1, 1, 1, 1, 0, 2, 3, 0, 0, 3, 1, 3, 2, 2, 1, 0, 0, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 40 and the episode is 852 and the total_steps are 64846\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.1     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1405     |\n",
      "|    total_timesteps  | 64846    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 3711     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 2, 0, 2, 3, 2, 1, 0, 1, 0, 1, 0, 1, 0, 3, 0, 1, 3, 1, 0, 1, 0, 2, 0, 3, 3, 3, 2, 0, 3, 0, 1, 0, 2, 3, 0, 2, 1, 3, 2, 0, 2, 0, 0, 2, 3, 0, 0, 0, 3, 3, 3, 1, 0, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1058. And steps were 60 and the episode is 853 and the total_steps are 64906\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 1, 3, 1, 1, 1, 2, 3, 0, 0, 0, 2, 2, 1, 1, 1, 0, 2, 2, 3, 1, 1, 0, 1, 2, 3, 2, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 34 and the episode is 854 and the total_steps are 64940\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 2, 0, 3, 1, 1, 1, 1, 0, 2, 3, 2, 3, 3, 1, 0, 0, 0, 2, 2, 2, 0, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 855 and the total_steps are 64969\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 3, 0, 2, 2, 0, 2, 1, 2, 3, 1, 0, 1, 3, 1, 0, 0, 0, 1, 1, 1, 0, 1, 3, 0, 3, 1, 1, 1, 2, 3, 1, 3, 2, 2, 0, 1, 2, 1, 2, 3, 1, 0, 1, 1, 2, 0, 0, 0, 2, 2, 3, 3, 2, 3, 0, 0, 0, 3, 3, 3, 2, 1, 3, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 71 and the episode is 856 and the total_steps are 65040\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.3     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 46       |\n",
      "|    time_elapsed     | 1413     |\n",
      "|    total_timesteps  | 65040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.929    |\n",
      "|    n_updates        | 3759     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 2, 2, 2, 1, 1, 0, 2, 3, 3, 1, 0, 1, 2, 3, 2, 0, 2, 2, 0, 3, 2, 1, 3, 1, 2, 3, 2, 0, 3, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 37 and the episode is 857 and the total_steps are 65077\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 1, 1, 2, 3, 3, 0, 0, 3, 1, 1, 2, 2, 1, 0, 0, 2, 1, 1, 0, 3, 2, 0, 1, 0, 2, 1, 1, 1, 3, 1, 0, 2, 3, 1, 1, 3, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 44 and the episode is 858 and the total_steps are 65121\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 3, 0, 3, 0, 3, 1, 1, 3, 0, 3, 0, 2, 3, 0, 3, 1, 1, 0, 2, 0, 2, 2, 1, 2, 3, 0, 1, 2, 0, 0, 1, 2, 1, 2, 2, 3, 1, 1, 0, 3, 2, 1, 1, 3, 0, 1, 3, 2, 0, 3, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 58 and the episode is 859 and the total_steps are 65179\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 0, 0, 0, 0, 3, 1, 1, 2, 1, 1, 3, 2, 2, 2, 2, 2, 2, 3, 2, 0, 3, 2, 0, 1, 1, 1, 0, 0, 2, 1, 3, 3, 2, 3, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 42 and the episode is 860 and the total_steps are 65221\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.6     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 1420     |\n",
      "|    total_timesteps  | 65221    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.2     |\n",
      "|    n_updates        | 3805     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 2, 2, 2, 0, 1, 2, 1, 3, 2, 2, 2, 0, 2, 3, 1, 1, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 861 and the total_steps are 65245\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 3, 0, 0, 3, 0, 1, 3, 3, 2, 3, 3, 0, 1, 1, 2, 1, 1, 2, 0, 1, 2, 2, 0, 3, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 862 and the total_steps are 65277\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 1, 3, 3, 0, 3, 2, 0, 0, 1, 2, 3, 2, 0, 0, 1, 3, 2, 3, 1, 3, 3, 0, 0, 3, 1, 2, 3, 0, 1, 0, 0, 2, 2, 1, 3, 1, 0, 3, 1, 2, 2, 0, 1, 3, 2, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 68 and the episode is 863 and the total_steps are 65345\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 3, 0, 1, 0, 1, 3, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 3, 1, 3, 1, 3, 3, 2, 1, 3, 0, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 864 and the total_steps are 65379\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.2     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 1426     |\n",
      "|    total_timesteps  | 65379    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 3844     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 2, 3, 0, 0, 0, 1, 2, 1, 3, 0, 3, 0, 1, 3, 3, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 865 and the total_steps are 65400\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 2, 1, 1, 1, 1, 0, 1, 0, 0, 3, 3, 2, 0, 0, 1, 0, 0, 0, 2, 3, 1, 1, 2, 3, 0, 1, 0, 1, 0, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 37 and the episode is 866 and the total_steps are 65437\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 1, 0, 0, 2, 0, 3, 0, 3, 3, 3, 2, 3, 3, 0, 1, 0, 0, 2, 3, 1, 1, 0, 0, 0, 0, 1, 1, 3, 0, 2, 0, 2, 2, 2, 1, 0, 2, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 3, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 56 and the episode is 867 and the total_steps are 65493\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 3, 2, 0, 3, 1, 2, 2, 3, 2, 0, 2, 0, 2, 3, 2, 1, 1, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 868 and the total_steps are 65525\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 1431     |\n",
      "|    total_timesteps  | 65525    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 3881     |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 0, 2, 0, 3, 0, 1, 3, 1, 1, 0, 2, 0, 0, 2, 0, 0, 1, 0, 3, 2, 1, 1, 2, 3, 0, 0, 1, 0, 3, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 37 and the episode is 869 and the total_steps are 65562\n",
      "Done condition: collision\n",
      "[0, 0, 1, 2, 3, 3, 1, 0, 1, 0, 0, 0, 2, 1, 3, 2, 3, 0, 0, 1, 2, 0, 2, 0, 2, 3, 0, 3, 0, 0, 3, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 35 and the episode is 870 and the total_steps are 65597\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 1, 1, 3, 1, 2, 3, 0, 0, 3, 2, 3, 2, 2, 3, 0, 1, 3, 1, 1, 2, 1, 3, 0, 0, 0, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 32 and the episode is 871 and the total_steps are 65629\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 0, 2, 2, 1, 3, 3, 0, 1, 2, 1, 3, 1, 3, 3, 2, 2, 0, 3, 2, 2, 2, 0, 0, 1, 3, 0, 0, 1, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 36 and the episode is 872 and the total_steps are 65665\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 1437     |\n",
      "|    total_timesteps  | 65665    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 3916     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 2, 2, 0, 1, 1, 3, 1, 2, 3, 3, 1, 1, 0, 2, 2, 2, 3, 1, 1, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 27 and the episode is 873 and the total_steps are 65692\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 0, 2, 2, 1, 2, 2, 2, 0, 3, 2, 3, 2, 1, 1, 1, 3, 0, 0, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 25 and the episode is 874 and the total_steps are 65717\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 1, 3, 2, 2, 0, 3, 0, 3, 0, 0, 3, 2, 1, 1, 3, 0, 3, 0, 1, 0, 2, 1, 1, 3, 3, 1, 2, 3, 1, 1, 3, 2, 0, 1, 0, 3, 3, 1, 1, 0, 1, 0, 0, 0, 1, 1, 2, 1, 3, 0, 0, 2, 3, 2, 0, 1, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1062. And steps were 64 and the episode is 875 and the total_steps are 65781\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 1, 1, 0, 1, 3, 1, 3, 0, 1, 0, 2, 2, 0, 2, 0, 0, 2, 3, 2, 3, 1, 2, 0, 0, 2, 3, 1, 3, 3, 3, 1, 2, 3, 1, 2, 0, 1, 3, 0, 0, 3, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 49 and the episode is 876 and the total_steps are 65830\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.6     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 1444     |\n",
      "|    total_timesteps  | 65830    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 3957     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 1, 2, 2, 2, 3, 2, 1, 2, 0, 1, 1, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 19 and the episode is 877 and the total_steps are 65849\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 2, 1, 1, 0, 1, 3, 2, 1, 2, 0, 3, 2, 0, 1, 1, 3, 1, 1, 2, 1, 0, 0, 2, 1, 3, 2, 0, 0, 3, 2, 0, 3, 3, 0, 0, 2, 3, 1, 1, 1, 1, 0, 0, 3, 3, 0, 1, 3, 3, 2, 1, 3, 3, 2, 2, 0, 1, 0, 1, 2, 1, 1, 0, 1, 0, 0, 2, 3, 1, 1, 3, 1, 1, 0, 3, 1, 2, 0, 1, 3, 2, 3, 3, 3, 2, 3, 1, 3, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 96 and the episode is 878 and the total_steps are 65945\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 1, 0, 1, 1, 2, 3, 2, 3, 0, 1, 0, 2, 1, 2, 3, 0, 0, 1, 3, 0, 0, 3, 2, 1, 3, 3, 0, 3, 3, 1, 1, 3, 3, 0, 1, 3, 2, 3, 0, 3, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 48 and the episode is 879 and the total_steps are 65993\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 1, 0, 3, 2, 3, 0, 2, 3, 1, 2, 1, 2, 3, 0, 2, 0, 2, 0, 2, 1, 3, 2, 0, 2, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 880 and the total_steps are 66025\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 1452     |\n",
      "|    total_timesteps  | 66025    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 4006     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 3, 2, 3, 3, 1, 2, 3, 2, 0, 0, 2, 2, 2, 2, 0, 3, 0, 0, 2, 2, 3, 0, 2, 0, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 881 and the total_steps are 66058\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 2, 3, 2, 1, 3, 0, 2, 1, 3, 0, 0, 1, 3, 2, 2, 3, 0, 2, 0, 0, 0, 1, 2, 2, 0, 1, 0, 3, 2, 2, 2, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 39 and the episode is 882 and the total_steps are 66097\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 3, 0, 3, 0, 1, 0, 2, 2, 2, 0, 3, 2, 0, 1, 3, 3, 3, 0, 0, 2, 2, 1, 3, 0, 1, 1, 1, 0, 2, 0, 0, 1, 0, 2, 3, 2, 2, 2, 1, 3, 2, 3, 1, 3, 0, 2, 2, 0, 1, 1, 0, 3, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 60 and the episode is 883 and the total_steps are 66157\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 2, 0, 0, 1, 0, 2, 2, 1, 2, 2, 1, 0, 1, 0, 0, 1, 3, 1, 3, 1, 3, 2, 3, 0, 0, 0, 2, 2, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 884 and the total_steps are 66192\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 1459     |\n",
      "|    total_timesteps  | 66192    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 4047     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 0, 3, 1, 3, 0, 2, 2, 3, 0, 0, 1, 2, 2, 0, 1, 3, 1, 3, 0, 1, 1, 0, 1, 2, 2, 3, 3, 2, 1, 2, 1, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 39 and the episode is 885 and the total_steps are 66231\n",
      "Done condition: collision\n",
      "[3, 1, 3, 1, 1, 2, 1, 2, 1, 0, 2, 3, 0, 0, 0, 1, 2, 1, 1, 0, 3, 3, 1, 2, 2, 0, 3, 3, 3, 1, 0, 2, 3, 3, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 886 and the total_steps are 66269\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 0, 1, 0, 1, 0, 3, 0, 0, 2, 2, 3, 0, 2, 3, 2, 0, 2, 2, 1, 1, 1, 2, 3, 2, 2, 2, 0, 3, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 887 and the total_steps are 66305\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 2, 2, 0, 0, 3, 2, 2, 3, 2, 3, 2, 2, 0, 3, 0, 1, 3, 0, 3, 2, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 28 and the episode is 888 and the total_steps are 66333\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 1465     |\n",
      "|    total_timesteps  | 66333    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.826    |\n",
      "|    n_updates        | 4083     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 0, 0, 0, 1, 2, 0, 1, 3, 2, 1, 3, 3, 2, 3, 2, 0, 3, 3, 3, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 889 and the total_steps are 66358\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 3, 2, 2, 1, 1, 3, 3, 2, 0, 3, 2, 3, 2, 0, 1, 2, 2, 0, 1, 3, 0, 0, 2, 3, 2, 3, 3, 2, 1, 3, 0, 2, 2, 3, 1, 3, 1, 0, 1, 1, 2, 2, 3, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 51 and the episode is 890 and the total_steps are 66409\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 0, 0, 0, 1, 1, 3, 1, 2, 3, 2, 0, 3, 1, 1, 0, 1, 2, 2, 1, 0, 0, 0, 2, 1, 2, 0, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 33 and the episode is 891 and the total_steps are 66442\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 2, 0, 3, 2, 2, 0, 3, 1, 1, 1, 1, 2, 3, 3, 0, 2, 1, 1, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 892 and the total_steps are 66468\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 1470     |\n",
      "|    total_timesteps  | 66468    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 4116     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 0, 1, 2, 0, 1, 0, 3, 2, 0, 0, 1, 2, 2, 0, 3, 3, 0, 2, 3, 2, 0, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 893 and the total_steps are 66497\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 0, 1, 2, 1, 2, 2, 1, 1, 3, 0, 1, 1, 2, 2, 3, 3, 0, 2, 2, 3, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 894 and the total_steps are 66525\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 2, 1, 0, 1, 1, 3, 3, 0, 2, 3, 1, 0, 0, 3, 2, 2, 2, 3, 1, 3, 1, 2, 0, 3, 2, 3, 3, 1, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 895 and the total_steps are 66561\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 1, 3, 3, 0, 0, 2, 3, 0, 2, 2, 3, 1, 0, 3, 1, 1, 2, 2, 2, 3, 3, 0, 1, 0, 0, 0, 2, 1, 0, 3, 1, 2, 2, 1, 0, 3, 2, 0, 0, 0, 0, 2, 1, 1, 1, 3, 3, 2, 0, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 57 and the episode is 896 and the total_steps are 66618\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 1476     |\n",
      "|    total_timesteps  | 66618    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 4154     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 2, 1, 0, 0, 3, 3, 2, 0, 1, 0, 3, 1, 3, 2, 0, 3, 3, 3, 3, 3, 2, 0, 3, 1, 0, 3, 1, 1, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 897 and the total_steps are 66654\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 1, 1, 1, 2, 1, 0, 1, 3, 0, 2, 0, 3, 1, 1, 0, 3, 2, 0, 1, 0, 2, 3, 1, 2, 0, 0, 2, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 35 and the episode is 898 and the total_steps are 66689\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 3, 1, 0, 0, 0, 3, 0, 0, 0, 1, 3, 1, 3, 0, 1, 1, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 899 and the total_steps are 66713\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 0, 1, 0, 1, 3, 1, 1, 3, 1, 1, 2, 3, 2, 2, 3, 2, 0, 2, 3, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 27 and the episode is 900 and the total_steps are 66740\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 1481     |\n",
      "|    total_timesteps  | 66740    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 4184     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 2, 0, 3, 0, 1, 3, 0, 3, 1, 0, 1, 0, 2, 1, 3, 3, 0, 3, 0, 2, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 29 and the episode is 901 and the total_steps are 66769\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 2, 3, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 1, 0, 2, 3, 1, 1, 2, 2, 1, 2, 1, 3, 3, 0, 1, 3, 0, 3, 1, 3, 3, 3, 2, 3, 1, 3, 2, 2, 2, 0, 3, 3, 0, 2, 3, 1, 0, 2, 0, 0, 0, 1, 1, 0, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 69 and the episode is 902 and the total_steps are 66838\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 3, 0, 3, 2, 2, 1, 2, 1, 0, 1, 1, 1, 3, 2, 2, 3, 1, 2, 0, 2, 3, 2, 0, 1, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 903 and the total_steps are 66870\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 2, 3, 2, 0, 2, 0, 1, 0, 2, 0, 2, 3, 3, 0, 1, 2, 1, 0, 2, 0, 3, 3, 3, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 31 and the episode is 904 and the total_steps are 66901\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1487     |\n",
      "|    total_timesteps  | 66901    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 4225     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 1, 2, 3, 3, 3, 1, 0, 0, 2, 1, 1, 0, 2, 2, 2, 1, 0, 1, 0, 0, 0, 1, 2, 2, 1, 3, 1, 2, 3, 1, 1, 3, 1, 3, 0, 2, 2, 0, 3, 3, 3, 1, 2, 0, 3, 1, 1, 2, 3, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 57 and the episode is 905 and the total_steps are 66958\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 3, 0, 1, 2, 3, 0, 3, 3, 0, 0, 3, 0, 0, 2, 1, 1, 0, 0, 0, 2, 2, 1, 2, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 906 and the total_steps are 66989\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 2, 3, 3, 3, 1, 2, 1, 2, 0, 1, 2, 3, 3, 3, 3, 0, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 3, 1, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 907 and the total_steps are 67037\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 1, 3, 2, 1, 3, 2, 0, 2, 2, 3, 2, 3, 3, 0, 2, 0, 0, 1, 0, 3, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 28 and the episode is 908 and the total_steps are 67065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1493     |\n",
      "|    total_timesteps  | 67065    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 4266     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 0, 0, 3, 3, 1, 0, 2, 1, 3, 0, 0, 0, 3, 3, 0, 1, 1, 1, 2, 1, 1, 3, 1, 0, 0, 3, 3, 3, 1, 2, 3, 2, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 40 and the episode is 909 and the total_steps are 67105\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 1, 2, 0, 1, 3, 2, 1, 3, 1, 3, 0, 2, 3, 0, 0, 2, 1, 0, 2, 2, 3, 3, 1, 3, 3, 1, 1, 2, 3, 1, 3, 2, 3, 0, 2, 2, 2, 0, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 46 and the episode is 910 and the total_steps are 67151\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 1, 1, 3, 0, 3, 2, 1, 3, 2, 1, 2, 3, 1, 1, 3, 1, 2, 2, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 26 and the episode is 911 and the total_steps are 67177\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 0, 3, 3, 3, 2, 3, 2, 2, 0, 3, 3, 3, 3, 1, 3, 1, 2, 0, 2, 3, 1, 3, 1, 2, 0, 3, 3, 2, 0, 3, 0, 3, 0, 3, 0, 2, 3, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 3, 3, 0, 3, 0, 2, 3, 0, 1, 1, 2, 1, 2, 3, 1, 1, 2, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1060. And steps were 84 and the episode is 912 and the total_steps are 67261\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1501     |\n",
      "|    total_timesteps  | 67261    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.345    |\n",
      "|    n_updates        | 4315     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 3, 3, 1, 1, 2, 2, 0, 1, 1, 3, 0, 3, 1, 0, 0, 3, 1, 2, 0, 1, 0, 1, 2, 0, 1, 3, 1, 1, 0, 3, 1, 0, 0, 2, 2, 3, 0, 2, 0, 3, 2, 0, 1, 1, 1, 2, 2, 1, 2, 0, 3, 3, 0, 3, 0, 2, 3, 1, 3, 0, 3, 1, 3, 0, 2, 2, 3, 0, 2, 0, 1, 0, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1058. And steps were 80 and the episode is 913 and the total_steps are 67341\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 1, 0, 0, 2, 0, 2, 1, 2, 1, 3, 1, 1, 3, 3, 0, 0, 2, 1, 0, 0, 1, 2, 0, 3, 1, 3, 0, 3, 0, 2, 2, 2, 3, 2, 0, 1, 2, 3, 0, 3, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 48 and the episode is 914 and the total_steps are 67389\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 2, 2, 1, 0, 0, 2, 0, 3, 2, 2, 0, 2, 1, 2, 2, 0, 3, 1, 3, 0, 2, 3, 2, 2, 3, 2, 3, 0, 2, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 37 and the episode is 915 and the total_steps are 67426\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 3, 2, 3, 1, 0, 1, 3, 2, 2, 0, 3, 1, 3, 3, 3, 1, 2, 1, 0, 3, 1, 2, 1, 3, 2, 3, 1, 3, 3, 1, 2, 1, 2, 3, 3, 3, 3, 0, 0, 2, 3, 3, 3, 3, 3, 0, 1, 3, 3, 3, 0, 0, 3, 1, 0, 1, 1, 3, 3, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 67 and the episode is 916 and the total_steps are 67493\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1510     |\n",
      "|    total_timesteps  | 67493    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.4     |\n",
      "|    n_updates        | 4373     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 2, 3, 3, 2, 2, 0, 3, 3, 2, 2, 3, 3, 3, 1, 1, 1, 0, 2, 3, 2, 3, 1, 3, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, 1, 2, 2, 1, 3, 3, 2, 1, 0, 1, 0, 0, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 53 and the episode is 917 and the total_steps are 67546\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 3, 1, 1, 0, 2, 0, 3, 2, 1, 0, 0, 0, 1, 0, 2, 1, 1, 2, 2, 3, 1, 3, 3, 0, 1, 3, 1, 0, 1, 0, 2, 2, 2, 3, 3, 3, 1, 0, 2, 3, 3, 3, 2, 0, 0, 3, 3, 0, 0, 0, 1, 0, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 60 and the episode is 918 and the total_steps are 67606\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 0, 2, 3, 2, 0, 0, 3, 3, 0, 3, 0, 1, 3, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was 984. And steps were 19 and the episode is 919 and the total_steps are 67625\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 3, 0, 0, 3, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 1, 0, 1, 0, 3, 0, 0, 2, 1, 2, 1, 2, 1, 1, 1, 3, 2, 3, 1, 3, 3, 3, 1, 1, 1, 1, 2, 1, 0, 3, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 52 and the episode is 920 and the total_steps are 67677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1518     |\n",
      "|    total_timesteps  | 67677    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 95.3     |\n",
      "|    n_updates        | 4419     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 0, 2, 1, 1, 1, 0, 1, 0, 1, 2, 1, 3, 2, 1, 3, 1, 0, 0, 3, 1, 0, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 3, 2, 3, 1, 1, 2, 3, 1, 1, 1, 3, 2, 3, 2, 1, 2, 3, 3, 0, 3, 1, 3, 0, 1, 2, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 64 and the episode is 921 and the total_steps are 67741\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 0, 1, 3, 3, 0, 1, 3, 3, 2, 3, 0, 0, 0, 2, 2, 3, 1, 2, 1, 2, 1, 3, 2, 3, 2, 3, 2, 0, 2, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 37 and the episode is 922 and the total_steps are 67778\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 0, 3, 0, 3, 1, 2, 0, 2, 3, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 17 and the episode is 923 and the total_steps are 67795\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 3, 2, 1, 0, 0, 1, 1, 2, 2, 1, 2, 1, 1, 0, 3, 0, 0, 1, 2, 0, 0, 1, 2, 2, 2, 0, 0, 2, 3, 1, 0, 3, 0, 2, 3, 3, 1, 0, 3, 2, 1, 2, 0, 2, 2, 2, 0, 3, 2, 1, 1, 2, 2, 3, 0, 0, 1, 1, 2, 2, 0, 2, 3, 1, 2, 3, 0, 2, 2, 1, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 78 and the episode is 924 and the total_steps are 67873\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1526     |\n",
      "|    total_timesteps  | 67873    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.329    |\n",
      "|    n_updates        | 4468     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 2, 1, 0, 3, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 24 and the episode is 925 and the total_steps are 67897\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 0, 2, 0, 1, 2, 3, 2, 3, 1, 1, 2, 3, 0, 1, 2, 0, 0, 1, 3, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 27 and the episode is 926 and the total_steps are 67924\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 3, 3, 0, 0, 3, 3, 2, 2, 1, 2, 3, 1, 2, 2, 2, 1, 0, 0, 2, 1, 2, 1, 1, 2, 0, 2, 0, 2, 3, 3, 3, 1, 0, 0, 1, 1, 3, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 45 and the episode is 927 and the total_steps are 67969\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 2, 3, 2, 2, 2, 3, 3, 3, 2, 0, 3, 2, 2, 0, 3, 1, 2, 3, 3, 1, 1, 0, 1, 3, 0, 0, 2, 3, 0, 2, 3, 0, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 40 and the episode is 928 and the total_steps are 68009\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1531     |\n",
      "|    total_timesteps  | 68009    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.2     |\n",
      "|    n_updates        | 4502     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 3, 0, 1, 0, 3, 0, 0, 3, 3, 2, 2, 3, 2, 1, 3, 3, 3, 0, 1, 1, 3, 0, 0, 3, 3, 0, 2, 1, 1, 3, 1, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 39 and the episode is 929 and the total_steps are 68048\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 1, 1, 3, 2, 3, 0, 3, 0, 1, 2, 2, 0, 1, 3, 3, 3, 2, 1, 3, 2, 3, 2, 2, 3, 2, 0, 1, 3, 2, 1, 0, 2, 3, 3, 3, 1, 3, 0, 0, 0, 0, 0, 3, 2, 3, 0, 3, 2, 2, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 57 and the episode is 930 and the total_steps are 68105\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 3, 0, 2, 2, 3, 1, 2, 0, 3, 2, 0, 1, 3, 3, 2, 1, 1, 2, 2, 2, 0, 1, 1, 1, 2, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 33 and the episode is 931 and the total_steps are 68138\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 0, 0, 1, 0, 1, 3, 2, 2, 2, 3, 3, 0, 1, 2, 0, 2, 3, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 25 and the episode is 932 and the total_steps are 68163\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1537     |\n",
      "|    total_timesteps  | 68163    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.213    |\n",
      "|    n_updates        | 4540     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 0, 1, 1, 1, 2, 0, 3, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 31 and the episode is 933 and the total_steps are 68194\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 3, 2, 1, 1, 3, 1, 3, 2, 0, 3, 1, 3, 3, 0, 2, 3, 3, 2, 2, 3, 0, 3, 3, 1, 1, 0, 1, 1, 2, 0, 1, 1, 2, 2, 2, 3, 0, 3, 1, 2, 0, 3, 2, 0, 0, 3, 2, 1, 0, 3, 1, 1, 3, 0, 2, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 63 and the episode is 934 and the total_steps are 68257\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 3, 0, 2, 3, 0, 1, 0, 3, 2, 3, 0, 3, 3, 1, 1, 3, 1, 3, 1, 2, 0, 2, 0, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 935 and the total_steps are 68288\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 3, 1, 3, 0, 3, 0, 1, 0, 3, 0, 0, 0, 2, 2, 3, 1, 3, 3, 3, 1, 3, 2, 2, 3, 0, 1, 2, 1, 1, 1, 2, 0, 0, 0, 1, 0, 0, 1, 3, 1, 0, 1, 3, 0, 1, 1, 0, 3, 0, 2, 3, 1, 0, 0, 0, 2, 1, 2, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1048. And steps were 66 and the episode is 936 and the total_steps are 68354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -903     |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1545     |\n",
      "|    total_timesteps  | 68354    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 4588     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 0, 1, 0, 0, 3, 1, 0, 3, 1, 0, 1, 1, 3, 3, 2, 3, 0, 0, 0, 3, 1, 3, 3, 0, 1, 1, 3, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 35 and the episode is 937 and the total_steps are 68389\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 3, 0, 2, 2, 2, 2, 0, 2, 2, 0, 3, 2, 1, 2, 1, 3, 1, 0, 2, 2, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 938 and the total_steps are 68417\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 2, 0, 2, 1, 1, 0, 1, 2, 3, 1, 1, 2, 0, 2, 1, 3, 1, 1, 0, 1, 1, 0, 0, 3, 1, 3, 1, 3, 0, 3, 1, 0, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 40 and the episode is 939 and the total_steps are 68457\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 3, 1, 0, 3, 1, 3, 2, 1, 2, 0, 3, 2, 0, 3, 2, 1, 1, 3, 0, 3, 3, 3, 3, 2, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 940 and the total_steps are 68489\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -923     |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1550     |\n",
      "|    total_timesteps  | 68489    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.852    |\n",
      "|    n_updates        | 4622     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 2, 3, 1, 3, 0, 1, 0, 1, 0, 2, 2, 3, 2, 0, 0, 0, 0, 1, 3, 1, 1, 1, 0, 0, 3, 0, 0, 3, 2, 2, 1, 0, 1, 1, 2, 3, 3, 3, 1, 1, 3, 3, 3, 0, 2, 0, 3, 1, 0, 0, 3, 3, 3, 3, 3, 0, 3, 1, 1, 2, 2, 0, 3, 1, 0, 2, 1, 3, 1, 1, 1, 2, 2, 1, 1, 3, 1, 1, 3, 1, 0, 2, 3, 1, 3, 0, 3, 2, 1, 2, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1096. And steps were 98 and the episode is 941 and the total_steps are 68587\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 0, 2, 2, 0, 3, 2, 3, 1, 3, 2, 3, 0, 1, 2, 0, 2, 3, 2, 2, 2, 1, 0, 3, 2, 2, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 33 and the episode is 942 and the total_steps are 68620\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 1, 1, 2, 3, 0, 0, 0, 3, 3, 1, 2, 2, 1, 0, 1, 0, 3, 3, 0, 1, 0, 3, 0, 1, 0, 0, 2, 1, 3, 3, 1, 1, 3, 1, 3, 1, 3, 1, 1, 3, 0, 3, 2, 1, 2, 3, 0, 0, 0, 1, 1, 2, 1, 3, 2, 2, 1, 2, 1, 1, 0, 1, 2, 3, 2, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1071. And steps were 73 and the episode is 943 and the total_steps are 68693\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 3, 0, 2, 0, 0, 2, 1, 3, 0, 2, 0, 0, 3, 0, 1, 1, 2, 3, 3, 3, 1, 2, 3, 0, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 944 and the total_steps are 68725\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -924     |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1559     |\n",
      "|    total_timesteps  | 68725    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.723    |\n",
      "|    n_updates        | 4681     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 2, 0, 3, 2, 0, 2, 1, 2, 0, 0, 3, 0, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 1, 3, 1, 2, 2, 1, 0, 2, 1, 0, 3, 0, 0, 3, 2, 0, 0, 2, 2, 2, 1, 1, 1, 2, 3, 1, 2, 3, 1, 1, 3, 2, 1, 2, 1, 2, 0, 0, 1, 3, 3, 2, 2, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 75 and the episode is 945 and the total_steps are 68800\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 0, 1, 2, 2, 0, 2, 1, 1, 3, 2, 1, 3, 2, 2, 1, 2, 2, 3, 3, 0, 2, 2, 3, 1, 3, 3, 0, 3, 0, 1, 0, 0, 3, 3, 1, 1, 1, 1, 2, 0, 2, 3, 3, 1, 0, 1, 0, 2, 1, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 57 and the episode is 946 and the total_steps are 68857\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 0, 1, 3, 3, 1, 0, 2, 2, 0, 3, 0, 1, 0, 2, 1, 2, 3, 3, 2, 1, 3, 1, 2, 2, 0, 1, 2, 0, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 36 and the episode is 947 and the total_steps are 68893\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 2, 3, 3, 3, 0, 3, 3, 1, 2, 2, 1, 0, 2, 3, 1, 0, 3, 0, 0, 1, 1, 0, 3, 2, 2, 3, 2, 0, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 3, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 47 and the episode is 948 and the total_steps are 68940\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | -944     |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1568     |\n",
      "|    total_timesteps  | 68940    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 4734     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 0, 3, 2, 2, 3, 0, 1, 3, 2, 0, 2, 2, 2, 1, 2, 0, 0, 1, 2, 3, 2, 1, 1, 1, 2, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 33 and the episode is 949 and the total_steps are 68973\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 2, 2, 1, 0, 3, 3, 0, 0, 0, 3, 1, 1, 1, 3, 2, 0, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 3, 2, 2, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 37 and the episode is 950 and the total_steps are 69010\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 3, 2, 2, 1, 3, 0, 1, 1, 0, 2, 0, 1, 0, 0, 3, 0, 2, 2, 2, 3, 3, 0, 2, 1, 3, 1, 1, 3, 2, 3, 2, 3, 2, 0, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 42 and the episode is 951 and the total_steps are 69052\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 0, 0, 0, 3, 2, 1, 3, 3, 2, 3, 1, 0, 3, 0, 1, 0, 0, 0, 3, 1, 2, 0, 3, 1, 3, 0, 1, 3, 1, 2, 2, 3, 3, 1, 3, 1, 2, 1, 0, 0, 2, 0, 1, 3, 1, 3, 0, 1, 3, 0, 3, 3, 1, 0, 3, 1, 3, 3, 2, 1, 1, 3, 3, 0, 2, 2, 1, 2, 2, 0, 1, 2, 3, 1, 2, 3, 1, 0, 3, 3, 2, 0, 3, 1, 1, 0, 0, 0, 3, 3, 1, 0, 2, 1, 2, 3, 3, 3, 0, 2, 2, 3, 1, 2, 0, 1, 0, 2, 0, 1, 3, 1, 1, 3, 2, 2, 2, 2, 2, 2, 3, 0, 2, 0, 2, 0, 1, 1, 0, 1, 0, 3, 3, 0, 1, 3, 2, 0, 1, 2, 0, 1, 3, 3, 0, 1, 2, 3, 2, 3, 1, 0, 0, 3, 1, 0, 1, 3, 0, 3, 1, 3, 1, 1, 0, 3, 1, 2, 0, 3, 1, 3, 1, 1, 2, 1, 1, 3, 3, 1, 1, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -843. And steps were 189 and the episode is 952 and the total_steps are 69241\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44       |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1580     |\n",
      "|    total_timesteps  | 69241    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.9     |\n",
      "|    n_updates        | 4810     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 2, 3, 3, 1, 2, 1, 2, 0, 3, 3, 0, 0, 3, 2, 2, 1, 1, 0, 1, 2, 1, 2, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 953 and the total_steps are 69271\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0, 3, 1, 2, 1, 3, 1, 0, 1, 1, 0, 3, 0, 3, 2, 1, 1, 2, 0, 3, 0, 0, 0, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 954 and the total_steps are 69311\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 1, 0, 1, 2, 0, 2, 2, 0, 2, 3, 0, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 955 and the total_steps are 69339\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 1, 0, 2, 3, 0, 2, 3, 0, 2, 0, 2, 0, 3, 3, 2, 0, 0, 3, 0, 1, 1, 1, 2, 1, 2, 3, 3, 1, 0, 2, 0, 1, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 40 and the episode is 956 and the total_steps are 69379\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.4     |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1585     |\n",
      "|    total_timesteps  | 69379    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.38     |\n",
      "|    n_updates        | 4844     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 1, 0, 3, 2, 3, 1, 2, 1, 1, 0, 0, 0, 3, 3, 2, 1, 3, 1, 3, 1, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 42 and the episode is 957 and the total_steps are 69421\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 2, 3, 1, 3, 2, 1, 2, 0, 0, 3, 2, 2, 1, 1, 1, 3, 0, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 25 and the episode is 958 and the total_steps are 69446\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 0, 0, 1, 2, 1, 1, 3, 0, 3, 0, 0, 1, 0, 2, 0, 3, 0, 2, 2, 3, 2, 1, 0, 0, 3, 0, 0, 1, 1, 2, 3, 0, 3, 0, 1, 0, 0, 0, 1, 2, 0, 2, 2, 2, 0, 0, 2, 3, 3, 2, 0, 3, 2, 2, 1, 3, 1, 3, 2, 1, 1, 3, 1, 0, 2, 2, 2, 1, 2, 3, 1, 3, 3, 0, 1, 2, 2, 3, 2, 2, 0, 3, 1, 0, 2, 1, 3, 2, 3, 3, 1, 0, 3, 2, 2, 3, 0, 1, 2, 2, 0, 1, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 110 and the episode is 959 and the total_steps are 69556\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 1, 3, 0, 1, 0, 2, 0, 2, 0, 3, 0, 0, 0, 0, 0, 2, 0, 3, 3, 3, 2, 0, 1, 2, 0, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 960 and the total_steps are 69589\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.7     |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1593     |\n",
      "|    total_timesteps  | 69589    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 4897     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 3, 3, 0, 1, 3, 0, 2, 3, 1, 0, 3, 2, 0, 1, 2, 1, 1, 3, 0, 1, 3, 0, 1, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 31 and the episode is 961 and the total_steps are 69620\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 1, 2, 1, 3, 2, 0, 1, 3, 1, 0, 0, 0, 3, 3, 0, 2, 0, 0, 0, 1, 0, 2, 3, 1, 2, 3, 0, 2, 1, 0, 1, 0, 1, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 41 and the episode is 962 and the total_steps are 69661\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 1, 1, 1, 0, 0, 1, 3, 3, 3, 1, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1013. And steps were 16 and the episode is 963 and the total_steps are 69677\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 1, 2, 1, 1, 0, 0, 0, 0, 3, 1, 2, 1, 1, 0, 3, 3, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1, 3, 2, 2, 2, 2, 1, 1, 2, 1, 0, 1, 3, 2, 3, 3, 0, 2, 1, 2, 3, 3, 1, 2, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 57 and the episode is 964 and the total_steps are 69734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.5     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1599     |\n",
      "|    total_timesteps  | 69734    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 94.8     |\n",
      "|    n_updates        | 4933     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 2, 1, 0, 1, 3, 1, 2, 3, 0, 2, 2, 1, 1, 1, 0, 2, 2, 2, 0, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 965 and the total_steps are 69759\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 1, 2, 0, 1, 3, 0, 3, 1, 3, 2, 0, 1, 3, 0, 0, 3, 2, 0, 2, 1, 1, 0, 3, 0, 1, 1, 0, 1, 2, 1, 3, 2, 3, 3, 1, 2, 0, 1, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 46 and the episode is 966 and the total_steps are 69805\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 1, 3, 3, 2, 3, 0, 3, 0, 2, 3, 2, 2, 0, 0, 1, 0, 0, 1, 2, 0, 3, 1, 3, 2, 3, 3, 1, 2, 0, 3, 2, 1, 0, 3, 0, 1, 3, 1, 3, 3, 0, 1, 2, 2, 1, 2, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 64 and the episode is 967 and the total_steps are 69869\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 1, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 2, 3, 3, 1, 2, 2, 2, 2, 1, 3, 2, 2, 1, 0, 1, 1, 1, 3, 2, 3, 1, 2, 2, 3, 1, 1, 3, 1, 1, 2, 2, 1, 2, 3, 0, 3, 1, 0, 1, 1, 2, 2, 1, 2, 3, 0, 2, 3, 0, 3, 0, 0, 2, 1, 2, 0, 1, 0, 1, 1, 3, 0, 2, 3, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 84 and the episode is 968 and the total_steps are 69953\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.3     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1607     |\n",
      "|    total_timesteps  | 69953    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.9     |\n",
      "|    n_updates        | 4988     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 1, 0, 1, 0, 0, 0, 0, 1, 3, 0, 1, 2, 0, 3, 0, 2, 0, 2, 2, 0, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 969 and the total_steps are 69981\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 2, 3, 1, 3, 1, 0, 3, 0, 0, 1, 0, 1, 3, 2, 1, 0, 3, 0, 1, 2, 1, 2, 3, 0, 1, 1, 3, 0, 2, 1, 3, 2, 1, 1, 1, 3, 0, 1, 2, 3, 1, 0, 1, 3, 0, 0, 0, 3, 0, 2, 3, 0, 2, 0, 0, 3, 2, 2, 3, 2, 1, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 69 and the episode is 970 and the total_steps are 70050\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 3, 3, 2, 0, 0, 3, 2, 2, 0, 2, 0, 2, 2, 2, 0, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 23 and the episode is 971 and the total_steps are 70073\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 2, 0, 3, 0, 0, 3, 0, 0, 3, 0, 3, 0, 0, 1, 0, 2, 1, 0, 3, 0, 2, 3, 0, 0, 0, 3, 0, 2, 3, 3, 2, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 0, 3, 3, 1, 1, 2, 3, 1, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 57 and the episode is 972 and the total_steps are 70130\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.6     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1614     |\n",
      "|    total_timesteps  | 70130    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 5032     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 0, 0, 2, 0, 3, 1, 2, 2, 0, 0, 0, 3, 0, 1, 3, 0, 3, 3, 2, 2, 3, 1, 0, 3, 0, 2, 0, 1, 3, 2, 2, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 39 and the episode is 973 and the total_steps are 70169\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 2, 0, 2, 0, 3, 3, 3, 0, 1, 2, 0, 0, 1, 1, 3, 0, 3, 0, 3, 1, 0, 0, 0, 3, 0, 0, 0, 2, 1, 1, 2, 2, 2, 1, 0, 0, 0, 2, 3, 3, 1, 0, 1, 2, 0, 0, 3, 2, 1, 2, 1, 2, 3, 3, 3, 3, 0, 2, 0, 1, 3, 0, 2, 1, 2, 0, 2, 3, 3, 3, 1, 2, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 80 and the episode is 974 and the total_steps are 70249\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 2, 2, 1, 2, 2, 1, 1, 3, 2, 3, 3, 2, 3, 3, 2, 1, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 24 and the episode is 975 and the total_steps are 70273\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 0, 3, 3, 1, 3, 3, 3, 0, 3, 0, 3, 0, 2, 3, 3, 3, 3, 1, 2, 2, 3, 3, 1, 2, 0, 1, 1, 1, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 36 and the episode is 976 and the total_steps are 70309\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.8     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1621     |\n",
      "|    total_timesteps  | 70309    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 5077     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 2, 2, 1, 0, 1, 3, 0, 1, 0, 3, 0, 1, 2, 1, 2, 1, 3, 3, 2, 0, 2, 0, 2, 3, 1, 3, 3, 2, 3, 1, 3, 0, 3, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 41 and the episode is 977 and the total_steps are 70350\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 1, 2, 1, 0, 3, 2, 1, 3, 2, 3, 1, 3, 2, 2, 3, 1, 2, 2, 2, 3, 2, 1, 2, 0, 1, 3, 1, 3, 0, 2, 2, 2, 1, 3, 0, 3, 1, 3, 2, 0, 3, 2, 3, 2, 1, 3, 3, 1, 3, 0, 1, 1, 0, 2, 1, 3, 3, 0, 2, 1, 3, 3, 2, 0, 1, 2, 0, 1, 2, 0, 0, 3, 3, 1, 3, 0, 0, 1, 3, 3, 0, 2, 1, 0, 0, 2, 3, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1093. And steps were 95 and the episode is 978 and the total_steps are 70445\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 3, 3, 1, 0, 0, 3, 3, 1, 3, 2, 1, 0, 2, 1, 1, 0, 3, 2, 1, 0, 2, 0, 3, 2, 2, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 44 and the episode is 979 and the total_steps are 70489\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 2, 1, 1, 3, 3, 3, 3, 0, 3, 2, 2, 0, 3, 0, 2, 1, 1, 2, 0, 2, 2, 1, 1, 1, 3, 0, 1, 0, 1, 3, 2, 1, 3, 3, 3, 0, 2, 1, 3, 1, 2, 3, 0, 2, 3, 1, 0, 1, 2, 0, 1, 2, 3, 2, 1, 0, 2, 0, 1, 0, 1, 1, 2, 2, 0, 2, 2, 1, 3, 3, 1, 1, 3, 2, 0, 0, 2, 0, 2, 0, 2, 1, 2, 3, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -918. And steps were 92 and the episode is 980 and the total_steps are 70581\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.6     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1632     |\n",
      "|    total_timesteps  | 70581    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.482    |\n",
      "|    n_updates        | 5145     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 0, 3, 2, 0, 3, 1, 1, 3, 1, 1, 3, 2, 0, 1, 3, 2, 3, 1, 2, 1, 0, 2, 1, 3, 3, 2, 1, 2, 0, 1, 1, 3, 0, 2, 3, 0, 0, 0, 0, 0, 2, 1, 2, 2, 2, 0, 2, 3, 1, 1, 3, 2, 1, 1, 3, 2, 2, 3, 0, 3, 2, 3, 2, 0, 2, 0, 3, 3, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -934. And steps were 76 and the episode is 981 and the total_steps are 70657\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 0, 2, 3, 0, 3, 0, 2, 1, 2, 1, 3, 2, 0, 3, 1, 3, 3, 1, 1, 0, 0, 2, 0, 3, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 32 and the episode is 982 and the total_steps are 70689\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 1, 1, 2, 2, 1, 0, 0, 2, 0, 2, 2, 0, 3, 0, 2, 2, 1, 2, 1, 3, 1, 3, 1, 2, 2, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 983 and the total_steps are 70722\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 0, 2, 0, 2, 2, 3, 3, 1, 1, 0, 3, 0, 1, 1, 2, 0, 1, 3, 0, 2, 1, 2, 1, 2, 2, 0, 0, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 35 and the episode is 984 and the total_steps are 70757\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.6     |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1639     |\n",
      "|    total_timesteps  | 70757    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 5189     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 0, 0, 2, 1, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 3, 2, 2, 0, 3, 0, 2, 1, 3, 2, 2, 3, 3, 1, 1, 0, 1, 3, 3, 1, 0, 1, 3, 1, 3, 3, 0, 2, 3, 3, 0, 1, 2, 0, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 67 and the episode is 985 and the total_steps are 70824\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 1, 0, 3, 1, 1, 2, 2, 0, 1, 3, 3, 0, 1, 0, 2, 3, 3, 3, 2, 3, 1, 2, 2, 0, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was 1029. And steps were 30 and the episode is 986 and the total_steps are 70854\n",
      "Done condition: collision\n",
      "[3, 3, 3, 3, 3, 3, 1, 3, 3, 0, 0, 0, 2, 0, 2, 1, 3, 0, 3, 3, 0, 0, 2, 3, 0, 0, 3, 3, 3, 1, 2, 3, 1, 1, 0, 2, 1, 0, 2, 3, 3, 2, 1, 1, 3, 1, 2, 1, 2, 2, 1, 3, 1, 2, 0, 2, 3, 2, 2, 0, 3, 1, 2, 0, 1, 1, 2, 0, 3, 2, 2, 2, 2, 3, 1, 0, 1, 3, 3, 2, 1, 2, 0, 2, 2, 2, 0, 2, 1, 1, 3, 0, 0, 0, 2, 3, 1, 0, 2, 1, 2, 3, 0, 2, 2, 1, 2, 3, 0, 3, 0, 1, 0, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1111. And steps were 117 and the episode is 987 and the total_steps are 70971\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 1, 0, 2, 1, 0, 1, 1, 1, 3, 3, 3, 1, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 3, 2, 2, 1, 2, 2, 0, 1, 1, 1, 1, 3, 3, 2, 0, 3, 0, 1, 1, 1, 3, 1, 3, 1, 0, 0, 3, 0, 1, 0, 2, 3, 2, 1, 3, 2, 2, 2, 1, 1, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 73 and the episode is 988 and the total_steps are 71044\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.1     |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1650     |\n",
      "|    total_timesteps  | 71044    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.4     |\n",
      "|    n_updates        | 5260     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 0, 1, 1, 3, 0, 1, 2, 0, 1, 0, 2, 2, 1, 1, 1, 2, 3, 1, 0, 3, 0, 1, 2, 1, 0, 0, 0, 0, 0, 3, 3, 2, 3, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 41 and the episode is 989 and the total_steps are 71085\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 1, 3, 2, 2, 2, 2, 0, 2, 0, 3, 0, 2, 0, 0, 0, 2, 2, 3, 0, 2, 1, 2, 3, 3, 2, 2, 2, 0, 2, 3, 3, 1, 1, 1, 3, 2, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 44 and the episode is 990 and the total_steps are 71129\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 1, 1, 0, 2, 2, 2, 1, 2, 2, 3, 2, 3, 0, 3, 2, 2, 3, 3, 2, 1, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 991 and the total_steps are 71157\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 0, 1, 0, 0, 2, 0, 1, 3, 2, 0, 3, 1, 3, 0, 0, 2, 2, 0, 3, 0, 1, 1, 3, 2, 2, 2, 1, 2, 0, 0, 2, 0, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 40 and the episode is 992 and the total_steps are 71197\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.3     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1656     |\n",
      "|    total_timesteps  | 71197    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 5299     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 0, 1, 0, 1, 2, 3, 1, 2, 2, 0, 2, 3, 2, 1, 2, 2, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 24 and the episode is 993 and the total_steps are 71221\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 1, 0, 2, 1, 1, 0, 3, 2, 2, 2, 3, 2, 0, 3, 3, 0, 2, 2, 3, 2, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 994 and the total_steps are 71249\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 2, 2, 3, 2, 2, 3, 1, 3, 0, 0, 0, 3, 0, 2, 1, 1, 3, 1, 1, 1, 3, 1, 2, 0, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 995 and the total_steps are 71281\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 0, 2, 3, 1, 1, 2, 0, 3, 1, 2, 2, 2, 2, 1, 3, 0, 2, 3, 3, 3, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 996 and the total_steps are 71309\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.9     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1661     |\n",
      "|    total_timesteps  | 71309    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.3     |\n",
      "|    n_updates        | 5327     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 0, 1, 0, 1, 1, 1, 2, 2, 1, 1, 0, 2, 2, 3, 3, 0, 0, 3, 2, 1, 3, 2, 3, 2, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 32 and the episode is 997 and the total_steps are 71341\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 0, 0, 1, 0, 1, 3, 2, 3, 1, 1, 1, 2, 1, 2, 3, 3, 2, 0, 1, 3, 0, 3, 2, 1, 2, 0, 2, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 35 and the episode is 998 and the total_steps are 71376\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 3, 2, 0, 1, 3, 0, 0, 3, 2, 0, 0, 0, 3, 1, 1, 1, 3, 0, 1, 1, 0, 0, 3, 1, 0, 1, 0, 2, 2, 3, 0, 1, 2, 0, 0, 1, 1, 2, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 46 and the episode is 999 and the total_steps are 71422\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 2, 2, 0, 3, 3, 2, 0, 1, 0, 0, 2, 1, 1, 3, 1, 1, 0, 1, 0, 1, 1, 2, 0, 1, 0, 0, 2, 1, 2, 2, 3, 2, 3, 3, 2, 1, 3, 3, 0, 3, 0, 3, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 50 and the episode is 1000 and the total_steps are 71472\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.3     |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1667     |\n",
      "|    total_timesteps  | 71472    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.03     |\n",
      "|    n_updates        | 5367     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 1, 2, 3, 2, 3, 2, 2, 0, 2, 0, 0, 3, 0, 3, 0, 2, 0, 1, 0, 3, 1, 2, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1001 and the total_steps are 71502\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 0, 2, 1, 3, 2, 1, 0, 3, 0, 1, 2, 2, 1, 2, 2, 1, 2, 3, 0, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 27 and the episode is 1002 and the total_steps are 71529\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 2, 3, 1, 1, 0, 1, 3, 2, 2, 0, 1, 0, 2, 2, 2, 0, 3, 2, 1, 2, 2, 2, 0, 0, 3, 3, 3, 2, 1, 0, 3, 1, 2, 1, 3, 0, 1, 3, 1, 0, 0, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 49 and the episode is 1003 and the total_steps are 71578\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 0, 2, 3, 1, 0, 1, 2, 3, 2, 0, 1, 2, 3, 2, 1, 2, 2, 1, 0, 3, 0, 1, 2, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 31 and the episode is 1004 and the total_steps are 71609\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.1     |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1673     |\n",
      "|    total_timesteps  | 71609    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 5402     |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 0, 2, 2, 2, 2, 0, 0, 0, 1, 1, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 3, 1, 1, 3, 0, 1, 1, 2, 0, 2, 0, 0, 2, 3, 0, 2, 0, 0, 3, 2, 3, 1, 2, 1, 2, 1, 0, 0, 0, 2, 2, 2, 2, 1, 1, 2, 1, 3, 0, 0, 0, 2, 0, 1, 2, 1, 3, 0, 0, 0, 3, 3, 3, 1, 2, 2, 1, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -926. And steps were 100 and the episode is 1005 and the total_steps are 71709\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 2, 2, 0, 0, 1, 1, 3, 0, 1, 3, 2, 1, 0, 2, 1, 2, 1, 1, 3, 3, 2, 1, 0, 1, 0, 1, 0, 3, 1, 0, 3, 1, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 40 and the episode is 1006 and the total_steps are 71749\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 0, 3, 0, 0, 2, 0, 3, 2, 1, 3, 1, 3, 1, 3, 1, 3, 3, 0, 0, 3, 1, 2, 0, 1, 3, 3, 3, 0, 2, 0, 1, 1, 0, 1, 0, 3, 2, 0, 3, 1, 3, 2, 2, 0, 2, 3, 0, 1, 3, 1, 2, 0, 1, 0, 2, 1, 2, 0, 2, 3, 2, 1, 2, 3, 0, 1, 1, 1, 2, 3, 3, 2, 2, 1, 1, 0, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 84 and the episode is 1007 and the total_steps are 71833\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 0, 2, 0, 0, 2, 2, 3, 3, 0, 1, 3, 0, 3, 0, 1, 3, 3, 0, 1, 2, 1, 0, 2, 2, 3, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 1008 and the total_steps are 71866\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48       |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1683     |\n",
      "|    total_timesteps  | 71866    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.62     |\n",
      "|    n_updates        | 5466     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 0, 2, 2, 3, 2, 1, 2, 1, 3, 1, 2, 2, 1, 1, 1, 3, 3, 1, 1, 0, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 1009 and the total_steps are 71894\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 2, 2, 1, 2, 3, 1, 2, 2, 0, 2, 0, 3, 3, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1016. And steps were 19 and the episode is 1010 and the total_steps are 71913\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 3, 3, 2, 1, 2, 1, 1, 0, 0, 1, 3, 1, 2, 0, 3, 2, 0, 3, 2, 0, 0, 0, 0, 1, 2, 2, 3, 0, 1, 0, 3, 3, 0, 2, 3, 3, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 44 and the episode is 1011 and the total_steps are 71957\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 2, 1, 0, 2, 2, 3, 1, 0, 0, 1, 2, 1, 3, 0, 2, 2, 2, 1, 3, 0, 3, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1012 and the total_steps are 71986\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.2     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1687     |\n",
      "|    total_timesteps  | 71986    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 5496     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 0, 0, 0, 3, 1, 1, 3, 1, 1, 3, 0, 1, 1, 3, 2, 2, 3, 3, 3, 0, 3, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 29 and the episode is 1013 and the total_steps are 72015\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 3, 3, 0, 1, 1, 1, 0, 3, 1, 1, 2, 3, 3, 3, 0, 1, 0, 0, 3, 2, 0, 0, 3, 1, 2, 1, 2, 1, 2, 1, 3, 2, 3, 0, 2, 2, 2, 0, 1, 3, 2, 2, 1, 0, 1, 0, 2, 3, 2, 1, 2, 1, 2, 2, 2, 0, 0, 0, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was 1063. And steps were 64 and the episode is 1014 and the total_steps are 72079\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 1, 1, 0, 1, 2, 0, 1, 2, 0, 2, 3, 0, 3, 3, 0, 1, 3, 2, 2, 3, 1, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 3, 2, 1, 2, 3, 2, 1, 1, 1, 3, 3, 1, 0, 0, 0, 0, 3, 0, 3, 3, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 59 and the episode is 1015 and the total_steps are 72138\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 0, 3, 0, 3, 2, 2, 2, 0, 2, 1, 2, 1, 0, 3, 1, 1, 2, 0, 3, 3, 3, 3, 3, 2, 1, 3, 1, 1, 2, 0, 2, 2, 0, 0, 2, 1, 1, 3, 1, 0, 3, 1, 3, 1, 2, 3, 1, 1, 1, 0, 2, 0, 2, 0, 0, 3, 2, 3, 0, 1, 0, 2, 1, 3, 2, 0, 3, 1, 0, 2, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1052. And steps were 78 and the episode is 1016 and the total_steps are 72216\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.2     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1697     |\n",
      "|    total_timesteps  | 72216    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 93.8     |\n",
      "|    n_updates        | 5553     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 0, 1, 2, 0, 1, 1, 3, 2, 2, 2, 2, 0, 0, 3, 0, 3, 3, 1, 0, 2, 3, 1, 2, 2, 1, 1, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 34 and the episode is 1017 and the total_steps are 72250\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 2, 0, 3, 3, 2, 0, 1, 3, 0, 2, 2, 3, 0, 2, 2, 0, 1, 3, 1, 1, 0, 1, 2, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 31 and the episode is 1018 and the total_steps are 72281\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 0, 0, 0, 3, 1, 0, 2, 0, 1, 3, 1, 0, 0, 0, 0, 1, 0, 1, 1, 2, 2, 0, 1, 3, 1, 2, 0, 1, 2, 0, 2, 3, 3, 1, 2, 2, 2, 3, 0, 2, 2, 0, 3, 2, 0, 0, 0, 0, 3, 0, 2, 1, 2, 0, 2, 2, 2, 1, 3, 3, 1, 2, 1, 0, 0, 2, 1, 0, 3, 0, 2, 0, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -930. And steps were 80 and the episode is 1019 and the total_steps are 72361\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 3, 1, 1, 0, 3, 3, 0, 0, 2, 3, 1, 1, 0, 1, 1, 3, 1, 1, 2, 2, 3, 1, 0, 0, 3, 1, 2, 2, 2, 0, 2, 0, 1, 2, 0, 1, 3, 2, 0, 3, 0, 2, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 50 and the episode is 1020 and the total_steps are 72411\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.3     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1704     |\n",
      "|    total_timesteps  | 72411    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.21     |\n",
      "|    n_updates        | 5602     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 0, 2, 1, 3, 3, 0, 3, 2, 3, 3, 2, 1, 0, 2, 3, 2, 1, 3, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 1021 and the total_steps are 72437\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 3, 0, 1, 2, 0, 2, 0, 3, 3, 2, 2, 3, 1, 2, 0, 0, 2, 0, 1, 3, 3, 0, 2, 0, 0, 2, 1, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 2, 0, 3, 3, 0, 1, 2, 3, 0, 1, 3, 2, 2, 0, 3, 1, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -935. And steps were 69 and the episode is 1022 and the total_steps are 72506\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 1, 0, 0, 1, 0, 2, 3, 2, 1, 3, 0, 2, 2, 0, 1, 2, 2, 1, 1, 2, 1, 1, 1, 3, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 32 and the episode is 1023 and the total_steps are 72538\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 0, 3, 1, 0, 2, 0, 0, 1, 0, 3, 0, 2, 2, 3, 0, 0, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 1024 and the total_steps are 72562\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.9     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1710     |\n",
      "|    total_timesteps  | 72562    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 156      |\n",
      "|    n_updates        | 5640     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 2, 1, 3, 0, 3, 1, 0, 2, 0, 2, 0, 1, 1, 0, 3, 2, 1, 0, 3, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 2, 0, 3, 0, 2, 3, 2, 2, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 3, 3, 1, 0, 0, 1, 1, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1043. And steps were 63 and the episode is 1025 and the total_steps are 72625\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 1026 and the total_steps are 72645\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 3, 3, 1, 0, 3, 2, 1, 0, 3, 2, 2, 0, 1, 2, 2, 3, 3, 0, 3, 3, 0, 3, 0, 2, 2, 0, 3, 1, 1, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 37 and the episode is 1027 and the total_steps are 72682\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 0, 2, 2, 0, 3, 3, 1, 1, 0, 0, 0, 1, 2, 1, 0, 0, 1, 2, 2, 1, 3, 0, 3, 2, 3, 1, 2, 0, 3, 1, 2, 2, 3, 0, 1, 1, 3, 0, 2, 1, 1, 1, 0, 1, 0, 3, 3, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 55 and the episode is 1028 and the total_steps are 72737\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.3     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1718     |\n",
      "|    total_timesteps  | 72737    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.325    |\n",
      "|    n_updates        | 5684     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 2, 3, 1, 1, 0, 2, 3, 0, 3, 1, 0, 0, 0, 1, 1, 2, 0, 3, 0, 3, 0, 1, 3, 3, 3, 2, 3, 0, 0, 3, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 45 and the episode is 1029 and the total_steps are 72782\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 0, 1, 0, 3, 2, 1, 1, 1, 3, 2, 1, 3, 1, 3, 0, 3, 2, 0, 2, 0, 1, 1, 2, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 31 and the episode is 1030 and the total_steps are 72813\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 3, 2, 2, 2, 1, 2, 1, 2, 3, 0, 0, 2, 3, 3, 0, 2, 1, 3, 0, 3, 2, 2, 1, 3, 2, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 33 and the episode is 1031 and the total_steps are 72846\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 3, 1, 1, 0, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 0, 3, 1, 0, 1, 0, 0, 0, 2, 3, 3, 3, 3, 1, 1, 2, 1, 3, 2, 2, 2, 2, 1, 0, 0, 0, 3, 3, 3, 1, 0, 1, 2, 0, 2, 1, 3, 2, 1, 2, 3, 3, 3, 3, 2, 3, 0, 2, 0, 2, 3, 0, 2, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -931. And steps were 75 and the episode is 1032 and the total_steps are 72921\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.6     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1725     |\n",
      "|    total_timesteps  | 72921    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 5730     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 3, 0, 2, 1, 1, 0, 3, 2, 1, 3, 1, 2, 1, 0, 0, 1, 3, 2, 2, 2, 2, 0, 1, 2, 3, 2, 2, 2, 1, 3, 1, 2, 3, 1, 0, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 43 and the episode is 1033 and the total_steps are 72964\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 0, 2, 2, 2, 0, 3, 0, 1, 0, 2, 1, 3, 1, 0, 3, 1, 1, 1, 2, 0, 1, 1, 2, 3, 1, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 1034 and the total_steps are 72997\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 3, 3, 2, 3, 2, 3, 1, 2, 2, 2, 0, 0, 0, 2, 1, 2, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 1035 and the total_steps are 73029\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 1, 3, 2, 2, 3, 0, 0, 3, 0, 0, 0, 2, 0, 0, 3, 1, 2, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 25 and the episode is 1036 and the total_steps are 73054\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47       |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1730     |\n",
      "|    total_timesteps  | 73054    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.225    |\n",
      "|    n_updates        | 5763     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 3, 1, 3, 1, 0, 2, 2, 3, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 16 and the episode is 1037 and the total_steps are 73070\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 2, 3, 2, 2, 0, 1, 1, 0, 0, 1, 3, 3, 2, 0, 1, 1, 2, 1, 1, 3, 0, 2, 3, 2, 0, 1, 0, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 1038 and the total_steps are 73105\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 1, 2, 2, 3, 3, 3, 0, 3, 2, 0, 1, 3, 1, 2, 3, 2, 0, 2, 0, 2, 3, 3, 2, 2, 1, 3, 1, 1, 2, 1, 3, 2, 1, 1, 1, 0, 0, 1, 0, 1, 3, 0, 3, 3, 1, 3, 1, 1, 3, 0, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 58 and the episode is 1039 and the total_steps are 73163\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 2, 3, 3, 0, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 0, 2, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 1040 and the total_steps are 73187\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47       |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1735     |\n",
      "|    total_timesteps  | 73187    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.1     |\n",
      "|    n_updates        | 5796     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 0, 1, 0, 3, 0, 2, 0, 0, 0, 3, 2, 2, 1, 3, 2, 2, 2, 3, 0, 0, 2, 1, 0, 0, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was 1029. And steps were 30 and the episode is 1041 and the total_steps are 73217\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 3, 3, 0, 3, 1, 2, 0, 3, 1, 2, 2, 0, 3, 2, 1, 0, 3, 0, 3, 1, 3, 0, 0, 0, 1, 1, 3, 0, 2, 1, 0, 1, 3, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 1, 2, 1, 2, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 60 and the episode is 1042 and the total_steps are 73277\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 2, 3, 2, 2, 2, 2, 0, 1, 0, 0, 3, 0, 3, 2, 1, 1, 3, 2, 2, 0, 1, 3, 2, 1, 2, 1, 0, 3, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 1043 and the total_steps are 73313\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 1, 1, 0, 1, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 1, 0, 1, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 24 and the episode is 1044 and the total_steps are 73337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.1     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1741     |\n",
      "|    total_timesteps  | 73337    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.967    |\n",
      "|    n_updates        | 5834     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 0, 3, 3, 3, 2, 3, 0, 2, 3, 0, 1, 3, 1, 0, 2, 0, 1, 1, 3, 0, 0, 1, 2, 0, 1, 3, 2, 1, 3, 1, 2, 1, 3, 1, 3, 0, 0, 2, 2, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 47 and the episode is 1045 and the total_steps are 73384\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 1, 2, 0, 3, 0, 2, 0, 0, 0, 2, 3, 3, 0, 2, 0, 3, 2, 2, 0, 0, 0, 3, 2, 3, 2, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 1046 and the total_steps are 73416\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 0, 0, 1, 0, 3, 3, 0, 3, 1, 3, 0, 3, 1, 2, 3, 3, 1, 3, 0, 3, 1, 1, 1, 1, 0, 0, 0, 1, 2, 1, 2, 0, 0, 2, 1, 2, 2, 3, 3, 0, 0, 0, 0, 1, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 1047 and the total_steps are 73468\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 2, 0, 1, 2, 1, 2, 2, 2, 1, 0, 0, 0, 0, 0, 1, 3, 2, 0, 0, 2, 0, 2, 1, 3, 1, 2, 3, 3, 0, 3, 1, 0, 3, 2, 1, 2, 3, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 45 and the episode is 1048 and the total_steps are 73513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.7     |\n",
      "|    ep_rew_mean      | -859     |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 1748     |\n",
      "|    total_timesteps  | 73513    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.9     |\n",
      "|    n_updates        | 5878     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 1, 1, 0, 0, 1, 3, 3, 1, 2, 3, 2, 1, 1, 0, 3, 0, 0, 2, 3, 2, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 1049 and the total_steps are 73541\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 1, 1, 1, 2, 2, 1, 3, 1, 1, 2, 2, 2, 1, 0, 1, 3, 0, 1, 3, 1, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 1050 and the total_steps are 73567\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 0, 0, 1, 0, 1, 0, 3, 1, 3, 2, 0, 2, 3, 1, 2, 0, 2, 1, 2, 2, 1, 0, 1, 2, 2, 0, 0, 1, 0, 3, 0, 3, 0, 2, 2, 1, 3, 0, 0, 2, 0, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1048. And steps were 50 and the episode is 1051 and the total_steps are 73617\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 1, 0, 0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 2, 3, 0, 1, 0, 3, 3, 2, 1, 0, 0, 0, 0, 1, 2, 1, 0, 3, 2, 0, 3, 0, 2, 2, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 44 and the episode is 1052 and the total_steps are 73661\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.2     |\n",
      "|    ep_rew_mean      | -841     |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1754     |\n",
      "|    total_timesteps  | 73661    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 5915     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 3, 2, 1, 1, 3, 2, 3, 3, 2, 1, 0, 3, 2, 3, 2, 0, 1, 3, 0, 0, 1, 1, 0, 3, 3, 1, 0, 0, 1, 3, 0, 3, 3, 3, 3, 1, 3, 3, 1, 0, 1, 1, 0, 3, 2, 3, 3, 0, 0, 3, 0, 3, 1, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 61 and the episode is 1053 and the total_steps are 73722\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 1, 0, 0, 2, 1, 2, 2, 0, 2, 0, 2, 0, 1, 3, 1, 1, 0, 1, 3, 0, 2, 2, 2, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 31 and the episode is 1054 and the total_steps are 73753\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 1, 0, 0, 0, 0, 0, 2, 3, 2, 1, 0, 0, 2, 0, 3, 3, 2, 0, 2, 2, 1, 0, 3, 3, 1, 2, 0, 1, 2, 0, 3, 3, 2, 0, 3, 3, 1, 1, 2, 1, 3, 0, 3, 0, 1, 2, 2, 0, 0, 3, 2, 3, 3, 2, 3, 3, 3, 2, 0, 2, 0, 1, 3, 3, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -938. And steps were 72 and the episode is 1055 and the total_steps are 73825\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 0, 2, 3, 2, 1, 3, 2, 2, 0, 0, 2, 3, 2, 3, 2, 0, 1, 0, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was 979. And steps were 24 and the episode is 1056 and the total_steps are 73849\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.7     |\n",
      "|    ep_rew_mean      | -820     |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1762     |\n",
      "|    total_timesteps  | 73849    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 30.7     |\n",
      "|    n_updates        | 5962     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 1, 1, 2, 3, 0, 3, 3, 0, 1, 1, 0, 2, 1, 2, 1, 2, 1, 0, 3, 1, 3, 0, 3, 3, 1, 3, 1, 3, 3, 0, 3, 2, 2, 3, 1, 3, 2, 3, 2, 3, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 48 and the episode is 1057 and the total_steps are 73897\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 3, 1, 0, 1, 0, 2, 0, 3, 1, 2, 0, 1, 2, 2, 2, 1, 2, 0, 0, 2, 3, 1, 3, 2, 1, 3, 0, 1, 3, 1, 0, 1, 2, 0, 0, 3, 3, 0, 1, 3, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 48 and the episode is 1058 and the total_steps are 73945\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 0, 2, 3, 3, 1, 2, 0, 1, 0, 1, 2, 1, 2, 1, 2, 2, 2, 0, 2, 3, 0, 2, 0, 0, 0, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 1059 and the total_steps are 73978\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 1, 0, 0, 2, 3, 3, 1, 0, 1, 0, 0, 3, 2, 0, 2, 0, 1, 3, 0, 1, 1, 1, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1060 and the total_steps are 74008\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.2     |\n",
      "|    ep_rew_mean      | -820     |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1768     |\n",
      "|    total_timesteps  | 74008    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.5     |\n",
      "|    n_updates        | 6001     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 3, 0, 1, 0, 1, 2, 2, 2, 3, 0, 2, 3, 1, 1, 0, 2, 3, 3, 3, 2, 3, 1, 3, 0, 0, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 1061 and the total_steps are 74041\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 3, 0, 2, 0, 3, 0, 2, 2, 2, 3, 1, 1, 2, 1, 0, 3, 2, 1, 3, 3, 0, 3, 2, 0, 1, 0, 1, 1, 3, 0, 0, 0, 1, 3, 1, 2, 1, 1, 0, 2, 3, 1, 3, 2, 1, 2, 1, 1, 3, 3, 1, 3, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 60 and the episode is 1062 and the total_steps are 74101\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 1, 2, 3, 0, 2, 3, 2, 2, 3, 2, 3, 3, 1, 2, 2, 0, 3, 1, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 26 and the episode is 1063 and the total_steps are 74127\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 0, 0, 2, 2, 3, 1, 1, 0, 3, 3, 2, 2, 3, 3, 3, 0, 1, 1, 3, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 1064 and the total_steps are 74152\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.2     |\n",
      "|    ep_rew_mean      | -820     |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1774     |\n",
      "|    total_timesteps  | 74152    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 6037     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 1, 2, 1, 3, 0, 2, 3, 1, 1, 1, 1, 3, 3, 0, 1, 2, 1, 0, 1, 3, 3, 0, 3, 3, 2, 2, 2, 0, 2, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 37 and the episode is 1065 and the total_steps are 74189\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 2, 1, 0, 3, 1, 1, 3, 2, 3, 2, 0, 2, 2, 2, 2, 2, 2, 0, 1, 0, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 28 and the episode is 1066 and the total_steps are 74217\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 3, 1, 2, 0, 3, 2, 0, 2, 0, 3, 0, 1, 1, 3, 0, 3, 3, 3, 1, 3, 1, 1, 3, 0, 3, 1, 2, 1, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 1067 and the total_steps are 74253\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 3, 3, 1, 3, 1, 3, 2, 1, 1, 2, 2, 1, 3, 3, 0, 2, 3, 1, 1, 3, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 28 and the episode is 1068 and the total_steps are 74281\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.3     |\n",
      "|    ep_rew_mean      | -840     |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1779     |\n",
      "|    total_timesteps  | 74281    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 6070     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 3, 3, 0, 3, 0, 3, 2, 2, 0, 0, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 18 and the episode is 1069 and the total_steps are 74299\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 1, 2, 0, 0, 3, 0, 3, 2, 0, 3, 3, 2, 2, 0, 1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 0, 0, 2, 0, 1, 3, 0, 1, 0, 1, 1, 1, 0, 0, 2, 3, 1, 1, 3, 1, 0, 1, 3, 2, 2, 0, 1, 0, 3, 0, 2, 0, 3, 0, 2, 3, 2, 3, 2, 3, 0, 0, 2, 3, 2, 1, 1, 0, 2, 2, 0, 3, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1065. And steps were 85 and the episode is 1070 and the total_steps are 74384\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 3, 0, 2, 0, 3, 1, 2, 2, 0, 2, 1, 0, 1, 2, 2, 0, 3, 0, 2, 2, 2, 3, 1, 2, 0, 2, 1, 0, 0, 3, 2, 0, 3, 1, 2, 1, 2, 3, 2, 3, 0, 2, 2, 0, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 52 and the episode is 1071 and the total_steps are 74436\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 3, 1, 3, 0, 2, 1, 1, 2, 0, 3, 2, 1, 1, 1, 2, 1, 3, 0, 2, 3, 0, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1072 and the total_steps are 74465\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.4     |\n",
      "|    ep_rew_mean      | -841     |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1787     |\n",
      "|    total_timesteps  | 74465    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.97     |\n",
      "|    n_updates        | 6116     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 2, 0, 2, 1, 0, 3, 3, 3, 0, 0, 0, 3, 0, 0, 1, 1, 3, 0, 2, 3, 1, 1, 2, 3, 1, 3, 2, 1, 3, 3, 1, 2, 1, 0, 3, 2, 2, 3, 0, 1, 0, 2, 1, 3, 3, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 53 and the episode is 1073 and the total_steps are 74518\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 3, 1, 1, 2, 1, 0, 1, 3, 2, 1, 2, 1, 2, 1, 3, 2, 1, 0, 3, 2, 0, 2, 1, 2, 1, 3, 1, 3, 1, 1, 0, 1, 3, 2, 0, 0, 3, 2, 2, 0, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 48 and the episode is 1074 and the total_steps are 74566\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 0, 2, 1, 3, 0, 3, 1, 2, 1, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 988. And steps were 15 and the episode is 1075 and the total_steps are 74581\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 2, 1, 0, 0, 1, 3, 0, 2, 1, 3, 0, 2, 3, 0, 1, 1, 3, 3, 3, 1, 2, 0, 0, 2, 2, 2, 3, 2, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 1076 and the total_steps are 74617\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.1     |\n",
      "|    ep_rew_mean      | -821     |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1793     |\n",
      "|    total_timesteps  | 74617    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 6154     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 1, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 3, 2, 1, 3, 1, 1, 0, 2, 1, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1077 and the total_steps are 74646\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 0, 3, 1, 0, 0, 1, 2, 3, 1, 0, 0, 1, 3, 3, 3, 0, 3, 1, 2, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 1078 and the total_steps are 74673\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 2, 3, 3, 2, 1, 1, 1, 2, 0, 1, 3, 1, 3, 0, 2, 0, 3, 0, 0, 0, 1, 0, 1, 3, 3, 0, 1, 0, 0, 0, 2, 1, 3, 3, 0, 1, 3, 2, 2, 2, 0, 1, 0, 2, 2, 1, 3, 2, 0, 2, 0, 0, 3, 0, 2, 0, 3, 1, 0, 0, 0, 3, 2, 3, 0, 3, 3, 3, 2, 0, 1, 1, 2, 0, 2, 2, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 84 and the episode is 1079 and the total_steps are 74757\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 0, 3, 3, 2, 1, 2, 0, 0, 1, 0, 0, 3, 2, 3, 2, 2, 2, 0, 0, 0, 3, 1, 1, 3, 1, 1, 1, 2, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 35 and the episode is 1080 and the total_steps are 74792\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -821     |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1799     |\n",
      "|    total_timesteps  | 74792    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.22     |\n",
      "|    n_updates        | 6197     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 2, 1, 1, 2, 3, 3, 0, 2, 0, 0, 3, 0, 1, 3, 1, 3, 1, 1, 2, 2, 1, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 29 and the episode is 1081 and the total_steps are 74821\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 0, 1, 3, 2, 2, 0, 1, 2, 2, 0, 3, 3, 3, 3, 1, 2, 2, 2, 0, 2, 3, 3, 0, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 32 and the episode is 1082 and the total_steps are 74853\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 0, 2, 1, 2, 0, 1, 2, 1, 3, 1, 0, 2, 2, 2, 2, 3, 2, 2, 3, 1, 3, 1, 0, 0, 2, 0, 0, 3, 1, 3, 0, 3, 2, 1, 0, 3, 1, 1, 2, 1, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 48 and the episode is 1083 and the total_steps are 74901\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 2, 3, 1, 1, 3, 0, 1, 2, 3, 0, 0, 0, 1, 1, 3, 0, 3, 1, 3, 2, 2, 3, 0, 1, 0, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 33 and the episode is 1084 and the total_steps are 74934\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -821     |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1084     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1805     |\n",
      "|    total_timesteps  | 74934    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.1     |\n",
      "|    n_updates        | 6233     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 2, 0, 2, 0, 2, 1, 3, 1, 1, 2, 2, 1, 0, 0, 0, 0, 3, 2, 1, 0, 3, 3, 3, 2, 0, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 33 and the episode is 1085 and the total_steps are 74967\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 1, 1, 3, 0, 0, 1, 0, 0, 1, 3, 3, 1, 0, 2, 3, 1, 2, 3, 0, 1, 3, 2, 3, 1, 0, 2, 3, 2, 2, 2, 3, 1, 1, 1, 3, 3, 1, 2, 1, 2, 2, 2, 3, 3, 2, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 59 and the episode is 1086 and the total_steps are 75026\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 0, 1, 0, 3, 3, 3, 3, 2, 1, 0, 1, 1, 3, 2, 2, 3, 1, 2, 0, 0, 1, 3, 2, 2, 3, 3, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 1, 3, 0, 3, 3, 1, 1, 3, 2, 3, 2, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1053. And steps were 55 and the episode is 1087 and the total_steps are 75081\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 2, 1, 0, 2, 1, 0, 3, 3, 0, 3, 3, 0, 3, 3, 2, 2, 0, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 0, 1, 2, 1, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 40 and the episode is 1088 and the total_steps are 75121\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -839     |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1088     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1813     |\n",
      "|    total_timesteps  | 75121    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 6280     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 3, 2, 1, 2, 0, 2, 0, 2, 2, 3, 1, 1, 2, 3, 3, 3, 3, 0, 0, 3, 0, 2, 3, 0, 1, 2, 1, 1, 0, 3, 0, 3, 0, 1, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 42 and the episode is 1089 and the total_steps are 75163\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 1, 1, 1, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 0, 1, 1, 1, 1, 3, 0, 1, 3, 1, 2, 1, 0, 2, 2, 3, 1, 2, 1, 2, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 41 and the episode is 1090 and the total_steps are 75204\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 1, 1, 0, 1, 1, 2, 3, 0, 0, 0, 0, 2, 2, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 3, 2, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 33 and the episode is 1091 and the total_steps are 75237\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 1, 3, 2, 1, 2, 1, 1, 2, 2, 0, 3, 3, 3, 0, 3, 0, 2, 1, 1, 1, 0, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1092 and the total_steps are 75266\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -839     |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1092     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1818     |\n",
      "|    total_timesteps  | 75266    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.88     |\n",
      "|    n_updates        | 6316     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 3, 3, 0, 0, 1, 1, 3, 2, 3, 1, 1, 2, 1, 2, 1, 2, 2, 0, 1, 3, 2, 0, 3, 0, 0, 0, 1, 2, 3, 2, 0, 2, 0, 1, 2, 2, 1, 3, 3, 3, 1, 0, 3, 3, 2, 3, 0, 0, 0, 3, 1, 1, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 60 and the episode is 1093 and the total_steps are 75326\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 2, 2, 0, 0, 1, 2, 1, 2, 3, 0, 0, 0, 2, 2, 0, 3, 0, 0, 1, 0, 1, 2, 1, 1, 1, 1, 3, 0, 0, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 37 and the episode is 1094 and the total_steps are 75363\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 2, 3, 3, 0, 2, 2, 3, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 1, 0, 2, 1, 0, 0, 3, 1, 2, 0, 2, 3, 1, 0, 2, 0, 3, 0, 2, 0, 3, 0, 1, 2, 2, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 50 and the episode is 1095 and the total_steps are 75413\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 0, 1, 0, 0, 3, 3, 0, 0, 3, 2, 1, 2, 0, 2, 0, 1, 2, 0, 3, 1, 3, 3, 2, 2, 0, 0, 3, 1, 1, 0, 2, 2, 2, 3, 1, 3, 3, 0, 3, 1, 2, 0, 0, 3, 0, 0, 1, 1, 1, 3, 3, 1, 2, 2, 3, 3, 3, 3, 2, 0, 1, 2, 2, 2, 3, 0, 1, 0, 0, 2, 0, 2, 2, 2, 1, 2, 2, 0, 2, 0, 1, 3, 1, 0, 3, 1, 2, 0, 3, 3, 2, 3, 2, 3, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -928. And steps were 102 and the episode is 1096 and the total_steps are 75515\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -838     |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1096     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1828     |\n",
      "|    total_timesteps  | 75515    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63       |\n",
      "|    n_updates        | 6378     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 3, 0, 2, 3, 1, 0, 2, 3, 2, 0, 3, 1, 3, 2, 0, 0, 0, 2, 3, 2, 3, 2, 1, 3, 0, 0, 2, 2, 2, 1, 3, 0, 2, 2, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 42 and the episode is 1097 and the total_steps are 75557\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 0, 0, 2, 2, 0, 3, 3, 3, 3, 2, 2, 1, 1, 2, 3, 0, 1, 0, 2, 1, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 1098 and the total_steps are 75585\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 1, 3, 2, 0, 1, 2, 3, 0, 0, 3, 2, 1, 0, 2, 3, 2, 0, 0, 0, 0, 2, 0, 3, 0, 1, 0, 0, 0, 3, 3, 2, 0, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 40 and the episode is 1099 and the total_steps are 75625\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 3, 2, 1, 3, 1, 3, 2, 1, 2, 3, 1, 2, 1, 2, 1, 1, 2, 2, 3, 2, 1, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 29 and the episode is 1100 and the total_steps are 75654\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -838     |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1834     |\n",
      "|    total_timesteps  | 75654    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.438    |\n",
      "|    n_updates        | 6413     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 0, 1, 2, 0, 3, 2, 2, 0, 1, 0, 3, 3, 3, 3, 2, 1, 3, 2, 2, 1, 2, 1, 2, 2, 0, 2, 1, 0, 3, 1, 1, 0, 2, 0, 1, 3, 0, 0, 3, 2, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 48 and the episode is 1101 and the total_steps are 75702\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 2, 3, 2, 2, 3, 1, 1, 3, 1, 0, 2, 0, 1, 2, 3, 0, 1, 2, 2, 0, 2, 1, 1, 2, 1, 3, 0, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 35 and the episode is 1102 and the total_steps are 75737\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 0, 1, 0, 1, 2, 1, 3, 0, 3, 2, 2, 2, 2, 3, 2, 1, 3, 2, 0, 1, 0, 2, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 30 and the episode is 1103 and the total_steps are 75767\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 1, 0, 3, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 2, 3, 3, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 1104 and the total_steps are 75793\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -838     |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1104     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1839     |\n",
      "|    total_timesteps  | 75793    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 6448     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 2, 2, 3, 3, 0, 0, 0, 1, 1, 2, 0, 2, 2, 0, 0, 1, 0, 2, 3, 3, 2, 3, 2, 1, 1, 0, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 1105 and the total_steps are 75827\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 1, 0, 2, 1, 0, 0, 1, 0, 2, 3, 0, 3, 0, 3, 2, 3, 1, 3, 2, 1, 2, 3, 2, 3, 0, 3, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 1106 and the total_steps are 75861\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 1, 2, 1, 3, 3, 3, 3, 2, 2, 1, 3, 1, 2, 1, 2, 0, 2, 2, 2, 1, 2, 0, 2, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 30 and the episode is 1107 and the total_steps are 75891\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 0, 3, 3, 0, 3, 1, 0, 0, 2, 2, 0, 3, 2, 1, 3, 1, 0, 0, 1, 2, 2, 2, 0, 1, 3, 1, 0, 3, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 1108 and the total_steps are 75927\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -839     |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1108     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1845     |\n",
      "|    total_timesteps  | 75927    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.562    |\n",
      "|    n_updates        | 6481     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 0, 3, 2, 2, 1, 2, 1, 3, 2, 0, 0, 2, 3, 3, 3, 1, 0, 3, 2, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 27 and the episode is 1109 and the total_steps are 75954\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 3, 3, 0, 0, 2, 0, 3, 1, 0, 3, 0, 1, 0, 0, 1, 0, 0, 2, 3, 1, 0, 2, 0, 1, 0, 1, 2, 3, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 1110 and the total_steps are 75990\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 0, 0, 0, 2, 3, 1, 2, 2, 1, 1, 2, 0, 2, 0, 1, 0, 0, 0, 2, 3, 2, 3, 3, 3, 0, 0, 0, 0, 1, 2, 1, 2, 2, 1, 2, 3, 0, 2, 3, 0, 3, 1, 2, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1049. And steps were 51 and the episode is 1111 and the total_steps are 76041\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 3, 3, 2, 1, 1, 1, 0, 1, 3, 0, 0, 1, 1, 1, 1, 1, 2, 3, 1, 0, 0, 2, 3, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 31 and the episode is 1112 and the total_steps are 76072\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -859     |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1112     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1850     |\n",
      "|    total_timesteps  | 76072    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.5     |\n",
      "|    n_updates        | 6517     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 3, 1, 3, 0, 3, 2, 3, 3, 2, 0, 3, 3, 2, 3, 3, 1, 1, 3, 2, 0, 0, 2, 0, 2, 1, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 33 and the episode is 1113 and the total_steps are 76105\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 1, 2, 1, 1, 0, 1, 3, 0, 2, 3, 3, 0, 2, 2, 0, 2, 0, 0, 3, 0, 2, 2, 3, 3, 3, 0, 1, 3, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 36 and the episode is 1114 and the total_steps are 76141\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 2, 3, 3, 0, 1, 2, 0, 0, 3, 3, 0, 1, 2, 3, 0, 2, 2, 2, 3, 1, 0, 3, 3, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 30 and the episode is 1115 and the total_steps are 76171\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 0, 2, 3, 1, 1, 3, 1, 2, 2, 0, 3, 3, 0, 3, 1, 1, 3, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 1116 and the total_steps are 76196\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1116     |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 1856     |\n",
      "|    total_timesteps  | 76196    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.5      |\n",
      "|    n_updates        | 6548     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 0, 2, 2, 0, 1, 1, 3, 0, 0, 3, 0, 1, 2, 2, 3, 2, 1, 3, 3, 1, 1, 0, 0, 0, 3, 2, 2, 0, 3, 2, 2, 3, 1, 2, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 42 and the episode is 1117 and the total_steps are 76238\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 2, 2, 1, 1, 1, 2, 1, 3, 1, 3, 1, 2, 3, 0, 3, 2, 1, 1, 0, 2, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 28 and the episode is 1118 and the total_steps are 76266\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 0, 1, 2, 2, 3, 1, 3, 0, 1, 3, 3, 0, 3, 1, 0, 2, 2, 2, 0, 3, 1, 0, 0, 3, 3, 3, 3, 0, 3, 1, 0, 1, 3, 1, 0, 2, 3, 1, 0, 0, 2, 0, 1, 2, 0, 0, 2, 3, 0, 1, 3, 1, 3, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 61 and the episode is 1119 and the total_steps are 76327\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 1, 3, 2, 3, 0, 0, 0, 1, 1, 3, 2, 2, 3, 0, 1, 3, 0, 0, 1, 3, 1, 0, 0, 3, 2, 1, 0, 1, 1, 3, 3, 3, 1, 0, 2, 1, 2, 2, 1, 3, 3, 3, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 50 and the episode is 1120 and the total_steps are 76377\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1863     |\n",
      "|    total_timesteps  | 76377    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 93.9     |\n",
      "|    n_updates        | 6594     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 0, 3, 2, 0, 0, 3, 0, 3, 2, 2, 0, 2, 2, 0, 1, 3, 1, 0, 0, 0, 0, 2, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 975. And steps were 28 and the episode is 1121 and the total_steps are 76405\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 1, 0, 1, 2, 1, 2, 0, 2, 3, 3, 0, 1, 2, 0, 0, 0, 0, 0, 1, 3, 0, 0, 2, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 31 and the episode is 1122 and the total_steps are 76436\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 0, 1, 2, 3, 3, 0, 2, 0, 3, 1, 2, 0, 0, 0, 3, 0, 3, 0, 0, 3, 2, 1, 1, 1, 1, 0, 1, 3, 1, 2, 0, 0, 1, 0, 0, 3, 3, 3, 0, 1, 2, 3, 3, 3, 1, 1, 3, 1, 2, 2, 2, 2, 0, 0, 2, 0, 2, 3, 0, 3, 2, 0, 1, 2, 1, 3, 3, 0, 0, 2, 2, 1, 1, 2, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1062. And steps were 82 and the episode is 1123 and the total_steps are 76518\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 3, 1, 0, 0, 1, 3, 2, 1, 3, 2, 3, 3, 3, 1, 0, 3, 0, 1, 0, 0, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 1124 and the total_steps are 76546\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -862     |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1124     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1870     |\n",
      "|    total_timesteps  | 76546    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.978    |\n",
      "|    n_updates        | 6636     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 2, 0, 0, 1, 3, 1, 3, 2, 3, 0, 3, 0, 2, 3, 0, 2, 2, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 32 and the episode is 1125 and the total_steps are 76578\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 2, 1, 0, 0, 0, 0, 3, 3, 2, 3, 0, 3, 2, 0, 2, 2, 3, 1, 1, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 27 and the episode is 1126 and the total_steps are 76605\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 2, 0, 3, 1, 2, 1, 1, 0, 0, 1, 3, 3, 3, 2, 3, 0, 2, 3, 1, 1, 3, 3, 2, 2, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1127 and the total_steps are 76637\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 0, 1, 3, 1, 3, 3, 2, 3, 1, 0, 0, 3, 0, 3, 0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 0, 2, 2, 2, 2, 2, 3, 3, 0, 0, 1, 2, 1, 2, 2, 0, 0, 0, 3, 2, 2, 0, 1, 2, 3, 1, 1, 2, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 60 and the episode is 1128 and the total_steps are 76697\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -861     |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1128     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1876     |\n",
      "|    total_timesteps  | 76697    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.238    |\n",
      "|    n_updates        | 6674     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 3, 0, 1, 2, 1, 0, 0, 3, 1, 0, 1, 3, 1, 1, 3, 0, 3, 3, 3, 0, 0, 1, 2, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 1129 and the total_steps are 76729\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 1, 3, 2, 3, 0, 1, 0, 3, 3, 2, 1, 0, 1, 3, 3, 0, 1, 0, 2, 1, 2, 3, 1, 2, 2, 2, 1, 0, 2, 3, 0, 0, 2, 2, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 1130 and the total_steps are 76771\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 1, 3, 3, 3, 0, 1, 1, 3, 1, 1, 0, 1, 2, 0, 2, 0, 0, 0, 2, 0, 2, 3, 0, 3, 3, 2, 3, 1, 2, 1, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 38 and the episode is 1131 and the total_steps are 76809\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 2, 3, 2, 3, 3, 2, 3, 0, 0, 3, 2, 0, 2, 0, 1, 0, 3, 1, 3, 3, 3, 2, 0, 0, 2, 0, 0, 2, 1, 2, 3, 0, 1, 1, 0, 0, 0, 2, 2, 0, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 48 and the episode is 1132 and the total_steps are 76857\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -862     |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1132     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1882     |\n",
      "|    total_timesteps  | 76857    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.315    |\n",
      "|    n_updates        | 6714     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 1, 1, 0, 1, 3, 3, 0, 1, 0, 0, 1, 0, 0, 3, 2, 0, 2, 0, 0, 0, 2, 2, 1, 1, 1, 0, 1, 3, 3, 1, 3, 2, 2, 1, 3, 0, 0, 1, 1, 1, 2, 1, 2, 2, 3, 2, 2, 0, 0, 3, 0, 3, 0, 1, 2, 3, 1, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 65 and the episode is 1133 and the total_steps are 76922\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 3, 3, 3, 0, 3, 1, 2, 0, 0, 0, 3, 2, 3, 1, 0, 2, 1, 0, 2, 3, 1, 3, 1, 1, 3, 2, 3, 2, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 36 and the episode is 1134 and the total_steps are 76958\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 3, 3, 0, 0, 0, 2, 1, 0, 0, 2, 0, 3, 0, 3, 3, 0, 1, 3, 2, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 27 and the episode is 1135 and the total_steps are 76985\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 3, 1, 3, 3, 0, 2, 2, 3, 0, 3, 2, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 19 and the episode is 1136 and the total_steps are 77004\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -862     |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1136     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1888     |\n",
      "|    total_timesteps  | 77004    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 6750     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 2, 1, 0, 1, 3, 1, 1, 2, 3, 2, 3, 0, 3, 0, 3, 1, 1, 2, 0, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 1137 and the total_steps are 77031\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 1, 2, 2, 1, 3, 1, 0, 3, 0, 3, 2, 3, 2, 0, 3, 1, 0, 3, 0, 3, 3, 1, 2, 3, 2, 2, 0, 2, 1, 2, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 1138 and the total_steps are 77069\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 0, 3, 3, 0, 0, 2, 0, 2, 2, 2, 0, 1, 3, 3, 3, 0, 2, 3, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was 979. And steps were 24 and the episode is 1139 and the total_steps are 77093\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 2, 2, 3, 3, 3, 3, 1, 3, 1, 1, 0, 3, 1, 0, 1, 2, 3, 0, 0, 3, 2, 1, 1, 2, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 32 and the episode is 1140 and the total_steps are 77125\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -842     |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1893     |\n",
      "|    total_timesteps  | 77125    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.36     |\n",
      "|    n_updates        | 6781     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 2, 2, 2, 1, 3, 3, 3, 1, 2, 2, 2, 3, 0, 1, 3, 2, 0, 2, 3, 3, 1, 2, 3, 0, 3, 0, 3, 2, 3, 3, 2, 3, 2, 0, 3, 1, 1, 1, 0, 0, 0, 3, 0, 3, 2, 1, 2, 2, 0, 0, 0, 0, 3, 0, 1, 0, 1, 0, 2, 0, 0, 3, 2, 0, 2, 3, 1, 2, 3, 3, 0, 0, 1, 3, 0, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 83 and the episode is 1141 and the total_steps are 77208\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 2, 0, 2, 1, 1, 3, 3, 3, 1, 0, 1, 0, 1, 3, 3, 2, 0, 1, 3, 1, 3, 1, 3, 0, 2, 3, 1, 0, 0, 0, 2, 0, 0, 1, 1, 2, 2, 3, 0, 0, 1, 3, 3, 3, 3, 1, 1, 3, 0, 3, 2, 2, 3, 1, 2, 2, 2, 1, 2, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 67 and the episode is 1142 and the total_steps are 77275\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 1, 2, 1, 2, 3, 2, 1, 3, 2, 1, 0, 3, 3, 0, 2, 3, 3, 1, 3, 0, 3, 2, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 30 and the episode is 1143 and the total_steps are 77305\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 3, 0, 3, 0, 0, 2, 3, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 3, 2, 2, 1, 2, 3, 0, 2, 3, 2, 0, 3, 0, 1, 1, 1, 2, 0, 1, 3, 2, 2, 0, 0, 2, 3, 1, 0, 3, 2, 1, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 60 and the episode is 1144 and the total_steps are 77365\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -883     |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1144     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1902     |\n",
      "|    total_timesteps  | 77365    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.428    |\n",
      "|    n_updates        | 6841     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 3, 0, 0, 3, 3, 0, 2, 3, 0, 3, 0, 3, 1, 2, 2, 0, 0, 2, 3, 3, 0, 0, 1, 3, 0, 0, 1, 3, 3, 2, 3, 1, 3, 1, 3, 3, 0, 1, 1, 0, 1, 0, 2, 2, 1, 1, 2, 2, 3, 3, 1, 2, 2, 0, 2, 1, 2, 0, 3, 1, 2, 1, 0, 1, 2, 3, 2, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 76 and the episode is 1145 and the total_steps are 77441\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 1, 0, 0, 2, 2, 1, 1, 0, 1, 2, 1, 2, 1, 2, 1, 0, 3, 0, 2, 1, 2, 2, 0, 1, 3, 0, 3, 0, 0, 2, 0, 0, 0, 3, 0, 1, 3, 3, 2, 3, 0, 2, 2, 3, 0, 1, 2, 3, 3, 1, 2, 3, 2, 2, 1, 1, 1, 0, 1, 2, 1, 2, 2, 2, 3, 0, 1, 2, 3, 1, 1, 1, 0, 1, 2, 0, 0, 0, 2, 3, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -944. And steps were 88 and the episode is 1146 and the total_steps are 77529\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 0, 1, 1, 1, 2, 2, 3, 3, 3, 2, 1, 3, 0, 2, 0, 1, 2, 1, 0, 2, 0, 1, 3, 2, 0, 1, 0, 3, 2, 3, 3, 0, 1, 0, 1, 0, 3, 2, 3, 1, 3, 1, 0, 3, 3, 2, 1, 3, 2, 3, 3, 2, 1, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 61 and the episode is 1147 and the total_steps are 77590\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 1, 0, 0, 1, 3, 0, 2, 0, 0, 2, 2, 1, 1, 0, 3, 0, 0, 2, 2, 3, 2, 2, 0, 2, 3, 3, 1, 0, 0, 3, 0, 2, 3, 3, 2, 1, 1, 0, 3, 2, 2, 0, 1, 2, 2, 1, 1, 3, 1, 1, 2, 1, 2, 2, 1, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 64 and the episode is 1148 and the total_steps are 77654\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1148     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1914     |\n",
      "|    total_timesteps  | 77654    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.52     |\n",
      "|    n_updates        | 6913     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 3, 2, 3, 1, 0, 3, 2, 3, 3, 2, 0, 1, 3, 1, 1, 2, 0, 3, 3, 3, 0, 3, 1, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 31 and the episode is 1149 and the total_steps are 77685\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 0, 1, 1, 1, 3, 0, 3, 3, 2, 0, 2, 3, 2, 0, 0, 0, 1, 2, 3, 2, 3, 2, 1, 2, 3, 1, 3, 1, 1, 2, 3, 2, 3, 2, 1, 1, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 44 and the episode is 1150 and the total_steps are 77729\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 2, 0, 0, 2, 3, 3, 3, 1, 3, 1, 2, 2, 0, 3, 2, 2, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 1151 and the total_steps are 77753\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 2, 0, 1, 2, 2, 3, 0, 0, 1, 0, 1, 1, 1, 2, 3, 0, 0, 1, 3, 1, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 1152 and the total_steps are 77781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1152     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1919     |\n",
      "|    total_timesteps  | 77781    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.9     |\n",
      "|    n_updates        | 6945     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 1, 0, 3, 0, 2, 1, 1, 0, 2, 3, 3, 1, 2, 2, 0, 3, 3, 2, 0, 2, 3, 1, 1, 3, 3, 1, 2, 2, 1, 2, 3, 0, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 40 and the episode is 1153 and the total_steps are 77821\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 1, 2, 0, 2, 3, 2, 2, 0, 0, 2, 1, 2, 3, 2, 2, 1, 0, 3, 1, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 1154 and the total_steps are 77848\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 0, 3, 2, 1, 3, 0, 1, 0, 3, 2, 0, 1, 2, 1, 3, 2, 1, 3, 0, 3, 3, 2, 1, 0, 1, 3, 1, 1, 2, 3, 0, 0, 3, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 41 and the episode is 1155 and the total_steps are 77889\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 0, 3, 1, 2, 2, 0, 3, 3, 0, 0, 2, 1, 1, 1, 0, 2, 1, 0, 0, 2, 2, 0, 2, 3, 0, 1, 1, 2, 3, 2, 0, 1, 3, 3, 1, 0, 2, 3, 3, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 3, 1, 0, 3, 3, 0, 3, 0, 1, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 66 and the episode is 1156 and the total_steps are 77955\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1156     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1926     |\n",
      "|    total_timesteps  | 77955    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.78     |\n",
      "|    n_updates        | 6988     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 0, 1, 0, 2, 3, 0, 3, 0, 3, 3, 3, 1, 1, 0, 1, 3, 3, 1, 1, 1, 3, 2, 0, 0, 1, 3, 2, 2, 2, 0, 0, 0, 2, 1, 0, 0, 2, 3, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 46 and the episode is 1157 and the total_steps are 78001\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 3, 2, 1, 1, 3, 0, 2, 1, 1, 1, 1, 2, 2, 1, 3, 3, 0, 3, 2, 1, 0, 0, 2, 1, 0, 1, 0, 0, 2, 0, 0, 1, 1, 2, 3, 3, 2, 2, 0, 2, 1, 1, 1, 3, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 52 and the episode is 1158 and the total_steps are 78053\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 3, 1, 2, 2, 0, 3, 1, 1, 1, 1, 0, 3, 0, 3, 0, 1, 2, 0, 0, 3, 3, 3, 3, 2, 0, 1, 0, 3, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 36 and the episode is 1159 and the total_steps are 78089\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 0, 0, 3, 2, 0, 1, 0, 3, 3, 0, 1, 2, 3, 3, 0, 2, 0, 3, 0, 1, 2, 0, 0, 0, 3, 3, 0, 0, 1, 3, 2, 0, 1, 2, 3, 2, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 44 and the episode is 1160 and the total_steps are 78133\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1933     |\n",
      "|    total_timesteps  | 78133    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 7033     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 2, 1, 2, 0, 1, 0, 1, 2, 0, 2, 0, 2, 1, 0, 1, 3, 0, 1, 3, 1, 2, 0, 3, 2, 1, 2, 3, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 35 and the episode is 1161 and the total_steps are 78168\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 0, 0, 0, 3, 3, 2, 3, 3, 3, 1, 0, 2, 2, 1, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 22 and the episode is 1162 and the total_steps are 78190\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 1, 1, 2, 1, 3, 1, 2, 3, 3, 1, 0, 1, 1, 2, 2, 0, 1, 0, 1, 1, 3, 0, 2, 3, 0, 3, 0, 3, 3, 1, 2, 3, 3, 0, 3, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 43 and the episode is 1163 and the total_steps are 78233\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 1, 1, 1, 1, 3, 0, 3, 1, 1, 3, 3, 2, 2, 0, 1, 3, 0, 1, 1, 0, 2, 2, 1, 0, 3, 0, 3, 2, 2, 0, 2, 0, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 1164 and the total_steps are 78273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1164     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1938     |\n",
      "|    total_timesteps  | 78273    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 7068     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 2, 3, 1, 1, 0, 2, 3, 0, 0, 2, 2, 0, 1, 2, 2, 2, 3, 1, 0, 1, 2, 0, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 30 and the episode is 1165 and the total_steps are 78303\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 3, 3, 2, 3, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 0, 3, 3, 0, 0, 1, 1, 3, 3, 2, 1, 2, 2, 3, 3, 1, 2, 0, 3, 0, 2, 0, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was 961. And steps were 42 and the episode is 1166 and the total_steps are 78345\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 1, 2, 3, 2, 0, 1, 1, 0, 1, 0, 2, 2, 3, 3, 2, 0, 0, 1, 3, 2, 3, 0, 0, 1, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1167 and the total_steps are 78377\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 1, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 3, 1, 3, 3, 2, 1, 2, 0, 3, 0, 3, 3, 1, 2, 0, 3, 1, 1, 2, 0, 1, 1, 0, 0, 1, 0, 1, 3, 1, 1, 0, 1, 2, 0, 1, 0, 1, 3, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1035. And steps were 59 and the episode is 1168 and the total_steps are 78436\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1168     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1945     |\n",
      "|    total_timesteps  | 78436    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 7108     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 3, 2, 1, 0, 0, 1, 2, 0, 3, 0, 2, 2, 2, 1, 1, 3, 1, 2, 1, 2, 3, 2, 3, 2, 3, 0, 2, 1, 0, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 37 and the episode is 1169 and the total_steps are 78473\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 3, 3, 3, 2, 2, 2, 2, 2, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 1170 and the total_steps are 78489\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 3, 0, 1, 3, 2, 2, 0, 1, 3, 3, 0, 1, 3, 0, 2, 3, 3, 2, 1, 0, 3, 3, 2, 0, 2, 3, 0, 2, 1, 0, 2, 3, 3, 0, 0, 0, 0, 3, 3, 3, 0, 2, 2, 1, 2, 2, 0, 0, 1, 3, 1, 0, 2, 3, 0, 3, 2, 2, 1, 3, 0, 0, 2, 0, 2, 2, 1, 1, 2, 1, 3, 2, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -930. And steps were 80 and the episode is 1171 and the total_steps are 78569\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 3, 1, 3, 3, 0, 2, 3, 2, 0, 0, 0, 2, 3, 3, 2, 2, 3, 2, 1, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 36 and the episode is 1172 and the total_steps are 78605\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1172     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1952     |\n",
      "|    total_timesteps  | 78605    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.1     |\n",
      "|    n_updates        | 7151     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 1, 2, 1, 2, 3, 2, 3, 0, 0, 0, 0, 2, 2, 1, 0, 3, 3, 0, 1, 2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 1173 and the total_steps are 78641\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 2, 3, 1, 2, 1, 1, 1, 2, 3, 3, 0, 0, 0, 0, 1, 1, 0, 0, 3, 1, 0, 3, 0, 0, 1, 3, 3, 3, 3, 0, 2, 3, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 40 and the episode is 1174 and the total_steps are 78681\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 2, 0, 1, 2, 1, 2, 2, 1, 0, 1, 3, 0, 1, 1, 0, 1, 3, 1, 2, 3, 2, 1, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 30 and the episode is 1175 and the total_steps are 78711\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 0, 2, 1, 0, 0, 3, 2, 1, 2, 2, 1, 1, 0, 3, 2, 1, 3, 0, 2, 0, 2, 2, 0, 2, 3, 2, 3, 1, 0, 1, 2, 3, 1, 0, 0, 0, 3, 2, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 46 and the episode is 1176 and the total_steps are 78757\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1176     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1958     |\n",
      "|    total_timesteps  | 78757    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2        |\n",
      "|    n_updates        | 7189     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 2, 3, 2, 2, 3, 1, 2, 0, 0, 2, 2, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 19 and the episode is 1177 and the total_steps are 78776\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 1, 0, 2, 2, 0, 0, 3, 0, 3, 1, 1, 3, 0, 1, 1, 3, 3, 1, 1, 0, 2, 0, 0, 1, 3, 1, 3, 3, 0, 2, 0, 3, 3, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 41 and the episode is 1178 and the total_steps are 78817\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 2, 0, 0, 3, 0, 3, 2, 3, 1, 2, 3, 0, 3, 1, 2, 1, 3, 3, 0, 1, 2, 0, 0, 1, 0, 0, 3, 3, 2, 3, 0, 2, 2, 3, 0, 0, 0, 1, 1, 0, 0, 2, 3, 3, 0, 0, 1, 0, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 56 and the episode is 1179 and the total_steps are 78873\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 3, 0, 2, 0, 1, 2, 1, 0, 2, 3, 2, 3, 2, 1, 2, 2, 3, 0, 0, 2, 3, 2, 3, 3, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 1180 and the total_steps are 78905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1964     |\n",
      "|    total_timesteps  | 78905    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.33     |\n",
      "|    n_updates        | 7226     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 3, 2, 3, 0, 0, 0, 3, 2, 3, 1, 1, 2, 2, 0, 3, 1, 3, 0, 2, 0, 1, 0, 0, 0, 1, 3, 3, 0, 1, 0, 2, 2, 0, 1, 0, 1, 2, 2, 2, 0, 3, 1, 3, 3, 2, 0, 3, 0, 2, 0, 3, 3, 3, 2, 1, 3, 2, 2, 2, 3, 0, 2, 2, 2, 1, 2, 3, 1, 2, 3, 1, 3, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 80 and the episode is 1181 and the total_steps are 78985\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 1, 3, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 2, 2, 1, 0, 1, 1, 0, 1, 3, 0, 2, 2, 2, 0, 3, 1, 0, 0, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 2, 0, 1, 1, 3, 1, 2, 3, 3, 2, 1, 0, 2, 2, 2, 3, 0, 0, 1, 1, 1, 0, 1, 1, 2, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 74 and the episode is 1182 and the total_steps are 79059\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 1, 3, 3, 0, 3, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 3, 3, 0, 1, 0, 1, 2, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1183 and the total_steps are 79089\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 3, 3, 1, 2, 3, 1, 0, 1, 1, 2, 1, 0, 3, 0, 2, 2, 1, 0, 3, 3, 1, 2, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 30 and the episode is 1184 and the total_steps are 79119\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1184     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1973     |\n",
      "|    total_timesteps  | 79119    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 7279     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 0, 2, 2, 2, 2, 2, 1, 1, 3, 2, 3, 0, 0, 0, 2, 2, 2, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 26 and the episode is 1185 and the total_steps are 79145\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 2, 0, 1, 3, 2, 1, 3, 0, 1, 3, 2, 2, 3, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 1186 and the total_steps are 79177\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 1, 2, 3, 0, 2, 0, 3, 1, 0, 1, 0, 0, 3, 3, 3, 3, 1, 1, 1, 0, 3, 0, 2, 2, 1, 1, 3, 1, 1, 0, 2, 2, 1, 0, 1, 2, 3, 3, 1, 1, 1, 0, 0, 2, 2, 3, 0, 0, 1, 1, 1, 2, 0, 3, 1, 2, 3, 1, 0, 2, 3, 2, 2, 0, 0, 0, 3, 3, 2, 2, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1054. And steps were 78 and the episode is 1187 and the total_steps are 79255\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 1, 0, 2, 1, 3, 0, 1, 0, 3, 2, 3, 2, 3, 3, 0, 2, 3, 3, 0, 3, 0, 1, 0, 0, 1, 2, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 34 and the episode is 1188 and the total_steps are 79289\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1188     |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 1979     |\n",
      "|    total_timesteps  | 79289    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 7322     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 0, 3, 2, 1, 0, 2, 3, 3, 1, 2, 3, 2, 2, 0, 0, 1, 0, 0, 3, 2, 0, 1, 2, 2, 0, 3, 2, 1, 1, 0, 3, 0, 1, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 41 and the episode is 1189 and the total_steps are 79330\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 3, 2, 3, 3, 0, 1, 0, 1, 1, 2, 2, 0, 0, 3, 1, 2, 2, 2, 1, 3, 2, 2, 2, 3, 2, 3, 3, 3, 3, 2, 0, 1, 0, 0, 0, 2, 2, 1, 1, 3, 2, 0, 3, 3, 2, 3, 1, 2, 1, 1, 0, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 59 and the episode is 1190 and the total_steps are 79389\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 2, 1, 3, 1, 0, 3, 2, 3, 2, 1, 2, 0, 0, 3, 2, 0, 2, 1, 1, 2, 2, 3, 0, 1, 2, 0, 2, 0, 0, 0, 2, 3, 0, 1, 1, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 43 and the episode is 1191 and the total_steps are 79432\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 0, 1, 3, 1, 0, 1, 1, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 25 and the episode is 1192 and the total_steps are 79457\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1192     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 1986     |\n",
      "|    total_timesteps  | 79457    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.994    |\n",
      "|    n_updates        | 7364     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 0, 1, 0, 1, 2, 0, 3, 2, 1, 3, 2, 2, 1, 0, 0, 3, 0, 0, 0, 2, 0, 3, 1, 3, 3, 3, 0, 0, 0, 0, 3, 2, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 40 and the episode is 1193 and the total_steps are 79497\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 3, 3, 0, 3, 2, 2, 1, 0, 1, 2, 2, 2, 1, 1, 3, 0, 2, 2, 2, 3, 2, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1194 and the total_steps are 79527\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 2, 1, 3, 3, 2, 1, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 14 and the episode is 1195 and the total_steps are 79541\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 0, 3, 0, 3, 2, 0, 1, 2, 3, 3, 1, 0, 1, 2, 2, 2, 1, 1, 1, 1, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 28 and the episode is 1196 and the total_steps are 79569\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1196     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 1991     |\n",
      "|    total_timesteps  | 79569    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.711    |\n",
      "|    n_updates        | 7392     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 3, 2, 1, 3, 3, 0, 3, 2, 2, 3, 2, 2, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 0, 1, 1, 2, 0, 2, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 46 and the episode is 1197 and the total_steps are 79615\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 2, 1, 1, 2, 2, 0, 2, 2, 1, 3, 3, 3, 3, 0, 1, 1, 3, 0, 0, 0, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 1, 0, 3, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 46 and the episode is 1198 and the total_steps are 79661\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 3, 2, 1, 3, 3, 0, 2, 3, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 3, 3, 0, 3, 0, 3, 3, 3, 2, 0, 2, 0, 3, 2, 1, 0, 3, 0, 2, 2, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 47 and the episode is 1199 and the total_steps are 79708\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 0, 3, 3, 2, 2, 2, 1, 3, 0, 0, 1, 1, 2, 3, 2, 3, 0, 0, 1, 1, 2, 3, 0, 1, 0, 3, 3, 1, 1, 2, 3, 3, 0, 3, 2, 1, 2, 0, 2, 2, 0, 0, 2, 3, 1, 1, 2, 1, 2, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -945. And steps were 57 and the episode is 1200 and the total_steps are 79765\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 1999     |\n",
      "|    total_timesteps  | 79765    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.852    |\n",
      "|    n_updates        | 7441     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 0, 2, 2, 2, 1, 3, 3, 2, 1, 2, 1, 2, 3, 0, 3, 1, 0, 2, 3, 3, 3, 2, 2, 3, 0, 1, 3, 3, 2, 2, 0, 2, 3, 3, 1, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 43 and the episode is 1201 and the total_steps are 79808\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 0, 1, 2, 2, 0, 3, 0, 2, 1, 2, 3, 0, 1, 1, 0, 2, 0, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 25 and the episode is 1202 and the total_steps are 79833\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 0, 0, 0, 1, 2, 3, 3, 1, 1, 3, 2, 2, 2, 3, 2, 2, 3, 1, 3, 1, 1, 1, 2, 0, 2, 0, 2, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 35 and the episode is 1203 and the total_steps are 79868\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 3, 3, 1, 3, 3, 2, 2, 1, 1, 0, 0, 0, 1, 3, 1, 1, 0, 2, 1, 2, 0, 1, 2, 2, 3, 3, 2, 2, 3, 1, 0, 2, 2, 0, 1, 1, 0, 0, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 46 and the episode is 1204 and the total_steps are 79914\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1204     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2005     |\n",
      "|    total_timesteps  | 79914    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.1     |\n",
      "|    n_updates        | 7478     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 2, 0, 3, 0, 0, 2, 2, 1, 2, 3, 3, 1, 2, 1, 3, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 23 and the episode is 1205 and the total_steps are 79937\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 1, 0, 2, 0, 3, 1, 2, 1, 2, 2, 0, 0, 0, 0, 3, 1, 2, 0, 0, 3, 1, 1, 2, 0, 0, 2, 1, 3, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 1206 and the total_steps are 79973\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 0, 0, 3, 2, 1, 3, 3, 2, 2, 2, 3, 3, 2, 2, 0, 1, 0, 3, 3, 2, 2, 0, 1, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 31 and the episode is 1207 and the total_steps are 80004\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 0, 1, 0, 0, 3, 0, 0, 1, 3, 2, 1, 2, 1, 2, 3, 0, 1, 3, 1, 2, 1, 1, 2, 2, 0, 2, 2, 1, 0, 2, 1, 1, 0, 1, 0, 3, 0, 1, 2, 2, 2, 0, 2, 3, 0, 1, 0, 0, 2, 2, 0, 1, 3, 3, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 3, 3, 2, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 78 and the episode is 1208 and the total_steps are 80082\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1208     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2012     |\n",
      "|    total_timesteps  | 80082    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.4     |\n",
      "|    n_updates        | 7520     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 2, 3, 3, 1, 0, 3, 1, 2, 1, 0, 3, 2, 3, 1, 2, 2, 0, 1, 0, 1, 0, 1, 3, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 31 and the episode is 1209 and the total_steps are 80113\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 0, 2, 3, 3, 1, 3, 1, 1, 3, 2, 0, 3, 2, 0, 0, 0, 0, 0, 1, 1, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 1210 and the total_steps are 80141\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 0, 2, 3, 1, 1, 3, 2, 2, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 1211 and the total_steps are 80157\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 2, 1, 3, 3, 2, 3, 1, 3, 2, 1, 0, 0, 1, 0, 3, 0, 0, 1, 1, 0, 0, 2, 1, 2, 3, 2, 2, 1, 2, 3, 3, 2, 3, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 1212 and the total_steps are 80198\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1212     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2016     |\n",
      "|    total_timesteps  | 80198    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 7549     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 1, 0, 1, 2, 3, 3, 2, 2, 1, 2, 3, 2, 1, 2, 2, 1, 1, 2, 2, 0, 3, 1, 0, 3, 1, 3, 2, 0, 1, 3, 3, 3, 3, 3, 0, 0, 1, 1, 1, 1, 2, 2, 2, 0, 1, 2, 0, 0, 2, 2, 3, 2, 1, 3, 3, 3, 2, 0, 2, 0, 0, 3, 2, 2, 0, 0, 0, 2, 1, 1, 0, 0, 0, 2, 3, 3, 1, 0, 1, 2, 0, 2, 0, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1059. And steps were 91 and the episode is 1213 and the total_steps are 80289\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 1, 3, 3, 0, 2, 2, 2, 2, 1, 0, 1, 2, 1, 2, 1, 2, 3, 1, 1, 0, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 1214 and the total_steps are 80317\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 3, 2, 1, 2, 3, 3, 0, 2, 2, 0, 0, 0, 1, 3, 0, 3, 2, 1, 3, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 1215 and the total_steps are 80344\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 1, 3, 0, 3, 2, 0, 0, 3, 3, 0, 3, 1, 2, 2, 3, 1, 0, 1, 3, 0, 2, 2, 3, 0, 3, 2, 0, 0, 3, 2, 0, 1, 1, 1, 3, 1, 1, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 45 and the episode is 1216 and the total_steps are 80389\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1216     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2024     |\n",
      "|    total_timesteps  | 80389    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.466    |\n",
      "|    n_updates        | 7597     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 1, 2, 1, 2, 1, 1, 2, 2, 0, 0, 0, 1, 1, 2, 0, 0, 3, 1, 2, 2, 1, 3, 1, 1, 2, 2, 0, 0, 1, 2, 2, 1, 2, 1, 3, 2, 3, 2, 1, 3, 0, 0, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 50 and the episode is 1217 and the total_steps are 80439\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 0, 1, 3, 0, 1, 1, 1, 2, 0, 3, 2, 1, 3, 1, 0, 2, 0, 2, 3, 2, 2, 1, 0, 1, 3, 0, 2, 2, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1041. And steps were 43 and the episode is 1218 and the total_steps are 80482\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 0, 3, 0, 2, 3, 2, 3, 0, 0, 3, 0, 1, 1, 2, 1, 3, 1, 1, 3, 2, 0, 3, 3, 1, 1, 0, 2, 2, 1, 1, 3, 1, 3, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 47 and the episode is 1219 and the total_steps are 80529\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 0, 2, 0, 0, 3, 1, 2, 2, 1, 1, 0, 3, 1, 2, 1, 3, 3, 3, 1, 2, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 1220 and the total_steps are 80557\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2031     |\n",
      "|    total_timesteps  | 80557    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 95.4     |\n",
      "|    n_updates        | 7639     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 2, 1, 3, 0, 3, 2, 3, 3, 0, 1, 2, 1, 0, 0, 2, 3, 3, 0, 2, 3, 3, 2, 0, 1, 0, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 33 and the episode is 1221 and the total_steps are 80590\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 3, 1, 3, 2, 2, 1, 0, 2, 1, 0, 1, 2, 1, 3, 0, 0, 0, 2, 2, 2, 1, 0, 2, 3, 1, 1, 1, 3, 0, 0, 0, 0, 3, 3, 0, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1041. And steps were 43 and the episode is 1222 and the total_steps are 80633\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 3, 0, 3, 0, 1, 0, 3, 2, 0, 1, 1, 3, 0, 2, 3, 2, 3, 0, 0, 0, 2, 0, 2, 2, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 1223 and the total_steps are 80665\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 2, 0, 3, 1, 2, 1, 0, 1, 1, 2, 3, 3, 2, 1, 2, 3, 1, 2, 0, 2, 1, 2, 2, 2, 1, 3, 1, 3, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 36 and the episode is 1224 and the total_steps are 80701\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1224     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2036     |\n",
      "|    total_timesteps  | 80701    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 7675     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 1, 0, 1, 3, 2, 2, 3, 0, 3, 2, 3, 1, 1, 2, 0, 1, 1, 2, 0, 3, 2, 0, 1, 1, 0, 0, 1, 0, 2, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 37 and the episode is 1225 and the total_steps are 80738\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 2, 2, 1, 3, 1, 0, 2, 2, 1, 1, 0, 3, 1, 1, 3, 1, 2, 0, 3, 3, 3, 3, 0, 1, 0, 0, 2, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 35 and the episode is 1226 and the total_steps are 80773\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 3, 1, 0, 0, 3, 1, 1, 1, 0, 0, 1, 0, 0, 3, 3, 1, 3, 1, 3, 1, 2, 0, 1, 2, 0, 0, 1, 1, 3, 1, 1, 0, 0, 3, 0, 1, 0, 2, 0, 2, 2, 3, 0, 3, 1, 1, 0, 3, 2, 1, 3, 2, 0, 3, 0, 2, 3, 3, 3, 1, 3, 1, 1, 2, 3, 0, 1, 3, 3, 1, 2, 1, 1, 3, 3, 2, 0, 0, 0, 2, 0, 0, 1, 3, 3, 2, 1, 1, 2, 3, 2, 3, 0, 2, 0, 0, 2, 3, 2, 2, 1, 0, 2, 0, 2, 0, 2, 2, 3, 2, 3, 3, 2, 0, 0, 0, 0, 0, 1, 3, 3, 0, 0, 1, 2, 3, 1, 2, 0, 2, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 138 and the episode is 1227 and the total_steps are 80911\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 0, 1, 3, 3, 2, 2, 1, 0, 3, 1, 2, 1, 3, 3, 2, 1, 1, 2, 0, 0, 0, 2, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1228 and the total_steps are 80941\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1228     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2046     |\n",
      "|    total_timesteps  | 80941    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.9     |\n",
      "|    n_updates        | 7735     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 1, 0, 3, 2, 0, 1, 1, 3, 3, 3, 3, 0, 1, 3, 0, 2, 1, 3, 2, 0, 0, 2, 0, 3, 1, 2, 0, 3, 2, 3, 0, 3, 2, 0, 3, 0, 0, 3, 2, 2, 3, 1, 3, 1, 1, 1, 2, 2, 3, 2, 1, 3, 0, 0, 1, 1, 1, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -947. And steps were 65 and the episode is 1229 and the total_steps are 81006\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 0, 2, 1, 3, 1, 0, 0, 1, 0, 1, 2, 1, 2, 2, 3, 3, 1, 0, 3, 2, 3, 3, 1, 1, 0, 2, 2, 2, 2, 2, 1, 2, 0, 0, 0, 0, 1, 3, 0, 0, 0, 3, 2, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 51 and the episode is 1230 and the total_steps are 81057\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 1, 3, 2, 0, 2, 3, 0, 3, 2, 2, 0, 3, 2, 1, 0, 3, 1, 1, 3, 1, 3, 3, 1, 0, 1, 3, 3, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 35 and the episode is 1231 and the total_steps are 81092\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 3, 2, 3, 1, 2, 1, 1, 1, 2, 2, 1, 2, 3, 1, 2, 1, 3, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 25 and the episode is 1232 and the total_steps are 81117\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.6     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1232     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2053     |\n",
      "|    total_timesteps  | 81117    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 7779     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 3, 1, 1, 2, 1, 3, 1, 1, 3, 0, 1, 3, 2, 0, 1, 1, 0, 1, 1, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 1233 and the total_steps are 81142\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 3, 3, 2, 2, 3, 3, 1, 2, 1, 1, 0, 3, 3, 0, 3, 0, 1, 1, 1, 1, 0, 3, 0, 1, 3, 2, 2, 2, 1, 3, 1, 3, 1, 0, 2, 0, 1, 2, 3, 3, 2, 0, 3, 1, 2, 0, 0, 2, 1, 3, 1, 2, 2, 1, 2, 2, 3, 1, 2, 0, 1, 0, 0, 2, 2, 3, 2, 0, 0, 1, 1, 0, 0, 1, 1, 3, 0, 1, 3, 1, 2, 1, 1, 0, 3, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 93 and the episode is 1234 and the total_steps are 81235\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 2, 1, 1, 1, 3, 1, 2, 1, 3, 2, 0, 3, 0, 0, 0, 1, 2, 2, 0, 0, 1, 0, 2, 2, 0, 3, 1, 0, 0, 1, 1, 1, 0, 2, 3, 1, 0, 2, 1, 2, 0, 0, 0, 2, 2, 1, 0, 0, 0, 2, 2, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 59 and the episode is 1235 and the total_steps are 81294\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 0, 0, 1, 1, 1, 1, 0, 1, 3, 3, 0, 1, 2, 2, 3, 2, 0, 1, 1, 3, 0, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1236 and the total_steps are 81323\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.2     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1236     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2061     |\n",
      "|    total_timesteps  | 81323    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.3     |\n",
      "|    n_updates        | 7830     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 3, 0, 2, 3, 0, 1, 1, 2, 2, 1, 3, 1, 3, 3, 0, 1, 3, 0, 2, 1, 3, 3, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 31 and the episode is 1237 and the total_steps are 81354\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 0, 1, 1, 3, 3, 1, 1, 2, 3, 0, 0, 3, 2, 0, 0, 0, 1, 0, 3, 1, 1, 3, 1, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 31 and the episode is 1238 and the total_steps are 81385\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 0, 1, 0, 0, 3, 1, 2, 2, 0, 1, 0, 0, 1, 3, 2, 1, 0, 2, 2, 2, 1, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 29 and the episode is 1239 and the total_steps are 81414\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 0, 3, 1, 2, 2, 0, 2, 0, 2, 2, 2, 0, 3, 0, 2, 0, 3, 0, 3, 1, 1, 2, 2, 0, 2, 1, 1, 1, 2, 1, 3, 1, 2, 3, 0, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 43 and the episode is 1240 and the total_steps are 81457\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.3     |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2066     |\n",
      "|    total_timesteps  | 81457    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 7864     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 0, 2, 3, 0, 1, 3, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 23 and the episode is 1241 and the total_steps are 81480\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 3, 0, 1, 2, 0, 3, 2, 3, 2, 2, 1, 0, 1, 3, 0, 3, 3, 0, 3, 2, 2, 1, 2, 3, 3, 0, 0, 3, 1, 2, 2, 3, 0, 3, 2, 1, 1, 0, 1, 0, 0, 1, 0, 3, 0, 3, 0, 0, 2, 0, 1, 0, 0, 2, 3, 0, 2, 1, 2, 0, 3, 2, 2, 2, 3, 2, 0, 2, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 76 and the episode is 1242 and the total_steps are 81556\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 0, 0, 3, 2, 0, 3, 2, 3, 3, 2, 1, 0, 1, 0, 3, 1, 3, 3, 0, 0, 3, 0, 1, 0, 1, 3, 2, 1, 3, 3, 2, 0, 2, 2, 1, 1, 0, 3, 2, 0, 2, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 49 and the episode is 1243 and the total_steps are 81605\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 2, 0, 3, 1, 3, 3, 2, 1, 0, 2, 2, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 19 and the episode is 1244 and the total_steps are 81624\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.6     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1244     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2073     |\n",
      "|    total_timesteps  | 81624    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.656    |\n",
      "|    n_updates        | 7905     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 2, 0, 2, 2, 2, 3, 3, 0, 1, 2, 3, 0, 2, 3, 2, 3, 0, 1, 0, 3, 2, 3, 2, 1, 2, 3, 2, 3, 0, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 37 and the episode is 1245 and the total_steps are 81661\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 0, 0, 2, 2, 0, 2, 3, 3, 2, 2, 2, 2, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 1246 and the total_steps are 81681\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 3, 3, 0, 1, 0, 1, 2, 1, 2, 0, 1, 0, 3, 3, 1, 0, 0, 1, 2, 1, 2, 3, 2, 1, 1, 1, 2, 1, 3, 3, 3, 1, 3, 0, 1, 2, 0, 2, 0, 0, 3, 1, 1, 0, 2, 2, 3, 2, 0, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 56 and the episode is 1247 and the total_steps are 81737\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 3, 1, 0, 2, 2, 3, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 20 and the episode is 1248 and the total_steps are 81757\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1248     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2078     |\n",
      "|    total_timesteps  | 81757    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 92.1     |\n",
      "|    n_updates        | 7939     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 2, 3, 1, 1, 2, 0, 0, 1, 3, 0, 3, 2, 2, 3, 2, 3, 2, 0, 2, 0, 3, 0, 2, 1, 3, 0, 1, 1, 1, 0, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 38 and the episode is 1249 and the total_steps are 81795\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 1, 0, 0, 3, 0, 2, 0, 1, 1, 0, 2, 0, 0, 3, 0, 0, 2, 2, 1, 2, 2, 3, 2, 0, 3, 3, 1, 3, 0, 2, 2, 2, 0, 1, 0, 2, 2, 3, 0, 0, 3, 3, 2, 1, 3, 3, 2, 2, 0, 0, 1, 0, 2, 1, 1, 2, 0, 3, 2, 1, 1, 1, 1, 2, 2, 0, 3, 1, 3, 3, 0, 3, 1, 3, 1, 0, 1, 3, 0, 2, 2, 2, 2, 0, 0, 2, 3, 1, 1, 3, 3, 2, 3, 2, 3, 1, 0, 1, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -928. And steps were 106 and the episode is 1250 and the total_steps are 81901\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 1, 1, 3, 3, 0, 2, 2, 1, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 1251 and the total_steps are 81929\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 3, 0, 3, 2, 2, 2, 2, 1, 2, 0, 0, 2, 3, 0, 2, 3, 3, 1, 1, 1, 3, 3, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 30 and the episode is 1252 and the total_steps are 81959\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1252     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2086     |\n",
      "|    total_timesteps  | 81959    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 126      |\n",
      "|    n_updates        | 7989     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 1, 3, 3, 0, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 2, 3, 2, 3, 0, 1, 2, 2, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1253 and the total_steps are 81989\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 1, 2, 0, 3, 0, 0, 2, 3, 1, 2, 0, 0, 3, 2, 2, 2, 3, 0, 2, 2, 0, 2, 1, 1, 3, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 1254 and the total_steps are 82022\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 0, 0, 1, 2, 3, 3, 1, 3, 3, 3, 2, 0, 3, 0, 2, 2, 2, 1, 0, 1, 1, 1, 0, 2, 1, 2, 3, 0, 3, 2, 2, 0, 1, 0, 0, 1, 2, 3, 3, 2, 0, 2, 3, 3, 1, 3, 3, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -947. And steps were 55 and the episode is 1255 and the total_steps are 82077\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 2, 3, 0, 3, 2, 2, 0, 2, 1, 2, 1, 2, 3, 2, 2, 0, 1, 0, 3, 1, 1, 2, 3, 1, 0, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 33 and the episode is 1256 and the total_steps are 82110\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1256     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2092     |\n",
      "|    total_timesteps  | 82110    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.341    |\n",
      "|    n_updates        | 8027     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 2, 1, 2, 0, 3, 1, 0, 0, 0, 0, 2, 1, 2, 0, 2, 1, 3, 3, 1, 0, 3, 3, 1, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 1257 and the total_steps are 82141\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 1, 0, 2, 1, 0, 0, 2, 0, 3, 3, 0, 0, 3, 2, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 1258 and the total_steps are 82169\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 2, 1, 0, 2, 1, 0, 3, 1, 0, 1, 2, 0, 1, 2, 0, 0, 3, 0, 0, 0, 1, 1, 1, 1, 3, 0, 1, 1, 2, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 44 and the episode is 1259 and the total_steps are 82213\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 1, 1, 3, 1, 3, 2, 1, 1, 0, 1, 0, 2, 2, 3, 0, 3, 0, 1, 1, 1, 1, 1, 0, 0, 1, 2, 3, 1, 2, 2, 3, 0, 0, 1, 1, 1, 0, 2, 3, 3, 0, 1, 3, 3, 3, 0, 2, 0, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 56 and the episode is 1260 and the total_steps are 82269\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2098     |\n",
      "|    total_timesteps  | 82269    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 8067     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 3, 3, 3, 0, 3, 3, 0, 2, 0, 0, 0, 3, 3, 0, 0, 1, 2, 0, 1, 2, 2, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1261 and the total_steps are 82298\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 2, 3, 3, 0, 3, 0, 2, 0, 0, 1, 2, 3, 0, 0, 3, 1, 1, 2, 0, 2, 0, 3, 1, 3, 2, 2, 3, 2, 3, 0, 3, 3, 1, 1, 3, 1, 2, 3, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 1, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 0, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 68 and the episode is 1262 and the total_steps are 82366\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 2, 3, 2, 1, 1, 0, 0, 0, 0, 2, 0, 3, 0, 2, 1, 2, 0, 3, 3, 2, 3, 3, 2, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 31 and the episode is 1263 and the total_steps are 82397\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 3, 2, 3, 0, 0, 3, 3, 3, 3, 1, 2, 2, 1, 3, 1, 1, 3, 1, 2, 3, 1, 3, 2, 3, 0, 3, 2, 1, 1, 3, 3, 0, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 40 and the episode is 1264 and the total_steps are 82437\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1264     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2105     |\n",
      "|    total_timesteps  | 82437    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 8109     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 0, 0, 2, 2, 1, 3, 0, 0, 0, 3, 2, 2, 1, 2, 3, 3, 2, 1, 1, 3, 1, 3, 1, 3, 0, 3, 0, 1, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 36 and the episode is 1265 and the total_steps are 82473\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 2, 0, 2, 0, 3, 1, 0, 2, 0, 0, 2, 0, 1, 3, 3, 1, 2, 3, 1, 2, 2, 0, 2, 1, 3, 1, 2, 2, 0, 2, 2, 3, 1, 0, 3, 1, 0, 2, 0, 0, 1, 3, 0, 1, 1, 0, 1, 3, 2, 2, 3, 2, 1, 2, 0, 0, 3, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 65 and the episode is 1266 and the total_steps are 82538\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 2, 1, 2, 3, 1, 1, 3, 2, 3, 0, 2, 1, 1, 2, 1, 2, 1, 2, 1, 0, 1, 0, 1, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 31 and the episode is 1267 and the total_steps are 82569\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 0, 3, 2, 3, 0, 0, 1, 1, 0, 0, 1, 0, 2, 0, 1, 1, 3, 2, 0, 0, 3, 2, 1, 0, 2, 0, 0, 1, 3, 1, 3, 0, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 40 and the episode is 1268 and the total_steps are 82609\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -978     |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1268     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2112     |\n",
      "|    total_timesteps  | 82609    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 8152     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 2, 1, 2, 0, 0, 1, 2, 1, 2, 3, 3, 3, 2, 3, 3, 3, 3, 0, 2, 0, 1, 0, 3, 1, 3, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 33 and the episode is 1269 and the total_steps are 82642\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 1, 2, 3, 2, 1, 0, 2, 2, 3, 0, 2, 0, 1, 3, 0, 3, 1, 0, 2, 1, 0, 3, 2, 0, 2, 3, 1, 3, 0, 1, 3, 3, 1, 1, 2, 3, 2, 2, 1, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 47 and the episode is 1270 and the total_steps are 82689\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 0, 2, 2, 1, 3, 1, 3, 2, 1, 3, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 3, 3, 0, 1, 1, 1, 3, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 36 and the episode is 1271 and the total_steps are 82725\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 1, 3, 2, 3, 1, 2, 1, 1, 3, 2, 0, 0, 2, 3, 2, 2, 3, 0, 0, 3, 0, 1, 3, 1, 3, 3, 1, 2, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 36 and the episode is 1272 and the total_steps are 82761\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -979     |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1272     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2119     |\n",
      "|    total_timesteps  | 82761    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 8190     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 3, 0, 2, 0, 1, 0, 1, 0, 2, 3, 3, 0, 0, 0, 2, 2, 2, 2, 0, 3, 2, 2, 1, 2, 1, 2, 0, 3, 2, 2, 2, 3, 2, 2, 2, 3, 3, 1, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 46 and the episode is 1273 and the total_steps are 82807\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 2, 0, 1, 3, 3, 0, 2, 1, 3, 2, 1, 0, 3, 3, 0, 2, 3, 3, 0, 3, 0, 2, 2, 3, 2, 1, 1, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 35 and the episode is 1274 and the total_steps are 82842\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 2, 0, 1, 2, 3, 2, 1, 3, 3, 0, 1, 1, 3, 1, 3, 3, 0, 0, 3, 0, 2, 1, 2, 1, 3, 2, 1, 2, 3, 1, 2, 0, 3, 2, 2, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 43 and the episode is 1275 and the total_steps are 82885\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 2, 0, 1, 0, 3, 0, 3, 2, 1, 0, 3, 0, 2, 1, 3, 1, 3, 1, 1, 3, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 1276 and the total_steps are 82911\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1276     |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 2124     |\n",
      "|    total_timesteps  | 82911    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.947    |\n",
      "|    n_updates        | 8227     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 3, 3, 2, 0, 2, 1, 2, 0, 2, 3, 2, 1, 0, 3, 2, 2, 0, 0, 1, 0, 1, 0, 3, 3, 2, 1, 0, 1, 1, 0, 3, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 47 and the episode is 1277 and the total_steps are 82958\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 1, 1, 2, 1, 0, 1, 2, 0, 2, 1, 2, 1, 1, 0, 1, 3, 0, 3, 0, 2, 0, 2, 2, 0, 3, 0, 3, 0, 3, 0, 1, 1, 3, 3, 3, 0, 0, 2, 0, 2, 3, 0, 0, 3, 3, 2, 1, 2, 2, 3, 3, 1, 1, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 61 and the episode is 1278 and the total_steps are 83019\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 2, 2, 3, 1, 0, 2, 2, 3, 3, 2, 1, 1, 1, 0, 0, 2, 2, 1, 1, 1, 3, 3, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 31 and the episode is 1279 and the total_steps are 83050\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 0, 1, 1, 2, 1, 2, 1, 3, 0, 2, 1, 1, 3, 0, 1, 3, 2, 2, 3, 2, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 28 and the episode is 1280 and the total_steps are 83078\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1280     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2131     |\n",
      "|    total_timesteps  | 83078    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 125      |\n",
      "|    n_updates        | 8269     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 1, 1, 3, 0, 2, 1, 2, 2, 0, 3, 1, 1, 2, 0, 1, 0, 0, 1, 1, 2, 2, 0, 3, 1, 0, 1, 0, 3, 0, 0, 0, 0, 0, 2, 1, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 43 and the episode is 1281 and the total_steps are 83121\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 2, 0, 0, 2, 2, 1, 0, 3, 1, 0, 1, 0, 1, 3, 3, 1, 3, 1, 1, 2, 2, 2, 1, 3, 2, 2, 0, 1, 2, 3, 2, 1, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 40 and the episode is 1282 and the total_steps are 83161\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 2, 0, 0, 1, 3, 0, 1, 3, 2, 1, 2, 3, 2, 0, 3, 0, 3, 0, 3, 3, 3, 0, 1, 2, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 32 and the episode is 1283 and the total_steps are 83193\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 1, 3, 3, 0, 0, 3, 0, 2, 1, 1, 0, 3, 0, 2, 3, 1, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 1284 and the total_steps are 83217\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1284     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2137     |\n",
      "|    total_timesteps  | 83217    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.534    |\n",
      "|    n_updates        | 8304     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 2, 0, 1, 2, 2, 2, 3, 1, 2, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 17 and the episode is 1285 and the total_steps are 83234\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 0, 0, 1, 0, 3, 3, 0, 0, 3, 3, 1, 1, 0, 1, 1, 2, 1, 3, 0, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 27 and the episode is 1286 and the total_steps are 83261\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 2, 2, 1, 1, 0, 3, 2, 0, 3, 2, 0, 1, 3, 1, 3, 3, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 24 and the episode is 1287 and the total_steps are 83285\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 2, 2, 0, 1, 2, 3, 1, 2, 1, 0, 2, 3, 3, 2, 0, 0, 3, 3, 0, 2, 0, 3, 0, 3, 2, 2, 1, 3, 1, 0, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 38 and the episode is 1288 and the total_steps are 83323\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1288     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2141     |\n",
      "|    total_timesteps  | 83323    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 8330     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 2, 3, 0, 2, 3, 2, 0, 2, 0, 3, 0, 3, 2, 3, 1, 3, 3, 1, 0, 0, 3, 0, 2, 2, 3, 2, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 34 and the episode is 1289 and the total_steps are 83357\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 1, 3, 1, 2, 3, 0, 3, 1, 1, 2, 2, 3, 3, 2, 0, 1, 1, 3, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 26 and the episode is 1290 and the total_steps are 83383\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 3, 3, 2, 1, 3, 2, 0, 2, 1, 3, 0, 3, 3, 2, 3, 2, 3, 0, 3, 2, 0, 1, 0, 3, 0, 0, 1, 0, 1, 3, 1, 1, 2, 3, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 42 and the episode is 1291 and the total_steps are 83425\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 3, 1, 0, 2, 0, 3, 0, 2, 2, 0, 3, 2, 2, 2, 2, 1, 0, 2, 0, 3, 2, 1, 2, 3, 1, 2, 1, 3, 1, 3, 1, 0, 3, 3, 1, 2, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 44 and the episode is 1292 and the total_steps are 83469\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1292     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2147     |\n",
      "|    total_timesteps  | 83469    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.56     |\n",
      "|    n_updates        | 8367     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 3, 2, 3, 2, 3, 1, 1, 0, 0, 3, 2, 1, 2, 0, 2, 1, 1, 1, 1, 3, 2, 3, 2, 1, 1, 0, 3, 3, 2, 1, 3, 1, 1, 3, 2, 1, 0, 1, 0, 3, 1, 2, 2, 1, 1, 1, 1, 2, 3, 3, 0, 0, 2, 0, 3, 1, 3, 1, 0, 0, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 68 and the episode is 1293 and the total_steps are 83537\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 1, 2, 3, 1, 3, 0, 1, 3, 1, 2, 3, 2, 0, 2, 1, 0, 3, 3, 2, 0, 0, 2, 0, 2, 3, 2, 1, 0, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 3, 3, 1, 3, 3, 2, 2, 1, 2, 0, 2, 3, 3, 3, 0, 2, 0, 0, 2, 2, 1, 3, 3, 0, 1, 1, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1070. And steps were 72 and the episode is 1294 and the total_steps are 83609\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 0, 1, 3, 2, 2, 2, 3, 3, 2, 0, 1, 1, 0, 3, 3, 0, 1, 1, 0, 2, 1, 1, 2, 1, 3, 2, 3, 0, 3, 2, 2, 2, 0, 2, 3, 1, 0, 3, 2, 0, 1, 3, 3, 1, 1, 3, 3, 0, 0, 1, 1, 0, 3, 1, 0, 3, 0, 3, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 66 and the episode is 1295 and the total_steps are 83675\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 1, 2, 3, 1, 0, 1, 0, 0, 0, 0, 1, 3, 2, 2, 3, 1, 0, 0, 1, 2, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 28 and the episode is 1296 and the total_steps are 83703\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1296     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2156     |\n",
      "|    total_timesteps  | 83703    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.778    |\n",
      "|    n_updates        | 8425     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 2, 1, 1, 0, 3, 2, 0, 1, 1, 3, 0, 2, 2, 2, 0, 1, 2, 3, 3, 1, 0, 1, 2, 2, 0, 2, 2, 3, 2, 0, 0, 2, 1, 0, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 51 and the episode is 1297 and the total_steps are 83754\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 1, 3, 2, 1, 3, 3, 1, 1, 1, 0, 3, 0, 1, 3, 2, 0, 1, 0, 0, 2, 2, 1, 3, 3, 2, 2, 1, 1, 1, 3, 1, 0, 2, 0, 1, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 43 and the episode is 1298 and the total_steps are 83797\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 3, 3, 3, 2, 2, 1, 0, 1, 0, 3, 1, 3, 0, 1, 0, 1, 2, 0, 3, 3, 3, 3, 3, 3, 2, 1, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 34 and the episode is 1299 and the total_steps are 83831\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 2, 1, 2, 3, 0, 1, 3, 2, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 1300 and the total_steps are 83857\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2162     |\n",
      "|    total_timesteps  | 83857    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.448    |\n",
      "|    n_updates        | 8464     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 2, 3, 2, 2, 0, 1, 0, 3, 1, 1, 2, 3, 3, 0, 2, 3, 3, 0, 3, 3, 1, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 29 and the episode is 1301 and the total_steps are 83886\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 1, 2, 0, 2, 1, 0, 0, 1, 3, 0, 1, 0, 3, 2, 1, 2, 3, 1, 2, 3, 3, 3, 2, 1, 3, 0, 3, 0, 0, 1, 3, 1, 0, 3, 2, 1, 1, 3, 3, 1, 2, 3, 3, 2, 0, 2, 3, 1, 2, 3, 3, 1, 0, 2, 0, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1061. And steps were 63 and the episode is 1302 and the total_steps are 83949\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 3, 0, 1, 3, 2, 0, 2, 3, 1, 2, 2, 0, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 1303 and the total_steps are 83969\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 3, 0, 0, 2, 3, 3, 0, 2, 2, 2, 1, 2, 0, 2, 1, 0, 3, 3, 3, 1, 0, 3, 1, 0, 2, 2, 3, 1, 0, 2, 1, 0, 1, 3, 3, 0, 2, 0, 1, 0, 3, 0, 0, 0, 3, 2, 1, 1, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 56 and the episode is 1304 and the total_steps are 84025\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1304     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2168     |\n",
      "|    total_timesteps  | 84025    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 8506     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 2, 0, 0, 3, 0, 1, 1, 1, 2, 2, 3, 0, 1, 2, 3, 0, 0, 1, 1, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 27 and the episode is 1305 and the total_steps are 84052\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 3, 0, 2, 2, 3, 0, 2, 0, 1, 2, 3, 0, 3, 0, 2, 1, 3, 3, 1, 2, 0, 0, 0, 1, 3, 3, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 33 and the episode is 1306 and the total_steps are 84085\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 0, 0, 2, 3, 1, 0, 0, 2, 2, 1, 1, 0, 1, 3, 2, 0, 0, 3, 1, 3, 0, 0, 0, 2, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 1307 and the total_steps are 84117\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 1, 2, 1, 3, 0, 0, 2, 3, 0, 0, 2, 1, 2, 2, 3, 2, 3, 3, 1, 0, 2, 0, 2, 2, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 1308 and the total_steps are 84149\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1308     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2174     |\n",
      "|    total_timesteps  | 84149    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.5     |\n",
      "|    n_updates        | 8537     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 3, 1, 0, 3, 3, 1, 3, 0, 3, 2, 1, 0, 0, 2, 3, 2, 2, 2, 3, 3, 3, 0, 1, 1, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was 1029. And steps were 30 and the episode is 1309 and the total_steps are 84179\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 2, 2, 0, 2, 1, 3, 2, 3, 2, 2, 2, 2, 2, 3, 0, 0, 2, 2, 0, 3, 1, 1, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 30 and the episode is 1310 and the total_steps are 84209\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 2, 3, 3, 3, 2, 0, 2, 2, 3, 1, 3, 3, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 25 and the episode is 1311 and the total_steps are 84234\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 1, 0, 1, 2, 3, 0, 3, 0, 3, 0, 3, 0, 1, 2, 3, 3, 3, 2, 1, 2, 3, 2, 1, 3, 3, 1, 0, 0, 3, 0, 2, 0, 0, 3, 3, 0, 0, 1, 1, 1, 2, 2, 1, 0, 0, 3, 1, 0, 2, 3, 0, 3, 2, 2, 2, 3, 0, 3, 1, 3, 1, 1, 3, 3, 3, 0, 3, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 75 and the episode is 1312 and the total_steps are 84309\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1312     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2180     |\n",
      "|    total_timesteps  | 84309    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.3     |\n",
      "|    n_updates        | 8577     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 0, 0, 3, 2, 3, 3, 1, 0, 3, 2, 3, 2, 2, 3, 1, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 23 and the episode is 1313 and the total_steps are 84332\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 3, 3, 0, 2, 3, 3, 0, 1, 2, 2, 2, 0, 0, 0, 3, 2, 2, 2, 3, 1, 1, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1314 and the total_steps are 84361\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 0, 0, 3, 2, 3, 0, 0, 1, 2, 2, 1, 0, 1, 2, 3, 1, 3, 3, 3, 2, 1, 0, 2, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 1315 and the total_steps are 84392\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 3, 1, 1, 1, 0, 1, 1, 0, 3, 0, 2, 3, 0, 0, 0, 2, 0, 0, 2, 1, 3, 1, 3, 2, 3, 1, 1, 3, 2, 3, 2, 2, 0, 1, 1, 3, 2, 0, 2, 0, 3, 2, 3, 0, 2, 2, 1, 2, 1, 0, 1, 3, 3, 1, 1, 3, 1, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 65 and the episode is 1316 and the total_steps are 84457\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1316     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2186     |\n",
      "|    total_timesteps  | 84457    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.6     |\n",
      "|    n_updates        | 8614     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 2, 2, 3, 0, 3, 0, 1, 3, 3, 1, 1, 1, 0, 2, 2, 0, 1, 3, 0, 0, 2, 0, 3, 0, 1, 1, 0, 0, 3, 0, 3, 2, 3, 1, 2, 1, 2, 0, 2, 1, 3, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 2, 1, 0, 0, 0, 2, 1, 3, 1, 2, 2, 2, 0, 2, 0, 3, 3, 1, 1, 1, 1, 3, 3, 0, 0, 2, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 96 and the episode is 1317 and the total_steps are 84553\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 3, 2, 1, 0, 2, 2, 1, 0, 0, 2, 3, 2, 1, 0, 2, 1, 3, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 25 and the episode is 1318 and the total_steps are 84578\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0, 1, 3, 2, 0, 3, 3, 2, 0, 0, 0, 1, 2, 1, 0, 0, 3, 2, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 34 and the episode is 1319 and the total_steps are 84612\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 3, 1, 3, 0, 2, 0, 2, 1, 3, 2, 3, 1, 0, 2, 3, 1, 0, 1, 0, 3, 2, 2, 3, 1, 0, 2, 2, 2, 0, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 37 and the episode is 1320 and the total_steps are 84649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -935     |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1320     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2194     |\n",
      "|    total_timesteps  | 84649    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 8662     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 2, 2, 2, 1, 3, 1, 0, 2, 1, 3, 1, 2, 0, 0, 1, 3, 0, 0, 0, 1, 3, 2, 0, 2, 2, 2, 2, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 1321 and the total_steps are 84684\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 0, 1, 0, 2, 0, 1, 3, 0, 2, 3, 3, 0, 0, 3, 3, 0, 3, 2, 3, 3, 3, 0, 2, 1, 2, 2, 3, 2, 2, 0, 3, 3, 0, 3, 0, 2, 1, 1, 3, 3, 1, 1, 3, 1, 2, 2, 1, 1, 0, 2, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 58 and the episode is 1322 and the total_steps are 84742\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 3, 1, 2, 0, 1, 3, 1, 0, 3, 2, 3, 1, 1, 3, 2, 0, 2, 3, 3, 1, 1, 1, 3, 2, 3, 1, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 34 and the episode is 1323 and the total_steps are 84776\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 3, 2, 1, 0, 1, 3, 3, 2, 1, 2, 1, 1, 0, 1, 1, 2, 1, 2, 3, 2, 1, 1, 1, 0, 0, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 1324 and the total_steps are 84809\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -935     |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1324     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2200     |\n",
      "|    total_timesteps  | 84809    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 8702     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 3, 1, 0, 1, 1, 0, 3, 2, 1, 1, 1, 2, 1, 3, 1, 0, 2, 1, 3, 3, 0, 1, 0, 2, 2, 3, 0, 1, 0, 2, 2, 2, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 1325 and the total_steps are 84849\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 1, 3, 0, 2, 3, 1, 2, 1, 3, 2, 0, 0, 2, 0, 1, 0, 3, 0, 2, 3, 2, 3, 2, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 1326 and the total_steps are 84880\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 2, 0, 1, 1, 3, 1, 3, 0, 0, 2, 2, 2, 3, 0, 0, 3, 1, 1, 1, 3, 2, 3, 0, 2, 1, 3, 2, 0, 1, 0, 0, 1, 2, 1, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 1327 and the total_steps are 84922\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 2, 1, 1, 1, 2, 2, 0, 1, 1, 0, 1, 0, 1, 0, 1, 2, 3, 0, 1, 2, 1, 3, 0, 1, 3, 2, 1, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 1328 and the total_steps are 84957\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1328     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2206     |\n",
      "|    total_timesteps  | 84957    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.18     |\n",
      "|    n_updates        | 8739     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 0, 0, 2, 1, 0, 1, 1, 1, 2, 2, 2, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 19 and the episode is 1329 and the total_steps are 84976\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 3, 1, 0, 2, 0, 1, 1, 1, 0, 2, 2, 3, 3, 1, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1017. And steps were 20 and the episode is 1330 and the total_steps are 84996\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 1, 3, 3, 1, 1, 3, 0, 3, 1, 2, 2, 2, 0, 2, 2, 2, 1, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 25 and the episode is 1331 and the total_steps are 85021\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 0, 0, 2, 1, 1, 2, 1, 3, 0, 0, 1, 0, 2, 3, 3, 1, 2, 3, 3, 1, 2, 0, 1, 0, 2, 3, 0, 3, 0, 2, 3, 1, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 40 and the episode is 1332 and the total_steps are 85061\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1332     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2210     |\n",
      "|    total_timesteps  | 85061    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 8765     |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 0, 0, 1, 3, 2, 3, 0, 3, 1, 0, 3, 1, 1, 1, 1, 2, 1, 1, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 1333 and the total_steps are 85085\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 1, 1, 2, 1, 0, 2, 0, 2, 1, 3, 1, 3, 3, 3, 2, 0, 3, 2, 0, 1, 3, 1, 0, 1, 0, 3, 2, 1, 3, 2, 0, 2, 2, 1, 0, 3, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 44 and the episode is 1334 and the total_steps are 85129\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 0, 1, 2, 2, 2, 3, 0, 3, 2, 0, 1, 0, 2, 1, 0, 0, 0, 3, 2, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 0, 0, 2, 3, 3, 0, 0, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 44 and the episode is 1335 and the total_steps are 85173\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 3, 0, 1, 2, 3, 1, 1, 1, 3, 2, 2, 3, 1, 3, 1, 0, 2, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 25 and the episode is 1336 and the total_steps are 85198\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1336     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2216     |\n",
      "|    total_timesteps  | 85198    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 8799     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 1, 1, 1, 1, 3, 2, 2, 1, 3, 3, 2, 1, 0, 2, 1, 1, 1, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 25 and the episode is 1337 and the total_steps are 85223\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 1, 1, 1, 0, 3, 2, 0, 0, 1, 2, 2, 1, 0, 0, 0, 3, 3, 1, 2, 3, 1, 3, 1, 1, 0, 3, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 34 and the episode is 1338 and the total_steps are 85257\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 3, 1, 1, 1, 0, 1, 0, 3, 2, 0, 3, 2, 2, 0, 0, 2, 0, 2, 0, 2, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 1339 and the total_steps are 85285\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 1, 0, 2, 3, 3, 2, 1, 2, 0, 2, 1, 3, 1, 2, 3, 0, 1, 3, 1, 2, 0, 3, 0, 0, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1340 and the total_steps are 85317\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1340     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2221     |\n",
      "|    total_timesteps  | 85317    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.614    |\n",
      "|    n_updates        | 8829     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 3, 2, 1, 1, 3, 3, 0, 1, 3, 3, 0, 2, 1, 0, 0, 1, 2, 2, 1, 0, 3, 1, 2, 2, 2, 1, 2, 3, 0, 1, 3, 3, 2, 0, 3, 1, 0, 3, 0, 3, 2, 2, 0, 3, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 1341 and the total_steps are 85369\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 2, 2, 2, 2, 1, 1, 2, 2, 3, 0, 1, 2, 3, 1, 1, 0, 0, 2, 0, 0, 2, 3, 0, 2, 2, 0, 3, 0, 2, 2, 2, 2, 3, 3, 3, 0, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 44 and the episode is 1342 and the total_steps are 85413\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 0, 0, 1, 3, 1, 0, 2, 2, 0, 0, 3, 0, 2, 1, 2, 0, 3, 0, 1, 0, 1, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1343 and the total_steps are 85442\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 3, 0, 0, 0, 0, 3, 0, 2, 1, 3, 3, 0, 2, 0, 1, 0, 0, 2, 0, 1, 1, 3, 0, 1, 3, 1, 3, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 35 and the episode is 1344 and the total_steps are 85477\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1344     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2227     |\n",
      "|    total_timesteps  | 85477    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.9     |\n",
      "|    n_updates        | 8869     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 0, 1, 1, 3, 0, 3, 1, 1, 1, 2, 3, 2, 3, 3, 1, 1, 3, 1, 0, 2, 3, 1, 2, 0, 2, 1, 1, 3, 0, 2, 1, 2, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 2, 2, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 52 and the episode is 1345 and the total_steps are 85529\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 1, 1, 3, 2, 2, 3, 0, 0, 0, 2, 0, 2, 0, 2, 3, 3, 0, 2, 1, 3, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 1346 and the total_steps are 85557\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 2, 1, 3, 2, 3, 1, 1, 1, 0, 1, 2, 0, 3, 2, 1, 2, 1, 3, 0, 2, 0, 3, 0, 0, 2, 0, 2, 0, 2, 3, 0, 2, 2, 3, 2, 3, 3, 0, 1, 3, 2, 2, 3, 0, 0, 3, 1, 1, 2, 0, 0, 0, 3, 0, 2, 2, 1, 1, 0, 1, 2, 2, 3, 3, 0, 1, 1, 2, 3, 0, 3, 1, 3, 2, 2, 2, 2, 1, 1, 3, 0, 1, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 3, 0, 3, 0, 0, 0, 2, 1, 1, 0, 2, 0, 0, 1, 2, 0, 3, 3, 2, 3, 1, 1, 1, 1, 1, 1, 3, 0, 1, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1064. And steps were 136 and the episode is 1347 and the total_steps are 85693\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 0, 2, 3, 1, 2, 2, 0, 2, 2, 0, 2, 2, 0, 1, 2, 2, 1, 3, 3, 1, 0, 3, 0, 3, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1348 and the total_steps are 85725\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1348     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2237     |\n",
      "|    total_timesteps  | 85725    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 8931     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 2, 1, 1, 0, 1, 2, 3, 2, 2, 3, 1, 0, 0, 1, 2, 1, 0, 0, 3, 1, 3, 1, 0, 0, 3, 3, 0, 3, 1, 3, 3, 3, 3, 3, 2, 3, 2, 2, 1, 2, 0, 2, 1, 2, 1, 3, 1, 2, 2, 0, 2, 3, 2, 2, 0, 0, 3, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 1, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 76 and the episode is 1349 and the total_steps are 85801\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 0, 1, 1, 1, 3, 3, 2, 3, 2, 0, 0, 3, 3, 2, 1, 3, 3, 3, 1, 2, 0, 3, 3, 2, 1, 3, 2, 3, 2, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 37 and the episode is 1350 and the total_steps are 85838\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 3, 3, 2, 3, 3, 3, 1, 3, 1, 2, 3, 2, 2, 3, 2, 0, 3, 3, 2, 1, 2, 3, 2, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 31 and the episode is 1351 and the total_steps are 85869\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 0, 3, 3, 1, 0, 2, 2, 3, 0, 2, 3, 3, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 20 and the episode is 1352 and the total_steps are 85889\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1352     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2244     |\n",
      "|    total_timesteps  | 85889    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 8972     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 3, 2, 2, 1, 1, 3, 3, 3, 1, 0, 0, 3, 0, 2, 3, 2, 0, 1, 1, 3, 0, 2, 3, 3, 3, 1, 2, 2, 1, 1, 3, 1, 3, 2, 2, 2, 3, 3, 1, 2, 2, 0, 3, 0, 1, 3, 3, 1, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 56 and the episode is 1353 and the total_steps are 85945\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 1, 2, 3, 1, 2, 2, 1, 3, 0, 3, 0, 1, 2, 2, 0, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 1354 and the total_steps are 85977\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 2, 3, 2, 1, 1, 2, 1, 1, 3, 2, 2, 2, 0, 0, 1, 1, 3, 2, 1, 2, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 1355 and the total_steps are 86005\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 2, 1, 3, 2, 0, 2, 2, 3, 2, 3, 2, 1, 3, 1, 1, 3, 3, 2, 2, 2, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 1356 and the total_steps are 86033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1356     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2249     |\n",
      "|    total_timesteps  | 86033    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 9008     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 3, 3, 1, 2, 3, 3, 3, 1, 2, 2, 3, 3, 3, 1, 3, 2, 3, 0, 1, 2, 0, 2, 0, 1, 3, 2, 1, 1, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 3, 0, 2, 2, 2, 2, 0, 3, 0, 1, 3, 2, 2, 2, 3, 2, 2, 3, 0, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 64 and the episode is 1357 and the total_steps are 86097\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 0, 2, 1, 1, 2, 0, 3, 2, 2, 1, 0, 2, 0, 2, 0, 1, 0, 0, 2, 3, 1, 0, 0, 0, 2, 2, 3, 3, 0, 2, 0, 2, 1, 3, 0, 2, 1, 0, 2, 3, 0, 2, 1, 3, 1, 2, 1, 0, 1, 2, 0, 0, 2, 2, 1, 0, 3, 2, 1, 0, 1, 3, 2, 3, 1, 1, 0, 2, 3, 3, 0, 1, 0, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1041. And steps were 81 and the episode is 1358 and the total_steps are 86178\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 1, 2, 2, 1, 3, 0, 3, 1, 1, 1, 2, 3, 3, 1, 0, 1, 1, 3, 3, 2, 3, 1, 1, 0, 0, 3, 3, 2, 0, 3, 2, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 39 and the episode is 1359 and the total_steps are 86217\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 0, 2, 1, 0, 0, 3, 3, 2, 3, 1, 2, 3, 1, 1, 2, 1, 1, 3, 3, 3, 3, 3, 1, 1, 3, 0, 3, 2, 1, 1, 1, 3, 1, 0, 0, 3, 3, 0, 0, 3, 1, 0, 0, 1, 2, 0, 3, 2, 0, 3, 1, 0, 3, 2, 1, 3, 3, 3, 1, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 67 and the episode is 1360 and the total_steps are 86284\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1360     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2259     |\n",
      "|    total_timesteps  | 86284    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.397    |\n",
      "|    n_updates        | 9070     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 3, 3, 2, 2, 3, 2, 1, 0, 1, 2, 2, 3, 0, 0, 0, 3, 3, 1, 0, 0, 1, 0, 3, 2, 3, 2, 0, 1, 2, 3, 2, 3, 3, 3, 2, 0, 3, 2, 2, 2, 2, 2, 3, 0, 3, 2, 0, 1, 3, 0, 1, 1, 0, 2, 2, 1, 3, 0, 3, 2, 3, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -941. And steps were 69 and the episode is 1361 and the total_steps are 86353\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 1, 0, 0, 2, 2, 1, 2, 0, 2, 0, 1, 3, 0, 0, 0, 1, 1, 1, 2, 1, 2, 0, 0, 3, 3, 2, 2, 3, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 36 and the episode is 1362 and the total_steps are 86389\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 3, 0, 0, 3, 2, 3, 3, 1, 2, 1, 1, 3, 3, 1, 3, 1, 3, 0, 2, 0, 1, 0, 1, 1, 3, 0, 0, 0, 2, 2, 2, 3, 1, 1, 2, 3, 1, 2, 0, 2, 3, 3, 3, 3, 1, 1, 1, 2, 3, 3, 1, 3, 0, 2, 0, 2, 0, 3, 2, 1, 0, 2, 2, 1, 2, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 1, 3, 2, 0, 0, 1, 3, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1058. And steps were 90 and the episode is 1363 and the total_steps are 86479\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 3, 1, 2, 1, 1, 3, 3, 0, 0, 1, 2, 0, 3, 0, 3, 0, 0, 1, 2, 3, 1, 1, 0, 3, 3, 2, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 34 and the episode is 1364 and the total_steps are 86513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1364     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2268     |\n",
      "|    total_timesteps  | 86513    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 9128     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 0, 3, 3, 3, 2, 3, 0, 3, 1, 1, 2, 0, 2, 2, 0, 0, 0, 1, 2, 2, 0, 3, 2, 1, 0, 3, 0, 1, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 36 and the episode is 1365 and the total_steps are 86549\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 2, 1, 1, 0, 3, 2, 2, 3, 2, 1, 1, 0, 2, 3, 1, 1, 3, 1, 3, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 1366 and the total_steps are 86576\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 3, 1, 3, 2, 3, 1, 1, 0, 3, 2, 2, 1, 0, 2, 1, 1, 0, 2, 1, 3, 0, 1, 3, 3, 3, 2, 0, 3, 0, 1, 1, 2, 3, 2, 3, 0, 3, 0, 2, 0, 2, 1, 1, 2, 1, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 53 and the episode is 1367 and the total_steps are 86629\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 0, 3, 2, 3, 0, 0, 2, 2, 3, 3, 2, 2, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 1368 and the total_steps are 86649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1368     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2274     |\n",
      "|    total_timesteps  | 86649    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 9162     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 2, 2, 3, 0, 3, 2, 1, 3, 1, 2, 0, 2, 2, 0, 1, 3, 3, 3, 2, 0, 1, 2, 2, 3, 2, 2, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 34 and the episode is 1369 and the total_steps are 86683\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 0, 3, 2, 2, 3, 2, 3, 0, 3, 1, 1, 1, 1, 1, 0, 0, 0, 3, 2, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 27 and the episode is 1370 and the total_steps are 86710\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 3, 1, 3, 2, 2, 0, 3, 3, 0, 1, 1, 1, 0, 0, 1, 0, 3, 1, 2, 0, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 3, 2, 3, 3, 1, 1, 2, 0, 1, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 47 and the episode is 1371 and the total_steps are 86757\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 0, 3, 3, 0, 3, 1, 0, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 3, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 26 and the episode is 1372 and the total_steps are 86783\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1372     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2280     |\n",
      "|    total_timesteps  | 86783    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 9195     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 1, 1, 3, 0, 0, 0, 1, 1, 2, 3, 3, 3, 0, 1, 2, 0, 1, 1, 1, 0, 1, 0, 0, 3, 0, 3, 2, 1, 0, 2, 0, 0, 3, 0, 1, 3, 0, 0, 0, 2, 0, 2, 2, 1, 0, 0, 3, 1, 1, 2, 3, 1, 2, 2, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 62 and the episode is 1373 and the total_steps are 86845\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 1, 3, 2, 3, 3, 2, 2, 2, 2, 0, 1, 3, 2, 2, 2, 1, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 24 and the episode is 1374 and the total_steps are 86869\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 3, 2, 0, 0, 1, 2, 0, 0, 1, 1, 0, 3, 3, 0, 2, 2, 0, 1, 0, 2, 0, 3, 1, 1, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1375 and the total_steps are 86901\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 1, 1, 0, 0, 1, 0, 1, 0, 2, 1, 0, 2, 3, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 32 and the episode is 1376 and the total_steps are 86933\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1376     |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 2286     |\n",
      "|    total_timesteps  | 86933    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.1     |\n",
      "|    n_updates        | 9233     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 1, 2, 3, 3, 1, 3, 1, 1, 1, 2, 1, 2, 1, 2, 3, 2, 3, 0, 3, 3, 1, 0, 2, 1, 1, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 33 and the episode is 1377 and the total_steps are 86966\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 1, 2, 1, 3, 1, 2, 1, 1, 3, 1, 3, 1, 3, 1, 2, 0, 2, 0, 1, 3, 1, 3, 1, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 31 and the episode is 1378 and the total_steps are 86997\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 3, 1, 1, 2, 3, 1, 3, 0, 1, 2, 2, 2, 0, 3, 3, 1, 3, 2, 3, 2, 3, 3, 3, 2, 1, 2, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 34 and the episode is 1379 and the total_steps are 87031\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 2, 3, 0, 2, 0, 0, 0, 2, 2, 1, 3, 3, 1, 2, 3, 1, 2, 1, 3, 1, 1, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 29 and the episode is 1380 and the total_steps are 87060\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1380     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2291     |\n",
      "|    total_timesteps  | 87060    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.412    |\n",
      "|    n_updates        | 9264     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 1, 2, 3, 2, 3, 0, 2, 3, 0, 0, 2, 3, 1, 0, 0, 2, 1, 2, 3, 0, 3, 2, 0, 0, 1, 2, 0, 1, 0, 3, 2, 3, 3, 3, 2, 3, 2, 0, 0, 2, 1, 0, 1, 3, 1, 1, 1, 3, 3, 2, 1, 2, 3, 3, 0, 3, 2, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 65 and the episode is 1381 and the total_steps are 87125\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 2, 0, 3, 2, 0, 2, 3, 2, 1, 1, 1, 0, 2, 2, 3, 1, 3, 3, 3, 1, 0, 2, 0, 0, 2, 3, 0, 1, 2, 2, 1, 2, 3, 1, 0, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 43 and the episode is 1382 and the total_steps are 87168\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 0, 0, 0, 1, 1, 3, 1, 1, 1, 0, 2, 3, 2, 2, 2, 1, 0, 0, 3, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 1383 and the total_steps are 87193\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 3, 3, 2, 1, 2, 2, 1, 1, 0, 3, 2, 2, 0, 1, 0, 2, 1, 2, 1, 1, 2, 3, 2, 2, 2, 3, 3, 2, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 1384 and the total_steps are 87229\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1384     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2298     |\n",
      "|    total_timesteps  | 87229    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.5     |\n",
      "|    n_updates        | 9307     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 1, 2, 2, 1, 1, 3, 2, 3, 1, 2, 3, 0, 3, 1, 1, 2, 1, 2, 0, 0, 2, 3, 2, 2, 3, 1, 2, 1, 3, 2, 2, 2, 2, 1, 3, 1, 0, 0, 1, 3, 3, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 49 and the episode is 1385 and the total_steps are 87278\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 0, 2, 3, 2, 0, 0, 3, 2, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 3, 2, 0, 2, 1, 0, 2, 1, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 37 and the episode is 1386 and the total_steps are 87315\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 2, 3, 1, 1, 2, 3, 0, 0, 1, 0, 0, 2, 2, 1, 3, 2, 3, 1, 1, 2, 0, 0, 1, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 1387 and the total_steps are 87346\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 2, 0, 3, 2, 2, 2, 3, 1, 2, 1, 3, 0, 0, 2, 3, 2, 0, 0, 3, 1, 2, 3, 2, 0, 0, 0, 3, 2, 0, 1, 2, 3, 3, 1, 2, 0, 1, 2, 0, 1, 2, 1, 3, 2, 2, 2, 2, 3, 1, 1, 0, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 59 and the episode is 1388 and the total_steps are 87405\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1388     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2305     |\n",
      "|    total_timesteps  | 87405    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34       |\n",
      "|    n_updates        | 9351     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 3, 3, 1, 3, 0, 1, 0, 0, 3, 3, 0, 1, 1, 1, 2, 1, 0, 3, 3, 1, 0, 0, 0, 3, 1, 0, 0, 0, 1, 2, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 38 and the episode is 1389 and the total_steps are 87443\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 0, 2, 2, 0, 3, 3, 0, 2, 1, 2, 2, 1, 1, 2, 0, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1018. And steps were 21 and the episode is 1390 and the total_steps are 87464\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 3, 1, 3, 2, 0, 3, 1, 2, 2, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 3, 0, 3, 2, 1, 0, 3, 0, 3, 1, 3, 0, 3, 2, 1, 0, 1, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 47 and the episode is 1391 and the total_steps are 87511\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 1, 1, 0, 0, 2, 0, 1, 2, 2, 2, 1, 0, 0, 3, 1, 1, 0, 3, 3, 3, 3, 2, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1392 and the total_steps are 87541\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1392     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2310     |\n",
      "|    total_timesteps  | 87541    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 9385     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 2, 1, 1, 1, 3, 3, 3, 2, 1, 2, 1, 3, 3, 1, 0, 1, 2, 2, 2, 1, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 1393 and the total_steps are 87569\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 2, 2, 3, 3, 3, 0, 0, 0, 1, 2, 0, 0, 3, 0, 3, 3, 3, 0, 1, 1, 1, 0, 1, 1, 1, 3, 0, 1, 3, 0, 2, 1, 3, 1, 2, 0, 2, 3, 2, 0, 2, 0, 1, 1, 2, 2, 2, 1, 1, 2, 1, 3, 2, 3, 3, 2, 0, 3, 2, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was 970. And steps were 65 and the episode is 1394 and the total_steps are 87634\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 3, 3, 2, 1, 3, 1, 3, 1, 2, 3, 1, 3, 0, 1, 0, 0, 2, 2, 2, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 27 and the episode is 1395 and the total_steps are 87661\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 0, 0, 2, 3, 0, 0, 3, 1, 3, 0, 3, 0, 1, 3, 1, 0, 1, 0, 2, 2, 1, 2, 0, 2, 0, 2, 1, 3, 0, 0, 1, 3, 0, 3, 3, 1, 1, 1, 1, 1, 0, 2, 3, 0, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 52 and the episode is 1396 and the total_steps are 87713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1396     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2317     |\n",
      "|    total_timesteps  | 87713    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 9428     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 3, 1, 3, 0, 3, 3, 0, 2, 0, 2, 1, 0, 0, 0, 3, 1, 2, 0, 0, 2, 0, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 38 and the episode is 1397 and the total_steps are 87751\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 2, 1, 3, 3, 1, 1, 0, 0, 2, 0, 1, 0, 2, 2, 3, 3, 2, 1, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 26 and the episode is 1398 and the total_steps are 87777\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 1, 0, 1, 3, 0, 2, 1, 3, 1, 1, 0, 1, 0, 0, 3, 0, 0, 1, 3, 0, 2, 0, 2, 3, 2, 3, 0, 0, 1, 2, 1, 1, 1, 2, 2, 0, 2, 2, 0, 2, 1, 2, 1, 0, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 52 and the episode is 1399 and the total_steps are 87829\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 1, 0, 2, 0, 2, 1, 2, 3, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 27 and the episode is 1400 and the total_steps are 87856\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2323     |\n",
      "|    total_timesteps  | 87856    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 9463     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 2, 2, 0, 2, 0, 2, 1, 1, 2, 3, 2, 2, 2, 0, 0, 0, 3, 3, 3, 0, 1, 2, 2, 2, 0, 0, 0, 1, 1, 3, 3, 0, 1, 1, 1, 3, 1, 1, 1, 3, 2, 0, 3, 3, 2, 0, 0, 1, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 56 and the episode is 1401 and the total_steps are 87912\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 0, 0, 1, 3, 3, 1, 2, 3, 1, 0, 3, 0, 0, 3, 2, 3, 2, 2, 0, 3, 2, 2, 2, 3, 3, 0, 0, 3, 1, 1, 2, 2, 2, 2, 2, 1, 0, 0, 1, 2, 1, 1, 2, 0, 1, 3, 0, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 54 and the episode is 1402 and the total_steps are 87966\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 2, 1, 0, 0, 0, 0, 1, 2, 2, 3, 1, 0, 3, 0, 3, 0, 0, 2, 3, 1, 0, 3, 3, 2, 3, 0, 2, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 35 and the episode is 1403 and the total_steps are 88001\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 0, 0, 1, 1, 1, 3, 2, 1, 3, 1, 3, 1, 0, 3, 3, 1, 1, 1, 2, 2, 0, 2, 3, 2, 0, 0, 0, 0, 2, 1, 3, 1, 0, 3, 2, 1, 0, 0, 1, 3, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 1404 and the total_steps are 88049\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1404     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2331     |\n",
      "|    total_timesteps  | 88049    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 9512     |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 2, 1, 2, 2, 3, 1, 3, 1, 1, 2, 0, 1, 3, 0, 2, 1, 3, 1, 3, 0, 2, 0, 3, 0, 1, 2, 0, 1, 2, 0, 0, 0, 3, 2, 0, 0, 1, 1, 3, 3, 1, 2, 1, 3, 3, 2, 2, 2, 1, 3, 1, 0, 2, 1, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 62 and the episode is 1405 and the total_steps are 88111\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 0, 3, 0, 1, 1, 3, 3, 3, 0, 1, 2, 1, 3, 2, 1, 1, 2, 3, 1, 3, 2, 3, 0, 1, 3, 0, 0, 1, 0, 0, 1, 3, 2, 1, 3, 2, 3, 2, 1, 3, 1, 2, 3, 1, 1, 3, 1, 1, 3, 0, 2, 2, 0, 0, 0, 1, 1, 2, 3, 1, 1, 2, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 70 and the episode is 1406 and the total_steps are 88181\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 1, 0, 1, 1, 3, 3, 3, 3, 2, 3, 0, 0, 3, 0, 3, 2, 3, 2, 0, 0, 3, 1, 0, 2, 2, 2, 1, 1, 0, 2, 1, 2, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 1407 and the total_steps are 88221\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 1, 0, 0, 0, 2, 2, 1, 1, 2, 3, 2, 2, 0, 0, 3, 2, 3, 0, 1, 1, 3, 0, 2, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 31 and the episode is 1408 and the total_steps are 88252\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1408     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2339     |\n",
      "|    total_timesteps  | 88252    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.84     |\n",
      "|    n_updates        | 9562     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 3, 3, 2, 1, 1, 2, 0, 1, 1, 2, 1, 3, 2, 2, 0, 1, 3, 3, 2, 0, 2, 0, 2, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 1, 2, 0, 0, 3, 3, 1, 0, 2, 3, 2, 2, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 54 and the episode is 1409 and the total_steps are 88306\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 0, 0, 3, 1, 0, 3, 2, 3, 0, 3, 2, 3, 2, 0, 2, 2, 1, 1, 1, 1, 3, 0, 0, 0, 2, 2, 0, 2, 0, 0, 3, 1, 0, 0, 3, 0, 0, 3, 2, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 47 and the episode is 1410 and the total_steps are 88353\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 3, 1, 1, 2, 3, 1, 1, 2, 3, 0, 0, 2, 1, 1, 1, 3, 2, 3, 2, 2, 2, 3, 2, 0, 0, 3, 2, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 35 and the episode is 1411 and the total_steps are 88388\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 3, 0, 3, 1, 1, 0, 3, 3, 1, 1, 0, 1, 2, 2, 2, 0, 1, 2, 2, 1, 0, 1, 1, 2, 0, 1, 3, 1, 3, 2, 1, 0, 3, 2, 3, 2, 3, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 46 and the episode is 1412 and the total_steps are 88434\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1412     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2346     |\n",
      "|    total_timesteps  | 88434    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64       |\n",
      "|    n_updates        | 9608     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 3, 3, 2, 0, 0, 0, 3, 3, 1, 0, 3, 2, 0, 3, 2, 0, 3, 3, 1, 2, 1, 0, 2, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 1413 and the total_steps are 88465\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 2, 1, 0, 1, 0, 2, 0, 1, 1, 2, 1, 2, 3, 1, 0, 3, 0, 2, 2, 3, 0, 3, 0, 2, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1414 and the total_steps are 88497\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 3, 3, 3, 1, 0, 1, 2, 1, 3, 3, 0, 2, 1, 1, 1, 3, 3, 2, 3, 1, 0, 2, 3, 1, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 32 and the episode is 1415 and the total_steps are 88529\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 0, 0, 1, 1, 1, 2, 0, 3, 2, 0, 1, 3, 3, 2, 1, 2, 3, 3, 1, 0, 2, 1, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 30 and the episode is 1416 and the total_steps are 88559\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1416     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2351     |\n",
      "|    total_timesteps  | 88559    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.2     |\n",
      "|    n_updates        | 9639     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 0, 3, 0, 3, 0, 0, 0, 2, 1, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 3, 2, 1, 2, 3, 2, 0, 1, 0, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 37 and the episode is 1417 and the total_steps are 88596\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 0, 2, 1, 2, 3, 3, 2, 2, 2, 0, 3, 3, 0, 0, 1, 2, 2, 2, 3, 2, 2, 1, 1, 3, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1418 and the total_steps are 88628\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 0, 3, 0, 2, 2, 0, 0, 0, 3, 3, 2, 2, 1, 2, 1, 3, 0, 3, 0, 2, 1, 1, 1, 3, 0, 2, 1, 1, 1, 2, 1, 2, 2, 0, 0, 3, 1, 1, 1, 2, 3, 3, 2, 0, 2, 2, 1, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1053. And steps were 55 and the episode is 1419 and the total_steps are 88683\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 3, 3, 0, 1, 2, 1, 0, 0, 0, 0, 3, 0, 1, 1, 0, 0, 2, 2, 3, 1, 1, 2, 3, 2, 3, 0, 3, 2, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 36 and the episode is 1420 and the total_steps are 88719\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1420     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2358     |\n",
      "|    total_timesteps  | 88719    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.299    |\n",
      "|    n_updates        | 9679     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 0, 0, 1, 0, 2, 3, 2, 0, 1, 0, 0, 1, 3, 3, 3, 1, 2, 3, 2, 1, 3, 3, 0, 1, 3, 2, 3, 0, 0, 2, 3, 0, 0, 2, 0, 2, 1, 2, 0, 3, 0, 1, 2, 0, 3, 3, 3, 3, 0, 3, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -949. And steps were 57 and the episode is 1421 and the total_steps are 88776\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 2, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 3, 1, 0, 0, 0, 0, 3, 3, 0, 3, 3, 3, 3, 3, 1, 1, 2, 3, 2, 0, 3, 3, 1, 3, 3, 1, 2, 3, 2, 2, 0, 0, 0, 2, 2, 2, 2, 3, 2, 3, 1, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 60 and the episode is 1422 and the total_steps are 88836\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 0, 0, 3, 2, 1, 3, 2, 3, 2, 3, 1, 2, 2, 0, 1, 0, 1, 2, 0, 3, 2, 3, 3, 1, 0, 0, 1, 1, 2, 3, 3, 2, 1, 0, 1, 3, 2, 1, 3, 2, 0, 1, 2, 2, 1, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 53 and the episode is 1423 and the total_steps are 88889\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 3, 0, 2, 2, 2, 1, 2, 1, 3, 1, 1, 1, 2, 3, 1, 3, 0, 1, 2, 2, 1, 1, 2, 0, 2, 3, 3, 0, 3, 1, 2, 3, 2, 0, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 1424 and the total_steps are 88931\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1424     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2366     |\n",
      "|    total_timesteps  | 88931    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 9732     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 1, 3, 1, 0, 0, 3, 2, 3, 2, 2, 2, 1, 3, 0, 2, 2, 2, 0, 1, 1, 3, 0, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 30 and the episode is 1425 and the total_steps are 88961\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 3, 1, 0, 0, 3, 2, 3, 2, 3, 2, 3, 0, 1, 2, 1, 3, 2, 3, 0, 0, 2, 2, 1, 3, 3, 0, 0, 1, 1, 1, 3, 1, 3, 0, 1, 3, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 44 and the episode is 1426 and the total_steps are 89005\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 0, 3, 3, 0, 0, 0, 2, 3, 0, 0, 2, 0, 0, 1, 0, 1, 2, 0, 0, 3, 2, 2, 3, 0, 2, 2, 1, 3, 2, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1035. And steps were 37 and the episode is 1427 and the total_steps are 89042\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 2, 1, 1, 1, 1, 2, 3, 3, 1, 3, 2, 0, 1, 0, 1, 2, 0, 1, 1, 3, 3, 0, 2, 0, 0, 2, 2, 2, 1, 2, 0, 2, 2, 3, 1, 3, 1, 3, 0, 3, 1, 2, 3, 0, 0, 0, 0, 2, 0, 2, 1, 1, 2, 2, 0, 3, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 64 and the episode is 1428 and the total_steps are 89106\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1428     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2373     |\n",
      "|    total_timesteps  | 89106    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.246    |\n",
      "|    n_updates        | 9776     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 2, 1, 2, 3, 2, 1, 3, 1, 0, 0, 3, 0, 0, 3, 0, 3, 1, 2, 0, 0, 2, 2, 1, 0, 1, 0, 2, 2, 0, 0, 2, 2, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 46 and the episode is 1429 and the total_steps are 89152\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 3, 3, 2, 0, 2, 0, 1, 1, 0, 3, 3, 0, 0, 0, 3, 3, 3, 2, 3, 1, 2, 1, 1, 3, 1, 0, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 34 and the episode is 1430 and the total_steps are 89186\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 3, 0, 2, 0, 0, 1, 2, 1, 0, 3, 1, 3, 1, 0, 0, 1, 0, 0, 0, 0, 1, 3, 2, 0, 2, 0, 1, 2, 0, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 37 and the episode is 1431 and the total_steps are 89223\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 2, 0, 1, 2, 3, 1, 2, 3, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 1432 and the total_steps are 89239\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1432     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2378     |\n",
      "|    total_timesteps  | 89239    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.9     |\n",
      "|    n_updates        | 9809     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 3, 1, 2, 2, 0, 1, 1, 1, 2, 2, 1, 0, 0, 2, 2, 1, 3, 2, 3, 0, 2, 0, 1, 1, 1, 2, 1, 3, 1, 3, 3, 0, 0, 3, 1, 0, 0, 2, 3, 3, 3, 0, 1, 0, 0, 3, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 54 and the episode is 1433 and the total_steps are 89293\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 3, 3, 0, 1, 1, 2, 3, 0, 3, 2, 1, 1, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 28 and the episode is 1434 and the total_steps are 89321\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 2, 2, 3, 1, 3, 2, 2, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1, 1, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 27 and the episode is 1435 and the total_steps are 89348\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 0, 1, 0, 0, 2, 3, 3, 2, 3, 3, 2, 1, 1, 0, 2, 0, 1, 0, 1, 2, 2, 1, 3, 0, 0, 2, 3, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 1436 and the total_steps are 89383\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1436     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2384     |\n",
      "|    total_timesteps  | 89383    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 155      |\n",
      "|    n_updates        | 9845     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 0, 0, 0, 1, 1, 2, 2, 2, 3, 1, 2, 3, 3, 1, 2, 1, 3, 1, 2, 3, 1, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 29 and the episode is 1437 and the total_steps are 89412\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 2, 2, 1, 1, 3, 2, 2, 2, 2, 3, 3, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 3, 2, 3, 0, 2, 3, 0, 3, 3, 0, 0, 0, 2, 2, 3, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 45 and the episode is 1438 and the total_steps are 89457\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 3, 3, 1, 2, 2, 1, 3, 0, 3, 0, 3, 1, 1, 2, 0, 1, 0, 2, 0, 2, 0, 3, 0, 2, 0, 0, 2, 0, 3, 3, 3, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 39 and the episode is 1439 and the total_steps are 89496\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 1, 2, 2, 3, 0, 2, 1, 2, 1, 0, 2, 3, 3, 2, 3, 2, 2, 0, 2, 2, 2, 0, 1, 1, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1440 and the total_steps are 89528\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1440     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2390     |\n",
      "|    total_timesteps  | 89528    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 9881     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 1, 3, 2, 2, 2, 1, 3, 1, 2, 0, 0, 0, 0, 2, 1, 0, 2, 1, 2, 1, 2, 0, 0, 3, 3, 1, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 34 and the episode is 1441 and the total_steps are 89562\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 2, 0, 2, 3, 3, 2, 0, 3, 0, 3, 1, 3, 3, 1, 2, 0, 2, 2, 0, 0, 0, 0, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1442 and the total_steps are 89592\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 2, 1, 0, 0, 0, 2, 0, 2, 0, 0, 1, 3, 0, 2, 1, 0, 0, 1, 2, 1, 3, 3, 2, 2, 0, 3, 1, 1, 2, 1, 0, 1, 2, 0, 0, 2, 2, 0, 2, 3, 3, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 49 and the episode is 1443 and the total_steps are 89641\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 3, 0, 2, 0, 1, 0, 1, 2, 1, 1, 2, 1, 1, 2, 0, 3, 3, 2, 0, 0, 0, 0, 2, 1, 2, 0, 3, 1, 0, 1, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 38 and the episode is 1444 and the total_steps are 89679\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1444     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2396     |\n",
      "|    total_timesteps  | 89679    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 9919     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 0, 2, 2, 1, 3, 3, 3, 1, 0, 0, 1, 1, 2, 0, 1, 2, 2, 0, 1, 1, 3, 0, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 30 and the episode is 1445 and the total_steps are 89709\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 0, 3, 2, 1, 0, 1, 3, 2, 3, 2, 2, 3, 3, 2, 0, 3, 0, 2, 0, 1, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 29 and the episode is 1446 and the total_steps are 89738\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 2, 1, 2, 0, 1, 2, 2, 2, 3, 1, 3, 0, 2, 3, 3, 0, 2, 0, 3, 0, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 1447 and the total_steps are 89766\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 1, 3, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 3, 0, 0, 2, 2, 2, 3, 2, 3, 2, 0, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 1448 and the total_steps are 89797\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1448     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2402     |\n",
      "|    total_timesteps  | 89797    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 9949     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 2, 0, 1, 0, 3, 0, 1, 1, 0, 1, 1, 2, 2, 3, 1, 1, 0, 2, 3, 0, 2, 3, 1, 1, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 32 and the episode is 1449 and the total_steps are 89829\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 1, 2, 2, 0, 2, 0, 0, 2, 3, 1, 0, 3, 0, 1, 3, 2, 2, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 25 and the episode is 1450 and the total_steps are 89854\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 3, 3, 2, 1, 1, 3, 0, 2, 0, 0, 2, 1, 3, 0, 1, 2, 2, 0, 2, 3, 0, 3, 1, 1, 0, 3, 1, 0, 0, 2, 1, 3, 1, 1, 0, 1, 2, 3, 3, 1, 0, 1, 2, 1, 1, 2, 1, 3, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 56 and the episode is 1451 and the total_steps are 89910\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 2, 2, 3, 1, 1, 2, 2, 1, 3, 0, 0, 2, 0, 3, 3, 2, 1, 1, 2, 0, 0, 2, 2, 3, 2, 2, 0, 2, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 1452 and the total_steps are 89946\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1452     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2408     |\n",
      "|    total_timesteps  | 89946    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 9986     |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 0, 0, 0, 2, 1, 3, 3, 3, 1, 0, 1, 3, 3, 2, 2, 1, 1, 1, 3, 1, 2, 2, 2, 0, 3, 0, 0, 3, 1, 1, 3, 3, 0, 2, 0, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 43 and the episode is 1453 and the total_steps are 89989\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 1, 2, 3, 2, 3, 2, 3, 1, 1, 2, 3, 3, 2, 2, 0, 1, 2, 3, 2, 0, 1, 0, 3, 0, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 32 and the episode is 1454 and the total_steps are 90021\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 3, 1, 0, 1, 3, 2, 1, 0, 3, 1, 3, 0, 2, 0, 3, 0, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 24 and the episode is 1455 and the total_steps are 90045\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 0, 1, 0, 0, 1, 3, 0, 0, 1, 1, 0, 3, 1, 2, 2, 3, 3, 3, 0, 3, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 36 and the episode is 1456 and the total_steps are 90081\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1456     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2413     |\n",
      "|    total_timesteps  | 90081    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.93     |\n",
      "|    n_updates        | 10020    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 0, 2, 2, 1, 0, 0, 3, 1, 1, 1, 3, 3, 2, 1, 0, 2, 0, 2, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 1457 and the total_steps are 90105\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 0, 2, 2, 1, 0, 1, 2, 2, 3, 0, 1, 0, 2, 3, 3, 2, 0, 1, 1, 0, 2, 0, 1, 2, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 32 and the episode is 1458 and the total_steps are 90137\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 3, 0, 1, 0, 0, 1, 2, 2, 0, 0, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 18 and the episode is 1459 and the total_steps are 90155\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 2, 0, 1, 0, 2, 2, 2, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 15 and the episode is 1460 and the total_steps are 90170\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1460     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2417     |\n",
      "|    total_timesteps  | 90170    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.42     |\n",
      "|    n_updates        | 10042    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 3, 1, 1, 2, 1, 0, 1, 0, 2, 3, 1, 2, 2, 2, 3, 2, 2, 1, 1, 1, 0, 2, 1, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 31 and the episode is 1461 and the total_steps are 90201\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 3, 3, 3, 0, 0, 1, 2, 1, 3, 0, 1, 0, 2, 3, 2, 2, 3, 2, 2, 3, 0, 0, 2, 3, 1, 2, 0, 1, 2, 0, 3, 1, 0, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 1462 and the total_steps are 90241\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 0, 1, 3, 1, 0, 1, 0, 1, 2, 1, 0, 0, 2, 3, 3, 2, 2, 3, 3, 2, 0, 2, 2, 2, 3, 2, 2, 1, 2, 3, 1, 0, 2, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 41 and the episode is 1463 and the total_steps are 90282\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 0, 1, 2, 3, 1, 3, 0, 3, 1, 2, 0, 0, 3, 3, 1, 2, 3, 3, 3, 0, 2, 1, 1, 3, 2, 2, 0, 1, 0, 0, 1, 3, 0, 1, 0, 0, 1, 1, 2, 2, 0, 1, 0, 2, 1, 2, 1, 1, 0, 2, 3, 1, 2, 2, 2, 2, 0, 3, 1, 3, 2, 1, 0, 2, 2, 2, 3, 1, 0, 2, 3, 0, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -949. And steps were 79 and the episode is 1464 and the total_steps are 90361\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1464     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2424     |\n",
      "|    total_timesteps  | 90361    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 10090    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 3, 0, 1, 1, 0, 3, 0, 1, 1, 0, 0, 3, 3, 3, 0, 0, 1, 1, 2, 1, 3, 3, 0, 0, 2, 2, 2, 3, 3, 0, 0, 2, 1, 3, 2, 2, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 0, 1, 0, 0, 2, 0, 3, 0, 3, 2, 1, 2, 1, 2, 0, 2, 1, 3, 0, 0, 2, 1, 0, 3, 2, 3, 2, 1, 0, 1, 2, 3, 1, 1, 3, 2, 3, 0, 1, 2, 3, 0, 3, 3, 3, 0, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1072. And steps were 100 and the episode is 1465 and the total_steps are 90461\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 3, 0, 1, 1, 1, 0, 2, 3, 1, 3, 3, 1, 0, 1, 3, 0, 1, 3, 1, 2, 0, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1466 and the total_steps are 90490\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 0, 1, 2, 2, 3, 0, 3, 2, 1, 0, 2, 2, 1, 2, 3, 0, 3, 3, 0, 3, 2, 0, 0, 0, 0, 1, 1, 2, 3, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 37 and the episode is 1467 and the total_steps are 90527\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 1, 3, 2, 3, 0, 0, 2, 0, 3, 0, 2, 3, 3, 2, 1, 2, 3, 2, 0, 0, 3, 2, 3, 2, 0, 3, 2, 2, 2, 1, 1, 1, 3, 2, 0, 0, 2, 2, 0, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 47 and the episode is 1468 and the total_steps are 90574\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1468     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2432     |\n",
      "|    total_timesteps  | 90574    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 10143    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 2, 3, 2, 2, 2, 3, 2, 0, 0, 1, 3, 1, 2, 1, 0, 0, 2, 2, 3, 3, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 28 and the episode is 1469 and the total_steps are 90602\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 0, 1, 1, 2, 3, 2, 0, 3, 3, 2, 0, 1, 0, 1, 3, 1, 1, 3, 2, 0, 1, 2, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 30 and the episode is 1470 and the total_steps are 90632\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 0, 0, 1, 2, 1, 1, 2, 3, 2, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 17 and the episode is 1471 and the total_steps are 90649\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 1, 2, 1, 3, 0, 1, 1, 2, 0, 2, 0, 2, 0, 2, 0, 1, 3, 3, 3, 1, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 1472 and the total_steps are 90677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1472     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2437     |\n",
      "|    total_timesteps  | 90677    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.908    |\n",
      "|    n_updates        | 10169    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 3, 2, 3, 2, 1, 2, 1, 0, 0, 0, 2, 0, 2, 1, 2, 3, 2, 1, 0, 2, 2, 2, 1, 1, 2, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 33 and the episode is 1473 and the total_steps are 90710\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 2, 2, 0, 0, 3, 2, 3, 3, 1, 0, 1, 1, 3, 1, 1, 1, 3, 1, 0, 0, 3, 3, 1, 0, 2, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 1474 and the total_steps are 90743\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 0, 1, 2, 3, 1, 2, 3, 0, 3, 0, 3, 1, 3, 2, 2, 3, 0, 2, 1, 3, 1, 2, 0, 3, 1, 2, 3, 2, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 36 and the episode is 1475 and the total_steps are 90779\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 2, 3, 1, 3, 0, 2, 2, 1, 2, 0, 1, 0, 1, 3, 0, 1, 1, 1, 0, 1, 3, 3, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1476 and the total_steps are 90809\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1476     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2442     |\n",
      "|    total_timesteps  | 90809    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 10202    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 0, 0, 3, 2, 1, 2, 2, 3, 2, 2, 0, 0, 2, 0, 3, 3, 0, 2, 2, 1, 1, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 29 and the episode is 1477 and the total_steps are 90838\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 2, 0, 2, 3, 3, 0, 0, 2, 3, 1, 2, 2, 1, 1, 2, 0, 0, 2, 2, 2, 2, 3, 2, 3, 2, 0, 0, 2, 3, 3, 1, 0, 0, 1, 3, 3, 1, 3, 3, 0, 3, 3, 0, 1, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 52 and the episode is 1478 and the total_steps are 90890\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 1, 3, 3, 3, 2, 1, 3, 2, 2, 1, 1, 3, 0, 0, 1, 3, 1, 2, 0, 3, 0, 1, 0, 1, 3, 0, 3, 1, 0, 0, 0, 3, 0, 3, 3, 3, 1, 2, 1, 3, 3, 2, 2, 0, 1, 0, 0, 0, 0, 3, 1, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 59 and the episode is 1479 and the total_steps are 90949\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 3, 2, 1, 0, 3, 3, 2, 1, 1, 2, 3, 3, 3, 1, 1, 1, 0, 2, 3, 2, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 1480 and the total_steps are 90977\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1480     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2449     |\n",
      "|    total_timesteps  | 90977    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65.3     |\n",
      "|    n_updates        | 10244    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 2, 3, 3, 3, 0, 3, 2, 0, 0, 0, 1, 3, 2, 1, 1, 3, 2, 3, 3, 3, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 1481 and the total_steps are 91003\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 2, 0, 2, 1, 0, 2, 2, 2, 2, 0, 3, 2, 2, 0, 0, 2, 0, 2, 3, 0, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 1482 and the total_steps are 91031\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 2, 1, 3, 3, 2, 3, 1, 2, 1, 1, 2, 2, 3, 3, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 22 and the episode is 1483 and the total_steps are 91053\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 3, 3, 0, 0, 0, 2, 3, 2, 2, 3, 3, 2, 1, 3, 1, 1, 1, 1, 0, 1, 2, 2, 1, 2, 3, 2, 1, 1, 2, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 3, 0, 1, 3, 3, 0, 0, 2, 3, 1, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was 1063. And steps were 64 and the episode is 1484 and the total_steps are 91117\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1484     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2455     |\n",
      "|    total_timesteps  | 91117    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 10279    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 0, 3, 2, 0, 2, 1, 2, 0, 2, 0, 0, 3, 1, 0, 2, 2, 0, 2, 1, 2, 3, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 29 and the episode is 1485 and the total_steps are 91146\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 0, 3, 0, 3, 0, 2, 3, 2, 1, 3, 3, 2, 3, 2, 3, 3, 1, 1, 2, 0, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 1486 and the total_steps are 91174\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 1, 1, 0, 3, 2, 1, 2, 0, 1, 3, 1, 3, 2, 3, 2, 3, 3, 3, 0, 3, 1, 3, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1487 and the total_steps are 91204\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 1, 2, 2, 2, 1, 3, 2, 1, 1, 1, 0, 1, 0, 0, 3, 2, 2, 0, 0, 1, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 1488 and the total_steps are 91232\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1488     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2460     |\n",
      "|    total_timesteps  | 91232    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 10307    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 2, 3, 3, 0, 1, 3, 3, 0, 2, 1, 2, 0, 0, 0, 1, 1, 0, 3, 1, 3, 0, 2, 3, 1, 3, 2, 1, 1, 0, 0, 1, 0, 1, 1, 3, 3, 2, 1, 2, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 47 and the episode is 1489 and the total_steps are 91279\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 1, 0, 0, 1, 0, 2, 0, 2, 0, 1, 3, 0, 0, 2, 1, 1, 1, 3, 2, 0, 1, 3, 3, 1, 1, 1, 0, 2, 3, 0, 2, 1, 0, 3, 0, 2, 3, 3, 3, 3, 2, 3, 0, 0, 2, 2, 1, 1, 1, 3, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 58 and the episode is 1490 and the total_steps are 91337\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 1, 0, 0, 3, 0, 0, 0, 1, 3, 2, 0, 1, 3, 3, 0, 3, 1, 3, 2, 3, 3, 3, 3, 1, 2, 0, 0, 2, 3, 3, 0, 1, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 40 and the episode is 1491 and the total_steps are 91377\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 3, 3, 1, 0, 1, 3, 0, 2, 1, 3, 1, 1, 3, 1, 0, 0, 0, 3, 2, 3, 2, 2, 0, 1, 2, 0, 0, 1, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 1492 and the total_steps are 91413\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1492     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2467     |\n",
      "|    total_timesteps  | 91413    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 10353    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 2, 2, 1, 1, 3, 2, 1, 3, 0, 3, 0, 2, 2, 1, 2, 0, 0, 0, 3, 1, 2, 2, 1, 0, 0, 0, 1, 0, 2, 0, 3, 1, 3, 2, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 42 and the episode is 1493 and the total_steps are 91455\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 0, 3, 1, 0, 3, 0, 1, 2, 0, 1, 0, 2, 0, 0, 0, 2, 1, 2, 1, 0, 0, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 29 and the episode is 1494 and the total_steps are 91484\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 2, 1, 2, 0, 3, 0, 1, 0, 2, 1, 1, 0, 3, 0, 3, 3, 0, 1, 0, 1, 3, 0, 1, 0, 3, 0, 2, 2, 2, 3, 3, 0, 0, 1, 3, 2, 0, 1, 2, 0, 1, 2, 1, 1, 3, 3, 0, 3, 2, 1, 0, 1, 2, 2, 3, 3, 0, 3, 1, 2, 3, 1, 3, 2, 0, 3, 1, 1, 1, 2, 1, 0, 2, 1, 0, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1049. And steps were 83 and the episode is 1495 and the total_steps are 91567\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 2, 3, 2, 1, 0, 1, 3, 3, 3, 0, 1, 0, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1017. And steps were 18 and the episode is 1496 and the total_steps are 91585\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1496     |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 2474     |\n",
      "|    total_timesteps  | 91585    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.9     |\n",
      "|    n_updates        | 10396    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 3, 0, 1, 0, 0, 3, 3, 0, 0, 2, 1, 1, 1, 1, 3, 1, 3, 0, 1, 3, 3, 0, 1, 2, 3, 0, 0, 0, 3, 0, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 38 and the episode is 1497 and the total_steps are 91623\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 2, 1, 0, 2, 3, 2, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 3, 2, 2, 1, 2, 0, 2, 1, 0, 1, 1, 2, 3, 1, 3, 3, 1, 2, 1, 1, 0, 2, 0, 2, 2, 0, 1, 2, 3, 0, 2, 2, 2, 2, 0, 0, 3, 0, 0, 1, 0, 2, 0, 2, 0, 2, 3, 1, 0, 1, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1052. And steps were 74 and the episode is 1498 and the total_steps are 91697\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 2, 3, 2, 2, 1, 1, 0, 3, 2, 0, 0, 1, 1, 2, 0, 2, 3, 3, 1, 2, 3, 1, 1, 1, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 32 and the episode is 1499 and the total_steps are 91729\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 2, 2, 1, 0, 3, 0, 2, 1, 1, 0, 0, 2, 0, 1, 2, 1, 0, 2, 1, 1, 3, 2, 3, 3, 1, 1, 2, 2, 2, 3, 2, 0, 1, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 1500 and the total_steps are 91770\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -923     |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2481     |\n",
      "|    total_timesteps  | 91770    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.3     |\n",
      "|    n_updates        | 10442    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 0, 3, 0, 2, 2, 2, 0, 1, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 16 and the episode is 1501 and the total_steps are 91786\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 0, 3, 3, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 3, 0, 3, 3, 2, 2, 1, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 1502 and the total_steps are 91814\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 3, 0, 0, 2, 1, 1, 3, 0, 0, 0, 1, 2, 2, 3, 0, 3, 0, 0, 3, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 27 and the episode is 1503 and the total_steps are 91841\n",
      "Done condition: collision\n",
      "[0, 0, 1, 2, 1, 1, 0, 2, 1, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 3, 1, 2, 3, 1, 0, 3, 3, 3, 0, 0, 3, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 41 and the episode is 1504 and the total_steps are 91882\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1504     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2486     |\n",
      "|    total_timesteps  | 91882    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 10470    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 2, 3, 2, 3, 0, 1, 0, 0, 1, 1, 1, 2, 3, 1, 2, 3, 2, 3, 3, 3, 1, 0, 3, 2, 2, 1, 3, 2, 1, 3, 0, 1, 2, 1, 2, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 43 and the episode is 1505 and the total_steps are 91925\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 2, 3, 0, 3, 2, 3, 3, 1, 0, 3, 1, 2, 2, 0, 2, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 1506 and the total_steps are 91946\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 2, 1, 3, 3, 1, 1, 0, 3, 1, 1, 1, 0, 0, 0, 0, 3, 1, 1, 0, 1, 2, 1, 2, 3, 3, 2, 2, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 35 and the episode is 1507 and the total_steps are 91981\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 3, 0, 0, 3, 0, 3, 2, 2, 3, 0, 0, 2, 1, 1, 0, 3, 1, 2, 2, 3, 1, 2, 2, 3, 0, 2, 3, 1, 0, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1035. And steps were 37 and the episode is 1508 and the total_steps are 92018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -903     |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1508     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2491     |\n",
      "|    total_timesteps  | 92018    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.799    |\n",
      "|    n_updates        | 10504    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 1, 2, 3, 0, 1, 0, 1, 2, 3, 0, 2, 0, 2, 0, 1, 1, 1, 3, 1, 2, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 1509 and the total_steps are 92046\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 3, 3, 0, 2, 2, 0, 1, 3, 2, 3, 2, 0, 2, 3, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 2, 3, 1, 1, 3, 1, 1, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 39 and the episode is 1510 and the total_steps are 92085\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 1, 2, 0, 3, 1, 3, 3, 1, 2, 3, 3, 0, 3, 3, 1, 3, 1, 3, 0, 1, 2, 3, 0, 3, 2, 0, 3, 3, 0, 3, 1, 3, 1, 2, 0, 1, 2, 2, 0, 0, 1, 3, 3, 2, 1, 2, 2, 3, 3, 1, 2, 1, 2, 0, 3, 1, 3, 2, 1, 3, 1, 2, 3, 3, 0, 2, 2, 2, 2, 3, 2, 3, 3, 3, 2, 3, 3, 3, 2, 3, 1, 3, 1, 0, 1, 0, 0, 3, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 96 and the episode is 1511 and the total_steps are 92181\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 0, 0, 3, 1, 2, 3, 2, 3, 1, 3, 0, 2, 0, 1, 0, 0, 1, 2, 3, 2, 1, 0, 1, 1, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1512 and the total_steps are 92213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -904     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1512     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2500     |\n",
      "|    total_timesteps  | 92213    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.2     |\n",
      "|    n_updates        | 10553    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 1, 2, 3, 0, 1, 0, 1, 0, 3, 3, 2, 2, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 20 and the episode is 1513 and the total_steps are 92233\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 1, 3, 0, 1, 2, 0, 2, 1, 0, 2, 0, 2, 1, 2, 0, 0, 1, 2, 2, 0, 2, 3, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1027. And steps were 28 and the episode is 1514 and the total_steps are 92261\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 2, 1, 1, 1, 0, 3, 1, 1, 1, 0, 0, 2, 1, 2, 3, 0, 2, 0, 0, 3, 1, 0, 3, 0, 3, 1, 1, 3, 3, 2, 1, 0, 1, 1, 3, 0, 0, 3, 2, 3, 2, 2, 3, 3, 1, 3, 3, 3, 0, 3, 2, 3, 2, 3, 2, 3, 2, 0, 2, 0, 1, 1, 1, 1, 0, 2, 2, 2, 0, 1, 3, 0, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1048. And steps were 80 and the episode is 1515 and the total_steps are 92341\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 1, 0, 2, 2, 3, 0, 3, 3, 0, 3, 2, 3, 1, 2, 0, 0, 2, 1, 1, 3, 2, 2, 0, 1, 2, 0, 2, 2, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 1516 and the total_steps are 92377\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -884     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1516     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2506     |\n",
      "|    total_timesteps  | 92377    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.6     |\n",
      "|    n_updates        | 10594    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 2, 2, 3, 1, 1, 3, 3, 2, 1, 2, 1, 1, 3, 2, 1, 2, 1, 1, 0, 3, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 46 and the episode is 1517 and the total_steps are 92423\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 3, 1, 1, 0, 0, 1, 0, 1, 3, 3, 1, 1, 1, 1, 2, 3, 1, 1, 1, 3, 3, 0, 3, 0, 0, 1, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 1518 and the total_steps are 92457\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 0, 3, 3, 3, 0, 3, 1, 2, 0, 2, 2, 0, 1, 1, 0, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1009. And steps were 22 and the episode is 1519 and the total_steps are 92479\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 0, 1, 2, 2, 1, 0, 0, 0, 1, 2, 0, 1, 2, 3, 2, 1, 3, 1, 3, 2, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 1520 and the total_steps are 92507\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -863     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1520     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2512     |\n",
      "|    total_timesteps  | 92507    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 10626    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 3, 2, 3, 3, 2, 1, 0, 2, 3, 0, 0, 1, 1, 3, 2, 2, 2, 2, 1, 1, 0, 0, 3, 3, 1, 1, 3, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 34 and the episode is 1521 and the total_steps are 92541\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 1, 3, 3, 0, 3, 2, 2, 0, 1, 0, 2, 2, 0, 1, 1, 0, 1, 0, 3, 3, 2, 2, 1, 2, 1, 3, 2, 0, 1, 1, 3, 3, 1, 2, 1, 3, 1, 2, 0, 1, 1, 2, 3, 2, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 52 and the episode is 1522 and the total_steps are 92593\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 0, 2, 3, 0, 1, 2, 1, 3, 3, 2, 0, 0, 0, 2, 0, 2, 3, 3, 1, 2, 2, 3, 3, 3, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 1523 and the total_steps are 92625\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 2, 1, 0, 0, 0, 0, 3, 3, 1, 1, 2, 0, 1, 2, 3, 1, 2, 2, 0, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 36 and the episode is 1524 and the total_steps are 92661\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -863     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1524     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2518     |\n",
      "|    total_timesteps  | 92661    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 30.9     |\n",
      "|    n_updates        | 10665    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 3, 0, 2, 0, 3, 2, 1, 1, 1, 3, 3, 0, 0, 0, 0, 2, 0, 1, 0, 2, 3, 3, 1, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 1525 and the total_steps are 92692\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 0, 0, 0, 0, 1, 2, 1, 3, 0, 2, 2, 3, 3, 0, 2, 3, 1, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 25 and the episode is 1526 and the total_steps are 92717\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 1, 1, 3, 1, 3, 3, 3, 0, 1, 2, 1, 1, 1, 0, 0, 0, 3, 0, 0, 1, 2, 1, 3, 0, 2, 2, 3, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 35 and the episode is 1527 and the total_steps are 92752\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 0, 3, 0, 3, 2, 1, 0, 1, 1, 0, 2, 2, 1, 0, 1, 3, 2, 1, 0, 1, 1, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1528 and the total_steps are 92781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | -864     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1528     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2523     |\n",
      "|    total_timesteps  | 92781    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 10695    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 1, 1, 3, 2, 2, 2, 1, 3, 3, 3, 1, 1, 1, 0, 1, 3, 2, 3, 0, 1, 3, 0, 0, 2, 3, 1, 2, 3, 1, 1, 3, 3, 3, 2, 0, 2, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 44 and the episode is 1529 and the total_steps are 92825\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 2, 3, 3, 0, 1, 3, 2, 1, 2, 1, 1, 3, 1, 2, 0, 0, 1, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 34 and the episode is 1530 and the total_steps are 92859\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 2, 1, 2, 2, 3, 1, 2, 3, 2, 3, 0, 3, 0, 3, 1, 3, 3, 1, 2, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 1531 and the total_steps are 92886\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 0, 2, 1, 3, 2, 3, 2, 0, 0, 3, 3, 3, 1, 0, 3, 0, 1, 0, 3, 3, 2, 2, 1, 1, 0, 3, 2, 3, 3, 2, 3, 0, 0, 2, 3, 2, 3, 3, 2, 2, 3, 1, 0, 1, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 52 and the episode is 1532 and the total_steps are 92938\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | -863     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1532     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2529     |\n",
      "|    total_timesteps  | 92938    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.633    |\n",
      "|    n_updates        | 10734    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 2, 2, 3, 2, 3, 1, 1, 0, 1, 2, 3, 1, 2, 3, 1, 3, 3, 1, 2, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 1533 and the total_steps are 92965\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 0, 1, 3, 2, 0, 1, 0, 3, 2, 3, 1, 0, 1, 3, 2, 1, 0, 0, 0, 2, 3, 1, 1, 0, 3, 2, 0, 1, 2, 0, 0, 1, 0, 3, 3, 0, 3, 3, 3, 1, 1, 0, 0, 3, 1, 2, 2, 0, 0, 2, 3, 2, 2, 1, 0, 1, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 64 and the episode is 1534 and the total_steps are 93029\n",
      "Done condition: collision\n",
      "[1, 1, 3, 0, 3, 1, 3, 2, 2, 1, 2, 0, 2, 3, 3, 0, 1, 2, 2, 3, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 1535 and the total_steps are 93053\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 3, 0, 3, 3, 0, 1, 2, 0, 0, 3, 1, 2, 3, 1, 1, 0, 1, 3, 0, 3, 2, 2, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 30 and the episode is 1536 and the total_steps are 93083\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | -863     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1536     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2535     |\n",
      "|    total_timesteps  | 93083    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.83     |\n",
      "|    n_updates        | 10770    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 0, 1, 1, 2, 3, 3, 2, 1, 0, 0, 2, 1, 2, 2, 1, 3, 1, 2, 0, 2, 2, 3, 1, 2, 3, 2, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 34 and the episode is 1537 and the total_steps are 93117\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 3, 1, 3, 2, 2, 3, 2, 0, 2, 3, 1, 0, 3, 1, 0, 1, 2, 0, 2, 0, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 1538 and the total_steps are 93145\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 1, 2, 3, 0, 1, 1, 0, 0, 1, 1, 3, 0, 2, 0, 2, 2, 1, 0, 1, 2, 3, 3, 1, 1, 2, 3, 2, 2, 2, 0, 0, 3, 2, 3, 0, 1, 1, 3, 2, 0, 1, 2, 3, 3, 3, 1, 0, 2, 1, 0, 1, 3, 1, 2, 2, 0, 1, 0, 0, 1, 1, 3, 0, 1, 0, 0, 1, 0, 0, 3, 1, 0, 2, 1, 1, 3, 3, 2, 3, 3, 2, 0, 1, 1, 3, 1, 1, 3, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1094. And steps were 96 and the episode is 1539 and the total_steps are 93241\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 1, 3, 2, 3, 2, 3, 2, 3, 0, 2, 3, 3, 0, 1, 2, 0, 2, 2, 2, 0, 1, 3, 2, 0, 3, 0, 2, 1, 1, 3, 3, 3, 0, 0, 0, 1, 0, 3, 2, 1, 0, 2, 1, 0, 3, 2, 1, 1, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 56 and the episode is 1540 and the total_steps are 93297\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -864     |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1540     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2543     |\n",
      "|    total_timesteps  | 93297    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 124      |\n",
      "|    n_updates        | 10824    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 0, 2, 0, 1, 0, 1, 2, 2, 3, 3, 3, 0, 2, 0, 2, 2, 3, 3, 1, 2, 2, 1, 1, 1, 0, 0, 1, 1, 3, 2, 1, 2, 2, 2, 3, 0, 2, 0, 2, 1, 1, 3, 1, 3, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 1541 and the total_steps are 93349\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 0, 1, 3, 2, 2, 0, 0, 0, 3, 0, 1, 3, 1, 2, 0, 0, 3, 0, 1, 0, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 1542 and the total_steps are 93377\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 1, 0, 0, 0, 3, 2, 2, 3, 1, 0, 1, 3, 2, 1, 2, 3, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 24 and the episode is 1543 and the total_steps are 93401\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 3, 2, 0, 1, 2, 3, 1, 2, 2, 2, 0, 0, 0, 2, 1, 2, 3, 1, 1, 0, 2, 3, 2, 1, 1, 3, 1, 0, 2, 3, 0, 0, 3, 0, 3, 2, 0, 0, 2, 3, 2, 1, 2, 2, 3, 2, 2, 2, 3, 1, 3, 2, 3, 3, 1, 3, 2, 1, 3, 1, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1066. And steps were 68 and the episode is 1544 and the total_steps are 93469\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -865     |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1544     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2550     |\n",
      "|    total_timesteps  | 93469    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 10867    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 2, 2, 2, 1, 0, 3, 1, 3, 2, 2, 1, 3, 0, 3, 3, 2, 1, 3, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1022. And steps were 23 and the episode is 1545 and the total_steps are 93492\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 2, 2, 1, 0, 2, 3, 3, 0, 0, 3, 2, 2, 0, 3, 2, 3, 0, 2, 1, 3, 2, 1, 2, 1, 0, 2, 0, 0, 0, 3, 2, 2, 2, 3, 3, 2, 2, 0, 1, 2, 0, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 49 and the episode is 1546 and the total_steps are 93541\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 3, 1, 3, 3, 1, 0, 2, 2, 2, 3, 2, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 19 and the episode is 1547 and the total_steps are 93560\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 3, 3, 1, 0, 0, 2, 1, 0, 0, 3, 2, 3, 1, 1, 0, 0, 2, 3, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 1548 and the total_steps are 93586\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -845     |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1548     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2555     |\n",
      "|    total_timesteps  | 93586    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.2     |\n",
      "|    n_updates        | 10896    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 0, 1, 0, 1, 2, 3, 1, 2, 1, 0, 3, 0, 1, 3, 3, 0, 2, 0, 3, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 27 and the episode is 1549 and the total_steps are 93613\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 3, 3, 2, 0, 3, 1, 1, 0, 0, 0, 3, 2, 1, 0, 3, 1, 2, 2, 1, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 27 and the episode is 1550 and the total_steps are 93640\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 0, 1, 0, 2, 2, 3, 0, 0, 0, 3, 3, 1, 3, 3, 0, 1, 3, 0, 3, 3, 1, 3, 1, 1, 1, 3, 0, 0, 1, 2, 2, 2, 2, 2, 3, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 43 and the episode is 1551 and the total_steps are 93683\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 1, 1, 1, 0, 1, 1, 2, 3, 3, 1, 3, 0, 2, 3, 3, 1, 2, 0, 3, 1, 0, 0, 3, 0, 1, 2, 3, 1, 1, 3, 0, 0, 0, 3, 3, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 3, 2, 0, 3, 2, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 58 and the episode is 1552 and the total_steps are 93741\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -844     |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1552     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2561     |\n",
      "|    total_timesteps  | 93741    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.9     |\n",
      "|    n_updates        | 10935    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 1, 3, 2, 3, 0, 2, 2, 0, 3, 3, 1, 1, 0, 3, 3, 3, 2, 1, 3, 1, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 1553 and the total_steps are 93769\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 2, 1, 2, 0, 0, 1, 1, 1, 2, 3, 2, 2, 3, 3, 0, 3, 3, 1, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 1554 and the total_steps are 93793\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 0, 0, 3, 3, 3, 3, 2, 0, 1, 3, 2, 3, 2, 3, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 22 and the episode is 1555 and the total_steps are 93815\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 3, 3, 0, 2, 1, 2, 3, 1, 0, 0, 0, 0, 2, 1, 0, 1, 1, 2, 0, 3, 2, 2, 3, 0, 1, 1, 2, 0, 3, 1, 2, 2, 0, 0, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 42 and the episode is 1556 and the total_steps are 93857\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -824     |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1556     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2566     |\n",
      "|    total_timesteps  | 93857    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 93.7     |\n",
      "|    n_updates        | 10964    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 2, 1, 3, 0, 3, 1, 0, 3, 3, 3, 2, 2, 0, 2, 3, 2, 0, 0, 1, 0, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 1557 and the total_steps are 93885\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 1, 3, 2, 0, 0, 3, 0, 2, 0, 2, 3, 0, 3, 1, 2, 3, 3, 2, 2, 1, 2, 2, 3, 2, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 32 and the episode is 1558 and the total_steps are 93917\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 3, 0, 3, 2, 1, 1, 3, 2, 2, 2, 0, 3, 2, 2, 2, 0, 1, 3, 1, 0, 0, 1, 0, 1, 0, 2, 1, 2, 3, 0, 1, 2, 0, 2, 1, 1, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 44 and the episode is 1559 and the total_steps are 93961\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 3, 2, 1, 2, 3, 2, 1, 1, 0, 2, 1, 0, 3, 0, 0, 2, 3, 0, 0, 3, 1, 2, 0, 0, 3, 1, 0, 0, 1, 1, 2, 1, 1, 1, 0, 2, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 2, 1, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1054. And steps were 56 and the episode is 1560 and the total_steps are 94017\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -845     |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1560     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2572     |\n",
      "|    total_timesteps  | 94017    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.6     |\n",
      "|    n_updates        | 11004    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 3, 1, 1, 1, 3, 3, 2, 3, 1, 0, 2, 1, 3, 3, 2, 3, 2, 3, 0, 3, 3, 2, 3, 3, 2, 1, 1, 3, 0, 1, 0, 2, 0, 2, 0, 3, 0, 1, 0, 2, 2, 3, 2, 3, 3, 0, 2, 2, 1, 2, 2, 1, 3, 1, 3, 0, 1, 0, 3, 2, 1, 1, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -942. And steps were 68 and the episode is 1561 and the total_steps are 94085\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 0, 3, 0, 1, 2, 3, 2, 0, 2, 1, 0, 3, 0, 3, 2, 0, 2, 2, 1, 3, 0, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1026. And steps were 27 and the episode is 1562 and the total_steps are 94112\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 1, 3, 3, 0, 3, 1, 1, 3, 1, 0, 0, 1, 1, 0, 3, 0, 2, 0, 3, 2, 3, 3, 3, 3, 1, 3, 0, 0, 2, 1, 3, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 39 and the episode is 1563 and the total_steps are 94151\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 2, 2, 3, 1, 0, 1, 1, 2, 0, 0, 2, 1, 2, 1, 1, 0, 0, 3, 1, 3, 3, 3, 2, 3, 3, 2, 0, 3, 3, 0, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 1564 and the total_steps are 94189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -825     |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1564     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2579     |\n",
      "|    total_timesteps  | 94189    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.15     |\n",
      "|    n_updates        | 11047    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 0, 1, 0, 3, 0, 0, 1, 2, 2, 1, 2, 2, 0, 3, 0, 3, 2, 2, 0, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 1565 and the total_steps are 94214\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 3, 2, 2, 0, 1, 1, 0, 2, 0, 1, 2, 2, 2, 1, 3, 1, 0, 0, 1, 0, 1, 0, 2, 2, 3, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 33 and the episode is 1566 and the total_steps are 94247\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 1, 1, 3, 1, 3, 3, 3, 1, 1, 3, 2, 0, 1, 0, 2, 3, 0, 3, 0, 2, 1, 1, 1, 1, 3, 1, 3, 2, 0, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 36 and the episode is 1567 and the total_steps are 94283\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 3, 1, 1, 1, 1, 0, 3, 0, 3, 2, 2, 1, 0, 1, 3, 2, 3, 3, 3, 1, 3, 3, 0, 2, 1, 0, 0, 2, 1, 2, 1, 1, 0, 3, 0, 2, 1, 2, 1, 0, 0, 3, 1, 1, 0, 2, 1, 0, 3, 0, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 58 and the episode is 1568 and the total_steps are 94341\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -804     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1568     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2585     |\n",
      "|    total_timesteps  | 94341    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 11085    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 1, 1, 1, 0, 3, 2, 0, 2, 2, 2, 0, 1, 0, 2, 2, 0, 0, 0, 3, 1, 2, 0, 1, 0, 0, 2, 3, 2, 3, 0, 0, 1, 0, 1, 2, 0, 1, 2, 3, 2, 0, 3, 1, 3, 1, 0, 1, 2, 3, 3, 3, 1, 3, 3, 0, 2, 2, 2, 2, 0, 3, 0, 0, 1, 0, 0, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 74 and the episode is 1569 and the total_steps are 94415\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 3, 1, 3, 0, 3, 2, 2, 3, 3, 1, 1, 0, 1, 3, 3, 0, 2, 2, 3, 1, 0, 0, 1, 1, 1, 1, 3, 0, 2, 1, 0, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 1570 and the total_steps are 94453\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 0, 1, 3, 2, 1, 3, 1, 3, 0, 1, 3, 1, 1, 0, 1, 2, 2, 0, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 26 and the episode is 1571 and the total_steps are 94479\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 2, 2, 3, 3, 1, 0, 3, 3, 3, 0, 1, 2, 0, 1, 1, 0, 2, 0, 0, 3, 1, 0, 2, 1, 0, 2, 1, 2, 0, 1, 2, 0, 0, 1, 0, 0, 3, 1, 2, 3, 1, 0, 1, 2, 3, 1, 3, 2, 0, 3, 3, 2, 3, 2, 0, 3, 1, 3, 1, 2, 2, 3, 0, 3, 1, 2, 1, 0, 1, 1, 1, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 86 and the episode is 1572 and the total_steps are 94565\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -805     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1572     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2594     |\n",
      "|    total_timesteps  | 94565    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 11141    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 2, 3, 3, 2, 3, 0, 0, 2, 2, 0, 3, 2, 3, 3, 0, 3, 2, 3, 3, 2, 1, 2, 3, 3, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 32 and the episode is 1573 and the total_steps are 94597\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 3, 0, 1, 2, 2, 1, 3, 1, 3, 1, 0, 0, 2, 1, 2, 1, 0, 3, 2, 0, 0, 2, 3, 2, 0, 1, 3, 3, 0, 1, 2, 2, 2, 1, 1, 0, 2, 0, 3, 2, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 48 and the episode is 1574 and the total_steps are 94645\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 0, 3, 3, 3, 3, 3, 0, 2, 3, 1, 1, 0, 3, 0, 2, 2, 0, 0, 0, 2, 3, 1, 0, 0, 1, 3, 3, 0, 2, 3, 0, 3, 0, 2, 3, 2, 1, 3, 2, 0, 3, 2, 1, 0, 0, 0, 3, 3, 1, 0, 3, 2, 2, 0, 3, 2, 2, 2, 3, 0, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1048. And steps were 68 and the episode is 1575 and the total_steps are 94713\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 3, 2, 1, 0, 3, 1, 2, 2, 1, 1, 1, 1, 3, 3, 3, 0, 3, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 25 and the episode is 1576 and the total_steps are 94738\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | -805     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1576     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2601     |\n",
      "|    total_timesteps  | 94738    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 30.8     |\n",
      "|    n_updates        | 11184    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 1, 2, 2, 3, 0, 1, 1, 0, 3, 2, 0, 2, 1, 2, 0, 3, 2, 3, 0, 1, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 1577 and the total_steps are 94766\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 1, 0, 2, 0, 2, 0, 0, 0, 0, 3, 0, 0, 2, 0, 2, 3, 1, 1, 1, 3, 2, 2, 1, 0, 3, 0, 1, 2, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 36 and the episode is 1578 and the total_steps are 94802\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 3, 2, 2, 1, 3, 0, 1, 1, 0, 2, 0, 1, 1, 0, 2, 3, 1, 3, 2, 1, 1, 3, 0, 2, 3, 1, 1, 1, 1, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 37 and the episode is 1579 and the total_steps are 94839\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 0, 3, 1, 1, 0, 3, 2, 0, 0, 0, 2, 2, 3, 3, 0, 0, 0, 0, 2, 1, 2, 0, 2, 1, 3, 0, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 34 and the episode is 1580 and the total_steps are 94873\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -805     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1580     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2606     |\n",
      "|    total_timesteps  | 94873    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 11218    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 0, 0, 1, 2, 1, 0, 2, 3, 2, 0, 0, 0, 2, 0, 0, 0, 1, 3, 0, 1, 1, 0, 1, 1, 2, 0, 2, 3, 3, 1, 3, 1, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 40 and the episode is 1581 and the total_steps are 94913\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 3, 1, 1, 1, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 1582 and the total_steps are 94933\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 2, 0, 3, 0, 2, 3, 3, 1, 3, 3, 3, 1, 3, 0, 3, 2, 1, 3, 1, 1, 2, 1, 3, 2, 3, 1, 2, 2, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 36 and the episode is 1583 and the total_steps are 94969\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 2, 2, 1, 3, 2, 3, 1, 3, 0, 1, 0, 0, 3, 1, 2, 2, 3, 2, 2, 0, 1, 3, 2, 1, 1, 1, 2, 3, 2, 3, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 38 and the episode is 1584 and the total_steps are 95007\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -845     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1584     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2611     |\n",
      "|    total_timesteps  | 95007    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.747    |\n",
      "|    n_updates        | 11251    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 2, 3, 3, 3, 0, 3, 1, 0, 0, 0, 1, 3, 1, 2, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 22 and the episode is 1585 and the total_steps are 95029\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 3, 0, 1, 3, 0, 1, 3, 0, 2, 0, 3, 1, 1, 1, 0, 0, 2, 1, 3, 1, 0, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1586 and the total_steps are 95058\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 2, 3, 0, 2, 2, 1, 2, 2, 0, 3, 1, 0, 2, 1, 2, 2, 0, 2, 0, 2, 1, 3, 1, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 31 and the episode is 1587 and the total_steps are 95089\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 3, 2, 0, 0, 3, 0, 2, 1, 1, 0, 1, 0, 1, 0, 3, 2, 1, 3, 1, 2, 2, 3, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 30 and the episode is 1588 and the total_steps are 95119\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -845     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1588     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2616     |\n",
      "|    total_timesteps  | 95119    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 11279    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 1, 0, 3, 2, 3, 0, 2, 1, 0, 0, 3, 1, 0, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 31 and the episode is 1589 and the total_steps are 95150\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 0, 0, 3, 3, 3, 3, 3, 0, 3, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 3, 1, 2, 3, 3, 2, 1, 2, 1, 0, 0, 0, 2, 1, 2, 3, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 43 and the episode is 1590 and the total_steps are 95193\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 2, 2, 0, 3, 2, 1, 2, 3, 0, 1, 2, 3, 1, 2, 2, 2, 1, 2, 0, 2, 3, 1, 3, 1, 3, 2, 1, 2, 1, 1, 0, 0, 1, 3, 3, 0, 2, 1, 3, 0, 0, 1, 1, 1, 2, 1, 2, 0, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 56 and the episode is 1591 and the total_steps are 95249\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 3, 2, 1, 1, 3, 1, 1, 0, 0, 2, 3, 2, 3, 2, 2, 2, 2, 1, 1, 0, 1, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 3, 0, 3, 2, 1, 3, 2, 2, 0, 2, 0, 3, 2, 0, 1, 2, 2, 1, 1, 2, 0, 3, 2, 1, 2, 0, 0, 3, 2, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 70 and the episode is 1592 and the total_steps are 95319\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -844     |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1592     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2624     |\n",
      "|    total_timesteps  | 95319    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.219    |\n",
      "|    n_updates        | 11329    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 3, 1, 0, 3, 3, 0, 3, 3, 2, 3, 3, 2, 0, 0, 3, 3, 3, 3, 1, 3, 3, 2, 0, 1, 0, 2, 2, 3, 2, 2, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 1593 and the total_steps are 95357\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 1, 1, 1, 1, 0, 2, 3, 1, 3, 0, 3, 2, 1, 3, 1, 1, 2, 1, 0, 2, 3, 0, 3, 2, 0, 3, 3, 1, 3, 3, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 38 and the episode is 1594 and the total_steps are 95395\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 0, 3, 1, 2, 0, 2, 3, 1, 2, 0, 0, 2, 0, 3, 1, 2, 2, 1, 2, 0, 1, 2, 0, 1, 1, 2, 3, 3, 0, 0, 0, 3, 1, 2, 0, 2, 3, 2, 3, 0, 3, 0, 2, 2, 3, 2, 0, 3, 1, 2, 2, 0, 2, 0, 3, 3, 0, 1, 1, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 67 and the episode is 1595 and the total_steps are 95462\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 1, 1, 3, 3, 0, 3, 0, 3, 0, 0, 1, 0, 0, 2, 0, 2, 3, 3, 1, 1, 2, 0, 1, 0, 1, 3, 3, 0, 3, 0, 1, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 39 and the episode is 1596 and the total_steps are 95501\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -864     |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1596     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2631     |\n",
      "|    total_timesteps  | 95501    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.792    |\n",
      "|    n_updates        | 11375    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 2, 3, 2, 2, 1, 3, 0, 0, 0, 3, 2, 3, 3, 0, 2, 0, 0, 0, 2, 3, 0, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1597 and the total_steps are 95530\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 3, 1, 2, 3, 3, 2, 1, 3, 2, 3, 2, 3, 1, 3, 3, 2, 1, 2, 1, 2, 0, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 29 and the episode is 1598 and the total_steps are 95559\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 1, 3, 3, 3, 3, 0, 1, 0, 2, 2, 2, 3, 2, 2, 0, 3, 0, 1, 0, 1, 2, 0, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 30 and the episode is 1599 and the total_steps are 95589\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 3, 0, 2, 0, 3, 3, 0, 0, 3, 0, 0, 2, 0, 2, 1, 2, 0, 2, 0, 2, 3, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 29 and the episode is 1600 and the total_steps are 95618\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -864     |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2636     |\n",
      "|    total_timesteps  | 95618    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.649    |\n",
      "|    n_updates        | 11404    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 3, 3, 3, 1, 2, 1, 2, 2, 0, 0, 3, 1, 3, 1, 2, 0, 2, 0, 1, 3, 0, 3, 0, 3, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 1601 and the total_steps are 95650\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 1, 0, 1, 3, 1, 3, 0, 3, 0, 2, 3, 1, 3, 1, 3, 2, 3, 2, 0, 0, 0, 3, 3, 3, 2, 0, 3, 3, 0, 1, 2, 2, 1, 0, 2, 0, 3, 1, 0, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 47 and the episode is 1602 and the total_steps are 95697\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 2, 0, 0, 1, 1, 1, 1, 3, 0, 0, 3, 2, 3, 2, 1, 0, 2, 0, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 979. And steps were 24 and the episode is 1603 and the total_steps are 95721\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 2, 1, 1, 1, 1, 0, 2, 3, 3, 0, 0, 0, 1, 0, 3, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 3, 2, 0, 2, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 1604 and the total_steps are 95761\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -845     |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1604     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2642     |\n",
      "|    total_timesteps  | 95761    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.594    |\n",
      "|    n_updates        | 11440    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 3, 0, 3, 1, 3, 2, 2, 2, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 17 and the episode is 1605 and the total_steps are 95778\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 3, 1, 1, 1, 2, 0, 0, 3, 3, 0, 2, 2, 3, 3, 1, 3, 2, 1, 2, 2, 3, 3, 3, 0, 2, 1, 0, 2, 2, 2, 3, 1, 2, 2, 3, 1, 1, 2, 3, 2, 2, 2, 3, 0, 3, 3, 2, 2, 1, 0, 3, 0, 2, 0, 2, 2, 3, 0, 2, 2, 2, 1, 0, 2, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -932. And steps were 72 and the episode is 1606 and the total_steps are 95850\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 3, 3, 2, 0, 0, 0, 2, 3, 1, 2, 3, 0, 1, 0, 1, 2, 2, 0, 3, 0, 2, 2, 0, 0, 1, 3, 2, 0, 3, 3, 0, 0, 1, 3, 0, 2, 0, 0, 1, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 47 and the episode is 1607 and the total_steps are 95897\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 1, 1, 3, 2, 2, 2, 2, 1, 0, 2, 0, 3, 0, 1, 2, 2, 2, 3, 0, 1, 0, 2, 1, 0, 0, 2, 0, 3, 2, 2, 1, 0, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 40 and the episode is 1608 and the total_steps are 95937\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -864     |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1608     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2649     |\n",
      "|    total_timesteps  | 95937    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.335    |\n",
      "|    n_updates        | 11484    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 3, 1, 0, 3, 3, 1, 1, 2, 1, 3, 0, 1, 3, 2, 2, 1, 0, 3, 0, 1, 2, 0, 2, 0, 2, 3, 0, 2, 1, 0, 2, 3, 1, 3, 1, 0, 2, 0, 0, 1, 3, 3, 3, 1, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 52 and the episode is 1609 and the total_steps are 95989\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 2, 1, 0, 2, 3, 2, 3, 1, 1, 3, 1, 0, 2, 0, 1, 3, 2, 0, 2, 0, 1, 1, 0, 2, 2, 1, 0, 0, 1, 0, 0, 2, 1, 1, 2, 1, 0, 3, 1, 0, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 48 and the episode is 1610 and the total_steps are 96037\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 2, 2, 2, 3, 3, 0, 2, 2, 1, 0, 3, 3, 1, 1, 2, 2, 2, 1, 1, 2, 0, 2, 1, 1, 1, 2, 2, 1, 3, 0, 1, 2, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 1611 and the total_steps are 96077\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 1, 3, 2, 3, 0, 1, 1, 3, 1, 2, 1, 0, 0, 0, 3, 3, 2, 1, 2, 0, 1, 0, 3, 0, 3, 1, 2, 3, 3, 0, 2, 3, 3, 0, 2, 2, 2, 0, 0, 2, 0, 1, 3, 1, 1, 1, 3, 0, 1, 0, 2, 2, 0, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 72 and the episode is 1612 and the total_steps are 96149\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -863     |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1612     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2657     |\n",
      "|    total_timesteps  | 96149    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 30.8     |\n",
      "|    n_updates        | 11537    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 1, 0, 1, 2, 1, 3, 2, 2, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 1613 and the total_steps are 96165\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 0, 0, 3, 2, 3, 3, 2, 3, 2, 2, 3, 1, 3, 1, 1, 2, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 24 and the episode is 1614 and the total_steps are 96189\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 2, 1, 1, 1, 0, 3, 1, 2, 2, 0, 0, 0, 2, 2, 0, 2, 3, 0, 3, 3, 0, 0, 3, 2, 2, 3, 2, 0, 2, 2, 1, 0, 2, 3, 0, 2, 3, 2, 0, 3, 1, 1, 2, 0, 0, 2, 2, 3, 2, 3, 0, 2, 1, 1, 1, 3, 0, 1, 2, 3, 0, 2, 0, 0, 3, 0, 0, 3, 1, 2, 0, 1, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -938. And steps were 80 and the episode is 1615 and the total_steps are 96269\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 2, 0, 0, 1, 0, 0, 1, 1, 0, 2, 0, 1, 2, 0, 2, 3, 1, 1, 1, 3, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 1616 and the total_steps are 96295\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -862     |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1616     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2663     |\n",
      "|    total_timesteps  | 96295    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.8     |\n",
      "|    n_updates        | 11573    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 0, 3, 0, 3, 2, 3, 3, 1, 1, 2, 1, 3, 1, 3, 1, 3, 2, 0, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 26 and the episode is 1617 and the total_steps are 96321\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 3, 0, 1, 1, 1, 1, 3, 1, 2, 1, 2, 1, 3, 0, 2, 1, 3, 2, 2, 3, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 1618 and the total_steps are 96349\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 1, 2, 1, 0, 2, 3, 3, 0, 2, 0, 2, 1, 1, 2, 3, 1, 0, 3, 2, 0, 0, 1, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 30 and the episode is 1619 and the total_steps are 96379\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 1, 2, 1, 2, 2, 2, 0, 1, 0, 1, 0, 1, 0, 3, 0, 1, 1, 3, 3, 2, 2, 2, 1, 3, 3, 3, 0, 0, 0, 0, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 38 and the episode is 1620 and the total_steps are 96417\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1620     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2668     |\n",
      "|    total_timesteps  | 96417    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.18     |\n",
      "|    n_updates        | 11604    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 0, 2, 3, 2, 1, 2, 2, 2, 3, 0, 0, 1, 1, 1, 1, 3, 3, 2, 1, 1, 0, 2, 3, 3, 1, 2, 0, 3, 0, 3, 3, 3, 0, 0, 3, 3, 1, 2, 2, 1, 2, 0, 0, 1, 1, 0, 1, 0, 3, 1, 2, 1, 3, 1, 0, 2, 0, 3, 1, 3, 1, 2, 1, 2, 2, 0, 0, 1, 3, 0, 0, 0, 1, 2, 2, 2, 3, 3, 2, 3, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 88 and the episode is 1621 and the total_steps are 96505\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 2, 3, 0, 3, 0, 0, 0, 0, 3, 0, 1, 2, 0, 0, 3, 3, 3, 1, 3, 3, 1, 1, 2, 2, 1, 0, 2, 1, 1, 0, 0, 3, 0, 2, 0, 3, 3, 0, 3, 3, 0, 2, 2, 0, 2, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 52 and the episode is 1622 and the total_steps are 96557\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 1, 3, 3, 1, 3, 3, 1, 3, 1, 0, 2, 3, 3, 1, 0, 1, 0, 1, 2, 1, 0, 1, 0, 2, 0, 0, 0, 3, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 36 and the episode is 1623 and the total_steps are 96593\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 0, 1, 1, 3, 0, 2, 3, 0, 0, 2, 3, 2, 3, 3, 3, 1, 3, 3, 3, 0, 3, 1, 2, 0, 3, 3, 3, 0, 3, 2, 0, 1, 0, 3, 0, 1, 1, 3, 3, 1, 0, 2, 2, 1, 1, 0, 2, 3, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 56 and the episode is 1624 and the total_steps are 96649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -882     |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1624     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2677     |\n",
      "|    total_timesteps  | 96649    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.575    |\n",
      "|    n_updates        | 11662    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 2, 1, 2, 1, 1, 1, 0, 1, 0, 2, 3, 1, 3, 0, 1, 1, 3, 1, 0, 1, 1, 0, 3, 1, 0, 3, 1, 1, 3, 0, 0, 1, 1, 2, 0, 0, 2, 0, 2, 3, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 48 and the episode is 1625 and the total_steps are 96697\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 2, 2, 2, 3, 1, 1, 0, 0, 1, 2, 3, 0, 1, 3, 1, 0, 2, 3, 3, 3, 3, 0, 3, 0, 0, 2, 0, 3, 3, 0, 3, 0, 2, 1, 1, 1, 1, 2, 2, 1, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 48 and the episode is 1626 and the total_steps are 96745\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 0, 3, 1, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 1, 2, 0, 1, 2, 2, 1, 2, 3, 0, 2, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 42 and the episode is 1627 and the total_steps are 96787\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 0, 2, 0, 1, 1, 0, 3, 0, 2, 3, 1, 0, 1, 1, 3, 3, 0, 3, 1, 1, 1, 2, 2, 0, 2, 3, 3, 0, 3, 3, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 38 and the episode is 1628 and the total_steps are 96825\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1628     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2684     |\n",
      "|    total_timesteps  | 96825    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.425    |\n",
      "|    n_updates        | 11706    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 0, 0, 0, 0, 1, 2, 0, 2, 2, 2, 3, 2, 1, 0, 1, 1, 2, 2, 0, 1, 1, 2, 2, 0, 1, 3, 2, 2, 1, 3, 1, 3, 0, 1, 0, 2, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 44 and the episode is 1629 and the total_steps are 96869\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 0, 1, 0, 2, 0, 1, 2, 1, 1, 1, 3, 1, 2, 0, 0, 0, 1, 3, 0, 0, 0, 2, 1, 2, 1, 1, 3, 3, 3, 1, 0, 1, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 40 and the episode is 1630 and the total_steps are 96909\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 0, 0, 2, 3, 1, 1, 1, 1, 0, 2, 3, 3, 3, 0, 3, 3, 2, 2, 1, 1, 3, 3, 0, 0, 1, 1, 2, 0, 1, 2, 2, 3, 0, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 51 and the episode is 1631 and the total_steps are 96960\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 1, 3, 3, 3, 0, 2, 2, 3, 3, 3, 2, 1, 3, 3, 1, 0, 3, 2, 3, 1, 1, 0, 1, 3, 1, 3, 0, 2, 0, 3, 2, 3, 1, 3, 0, 2, 2, 0, 1, 0, 3, 2, 3, 2, 0, 1, 3, 1, 0, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 57 and the episode is 1632 and the total_steps are 97017\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1632     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2691     |\n",
      "|    total_timesteps  | 97017    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.732    |\n",
      "|    n_updates        | 11754    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 2, 2, 2, 2, 3, 1, 0, 0, 3, 0, 1, 0, 0, 3, 1, 1, 1, 1, 2, 0, 1, 3, 2, 2, 2, 1, 1, 3, 3, 2, 1, 3, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 40 and the episode is 1633 and the total_steps are 97057\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 3, 0, 2, 1, 3, 0, 0, 3, 0, 1, 1, 0, 1, 3, 2, 3, 3, 2, 1, 1, 0, 3, 3, 2, 1, 3, 3, 3, 2, 1, 0, 3, 3, 0, 0, 3, 3, 2, 2, 2, 0, 0, 1, 1, 0, 1, 1, 1, 3, 1, 2, 0, 1, 1, 3, 2, 2, 3, 0, 0, 1, 3, 1, 3, 3, 2, 0, 1, 1, 2, 1, 1, 0, 1, 3, 2, 2, 2, 3, 0, 2, 0, 1, 0, 0, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -921. And steps were 93 and the episode is 1634 and the total_steps are 97150\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 2, 0, 1, 3, 3, 0, 3, 3, 2, 2, 2, 2, 2, 0, 1, 3, 1, 1, 3, 2, 3, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1635 and the total_steps are 97179\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 1, 0, 3, 0, 2, 3, 3, 2, 0, 3, 0, 2, 0, 2, 3, 1, 3, 1, 1, 3, 3, 1, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 30 and the episode is 1636 and the total_steps are 97209\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1636     |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2699     |\n",
      "|    total_timesteps  | 97209    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.72     |\n",
      "|    n_updates        | 11802    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 1, 1, 3, 1, 1, 3, 3, 2, 0, 2, 2, 2, 3, 1, 2, 2, 3, 3, 1, 3, 2, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 29 and the episode is 1637 and the total_steps are 97238\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 3, 3, 1, 3, 3, 3, 3, 0, 1, 3, 0, 0, 1, 0, 2, 0, 1, 1, 1, 3, 0, 2, 2, 0, 3, 2, 2, 0, 0, 2, 1, 2, 0, 1, 2, 3, 3, 0, 3, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 47 and the episode is 1638 and the total_steps are 97285\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 1, 3, 0, 3, 1, 3, 1, 1, 3, 0, 3, 3, 3, 1, 1, 3, 2, 2, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 1639 and the total_steps are 97311\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 2, 3, 2, 3, 1, 0, 1, 0, 0, 2, 3, 2, 1, 3, 3, 1, 1, 3, 2, 2, 3, 3, 3, 0, 0, 1, 2, 2, 2, 0, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 38 and the episode is 1640 and the total_steps are 97349\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1640     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2705     |\n",
      "|    total_timesteps  | 97349    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.6     |\n",
      "|    n_updates        | 11837    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 2, 3, 3, 0, 0, 0, 3, 1, 0, 2, 2, 0, 2, 1, 1, 0, 2, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 25 and the episode is 1641 and the total_steps are 97374\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 3, 2, 1, 2, 1, 0, 2, 0, 3, 2, 1, 0, 2, 0, 2, 2, 0, 1, 0, 1, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 1642 and the total_steps are 97402\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 1, 2, 2, 1, 0, 0, 3, 0, 2, 2, 0, 0, 0, 1, 3, 1, 0, 1, 2, 0, 0, 1, 1, 2, 1, 0, 3, 3, 3, 2, 3, 1, 2, 2, 2, 0, 1, 1, 3, 0, 2, 1, 1, 0, 1, 0, 3, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 55 and the episode is 1643 and the total_steps are 97457\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 3, 0, 0, 0, 3, 2, 0, 2, 3, 1, 2, 1, 0, 2, 2, 2, 3, 1, 2, 1, 0, 3, 0, 1, 3, 2, 1, 1, 2, 3, 0, 2, 3, 3, 0, 3, 1, 0, 2, 0, 2, 3, 3, 2, 3, 0, 1, 0, 2, 3, 3, 0, 0, 1, 0, 1, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 64 and the episode is 1644 and the total_steps are 97521\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1644     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2712     |\n",
      "|    total_timesteps  | 97521    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 11880    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 3, 1, 1, 1, 3, 3, 3, 0, 1, 0, 2, 1, 1, 1, 2, 0, 3, 2, 3, 2, 0, 3, 2, 1, 0, 2, 0, 2, 1, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 37 and the episode is 1645 and the total_steps are 97558\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 2, 2, 3, 0, 1, 2, 2, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 15 and the episode is 1646 and the total_steps are 97573\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 2, 1, 3, 0, 2, 3, 2, 1, 2, 0, 0, 2, 2, 1, 3, 2, 1, 1, 3, 3, 0, 1, 1, 0, 3, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 3, 0, 0, 3, 1, 0, 0, 2, 0, 3, 0, 2, 0, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 56 and the episode is 1647 and the total_steps are 97629\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 0, 0, 3, 3, 3, 1, 2, 1, 3, 2, 0, 3, 0, 0, 3, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 3, 3, 3, 2, 0, 0, 1, 1, 1, 2, 0, 3, 0, 0, 2, 1, 2, 2, 3, 2, 1, 3, 3, 1, 0, 3, 2, 2, 3, 0, 1, 0, 1, 0, 0, 3, 1, 1, 2, 1, 0, 0, 1, 0, 0, 3, 1, 1, 3, 0, 1, 0, 2, 0, 2, 1, 3, 2, 3, 3, 1, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 100 and the episode is 1648 and the total_steps are 97729\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1648     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2720     |\n",
      "|    total_timesteps  | 97729    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.21     |\n",
      "|    n_updates        | 11932    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 0, 0, 3, 3, 0, 3, 0, 1, 0, 0, 1, 0, 0, 1, 0, 3, 0, 2, 0, 1, 1, 0, 3, 1, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 32 and the episode is 1649 and the total_steps are 97761\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 2, 1, 0, 2, 2, 1, 1, 1, 0, 1, 1, 2, 2, 2, 0, 0, 3, 3, 1, 3, 0, 3, 0, 2, 1, 3, 0, 1, 1, 2, 0, 2, 1, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 41 and the episode is 1650 and the total_steps are 97802\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 2, 1, 3, 3, 3, 3, 3, 2, 0, 1, 2, 3, 1, 2, 1, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 23 and the episode is 1651 and the total_steps are 97825\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 0, 1, 1, 0, 1, 0, 1, 3, 3, 0, 0, 2, 0, 1, 3, 3, 0, 1, 1, 0, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 28 and the episode is 1652 and the total_steps are 97853\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1652     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2725     |\n",
      "|    total_timesteps  | 97853    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.4     |\n",
      "|    n_updates        | 11963    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 1, 0, 2, 0, 3, 1, 0, 2, 0, 2, 0, 2, 0, 2, 0, 3, 3, 3, 3, 1, 3, 2, 2, 1, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1653 and the total_steps are 97885\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 3, 3, 2, 1, 2, 0, 3, 0, 2, 2, 0, 0, 3, 0, 3, 3, 2, 2, 0, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 27 and the episode is 1654 and the total_steps are 97912\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 0, 2, 1, 0, 3, 0, 0, 1, 2, 1, 2, 0, 1, 0, 3, 3, 0, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 25 and the episode is 1655 and the total_steps are 97937\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 0, 1, 2, 2, 1, 1, 1, 3, 3, 0, 1, 1, 2, 3, 3, 0, 2, 1, 1, 3, 0, 3, 3, 3, 2, 2, 0, 2, 3, 2, 0, 1, 1, 3, 0, 3, 3, 1, 3, 3, 3, 1, 0, 0, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 52 and the episode is 1656 and the total_steps are 97989\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1656     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2730     |\n",
      "|    total_timesteps  | 97989    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 11997    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 0, 1, 3, 3, 2, 3, 0, 1, 0, 1, 0, 3, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1017. And steps were 18 and the episode is 1657 and the total_steps are 98007\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 2, 2, 0, 2, 0, 2, 0, 3, 2, 3, 0, 2, 0, 1, 1, 2, 1, 2, 2, 3, 3, 2, 3, 1, 1, 1, 0, 3, 0, 1, 0, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 39 and the episode is 1658 and the total_steps are 98046\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 1, 0, 1, 3, 2, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 0, 3, 1, 0, 1, 3, 1, 0, 1, 1, 3, 3, 3, 1, 1, 0, 0, 0, 3, 1, 1, 3, 2, 2, 3, 0, 0, 1, 3, 2, 1, 0, 3, 3, 2, 3, 0, 2, 0, 3, 3, 1, 0, 3, 1, 0, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1041. And steps were 79 and the episode is 1659 and the total_steps are 98125\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 3, 2, 3, 2, 3, 2, 0, 2, 2, 1, 1, 0, 1, 0, 1, 2, 0, 3, 3, 2, 2, 3, 3, 0, 2, 1, 1, 1, 0, 2, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 38 and the episode is 1660 and the total_steps are 98163\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1660     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2737     |\n",
      "|    total_timesteps  | 98163    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 35       |\n",
      "|    n_updates        | 12040    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 2, 0, 1, 2, 2, 2, 1, 0, 0, 0, 0, 2, 2, 3, 3, 0, 2, 1, 3, 0, 2, 2, 0, 3, 2, 0, 2, 3, 0, 1, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 38 and the episode is 1661 and the total_steps are 98201\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 0, 2, 3, 1, 2, 3, 2, 2, 3, 0, 3, 2, 2, 0, 2, 3, 0, 0, 0, 1, 0, 0, 1, 3, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 32 and the episode is 1662 and the total_steps are 98233\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 0, 1, 0, 1, 2, 1, 1, 1, 1, 0, 3, 1, 2, 2, 0, 2, 0, 3, 0, 2, 3, 1, 0, 3, 2, 3, 2, 1, 2, 1, 2, 1, 0, 0, 3, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 43 and the episode is 1663 and the total_steps are 98276\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 2, 2, 0, 3, 3, 1, 2, 2, 0, 0, 0, 2, 1, 0, 2, 0, 3, 0, 0, 0, 2, 2, 3, 2, 0, 1, 3, 2, 2, 1, 2, 1, 3, 3, 2, 1, 0, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 45 and the episode is 1664 and the total_steps are 98321\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1664     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2744     |\n",
      "|    total_timesteps  | 98321    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.684    |\n",
      "|    n_updates        | 12080    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 3, 1, 3, 0, 3, 3, 2, 1, 2, 1, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 1, 2, 0, 3, 2, 1, 2, 2, 2, 1, 0, 2, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 40 and the episode is 1665 and the total_steps are 98361\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 1, 1, 2, 1, 1, 2, 2, 0, 0, 1, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 18 and the episode is 1666 and the total_steps are 98379\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 0, 0, 1, 0, 2, 0, 3, 3, 2, 2, 0, 0, 1, 0, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 22 and the episode is 1667 and the total_steps are 98401\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 3, 2, 3, 1, 2, 3, 2, 0, 1, 1, 2, 2, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 20 and the episode is 1668 and the total_steps are 98421\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1668     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2748     |\n",
      "|    total_timesteps  | 98421    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.9     |\n",
      "|    n_updates        | 12105    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 0, 0, 1, 2, 0, 0, 2, 0, 1, 3, 3, 1, 2, 1, 1, 1, 1, 0, 2, 1, 2, 1, 0, 0, 3, 2, 1, 3, 2, 0, 3, 1, 2, 2, 1, 1, 2, 2, 1, 0, 2, 1, 0, 1, 2, 0, 3, 3, 3, 0, 3, 1, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 60 and the episode is 1669 and the total_steps are 98481\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 2, 1, 2, 0, 2, 1, 3, 0, 3, 3, 2, 3, 2, 1, 3, 0, 1, 0, 2, 2, 3, 3, 2, 3, 1, 3, 2, 1, 2, 0, 0, 3, 2, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 41 and the episode is 1670 and the total_steps are 98522\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 3, 1, 2, 0, 0, 2, 3, 0, 0, 1, 3, 2, 2, 1, 1, 1, 0, 2, 2, 3, 0, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1022. And steps were 27 and the episode is 1671 and the total_steps are 98549\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 2, 0, 1, 1, 2, 1, 0, 3, 2, 1, 0, 2, 1, 0, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was 983. And steps were 20 and the episode is 1672 and the total_steps are 98569\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1672     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2753     |\n",
      "|    total_timesteps  | 98569    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 12142    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 0, 3, 2, 3, 1, 2, 1, 1, 2, 1, 1, 0, 3, 3, 2, 0, 2, 2, 2, 1, 3, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 3, 3, 2, 3, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 56 and the episode is 1673 and the total_steps are 98625\n",
      "Done condition: collision\n",
      "[3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 1, 0, 1, 3, 3, 0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 3, 3, 2, 0, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 40 and the episode is 1674 and the total_steps are 98665\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 3, 0, 2, 1, 1, 1, 1, 0, 2, 3, 2, 3, 1, 1, 0, 1, 3, 0, 0, 2, 3, 3, 3, 2, 1, 0, 3, 2, 3, 2, 3, 2, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 40 and the episode is 1675 and the total_steps are 98705\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 3, 1, 2, 3, 0, 2, 3, 3, 1, 3, 3, 0, 1, 1, 1, 1, 2, 3, 2, 3, 1, 3, 3, 1, 3, 1, 1, 2, 1, 1, 3, 2, 3, 3, 3, 1, 2, 3, 0, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 0, 3, 2, 2, 0, 2, 2, 0, 1, 2, 3, 0, 0, 1, 2, 2, 1, 3, 1, 1, 1, 3, 3, 0, 3, 2, 0, 0, 3, 3, 0, 0, 2, 0, 3, 0, 3, 0, 0, 0, 1, 0, 0, 1, 0, 3, 2, 3, 1, 2, 3, 0, 1, 2, 3, 1, 2, 0, 2, 2, 0, 1, 1, 3, 3, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -902. And steps were 124 and the episode is 1676 and the total_steps are 98829\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1676     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2763     |\n",
      "|    total_timesteps  | 98829    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 12207    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 2, 0, 3, 2, 0, 1, 2, 0, 0, 3, 1, 0, 2, 2, 1, 2, 1, 1, 3, 2, 2, 3, 2, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 31 and the episode is 1677 and the total_steps are 98860\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 0, 1, 0, 2, 3, 0, 0, 1, 2, 0, 1, 1, 2, 0, 0, 3, 3, 2, 2, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 1678 and the total_steps are 98887\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 2, 0, 0, 0, 3, 0, 2, 1, 2, 0, 3, 2, 3, 3, 3, 3, 3, 0, 0, 1, 1, 3, 3, 2, 2, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 1679 and the total_steps are 98920\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 1, 3, 1, 0, 0, 1, 1, 2, 3, 3, 0, 1, 3, 3, 0, 2, 2, 0, 0, 1, 3, 3, 1, 3, 0, 0, 3, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 3, 3, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 47 and the episode is 1680 and the total_steps are 98967\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1680     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2769     |\n",
      "|    total_timesteps  | 98967    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 12241    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 2, 1, 3, 3, 0, 1, 2, 1, 3, 2, 1, 1, 0, 0, 0, 2, 2, 3, 1, 0, 3, 2, 3, 1, 3, 3, 1, 1, 0, 1, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 38 and the episode is 1681 and the total_steps are 99005\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 3, 0, 0, 2, 1, 2, 0, 2, 2, 1, 1, 2, 1, 3, 0, 2, 2, 2, 0, 0, 3, 0, 1, 0, 0, 3, 1, 3, 1, 0, 3, 0, 3, 2, 3, 2, 2, 0, 2, 0, 1, 0, 3, 0, 1, 2, 2, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 55 and the episode is 1682 and the total_steps are 99060\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 3, 3, 2, 2, 2, 0, 3, 1, 3, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 17 and the episode is 1683 and the total_steps are 99077\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 2, 0, 3, 2, 2, 3, 1, 0, 1, 0, 3, 0, 3, 2, 1, 3, 0, 0, 3, 1, 2, 0, 2, 0, 1, 3, 1, 2, 0, 0, 3, 3, 0, 3, 3, 1, 0, 1, 1, 2, 3, 0, 2, 3, 3, 1, 0, 2, 3, 1, 1, 2, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 60 and the episode is 1684 and the total_steps are 99137\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1684     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2776     |\n",
      "|    total_timesteps  | 99137    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.605    |\n",
      "|    n_updates        | 12284    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 1, 1, 3, 1, 2, 3, 2, 2, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 1685 and the total_steps are 99153\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 1, 1, 0, 1, 0, 2, 0, 2, 0, 3, 1, 2, 1, 3, 3, 2, 2, 2, 3, 2, 1, 2, 0, 0, 1, 3, 3, 1, 3, 2, 3, 1, 2, 2, 3, 2, 2, 1, 3, 3, 0, 1, 3, 0, 0, 3, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 54 and the episode is 1686 and the total_steps are 99207\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 3, 3, 0, 1, 0, 1, 2, 3, 2, 2, 2, 1, 2, 2, 0, 3, 1, 3, 0, 1, 1, 1, 1, 2, 1, 2, 2, 2, 3, 3, 0, 1, 0, 0, 2, 3, 3, 2, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 46 and the episode is 1687 and the total_steps are 99253\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 2, 2, 3, 1, 0, 3, 3, 0, 0, 0, 1, 0, 2, 1, 3, 0, 0, 2, 3, 0, 0, 0, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1688 and the total_steps are 99283\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1688     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2782     |\n",
      "|    total_timesteps  | 99283    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 12320    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 1, 0, 0, 3, 3, 0, 1, 1, 2, 0, 1, 3, 3, 0, 3, 2, 2, 1, 0, 3, 2, 1, 1, 2, 2, 3, 2, 0, 2, 3, 2, 1, 1, 2, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 1689 and the total_steps are 99325\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 3, 3, 3, 2, 3, 1, 2, 3, 2, 1, 1, 2, 3, 2, 3, 1, 2, 3, 3, 3, 2, 0, 2, 3, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 32 and the episode is 1690 and the total_steps are 99357\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 0, 3, 2, 3, 2, 0, 3, 3, 1, 3, 0, 3, 0, 1, 2, 0, 2, 2, 3, 1, 2, 3, 3, 1, 0, 2, 2, 2, 3, 0, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 38 and the episode is 1691 and the total_steps are 99395\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 2, 3, 0, 3, 0, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3, 1, 2, 3, 3, 1, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 30 and the episode is 1692 and the total_steps are 99425\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1692     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2788     |\n",
      "|    total_timesteps  | 99425    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 12356    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 1, 3, 3, 2, 2, 3, 3, 1, 0, 2, 2, 0, 0, 3, 1, 3, 3, 3, 2, 3, 1, 3, 3, 0, 3, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 1693 and the total_steps are 99458\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 2, 1, 1, 1, 1, 1, 1, 0, 3, 1, 1, 3, 3, 3, 2, 3, 3, 2, 0, 2, 1, 2, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 30 and the episode is 1694 and the total_steps are 99488\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 1, 2, 3, 1, 3, 1, 2, 3, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 17 and the episode is 1695 and the total_steps are 99505\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 3, 1, 1, 0, 2, 1, 1, 2, 3, 3, 3, 3, 2, 3, 2, 2, 1, 3, 2, 1, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 40 and the episode is 1696 and the total_steps are 99545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1696     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2792     |\n",
      "|    total_timesteps  | 99545    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 93.5     |\n",
      "|    n_updates        | 12386    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 2, 0, 0, 2, 1, 1, 3, 1, 2, 0, 2, 3, 3, 2, 0, 1, 0, 2, 3, 0, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 0, 1, 2, 2, 1, 0, 1, 2, 1, 1, 2, 3, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 50 and the episode is 1697 and the total_steps are 99595\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 0, 0, 0, 1, 2, 1, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 14 and the episode is 1698 and the total_steps are 99609\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 0, 2, 3, 1, 2, 2, 0, 1, 0, 3, 0, 0, 3, 0, 0, 1, 2, 1, 1, 2, 1, 2, 1, 2, 3, 2, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 34 and the episode is 1699 and the total_steps are 99643\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 0, 3, 3, 2, 3, 0, 2, 2, 1, 1, 0, 2, 1, 2, 2, 3, 2, 1, 1, 2, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 1700 and the total_steps are 99683\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2798     |\n",
      "|    total_timesteps  | 99683    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.37     |\n",
      "|    n_updates        | 12420    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 3, 1, 0, 1, 0, 3, 2, 3, 2, 2, 2, 1, 0, 3, 0, 3, 0, 2, 2, 1, 2, 2, 1, 3, 2, 3, 0, 2, 1, 0, 1, 2, 1, 3, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 42 and the episode is 1701 and the total_steps are 99725\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 3, 2, 0, 1, 2, 1, 3, 3, 1, 1, 2, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 1702 and the total_steps are 99751\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 2, 2, 3, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 3, 2, 1, 3, 1, 0, 3, 0, 0, 2, 1, 2, 0, 0, 3, 2, 1, 3, 0, 0, 1, 0, 2, 1, 1, 2, 1, 1, 2, 3, 3, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 52 and the episode is 1703 and the total_steps are 99803\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 2, 3, 1, 3, 0, 1, 0, 0, 0, 2, 1, 1, 1, 2, 1, 0, 2, 3, 2, 2, 0, 2, 3, 2, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1704 and the total_steps are 99835\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1704     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2804     |\n",
      "|    total_timesteps  | 99835    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.548    |\n",
      "|    n_updates        | 12458    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 0, 0, 2, 3, 2, 1, 0, 1, 2, 3, 1, 2, 1, 2, 3, 3, 3, 0, 3, 1, 2, 1, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 30 and the episode is 1705 and the total_steps are 99865\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 3, 1, 1, 2, 3, 3, 3, 1, 1, 0, 2, 0, 2, 1, 0, 1, 0, 1, 2, 2, 2, 1, 2, 3, 3, 1, 3, 0, 3, 3, 1, 0, 0, 0, 1, 0, 0, 3, 1, 0, 3, 3, 1, 1, 3, 2, 2, 2, 2, 0, 2, 2, 0, 2, 3, 3, 3, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -944. And steps were 76 and the episode is 1706 and the total_steps are 99941\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 2, 0, 1, 2, 3, 0, 0, 1, 0, 0, 0, 3, 3, 1, 1, 2, 2, 0, 1, 1, 0, 0, 0, 2, 2, 3, 2, 0, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 36 and the episode is 1707 and the total_steps are 99977\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 3, 0, 2, 0, 1, 3, 3, 3, 0, 1, 3, 3, 0, 0, 1, 3, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 1708 and the total_steps are 100009\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1708     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2811     |\n",
      "|    total_timesteps  | 100009   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.5     |\n",
      "|    n_updates        | 12502    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 1, 3, 3, 2, 0, 3, 2, 3, 1, 0, 2, 3, 3, 3, 3, 3, 0, 3, 2, 0, 1, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 29 and the episode is 1709 and the total_steps are 100038\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 2, 1, 3, 2, 2, 0, 3, 2, 0, 0, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 0, 1, 2, 3, 0, 2, 0, 3, 0, 0, 2, 2, 1, 3, 3, 0, 3, 3, 3, 3, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 49 and the episode is 1710 and the total_steps are 100087\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 0, 2, 0, 1, 3, 1, 2, 3, 1, 2, 1, 1, 0, 1, 3, 3, 0, 0, 1, 2, 2, 2, 2, 0, 3, 1, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 34 and the episode is 1711 and the total_steps are 100121\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 1, 2, 1, 2, 3, 0, 3, 0, 2, 3, 1, 0, 1, 2, 3, 1, 3, 1, 0, 3, 1, 3, 0, 2, 3, 2, 0, 3, 1, 1, 2, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 1712 and the total_steps are 100161\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1712     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2817     |\n",
      "|    total_timesteps  | 100161   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 12540    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 1, 0, 2, 1, 2, 1, 0, 2, 3, 1, 1, 1, 2, 0, 3, 2, 1, 0, 0, 1, 0, 3, 1, 0, 3, 0, 3, 0, 1, 0, 3, 0, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 40 and the episode is 1713 and the total_steps are 100201\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 3, 2, 0, 2, 1, 1, 2, 2, 1, 3, 1, 1, 1, 1, 3, 1, 1, 2, 3, 0, 3, 1, 2, 2, 3, 3, 3, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 1714 and the total_steps are 100236\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 3, 2, 1, 1, 3, 0, 3, 3, 1, 0, 1, 0, 1, 3, 3, 0, 0, 1, 0, 0, 2, 3, 1, 1, 0, 2, 3, 0, 1, 3, 2, 2, 3, 0, 1, 0, 2, 0, 2, 0, 3, 0, 0, 3, 0, 2, 1, 3, 2, 1, 3, 0, 1, 3, 3, 3, 1, 0, 1, 3, 2, 1, 1, 2, 2, 1, 3, 2, 0, 3, 0, 0, 3, 3, 3, 1, 1, 3, 2, 1, 0, 3, 1, 3, 2, 0, 0, 2, 3, 1, 0, 1, 1, 3, 0, 3, 2, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -905. And steps were 105 and the episode is 1715 and the total_steps are 100341\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 2, 3, 1, 0, 2, 3, 2, 3, 1, 0, 2, 1, 2, 1, 2, 2, 2, 3, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 36 and the episode is 1716 and the total_steps are 100377\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1716     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2826     |\n",
      "|    total_timesteps  | 100377   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 12594    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 1, 3, 2, 1, 0, 2, 3, 0, 3, 3, 2, 3, 1, 1, 0, 0, 2, 2, 3, 2, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 1717 and the total_steps are 100405\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 1, 0, 0, 0, 0, 2, 2, 1, 3, 0, 0, 1, 2, 2, 0, 2, 1, 3, 1, 3, 2, 3, 0, 2, 3, 1, 2, 3, 1, 2, 0, 1, 3, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 41 and the episode is 1718 and the total_steps are 100446\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 3, 0, 1, 2, 1, 0, 2, 1, 2, 0, 0, 3, 3, 1, 1, 3, 0, 0, 3, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 27 and the episode is 1719 and the total_steps are 100473\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 1, 3, 0, 0, 2, 1, 0, 3, 1, 3, 1, 2, 2, 3, 1, 1, 3, 0, 1, 3, 1, 3, 1, 1, 3, 2, 2, 0, 0, 0, 3, 0, 3, 2, 0, 1, 2, 1, 0, 0, 1, 1, 3, 3, 1, 3, 0, 1, 2, 1, 1, 0, 3, 0, 0, 2, 1, 0, 3, 2, 1, 1, 3, 1, 0, 3, 1, 0, 0, 1, 2, 0, 2, 2, 3, 0, 1, 3, 0, 0, 2, 1, 1, 2, 2, 2, 1, 1, 0, 3, 0, 2, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -924. And steps were 100 and the episode is 1720 and the total_steps are 100573\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1720     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2834     |\n",
      "|    total_timesteps  | 100573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.24     |\n",
      "|    n_updates        | 12643    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 0, 0, 2, 0, 0, 0, 3, 0, 1, 3, 0, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 0, 1, 1, 3, 0, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 35 and the episode is 1721 and the total_steps are 100608\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 2, 2, 2, 3, 0, 3, 1, 1, 3, 0, 2, 2, 3, 2, 1, 0, 0, 2, 2, 0, 0, 0, 3, 0, 0, 3, 1, 1, 3, 3, 2, 0, 3, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 41 and the episode is 1722 and the total_steps are 100649\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 1, 0, 2, 2, 1, 3, 3, 1, 2, 1, 0, 1, 0, 2, 3, 1, 2, 3, 1, 3, 3, 3, 3, 2, 3, 0, 2, 3, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 36 and the episode is 1723 and the total_steps are 100685\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 0, 0, 3, 0, 1, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 3, 1, 3, 2, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 29 and the episode is 1724 and the total_steps are 100714\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1724     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2840     |\n",
      "|    total_timesteps  | 100714   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 12678    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 0, 0, 0, 1, 0, 1, 2, 3, 2, 2, 1, 2, 3, 2, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1019. And steps were 20 and the episode is 1725 and the total_steps are 100734\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 0, 0, 3, 1, 3, 3, 3, 1, 3, 1, 0, 1, 1, 2, 3, 0, 2, 2, 0, 3, 2, 3, 1, 1, 0, 2, 0, 1, 2, 0, 2, 2, 0, 1, 3, 3, 0, 3, 2, 0, 3, 1, 2, 0, 1, 1, 1, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 55 and the episode is 1726 and the total_steps are 100789\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 0, 3, 0, 3, 0, 2, 2, 3, 2, 0, 3, 2, 0, 3, 3, 1, 0, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 31 and the episode is 1727 and the total_steps are 100820\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 0, 2, 1, 0, 1, 0, 0, 1, 3, 2, 3, 1, 1, 3, 0, 0, 0, 2, 1, 2, 3, 1, 0, 2, 2, 2, 3, 1, 3, 1, 3, 0, 2, 1, 2, 1, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 44 and the episode is 1728 and the total_steps are 100864\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1728     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2846     |\n",
      "|    total_timesteps  | 100864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.2     |\n",
      "|    n_updates        | 12715    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 3, 2, 1, 3, 1, 1, 0, 0, 1, 2, 1, 2, 2, 1, 1, 1, 3, 1, 3, 3, 2, 0, 2, 3, 0, 1, 1, 0, 3, 3, 3, 1, 1, 2, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 42 and the episode is 1729 and the total_steps are 100906\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 2, 3, 1, 3, 1, 3, 0, 1, 0, 1, 2, 1, 2, 3, 0, 3, 0, 3, 1, 1, 2, 1, 3, 2, 3, 2, 0, 3, 2, 2, 1, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 39 and the episode is 1730 and the total_steps are 100945\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 0, 0, 1, 2, 2, 1, 2, 0, 0, 0, 1, 2, 0, 3, 0, 1, 0, 2, 2, 1, 2, 2, 0, 1, 3, 0, 1, 0, 0, 1, 2, 0, 2, 1, 1, 2, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 1731 and the total_steps are 100989\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 2, 2, 0, 0, 1, 3, 0, 2, 3, 3, 0, 0, 1, 0, 3, 3, 0, 0, 2, 3, 3, 0, 0, 3, 1, 3, 3, 0, 2, 2, 3, 0, 3, 2, 3, 2, 0, 2, 2, 3, 3, 0, 0, 2, 2, 1, 2, 2, 0, 1, 2, 0, 0, 0, 1, 2, 0, 3, 0, 1, 2, 3, 0, 0, 2, 1, 3, 1, 2, 0, 1, 1, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 80 and the episode is 1732 and the total_steps are 101069\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1732     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2854     |\n",
      "|    total_timesteps  | 101069   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 12767    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 3, 0, 2, 0, 3, 2, 1, 1, 1, 2, 1, 2, 0, 1, 2, 2, 2, 1, 2, 1, 3, 0, 1, 2, 1, 0, 3, 2, 1, 1, 0, 1, 0, 1, 2, 2, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 1733 and the total_steps are 101113\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 2, 3, 1, 3, 1, 1, 2, 0, 0, 0, 1, 3, 3, 2, 3, 0, 0, 2, 3, 1, 2, 0, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1734 and the total_steps are 101143\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 0, 3, 1, 1, 2, 0, 1, 3, 3, 2, 2, 3, 1, 1, 0, 0, 3, 3, 0, 1, 1, 2, 1, 2, 2, 1, 3, 1, 0, 2, 3, 1, 3, 0, 2, 2, 3, 0, 0, 0, 0, 3, 0, 1, 2, 3, 3, 1, 2, 2, 3, 3, 3, 0, 0, 3, 1, 0, 1, 2, 1, 0, 0, 2, 3, 1, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 74 and the episode is 1735 and the total_steps are 101217\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 0, 1, 0, 0, 1, 3, 3, 1, 0, 2, 2, 2, 0, 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 2, 0, 3, 3, 1, 2, 2, 2, 2, 2, 3, 2, 0, 2, 2, 1, 2, 2, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 0, 3, 1, 1, 1, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 64 and the episode is 1736 and the total_steps are 101281\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1736     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2862     |\n",
      "|    total_timesteps  | 101281   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 12820    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 3, 2, 3, 0, 1, 2, 1, 3, 3, 1, 0, 1, 1, 3, 1, 2, 0, 3, 2, 1, 2, 3, 2, 3, 2, 3, 1, 2, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 36 and the episode is 1737 and the total_steps are 101317\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 2, 1, 2, 1, 1, 0, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 2, 3, 3, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 0, 1, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 1738 and the total_steps are 101359\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 2, 3, 0, 2, 3, 0, 0, 0, 0, 3, 3, 3, 0, 2, 3, 0, 0, 0, 2, 2, 2, 1, 3, 1, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 38 and the episode is 1739 and the total_steps are 101397\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 3, 0, 0, 2, 2, 3, 1, 1, 2, 1, 2, 3, 3, 3, 3, 1, 0, 2, 2, 0, 1, 2, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was 1027. And steps were 28 and the episode is 1740 and the total_steps are 101425\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1740     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2868     |\n",
      "|    total_timesteps  | 101425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.5     |\n",
      "|    n_updates        | 12856    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 1, 0, 1, 1, 3, 0, 3, 2, 2, 2, 0, 2, 3, 0, 2, 0, 3, 0, 2, 1, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 1741 and the total_steps are 101453\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 1, 1, 0, 0, 2, 2, 3, 0, 0, 3, 0, 3, 1, 3, 3, 1, 3, 1, 2, 1, 0, 1, 1, 1, 3, 2, 3, 1, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 36 and the episode is 1742 and the total_steps are 101489\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 2, 2, 3, 3, 1, 0, 0, 0, 0, 2, 2, 2, 3, 1, 0, 3, 2, 2, 3, 0, 2, 2, 1, 2, 2, 1, 2, 1, 1, 3, 0, 1, 2, 2, 1, 1, 3, 1, 2, 3, 2, 3, 1, 1, 2, 0, 1, 2, 1, 0, 3, 1, 3, 0, 0, 3, 2, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 65 and the episode is 1743 and the total_steps are 101554\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 1, 2, 3, 3, 0, 3, 3, 0, 0, 0, 3, 1, 0, 0, 1, 1, 2, 1, 2, 3, 3, 2, 1, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 1744 and the total_steps are 101585\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1744     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2874     |\n",
      "|    total_timesteps  | 101585   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.955    |\n",
      "|    n_updates        | 12896    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 1, 3, 2, 1, 3, 3, 1, 1, 0, 3, 2, 2, 1, 2, 1, 3, 2, 0, 0, 1, 0, 1, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 30 and the episode is 1745 and the total_steps are 101615\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 2, 0, 0, 2, 2, 0, 1, 0, 0, 2, 1, 1, 3, 1, 3, 2, 3, 3, 1, 3, 1, 3, 2, 0, 1, 1, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 34 and the episode is 1746 and the total_steps are 101649\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 1, 2, 0, 3, 1, 2, 0, 3, 2, 2, 0, 0, 2, 1, 3, 3, 3, 1, 0, 2, 1, 3, 0, 1, 0, 3, 1, 0, 2, 2, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 1747 and the total_steps are 101687\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 2, 3, 3, 0, 0, 1, 1, 2, 2, 2, 3, 2, 0, 3, 3, 0, 2, 2, 0, 2, 3, 3, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1748 and the total_steps are 101717\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1748     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2880     |\n",
      "|    total_timesteps  | 101717   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.98     |\n",
      "|    n_updates        | 12929    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 0, 0, 2, 1, 3, 2, 3, 0, 2, 2, 2, 2, 2, 0, 3, 1, 1, 0, 2, 2, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 28 and the episode is 1749 and the total_steps are 101745\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 0, 3, 2, 3, 0, 1, 3, 0, 1, 0, 3, 1, 2, 0, 2, 2, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 24 and the episode is 1750 and the total_steps are 101769\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 1, 3, 3, 2, 1, 2, 3, 0, 3, 0, 2, 2, 3, 3, 0, 3, 0, 1, 1, 0, 1, 0, 1, 3, 2, 0, 0, 2, 1, 1, 3, 1, 1, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 41 and the episode is 1751 and the total_steps are 101810\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 3, 3, 2, 2, 3, 1, 1, 2, 1, 0, 2, 0, 0, 0, 0, 1, 2, 2, 1, 3, 2, 2, 0, 2, 0, 1, 3, 1, 3, 3, 0, 2, 2, 3, 3, 1, 0, 3, 3, 0, 0, 2, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 50 and the episode is 1752 and the total_steps are 101860\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1752     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2885     |\n",
      "|    total_timesteps  | 101860   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 12964    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 2, 1, 1, 1, 0, 3, 1, 1, 1, 1, 1, 2, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 1753 and the total_steps are 101888\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 1, 1, 2, 0, 2, 1, 3, 2, 1, 0, 2, 2, 0, 1, 0, 3, 3, 0, 2, 3, 1, 3, 2, 2, 2, 2, 0, 1, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 36 and the episode is 1754 and the total_steps are 101924\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 2, 0, 3, 3, 0, 2, 0, 2, 0, 2, 3, 3, 3, 0, 0, 1, 0, 1, 1, 3, 3, 3, 1, 2, 1, 0, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 1755 and the total_steps are 101958\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 1, 1, 1, 0, 0, 3, 2, 2, 2, 1, 2, 2, 3, 1, 3, 1, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 24 and the episode is 1756 and the total_steps are 101982\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1756     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2891     |\n",
      "|    total_timesteps  | 101982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 12995    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 1, 3, 2, 0, 2, 1, 2, 2, 0, 3, 2, 1, 1, 2, 3, 3, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 1757 and the total_steps are 102006\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 1, 1, 3, 0, 3, 0, 0, 2, 3, 1, 3, 2, 2, 1, 3, 1, 3, 3, 2, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 27 and the episode is 1758 and the total_steps are 102033\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 3, 2, 3, 0, 1, 0, 2, 1, 1, 0, 3, 3, 0, 1, 2, 3, 1, 1, 3, 2, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 1759 and the total_steps are 102061\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 2, 1, 0, 2, 3, 2, 3, 2, 3, 3, 1, 1, 2, 0, 1, 2, 0, 2, 1, 2, 2, 2, 3, 2, 0, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 33 and the episode is 1760 and the total_steps are 102094\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1760     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2895     |\n",
      "|    total_timesteps  | 102094   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.482    |\n",
      "|    n_updates        | 13023    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 3, 0, 2, 3, 2, 3, 3, 3, 2, 3, 1, 3, 2, 1, 0, 1, 2, 1, 3, 0, 3, 1, 3, 2, 2, 2, 2, 3, 0, 2, 2, 1, 1, 3, 3, 2, 2, 2, 3, 1, 2, 2, 0, 1, 2, 1, 0, 1, 0, 0, 1, 0, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -944. And steps were 60 and the episode is 1761 and the total_steps are 102154\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 0, 1, 1, 0, 0, 0, 3, 3, 0, 2, 3, 1, 0, 3, 2, 3, 3, 3, 0, 1, 3, 3, 1, 2, 0, 1, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 34 and the episode is 1762 and the total_steps are 102188\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 0, 3, 2, 1, 2, 3, 3, 1, 0, 2, 3, 2, 2, 1, 3, 3, 3, 2, 3, 2, 0, 0, 3, 1, 1, 3, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 2, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 45 and the episode is 1763 and the total_steps are 102233\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 3, 1, 2, 3, 3, 2, 3, 2, 1, 0, 3, 0, 3, 0, 0, 3, 0, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 25 and the episode is 1764 and the total_steps are 102258\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1764     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2902     |\n",
      "|    total_timesteps  | 102258   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 13064    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 3, 1, 2, 2, 2, 3, 0, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 15 and the episode is 1765 and the total_steps are 102273\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 2, 0, 3, 2, 3, 1, 3, 2, 1, 2, 2, 2, 1, 1, 0, 3, 3, 1, 0, 2, 1, 2, 3, 3, 1, 2, 3, 1, 1, 3, 1, 3, 3, 3, 3, 2, 0, 0, 2, 1, 1, 1, 0, 2, 3, 1, 0, 3, 1, 0, 1, 1, 3, 0, 2, 3, 3, 3, 0, 1, 1, 3, 2, 0, 2, 0, 2, 1, 3, 1, 0, 3, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -930. And steps were 80 and the episode is 1766 and the total_steps are 102353\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 3, 1, 2, 1, 2, 0, 0, 3, 0, 1, 3, 0, 3, 3, 1, 0, 2, 2, 3, 0, 3, 2, 2, 0, 1, 1, 3, 0, 0, 3, 1, 1, 3, 2, 3, 1, 2, 0, 1, 2, 2, 3, 2, 1, 0, 2, 1, 2, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 56 and the episode is 1767 and the total_steps are 102409\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 0, 0, 1, 0, 1, 1, 2, 3, 2, 2, 3, 1, 1, 2, 0, 3, 0, 0, 0, 1, 2, 2, 0, 1, 1, 0, 3, 0, 2, 3, 0, 3, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 40 and the episode is 1768 and the total_steps are 102449\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1768     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2910     |\n",
      "|    total_timesteps  | 102449   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.901    |\n",
      "|    n_updates        | 13112    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 3, 3, 2, 0, 2, 3, 3, 0, 0, 2, 3, 2, 0, 0, 3, 2, 3, 2, 3, 0, 0, 2, 1, 1, 0, 0, 3, 1, 3, 3, 0, 0, 1, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 41 and the episode is 1769 and the total_steps are 102490\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 2, 1, 1, 3, 3, 3, 0, 1, 0, 1, 3, 3, 1, 2, 1, 3, 0, 0, 0, 2, 3, 2, 0, 1, 1, 1, 1, 3, 1, 1, 1, 3, 2, 1, 2, 1, 0, 0, 2, 2, 0, 2, 3, 3, 1, 1, 2, 3, 3, 2, 0, 2, 2, 1, 0, 0, 1, 2, 3, 0, 1, 0, 3, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -939. And steps were 71 and the episode is 1770 and the total_steps are 102561\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 3, 1, 3, 0, 0, 1, 3, 1, 3, 3, 2, 1, 3, 0, 3, 2, 3, 0, 1, 0, 2, 0, 0, 1, 3, 0, 2, 2, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 36 and the episode is 1771 and the total_steps are 102597\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 0, 3, 1, 0, 3, 2, 1, 2, 0, 2, 1, 3, 2, 2, 1, 1, 1, 1, 0, 0, 2, 2, 0, 0, 1, 2, 2, 2, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 1772 and the total_steps are 102633\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1772     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2917     |\n",
      "|    total_timesteps  | 102633   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.936    |\n",
      "|    n_updates        | 13158    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 3, 1, 2, 1, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 3, 1, 0, 1, 3, 2, 2, 1, 0, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 1773 and the total_steps are 102665\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 3, 3, 0, 0, 3, 3, 1, 0, 3, 3, 1, 0, 0, 0, 1, 3, 2, 2, 2, 0, 2, 3, 2, 1, 3, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 33 and the episode is 1774 and the total_steps are 102698\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 0, 0, 2, 1, 1, 2, 0, 0, 3, 2, 3, 3, 2, 3, 3, 3, 1, 0, 2, 3, 1, 1, 0, 2, 3, 3, 1, 3, 3, 3, 3, 0, 3, 1, 0, 3, 1, 1, 3, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 47 and the episode is 1775 and the total_steps are 102745\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 0, 0, 3, 0, 0, 3, 1, 2, 2, 0, 1, 0, 2, 2, 3, 2, 2, 1, 0, 0, 3, 0, 1, 1, 1, 2, 0, 2, 0, 2, 0, 3, 0, 1, 3, 0, 3, 0, 0, 0, 2, 2, 0, 3, 2, 1, 1, 1, 0, 1, 3, 1, 1, 0, 3, 0, 2, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 65 and the episode is 1776 and the total_steps are 102810\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1776     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2924     |\n",
      "|    total_timesteps  | 102810   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.8     |\n",
      "|    n_updates        | 13202    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 1, 1, 3, 0, 3, 3, 2, 1, 3, 2, 2, 1, 2, 2, 1, 2, 3, 1, 1, 2, 1, 1, 3, 3, 2, 2, 2, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 1777 and the total_steps are 102845\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 3, 3, 0, 3, 2, 2, 3, 3, 3, 2, 1, 1, 0, 0, 3, 3, 0, 0, 2, 2, 0, 1, 1, 1, 3, 1, 1, 3, 3, 0, 2, 0, 2, 1, 2, 3, 2, 0, 0, 2, 3, 0, 0, 3, 1, 3, 0, 1, 1, 2, 0, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 59 and the episode is 1778 and the total_steps are 102904\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 1, 2, 2, 3, 0, 1, 0, 3, 2, 2, 1, 2, 2, 0, 2, 2, 3, 3, 3, 3, 0, 2, 1, 0, 1, 1, 0, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 35 and the episode is 1779 and the total_steps are 102939\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 1, 3, 1, 2, 2, 1, 2, 3, 3, 0, 0, 2, 2, 0, 2, 2, 2, 0, 3, 2, 0, 1, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 30 and the episode is 1780 and the total_steps are 102969\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1780     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2931     |\n",
      "|    total_timesteps  | 102969   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 13242    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 3, 3, 2, 3, 3, 2, 0, 1, 2, 0, 0, 3, 0, 2, 2, 1, 0, 0, 3, 2, 0, 3, 0, 1, 2, 2, 0, 0, 0, 0, 2, 3, 3, 1, 0, 3, 3, 2, 1, 0, 0, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 49 and the episode is 1781 and the total_steps are 103018\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 0, 3, 3, 1, 1, 2, 1, 0, 0, 2, 0, 0, 3, 3, 2, 1, 2, 2, 0, 1, 3, 0, 2, 3, 1, 0, 2, 3, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 43 and the episode is 1782 and the total_steps are 103061\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 2, 3, 3, 3, 0, 1, 2, 0, 3, 0, 1, 1, 1, 2, 3, 2, 2, 3, 3, 2, 3, 0, 0, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 1783 and the total_steps are 103092\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 1, 1, 3, 1, 3, 1, 3, 1, 2, 1, 0, 2, 3, 3, 3, 2, 2, 2, 3, 1, 2, 2, 0, 3, 3, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 1784 and the total_steps are 103125\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1784     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2937     |\n",
      "|    total_timesteps  | 103125   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 13281    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 1, 2, 2, 2, 3, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 2, 1, 3, 0, 1, 2, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 31 and the episode is 1785 and the total_steps are 103156\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 3, 0, 0, 3, 3, 3, 0, 3, 2, 0, 0, 0, 2, 3, 1, 1, 1, 1, 2, 3, 1, 0, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 1786 and the total_steps are 103186\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 0, 2, 1, 0, 3, 1, 1, 2, 1, 0, 3, 3, 2, 0, 0, 2, 1, 1, 2, 2, 3, 3, 1, 3, 2, 1, 3, 0, 0, 3, 1, 0, 3, 2, 2, 3, 3, 3, 2, 1, 1, 2, 3, 3, 1, 2, 3, 1, 0, 0, 3, 1, 1, 2, 1, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 63 and the episode is 1787 and the total_steps are 103249\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 3, 0, 1, 1, 0, 0, 3, 2, 1, 2, 1, 2, 3, 0, 1, 1, 1, 1, 0, 2, 3, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 3, 1, 0, 0, 3, 1, 1, 3, 0, 3, 3, 1, 0, 3, 1, 2, 1, 3, 0, 3, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 61 and the episode is 1788 and the total_steps are 103310\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1788     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2944     |\n",
      "|    total_timesteps  | 103310   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.774    |\n",
      "|    n_updates        | 13327    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 1, 0, 1, 3, 3, 2, 1, 3, 3, 3, 0, 1, 3, 2, 1, 1, 0, 0, 1, 2, 3, 2, 2, 0, 3, 1, 2, 2, 0, 3, 3, 2, 1, 3, 3, 1, 0, 0, 1, 0, 3, 1, 1, 2, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 52 and the episode is 1789 and the total_steps are 103362\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 2, 3, 2, 2, 0, 1, 1, 3, 1, 3, 2, 2, 0, 1, 0, 2, 1, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 1790 and the total_steps are 103387\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 1, 2, 0, 2, 3, 2, 1, 0, 0, 1, 1, 3, 3, 0, 2, 0, 2, 3, 2, 3, 2, 1, 0, 3, 2, 2, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 34 and the episode is 1791 and the total_steps are 103421\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 0, 3, 3, 3, 2, 1, 3, 1, 0, 3, 2, 2, 3, 2, 3, 2, 1, 2, 1, 2, 3, 3, 0, 0, 1, 2, 3, 3, 1, 3, 1, 3, 3, 1, 2, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 43 and the episode is 1792 and the total_steps are 103464\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1792     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2950     |\n",
      "|    total_timesteps  | 103464   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.5     |\n",
      "|    n_updates        | 13365    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 0, 3, 3, 3, 3, 3, 0, 3, 2, 2, 3, 0, 0, 0, 1, 2, 0, 3, 2, 3, 2, 2, 0, 3, 3, 0, 3, 2, 2, 2, 0, 2, 2, 1, 1, 2, 2, 3, 1, 2, 1, 3, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1048. And steps were 50 and the episode is 1793 and the total_steps are 103514\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 2, 2, 0, 2, 2, 0, 2, 3, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 1, 3, 0, 1, 1, 0, 0, 3, 3, 0, 1, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 39 and the episode is 1794 and the total_steps are 103553\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 2, 3, 0, 0, 3, 3, 3, 3, 2, 2, 3, 1, 1, 0, 0, 0, 1, 3, 2, 3, 1, 0, 0, 1, 0, 3, 2, 1, 3, 3, 0, 1, 2, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 41 and the episode is 1795 and the total_steps are 103594\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 1, 0, 2, 1, 0, 0, 0, 2, 2, 2, 0, 1, 3, 2, 1, 3, 3, 1, 1, 1, 1, 3, 0, 1, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 1796 and the total_steps are 103626\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1796     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2957     |\n",
      "|    total_timesteps  | 103626   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.769    |\n",
      "|    n_updates        | 13406    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 1, 1, 3, 2, 0, 1, 3, 0, 3, 0, 2, 0, 2, 0, 2, 3, 0, 3, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 26 and the episode is 1797 and the total_steps are 103652\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 3, 2, 2, 0, 2, 2, 1, 1, 3, 1, 1, 0, 3, 3, 0, 0, 2, 0, 0, 1, 1, 3, 1, 2, 3, 0, 2, 1, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 36 and the episode is 1798 and the total_steps are 103688\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 3, 0, 1, 3, 0, 3, 3, 1, 0, 0, 1, 2, 0, 2, 3, 0, 0, 0, 3, 2, 2, 0, 3, 2, 3, 0, 1, 2, 1, 3, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 38 and the episode is 1799 and the total_steps are 103726\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 3, 0, 3, 2, 3, 0, 2, 0, 0, 1, 0, 3, 0, 1, 3, 0, 0, 1, 3, 1, 0, 2, 2, 2, 3, 2, 1, 1, 2, 2, 1, 2, 1, 3, 3, 2, 3, 2, 1, 0, 0, 3, 0, 3, 2, 0, 3, 3, 0, 0, 1, 1, 0, 1, 3, 3, 1, 2, 3, 1, 2, 2, 0, 3, 0, 3, 1, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 75 and the episode is 1800 and the total_steps are 103801\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 2964     |\n",
      "|    total_timesteps  | 103801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 93.6     |\n",
      "|    n_updates        | 13450    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 1, 0, 3, 3, 0, 2, 0, 1, 0, 0, 3, 0, 0, 1, 1, 2, 3, 2, 3, 1, 1, 1, 0, 1, 2, 0, 1, 3, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 1801 and the total_steps are 103837\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 2, 2, 1, 3, 0, 0, 0, 2, 3, 1, 0, 3, 3, 1, 1, 1, 2, 2, 0, 3, 0, 3, 2, 0, 2, 3, 2, 1, 2, 2, 1, 3, 3, 0, 1, 0, 1, 2, 2, 1, 3, 2, 1, 2, 0, 1, 1, 1, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 56 and the episode is 1802 and the total_steps are 103893\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 3, 0, 2, 2, 1, 1, 0, 3, 2, 0, 3, 0, 3, 0, 3, 3, 1, 1, 0, 3, 0, 2, 2, 3, 2, 0, 3, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 35 and the episode is 1803 and the total_steps are 103928\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 0, 0, 2, 1, 2, 3, 3, 0, 2, 3, 2, 0, 0, 0, 3, 3, 0, 1, 1, 2, 2, 3, 0, 0, 2, 3, 2, 0, 0, 3, 3, 2, 2, 0, 0, 0, 2, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 45 and the episode is 1804 and the total_steps are 103973\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1804     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 2970     |\n",
      "|    total_timesteps  | 103973   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.62     |\n",
      "|    n_updates        | 13493    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 3, 3, 1, 3, 0, 3, 2, 0, 2, 3, 1, 1, 2, 1, 3, 1, 3, 2, 2, 2, 3, 0, 1, 0, 3, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 32 and the episode is 1805 and the total_steps are 104005\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 1, 0, 1, 1, 0, 3, 1, 1, 1, 3, 1, 0, 1, 3, 1, 1, 2, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 26 and the episode is 1806 and the total_steps are 104031\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 3, 0, 3, 0, 0, 0, 2, 1, 1, 2, 0, 2, 0, 1, 1, 3, 1, 3, 1, 3, 2, 2, 2, 0, 1, 3, 1, 2, 3, 2, 2, 1, 0, 2, 2, 2, 1, 3, 1, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 47 and the episode is 1807 and the total_steps are 104078\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 2, 2, 0, 0, 3, 0, 1, 2, 3, 3, 3, 2, 0, 3, 3, 3, 2, 1, 2, 2, 0, 2, 1, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 31 and the episode is 1808 and the total_steps are 104109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1808     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 2976     |\n",
      "|    total_timesteps  | 104109   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.07     |\n",
      "|    n_updates        | 13527    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 3, 2, 0, 2, 2, 2, 3, 2, 1, 1, 1, 3, 2, 1, 3, 3, 3, 2, 1, 0, 0, 3, 2, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 31 and the episode is 1809 and the total_steps are 104140\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 3, 2, 1, 1, 1, 0, 1, 2, 0, 2, 0, 1, 2, 3, 1, 3, 2, 1, 3, 3, 2, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 29 and the episode is 1810 and the total_steps are 104169\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 1, 3, 1, 1, 3, 0, 1, 3, 2, 2, 0, 2, 1, 1, 3, 2, 1, 2, 0, 3, 2, 3, 2, 0, 3, 1, 1, 2, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 36 and the episode is 1811 and the total_steps are 104205\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 2, 2, 1, 2, 1, 2, 1, 2, 2, 3, 0, 0, 1, 2, 3, 1, 1, 2, 0, 0, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 1812 and the total_steps are 104233\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1812     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 2981     |\n",
      "|    total_timesteps  | 104233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.71     |\n",
      "|    n_updates        | 13558    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 1, 3, 0, 1, 3, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 2, 2, 3, 3, 1, 1, 0, 1, 2, 3, 2, 3, 0, 1, 1, 3, 0, 1, 3, 1, 0, 1, 3, 0, 3, 0, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 49 and the episode is 1813 and the total_steps are 104282\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 0, 3, 0, 3, 1, 3, 3, 1, 1, 1, 3, 1, 3, 0, 2, 3, 2, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was 1022. And steps were 23 and the episode is 1814 and the total_steps are 104305\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 2, 2, 1, 3, 0, 2, 1, 1, 0, 2, 1, 1, 3, 2, 2, 1, 3, 3, 2, 1, 0, 1, 3, 1, 0, 3, 3, 2, 0, 0, 1, 3, 2, 2, 0, 2, 0, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 45 and the episode is 1815 and the total_steps are 104350\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 1, 0, 2, 2, 3, 3, 1, 3, 1, 0, 2, 1, 3, 2, 0, 1, 0, 3, 2, 2, 3, 1, 3, 2, 2, 1, 1, 0, 0, 2, 3, 0, 2, 0, 1, 0, 3, 2, 3, 3, 3, 1, 3, 0, 2, 3, 2, 1, 2, 2, 1, 3, 2, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -953. And steps were 61 and the episode is 1816 and the total_steps are 104411\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1816     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 2988     |\n",
      "|    total_timesteps  | 104411   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.3     |\n",
      "|    n_updates        | 13602    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 2, 3, 2, 3, 1, 3, 1, 1, 2, 1, 2, 0, 0, 0, 2, 3, 1, 2, 0, 1, 0, 2, 2, 1, 1, 0, 2, 1, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 1817 and the total_steps are 104447\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 2, 3, 2, 0, 1, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 0, 3, 3, 3, 2, 1, 1, 2, 3, 0, 2, 0, 0, 3, 2, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 38 and the episode is 1818 and the total_steps are 104485\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 3, 0, 2, 1, 2, 3, 3, 3, 2, 0, 0, 1, 0, 3, 0, 1, 3, 0, 3, 0, 1, 3, 0, 0, 1, 3, 1, 2, 2, 1, 1, 2, 3, 3, 3, 1, 3, 0, 0, 0, 3, 3, 0, 1, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 52 and the episode is 1819 and the total_steps are 104537\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 2, 2, 0, 2, 3, 1, 3, 1, 1, 1, 2, 3, 0, 0, 0, 2, 0, 2, 0, 0, 1, 1, 0, 3, 2, 2, 0, 0, 0, 0, 0, 2, 3, 0, 0, 3, 3, 0, 2, 3, 3, 0, 1, 3, 1, 0, 0, 1, 0, 2, 2, 0, 2, 1, 3, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -938. And steps were 64 and the episode is 1820 and the total_steps are 104601\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1820     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 2995     |\n",
      "|    total_timesteps  | 104601   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.2     |\n",
      "|    n_updates        | 13650    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 0, 2, 3, 3, 3, 0, 3, 0, 0, 2, 0, 1, 3, 1, 2, 2, 1, 2, 0, 0, 0, 0, 2, 2, 1, 2, 3, 0, 1, 3, 2, 3, 2, 3, 0, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 43 and the episode is 1821 and the total_steps are 104644\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 0, 1, 3, 0, 3, 2, 3, 1, 1, 1, 0, 2, 0, 1, 1, 2, 1, 1, 3, 0, 3, 0, 1, 3, 3, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 33 and the episode is 1822 and the total_steps are 104677\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 1, 3, 2, 1, 2, 3, 0, 1, 3, 2, 3, 2, 0, 1, 2, 3, 2, 2, 0, 3, 3, 2, 1, 3, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1823 and the total_steps are 104709\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 3, 3, 2, 0, 1, 1, 1, 3, 3, 0, 2, 2, 0, 0, 2, 1, 1, 2, 0, 2, 0, 1, 2, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 1824 and the total_steps are 104740\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1824     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3001     |\n",
      "|    total_timesteps  | 104740   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 13684    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 0, 1, 0, 3, 3, 1, 0, 2, 3, 2, 1, 0, 3, 0, 2, 2, 2, 0, 0, 0, 2, 3, 1, 3, 2, 0, 0, 1, 3, 3, 2, 2, 2, 0, 2, 3, 2, 1, 3, 2, 1, 3, 3, 0, 3, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1051. And steps were 53 and the episode is 1825 and the total_steps are 104793\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 1, 2, 3, 0, 3, 1, 1, 2, 1, 1, 2, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 19 and the episode is 1826 and the total_steps are 104812\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 2, 3, 1, 1, 3, 3, 2, 2, 1, 3, 1, 1, 1, 3, 1, 3, 3, 3, 2, 0, 3, 0, 1, 2, 2, 3, 2, 2, 1, 0, 1, 0, 2, 1, 0, 3, 0, 0, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 46 and the episode is 1827 and the total_steps are 104858\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 3, 3, 0, 0, 3, 1, 0, 1, 2, 0, 3, 3, 3, 0, 2, 0, 2, 3, 1, 1, 0, 0, 1, 2, 1, 2, 0, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 1828 and the total_steps are 104893\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1828     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3007     |\n",
      "|    total_timesteps  | 104893   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 13723    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1, 2, 2, 3, 2, 1, 3, 2, 3, 1, 0, 0, 3, 0, 1, 2, 0, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 1829 and the total_steps are 104926\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 1, 2, 1, 0, 3, 1, 2, 0, 3, 1, 1, 1, 0, 3, 1, 2, 0, 0, 0, 3, 3, 0, 0, 3, 1, 1, 0, 3, 1, 2, 2, 1, 1, 3, 1, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 51 and the episode is 1830 and the total_steps are 104977\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 0, 2, 0, 0, 3, 3, 3, 0, 3, 2, 0, 2, 2, 2, 3, 2, 3, 1, 0, 0, 3, 0, 3, 0, 0, 2, 3, 3, 2, 3, 1, 3, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 40 and the episode is 1831 and the total_steps are 105017\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 2, 0, 3, 1, 1, 0, 1, 2, 3, 2, 0, 3, 0, 2, 2, 1, 3, 1, 3, 3, 2, 3, 0, 0, 3, 0, 2, 0, 2, 2, 2, 3, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 40 and the episode is 1832 and the total_steps are 105057\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1832     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3014     |\n",
      "|    total_timesteps  | 105057   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.66     |\n",
      "|    n_updates        | 13764    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 1, 3, 0, 2, 2, 2, 1, 2, 1, 0, 0, 0, 1, 2, 2, 1, 3, 2, 2, 1, 3, 0, 2, 0, 2, 1, 2, 3, 3, 0, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 37 and the episode is 1833 and the total_steps are 105094\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 1, 3, 3, 3, 2, 0, 1, 2, 1, 2, 3, 0, 2, 0, 1, 2, 1, 0, 3, 3, 0, 0, 2, 1, 1, 3, 2, 0, 2, 2, 3, 3, 1, 0, 3, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 43 and the episode is 1834 and the total_steps are 105137\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 1, 2, 0, 3, 0, 0, 0, 3, 1, 0, 2, 2, 2, 0, 3, 0, 3, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 1835 and the total_steps are 105162\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 1, 3, 3, 0, 0, 3, 3, 0, 3, 2, 0, 2, 3, 3, 0, 3, 3, 0, 1, 0, 2, 2, 3, 0, 3, 0, 3, 3, 2, 3, 3, 1, 2, 2, 1, 0, 2, 3, 2, 2, 1, 2, 2, 0, 1, 1, 0, 1, 0, 2, 3, 3, 0, 0, 3, 1, 2, 2, 0, 2, 1, 2, 1, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -943. And steps were 71 and the episode is 1836 and the total_steps are 105233\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1836     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3021     |\n",
      "|    total_timesteps  | 105233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.74     |\n",
      "|    n_updates        | 13808    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 1, 2, 2, 2, 2, 1, 1, 2, 0, 3, 0, 2, 3, 3, 2, 3, 3, 2, 0, 0, 2, 3, 2, 0, 1, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 1837 and the total_steps are 105266\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 1, 2, 1, 3, 1, 3, 3, 2, 3, 3, 2, 1, 0, 0, 0, 0, 2, 0, 0, 3, 1, 3, 1, 0, 3, 2, 1, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 35 and the episode is 1838 and the total_steps are 105301\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 3, 3, 2, 1, 2, 0, 3, 0, 2, 0, 0, 0, 3, 2, 1, 1, 1, 0, 3, 3, 3, 3, 1, 2, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 1839 and the total_steps are 105333\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 1, 2, 2, 1, 3, 1, 2, 2, 0, 1, 1, 1, 2, 3, 1, 1, 0, 1, 0, 1, 0, 0, 2, 1, 3, 3, 0, 3, 3, 1, 0, 3, 1, 1, 2, 2, 1, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 45 and the episode is 1840 and the total_steps are 105378\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -980     |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1840     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3027     |\n",
      "|    total_timesteps  | 105378   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 13844    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 1, 2, 1, 1, 0, 1, 1, 0, 0, 3, 0, 0, 2, 0, 2, 1, 2, 1, 1, 2, 3, 0, 2, 0, 2, 3, 3, 3, 1, 3, 0, 3, 2, 0, 0, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 43 and the episode is 1841 and the total_steps are 105421\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 0, 3, 0, 1, 0, 3, 2, 1, 2, 0, 3, 2, 1, 2, 3, 1, 1, 1, 0, 0, 0, 1, 3, 2, 0, 3, 0, 0, 2, 0, 0, 1, 0, 0, 2, 3, 1, 3, 0, 1, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 48 and the episode is 1842 and the total_steps are 105469\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 0, 0, 0, 0, 3, 2, 2, 2, 1, 3, 3, 0, 2, 1, 3, 2, 2, 3, 0, 0, 2, 0, 1, 1, 0, 0, 3, 2, 2, 0, 3, 0, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 40 and the episode is 1843 and the total_steps are 105509\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 2, 2, 0, 1, 2, 1, 2, 3, 3, 2, 0, 1, 3, 0, 1, 1, 2, 1, 3, 3, 2, 3, 0, 1, 1, 1, 2, 1, 3, 3, 0, 1, 2, 1, 3, 2, 1, 1, 0, 1, 1, 2, 0, 3, 3, 3, 0, 3, 2, 1, 1, 0, 3, 0, 0, 2, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 64 and the episode is 1844 and the total_steps are 105573\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -979     |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1844     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3034     |\n",
      "|    total_timesteps  | 105573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.17     |\n",
      "|    n_updates        | 13893    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 3, 3, 3, 1, 2, 0, 3, 2, 2, 2, 1, 1, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 20 and the episode is 1845 and the total_steps are 105593\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 0, 1, 1, 2, 3, 3, 3, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 3, 0, 2, 2, 2, 2, 0, 1, 1, 2, 1, 3, 1, 3, 3, 2, 2, 2, 0, 3, 1, 0, 2, 3, 1, 3, 0, 1, 0, 3, 1, 2, 0, 2, 0, 2, 2, 1, 2, 3, 0, 0, 1, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -950. And steps were 68 and the episode is 1846 and the total_steps are 105661\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 0, 3, 2, 2, 0, 3, 3, 1, 2, 2, 3, 3, 0, 0, 1, 3, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 24 and the episode is 1847 and the total_steps are 105685\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 2, 3, 3, 0, 1, 3, 1, 0, 2, 1, 3, 1, 3, 0, 3, 2, 1, 1, 2, 2, 2, 0, 1, 1, 1, 1, 1, 2, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 36 and the episode is 1848 and the total_steps are 105721\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1848     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3041     |\n",
      "|    total_timesteps  | 105721   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 13930    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 0, 0, 3, 3, 1, 1, 0, 1, 1, 1, 0, 0, 3, 0, 3, 1, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 24 and the episode is 1849 and the total_steps are 105745\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 2, 2, 1, 2, 1, 3, 0, 3, 3, 0, 2, 3, 3, 2, 0, 2, 0, 0, 2, 1, 3, 2, 1, 0, 2, 2, 3, 0, 3, 2, 2, 3, 2, 0, 3, 1, 3, 0, 2, 0, 2, 1, 3, 3, 0, 0, 2, 1, 3, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 3, 2, 2, 2, 0, 3, 0, 2, 1, 3, 1, 3, 2, 2, 2, 0, 1, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 84 and the episode is 1850 and the total_steps are 105829\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 2, 3, 2, 1, 0, 2, 3, 1, 0, 0, 3, 2, 2, 2, 2, 3, 3, 2, 1, 3, 3, 0, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 30 and the episode is 1851 and the total_steps are 105859\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 3, 2, 1, 2, 3, 3, 3, 1, 3, 0, 0, 3, 3, 2, 2, 1, 1, 3, 3, 1, 2, 2, 3, 2, 0, 3, 0, 1, 0, 2, 2, 3, 2, 1, 2, 1, 2, 1, 3, 1, 0, 2, 3, 0, 3, 3, 1, 3, 2, 0, 1, 1, 3, 0, 3, 1, 0, 0, 3, 3, 1, 3, 3, 0, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 76 and the episode is 1852 and the total_steps are 105935\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1852     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3049     |\n",
      "|    total_timesteps  | 105935   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 13983    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 2, 1, 0, 3, 2, 2, 0, 2, 2, 0, 3, 0, 3, 1, 1, 2, 0, 3, 1, 1, 3, 0, 1, 1, 3, 2, 0, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 35 and the episode is 1853 and the total_steps are 105970\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 0, 2, 2, 3, 0, 0, 0, 1, 0, 3, 1, 1, 0, 1, 2, 3, 2, 1, 2, 3, 0, 3, 1, 0, 0, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 33 and the episode is 1854 and the total_steps are 106003\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 2, 1, 0, 0, 2, 3, 3, 3, 1, 2, 1, 3, 3, 0, 3, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 3, 2, 0, 2, 2, 1, 3, 3, 0, 2, 0, 1, 0, 1, 2, 3, 0, 0, 0, 2, 1, 1, 1, 0, 0, 3, 1, 0, 3, 1, 1, 0, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 65 and the episode is 1855 and the total_steps are 106068\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 1, 2, 2, 3, 2, 0, 3, 3, 1, 3, 1, 1, 0, 1, 3, 2, 2, 2, 1, 2, 2, 2, 1, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 31 and the episode is 1856 and the total_steps are 106099\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1856     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3056     |\n",
      "|    total_timesteps  | 106099   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 14024    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 0, 0, 2, 3, 0, 0, 3, 3, 3, 0, 3, 3, 1, 0, 3, 1, 2, 3, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 1857 and the total_steps are 106125\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 0, 0, 1, 1, 1, 1, 3, 0, 3, 2, 1, 1, 3, 3, 1, 0, 0, 1, 2, 2, 0, 1, 3, 0, 3, 3, 1, 2, 3, 3, 1, 2, 2, 3, 1, 2, 1, 1, 3, 3, 3, 1, 3, 1, 0, 2, 0, 0, 2, 0, 2, 1, 2, 1, 0, 3, 2, 3, 1, 3, 1, 3, 0, 2, 2, 1, 3, 2, 1, 3, 1, 0, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 80 and the episode is 1858 and the total_steps are 106205\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 0, 3, 2, 3, 0, 0, 2, 1, 2, 0, 1, 1, 3, 3, 1, 0, 1, 2, 1, 0, 0, 2, 2, 1, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 32 and the episode is 1859 and the total_steps are 106237\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 3, 1, 2, 1, 2, 2, 2, 2, 1, 2, 3, 1, 0, 2, 1, 0, 2, 3, 2, 3, 0, 0, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 30 and the episode is 1860 and the total_steps are 106267\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1860     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3063     |\n",
      "|    total_timesteps  | 106267   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 14066    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 3, 2, 1, 0, 3, 0, 0, 3, 0, 1, 1, 3, 2, 2, 1, 0, 0, 3, 2, 1, 0, 3, 1, 2, 3, 0, 0, 1, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 36 and the episode is 1861 and the total_steps are 106303\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 0, 1, 3, 0, 0, 3, 0, 1, 3, 0, 0, 2, 2, 3, 3, 1, 2, 0, 2, 1, 2, 2, 1, 2, 2, 2, 1, 0, 1, 0, 2, 2, 2, 0, 3, 2, 2, 2, 0, 3, 3, 0, 1, 0, 3, 3, 1, 2, 3, 1, 0, 1, 1, 3, 1, 2, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 64 and the episode is 1862 and the total_steps are 106367\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 3, 3, 3, 1, 0, 1, 0, 0, 3, 3, 2, 3, 3, 3, 1, 0, 0, 0, 3, 3, 0, 2, 3, 2, 1, 0, 1, 3, 3, 0, 1, 1, 0, 2, 2, 2, 0, 3, 3, 1, 3, 0, 1, 1, 1, 0, 3, 3, 0, 1, 2, 1, 1, 0, 3, 0, 3, 0, 0, 2, 3, 0, 0, 2, 0, 1, 1, 3, 0, 0, 2, 3, 3, 3, 1, 0, 3, 0, 2, 1, 0, 1, 3, 1, 3, 0, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1060. And steps were 94 and the episode is 1863 and the total_steps are 106461\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 2, 2, 2, 0, 1, 3, 2, 2, 1, 3, 2, 2, 1, 3, 2, 3, 2, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 25 and the episode is 1864 and the total_steps are 106486\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | -978     |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1864     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3071     |\n",
      "|    total_timesteps  | 106486   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 30.5     |\n",
      "|    n_updates        | 14121    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 0, 2, 3, 3, 0, 0, 2, 0, 0, 3, 1, 2, 1, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 1865 and the total_steps are 106514\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 0, 3, 1, 2, 3, 3, 1, 0, 1, 1, 2, 3, 2, 0, 3, 1, 0, 3, 2, 3, 2, 3, 0, 1, 3, 0, 3, 0, 0, 0, 0, 3, 0, 1, 1, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 43 and the episode is 1866 and the total_steps are 106557\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 1, 2, 2, 0, 0, 0, 1, 0, 0, 1, 1, 3, 0, 1, 2, 3, 1, 3, 1, 0, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 1867 and the total_steps are 106585\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 3, 1, 3, 3, 1, 1, 1, 1, 2, 0, 0, 2, 0, 3, 1, 3, 3, 1, 0, 1, 2, 1, 1, 1, 3, 3, 0, 1, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 1868 and the total_steps are 106621\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -979     |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1868     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3077     |\n",
      "|    total_timesteps  | 106621   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.3     |\n",
      "|    n_updates        | 14155    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 3, 1, 3, 3, 0, 2, 3, 2, 1, 3, 0, 0, 2, 3, 2, 3, 3, 2, 2, 3, 2, 3, 0, 0, 2, 3, 0, 1, 3, 3, 0, 0, 0, 1, 3, 0, 0, 2, 0, 3, 2, 1, 1, 1, 3, 1, 3, 0, 0, 2, 3, 1, 3, 3, 1, 3, 1, 0, 0, 3, 3, 2, 3, 0, 3, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 73 and the episode is 1869 and the total_steps are 106694\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 1, 0, 1, 1, 2, 0, 3, 3, 0, 1, 0, 1, 0, 2, 3, 1, 0, 2, 0, 2, 2, 0, 3, 3, 3, 3, 2, 0, 3, 0, 2, 1, 0, 0, 1, 2, 0, 3, 3, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 47 and the episode is 1870 and the total_steps are 106741\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 1, 0, 0, 2, 2, 0, 2, 1, 2, 1, 2, 2, 2, 1, 1, 3, 2, 0, 2, 1, 1, 2, 3, 0, 0, 1, 3, 3, 3, 1, 2, 0, 3, 2, 2, 3, 2, 1, 0, 0, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 1871 and the total_steps are 106789\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 2, 3, 2, 2, 2, 3, 3, 2, 0, 0, 3, 1, 0, 3, 3, 2, 3, 0, 2, 1, 1, 1, 2, 2, 2, 2, 2, 3, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 1872 and the total_steps are 106825\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -979     |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1872     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3085     |\n",
      "|    total_timesteps  | 106825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.728    |\n",
      "|    n_updates        | 14206    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 2, 2, 3, 3, 1, 3, 0, 3, 1, 0, 0, 0, 3, 2, 3, 2, 0, 2, 0, 0, 2, 1, 1, 2, 2, 3, 3, 1, 1, 3, 3, 0, 0, 1, 0, 1, 1, 0, 0, 3, 3, 0, 0, 0, 1, 3, 1, 3, 0, 3, 0, 0, 0, 2, 0, 2, 2, 3, 2, 3, 1, 1, 0, 0, 0, 1, 2, 1, 2, 3, 3, 3, 2, 0, 3, 2, 1, 3, 2, 0, 2, 2, 3, 2, 2, 0, 2, 2, 3, 0, 2, 1, 1, 0, 2, 1, 1, 3, 2, 1, 3, 2, 3, 1, 0, 0, 3, 0, 3, 0, 2, 3, 3, 0, 1, 0, 1, 1, 1, 3, 2, 1, 2, 3, 0, 0, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1112. And steps were 134 and the episode is 1873 and the total_steps are 106959\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 1, 1, 2, 0, 0, 2, 1, 2, 0, 2, 1, 2, 2, 1, 3, 0, 3, 0, 2, 0, 1, 0, 0, 0, 2, 3, 1, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 35 and the episode is 1874 and the total_steps are 106994\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 0, 2, 2, 3, 3, 1, 0, 2, 0, 3, 3, 2, 0, 1, 0, 0, 0, 0, 2, 3, 0, 3, 1, 3, 3, 0, 2, 0, 3, 2, 0, 2, 2, 3, 3, 3, 3, 2, 2, 0, 1, 1, 0, 1, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 52 and the episode is 1875 and the total_steps are 107046\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 0, 3, 0, 2, 2, 0, 2, 0, 3, 1, 3, 3, 0, 3, 3, 3, 0, 3, 3, 1, 2, 2, 1, 0, 0, 0, 2, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 35 and the episode is 1876 and the total_steps are 107081\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -981     |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1876     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3095     |\n",
      "|    total_timesteps  | 107081   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 14270    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 1, 3, 2, 0, 2, 1, 0, 0, 0, 1, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 3, 2, 3, 3, 1, 0, 1, 2, 3, 1, 1, 2, 0, 1, 2, 1, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 44 and the episode is 1877 and the total_steps are 107125\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 2, 1, 3, 3, 0, 0, 2, 1, 2, 2, 0, 1, 0, 1, 2, 3, 0, 3, 2, 3, 1, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 29 and the episode is 1878 and the total_steps are 107154\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 2, 0, 2, 3, 3, 0, 2, 3, 3, 2, 2, 3, 0, 2, 0, 1, 0, 3, 3, 0, 3, 1, 0, 2, 0, 2, 0, 3, 2, 3, 0, 2, 0, 0, 3, 0, 1, 3, 3, 2, 0, 0, 2, 2, 2, 3, 3, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 55 and the episode is 1879 and the total_steps are 107209\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 1, 2, 2, 3, 2, 0, 3, 2, 2, 3, 3, 0, 1, 2, 3, 2, 2, 1, 1, 3, 0, 1, 1, 0, 3, 1, 1, 1, 2, 0, 1, 3, 0, 0, 3, 0, 1, 3, 0, 2, 0, 3, 0, 1, 3, 2, 2, 3, 3, 3, 3, 1, 0, 3, 2, 2, 1, 2, 2, 3, 0, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -943. And steps were 69 and the episode is 1880 and the total_steps are 107278\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.1     |\n",
      "|    ep_rew_mean      | -980     |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1880     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3103     |\n",
      "|    total_timesteps  | 107278   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.44     |\n",
      "|    n_updates        | 14319    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 1, 3, 3, 1, 3, 3, 2, 3, 2, 0, 3, 3, 3, 0, 1, 0, 1, 3, 2, 1, 2, 3, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 30 and the episode is 1881 and the total_steps are 107308\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 0, 3, 2, 3, 1, 1, 3, 3, 2, 2, 0, 3, 1, 1, 0, 3, 3, 0, 2, 0, 3, 2, 2, 1, 3, 3, 2, 3, 3, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 37 and the episode is 1882 and the total_steps are 107345\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 3, 2, 3, 2, 1, 0, 3, 0, 0, 2, 1, 2, 3, 3, 3, 0, 1, 0, 3, 1, 0, 0, 0, 1, 3, 1, 1, 2, 2, 1, 2, 3, 0, 3, 2, 1, 1, 1, 1, 0, 2, 2, 0, 0, 2, 3, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 53 and the episode is 1883 and the total_steps are 107398\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 3, 1, 3, 0, 1, 0, 0, 2, 1, 3, 2, 0, 3, 1, 3, 3, 0, 2, 0, 0, 1, 0, 0, 2, 1, 1, 0, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 35 and the episode is 1884 and the total_steps are 107433\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.1     |\n",
      "|    ep_rew_mean      | -979     |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1884     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3109     |\n",
      "|    total_timesteps  | 107433   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 14358    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 0, 3, 2, 0, 0, 2, 1, 3, 0, 1, 3, 2, 0, 3, 2, 1, 2, 1, 3, 1, 0, 3, 0, 3, 0, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 1885 and the total_steps are 107466\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 0, 1, 2, 1, 0, 2, 1, 1, 1, 3, 3, 3, 3, 1, 0, 0, 2, 3, 1, 0, 0, 2, 3, 2, 1, 0, 1, 2, 0, 0, 2, 1, 2, 1, 3, 1, 1, 1, 2, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 47 and the episode is 1886 and the total_steps are 107513\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 1, 1, 0, 2, 2, 0, 2, 2, 0, 0, 3, 2, 1, 2, 3, 0, 3, 2, 0, 1, 0, 2, 3, 0, 2, 0, 3, 1, 0, 2, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 38 and the episode is 1887 and the total_steps are 107551\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 0, 2, 0, 2, 3, 0, 0, 2, 3, 3, 3, 1, 3, 2, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 22 and the episode is 1888 and the total_steps are 107573\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.6     |\n",
      "|    ep_rew_mean      | -978     |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1888     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3116     |\n",
      "|    total_timesteps  | 107573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 14393    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 2, 1, 1, 3, 2, 0, 1, 3, 0, 2, 0, 3, 1, 3, 2, 3, 2, 1, 0, 0, 3, 3, 3, 0, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 1889 and the total_steps are 107605\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 3, 0, 3, 2, 3, 2, 0, 1, 3, 0, 3, 3, 2, 0, 1, 3, 1, 1, 0, 0, 3, 1, 3, 0, 2, 0, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 34 and the episode is 1890 and the total_steps are 107639\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 1, 3, 1, 2, 2, 0, 3, 3, 3, 2, 3, 3, 3, 2, 1, 1, 3, 3, 2, 3, 3, 0, 1, 2, 0, 1, 2, 3, 1, 1, 0, 3, 3, 2, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 42 and the episode is 1891 and the total_steps are 107681\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 0, 0, 2, 0, 3, 3, 1, 0, 2, 0, 3, 2, 1, 0, 1, 3, 1, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 25 and the episode is 1892 and the total_steps are 107706\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1892     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3121     |\n",
      "|    total_timesteps  | 107706   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.81     |\n",
      "|    n_updates        | 14426    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 1, 3, 2, 3, 3, 0, 1, 1, 0, 2, 2, 0, 1, 2, 2, 1, 0, 2, 3, 3, 2, 1, 3, 1, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 1893 and the total_steps are 107738\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 2, 1, 1, 0, 3, 1, 2, 3, 3, 0, 2, 1, 3, 1, 3, 0, 0, 3, 2, 0, 3, 3, 0, 0, 0, 0, 0, 1, 3, 2, 2, 1, 3, 1, 0, 2, 2, 0, 3, 2, 1, 3, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 50 and the episode is 1894 and the total_steps are 107788\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 1, 2, 2, 2, 1, 3, 0, 3, 3, 1, 3, 0, 2, 0, 0, 3, 3, 2, 0, 0, 3, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 37 and the episode is 1895 and the total_steps are 107825\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 2, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 1, 1, 3, 0, 1, 3, 2, 3, 1, 0, 3, 1, 1, 1, 2, 0, 3, 1, 3, 1, 0, 2, 2, 0, 0, 1, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 45 and the episode is 1896 and the total_steps are 107870\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1896     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3128     |\n",
      "|    total_timesteps  | 107870   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 14467    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 2, 1, 1, 2, 0, 3, 2, 0, 1, 2, 2, 3, 3, 2, 3, 3, 0, 2, 2, 0, 1, 1, 0, 3, 2, 3, 1, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 35 and the episode is 1897 and the total_steps are 107905\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 0, 1, 1, 1, 3, 3, 0, 0, 1, 0, 1, 0, 3, 3, 1, 0, 2, 0, 3, 3, 2, 3, 3, 3, 0, 0, 2, 0, 3, 0, 1, 3, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 40 and the episode is 1898 and the total_steps are 107945\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 3, 0, 0, 3, 1, 0, 3, 3, 2, 0, 0, 3, 1, 1, 0, 0, 1, 3, 2, 0, 1, 3, 1, 1, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 1899 and the total_steps are 107977\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 1, 3, 0, 2, 2, 0, 2, 2, 3, 1, 1, 2, 1, 3, 1, 0, 1, 0, 0, 2, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 0, 0, 0, 2, 2, 1, 2, 0, 1, 2, 0, 0, 1, 0, 0, 3, 3, 1, 0, 1, 1, 3, 0, 0, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 62 and the episode is 1900 and the total_steps are 108039\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3134     |\n",
      "|    total_timesteps  | 108039   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 94.5     |\n",
      "|    n_updates        | 14509    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 1, 2, 0, 1, 3, 3, 0, 3, 2, 0, 2, 1, 0, 3, 2, 3, 1, 3, 0, 2, 2, 1, 3, 2, 1, 1, 1, 3, 0, 1, 1, 0, 0, 1, 3, 3, 2, 3, 0, 2, 3, 3, 0, 0, 3, 3, 2, 1, 1, 2, 3, 3, 2, 0, 1, 2, 1, 2, 3, 1, 3, 1, 2, 3, 3, 3, 0, 2, 0, 2, 3, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -933. And steps were 79 and the episode is 1901 and the total_steps are 108118\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 1, 3, 3, 1, 3, 3, 1, 0, 1, 3, 3, 1, 3, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 3, 2, 0, 0, 2, 0, 3, 0, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 39 and the episode is 1902 and the total_steps are 108157\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 3, 1, 3, 3, 0, 0, 1, 2, 0, 2, 1, 2, 2, 2, 3, 2, 3, 3, 1, 0, 1, 0, 1, 0, 3, 3, 2, 3, 3, 2, 3, 3, 3, 0, 1, 3, 2, 3, 0, 2, 2, 1, 1, 2, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 52 and the episode is 1903 and the total_steps are 108209\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 0, 0, 3, 1, 1, 2, 1, 0, 3, 0, 0, 1, 1, 2, 0, 0, 2, 2, 0, 0, 3, 1, 1, 1, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 38 and the episode is 1904 and the total_steps are 108247\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1904     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3142     |\n",
      "|    total_timesteps  | 108247   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 14561    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 0, 2, 2, 3, 0, 3, 1, 3, 2, 2, 2, 0, 3, 3, 0, 1, 1, 0, 3, 3, 2, 0, 3, 3, 3, 2, 2, 0, 0, 2, 1, 1, 1, 3, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 1905 and the total_steps are 108289\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 0, 0, 2, 2, 0, 3, 1, 3, 3, 1, 0, 1, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 1, 0, 3, 1, 3, 3, 2, 3, 3, 0, 3, 1, 2, 3, 0, 2, 0, 2, 0, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 1906 and the total_steps are 108337\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 3, 2, 0, 0, 2, 2, 0, 2, 3, 2, 1, 1, 3, 0, 1, 1, 2, 3, 0, 2, 2, 1, 0, 2, 2, 0, 0, 1, 3, 2, 1, 1, 0, 2, 1, 2, 2, 3, 3, 0, 1, 0, 0, 0, 2, 1, 1, 2, 3, 2, 0, 0, 2, 0, 3, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 63 and the episode is 1907 and the total_steps are 108400\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 3, 3, 0, 3, 3, 3, 2, 2, 1, 3, 2, 1, 0, 3, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 22 and the episode is 1908 and the total_steps are 108422\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.1     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1908     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3150     |\n",
      "|    total_timesteps  | 108422   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 14605    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 2, 0, 0, 1, 3, 1, 2, 2, 3, 3, 3, 2, 1, 1, 2, 1, 2, 2, 3, 3, 3, 3, 3, 1, 1, 1, 2, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 35 and the episode is 1909 and the total_steps are 108457\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 1, 2, 3, 1, 3, 1, 1, 1, 3, 1, 2, 1, 2, 3, 3, 0, 2, 1, 3, 2, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 1910 and the total_steps are 108485\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 3, 2, 2, 0, 1, 3, 1, 1, 2, 2, 1, 2, 3, 0, 2, 2, 2, 1, 2, 3, 1, 0, 0, 2, 3, 0, 3, 1, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 36 and the episode is 1911 and the total_steps are 108521\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 1, 1, 1, 1, 0, 2, 3, 3, 1, 0, 3, 2, 0, 0, 3, 2, 1, 1, 3, 2, 1, 2, 2, 3, 0, 0, 0, 0, 3, 3, 0, 3, 2, 0, 2, 1, 3, 0, 1, 3, 2, 1, 2, 3, 0, 1, 3, 0, 1, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 57 and the episode is 1912 and the total_steps are 108578\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.5     |\n",
      "|    ep_rew_mean      | -978     |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1912     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3156     |\n",
      "|    total_timesteps  | 108578   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 14644    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 0, 3, 2, 0, 1, 3, 3, 2, 3, 3, 2, 0, 2, 3, 3, 1, 3, 3, 3, 1, 2, 2, 1, 3, 2, 3, 0, 0, 2, 3, 3, 3, 2, 2, 1, 1, 2, 2, 2, 3, 3, 1, 1, 2, 3, 0, 2, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 55 and the episode is 1913 and the total_steps are 108633\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 2, 3, 1, 3, 1, 0, 0, 2, 1, 0, 3, 0, 3, 0, 0, 0, 0, 3, 3, 3, 0, 2, 0, 0, 1, 1, 1, 1, 1, 0, 3, 2, 3, 0, 1, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 43 and the episode is 1914 and the total_steps are 108676\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 2, 2, 0, 0, 1, 3, 0, 2, 2, 3, 3, 0, 3, 3, 1, 1, 0, 2, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 1915 and the total_steps are 108700\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 2, 1, 0, 2, 1, 3, 1, 0, 0, 2, 3, 1, 2, 3, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 2, 1, 0, 1, 1, 2, 2, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 38 and the episode is 1916 and the total_steps are 108738\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.3     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1916     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3162     |\n",
      "|    total_timesteps  | 108738   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26     |\n",
      "|    n_updates        | 14684    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 1, 3, 2, 3, 3, 0, 0, 0, 3, 0, 3, 3, 0, 1, 2, 0, 2, 0, 2, 2, 2, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 0, 0, 2, 2, 0, 3, 2, 1, 0, 3, 2, 2, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 51 and the episode is 1917 and the total_steps are 108789\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 0, 1, 3, 3, 2, 1, 2, 1, 3, 0, 0, 3, 0, 2, 2, 2, 1, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 25 and the episode is 1918 and the total_steps are 108814\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 3, 3, 3, 3, 1, 3, 1, 2, 1, 3, 0, 1, 3, 3, 0, 1, 0, 1, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 1919 and the total_steps are 108838\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 0, 1, 0, 3, 3, 3, 0, 0, 0, 2, 1, 2, 1, 2, 3, 0, 3, 0, 3, 0, 2, 0, 2, 0, 0, 1, 1, 1, 2, 2, 1, 1, 2, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 41 and the episode is 1920 and the total_steps are 108879\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.8     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1920     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3168     |\n",
      "|    total_timesteps  | 108879   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.78     |\n",
      "|    n_updates        | 14719    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 1, 2, 0, 2, 1, 3, 0, 2, 0, 2, 0, 2, 0, 1, 2, 3, 0, 3, 3, 1, 2, 3, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 30 and the episode is 1921 and the total_steps are 108909\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 2, 1, 0, 2, 0, 1, 1, 3, 0, 3, 3, 1, 3, 2, 1, 2, 2, 3, 2, 2, 2, 0, 2, 2, 3, 0, 3, 2, 1, 2, 0, 2, 2, 2, 3, 1, 0, 1, 2, 0, 3, 0, 3, 1, 0, 1, 2, 2, 2, 1, 2, 1, 2, 3, 0, 2, 2, 0, 1, 1, 0, 0, 3, 3, 0, 0, 0, 1, 2, 2, 3, 3, 3, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -923. And steps were 91 and the episode is 1922 and the total_steps are 109000\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 0, 1, 1, 1, 3, 3, 0, 3, 0, 0, 3, 3, 1, 1, 2, 3, 2, 0, 0, 2, 1, 2, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 45 and the episode is 1923 and the total_steps are 109045\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 0, 3, 3, 3, 2, 0, 2, 2, 1, 0, 2, 3, 0, 3, 1, 1, 0, 1, 0, 2, 1, 3, 0, 0, 3, 0, 3, 3, 1, 1, 0, 3, 3, 3, 3, 1, 1, 0, 0, 1, 1, 1, 0, 2, 2, 3, 3, 1, 3, 0, 2, 1, 0, 3, 3, 1, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 64 and the episode is 1924 and the total_steps are 109109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.7     |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1924     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3177     |\n",
      "|    total_timesteps  | 109109   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 14777    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 3, 2, 1, 1, 1, 2, 0, 1, 2, 3, 3, 2, 3, 3, 3, 3, 1, 0, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 1925 and the total_steps are 109141\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 1, 2, 3, 0, 1, 1, 2, 2, 0, 2, 1, 1, 1, 0, 2, 2, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 1926 and the total_steps are 109165\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 1, 1, 2, 1, 3, 3, 0, 2, 2, 3, 3, 1, 2, 1, 2, 3, 2, 1, 0, 3, 3, 0, 1, 1, 0, 2, 1, 0, 3, 2, 2, 0, 1, 3, 1, 2, 2, 3, 2, 2, 3, 0, 3, 2, 3, 0, 2, 2, 0, 1, 0, 2, 2, 1, 3, 1, 2, 0, 0, 3, 3, 0, 0, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 71 and the episode is 1927 and the total_steps are 109236\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 1, 0, 0, 1, 0, 3, 2, 2, 2, 0, 2, 3, 1, 3, 2, 3, 3, 2, 2, 3, 2, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 29 and the episode is 1928 and the total_steps are 109265\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.7     |\n",
      "|    ep_rew_mean      | -955     |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1928     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3184     |\n",
      "|    total_timesteps  | 109265   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.985    |\n",
      "|    n_updates        | 14816    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 1, 1, 0, 1, 0, 3, 2, 3, 1, 2, 2, 2, 2, 2, 0, 3, 1, 0, 1, 3, 1, 3, 3, 3, 2, 3, 1, 3, 3, 1, 2, 2, 2, 3, 0, 2, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 44 and the episode is 1929 and the total_steps are 109309\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 3, 2, 1, 1, 0, 0, 0, 0, 2, 1, 0, 2, 1, 2, 3, 0, 2, 2, 1, 0, 1, 3, 0, 0, 0, 1, 3, 2, 0, 0, 3, 0, 3, 1, 3, 1, 0, 0, 2, 0, 0, 1, 0, 0, 3, 3, 0, 3, 1, 3, 0, 0, 2, 3, 2, 1, 1, 1, 3, 2, 0, 0, 2, 1, 2, 2, 0, 3, 3, 3, 2, 2, 3, 1, 0, 2, 2, 3, 0, 1, 3, 0, 3, 2, 1, 0, 2, 3, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1094. And steps were 96 and the episode is 1930 and the total_steps are 109405\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 3, 3, 0, 2, 1, 2, 2, 0, 3, 1, 2, 0, 3, 2, 2, 0, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 24 and the episode is 1931 and the total_steps are 109429\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 1, 1, 0, 0, 2, 0, 1, 0, 2, 3, 2, 3, 1, 2, 0, 3, 2, 2, 2, 3, 1, 2, 1, 0, 0, 2, 0, 3, 3, 0, 1, 1, 2, 0, 1, 1, 2, 3, 1, 3, 2, 0, 3, 3, 3, 0, 2, 1, 2, 3, 3, 2, 3, 0, 1, 2, 0, 3, 0, 3, 2, 2, 0, 3, 3, 2, 0, 1, 2, 1, 0, 0, 3, 0, 0, 3, 1, 0, 2, 1, 2, 1, 1, 1, 3, 2, 0, 3, 1, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1095. And steps were 97 and the episode is 1932 and the total_steps are 109526\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.7     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1932     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3194     |\n",
      "|    total_timesteps  | 109526   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.739    |\n",
      "|    n_updates        | 14881    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 0, 2, 0, 2, 0, 0, 3, 0, 3, 3, 1, 0, 2, 2, 3, 0, 1, 3, 2, 3, 0, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 30 and the episode is 1933 and the total_steps are 109556\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 2, 3, 0, 1, 0, 1, 2, 3, 1, 2, 2, 2, 2, 2, 3, 3, 3, 0, 2, 0, 3, 1, 1, 1, 2, 1, 3, 1, 1, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 37 and the episode is 1934 and the total_steps are 109593\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 1, 3, 1, 3, 0, 2, 0, 1, 1, 1, 1, 0, 3, 0, 0, 2, 3, 0, 2, 2, 3, 2, 0, 3, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 32 and the episode is 1935 and the total_steps are 109625\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 1, 3, 2, 2, 0, 2, 0, 0, 3, 3, 2, 0, 0, 2, 3, 1, 3, 1, 2, 2, 0, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 29 and the episode is 1936 and the total_steps are 109654\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.2     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1936     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3199     |\n",
      "|    total_timesteps  | 109654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.4     |\n",
      "|    n_updates        | 14913    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 0, 2, 0, 1, 2, 0, 0, 2, 1, 1, 0, 3, 0, 0, 1, 0, 1, 2, 0, 3, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 1, 2, 0, 0, 0, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 43 and the episode is 1937 and the total_steps are 109697\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 1, 3, 3, 2, 3, 2, 3, 0, 0, 2, 3, 3, 3, 0, 2, 0, 1, 0, 1, 1, 3, 3, 1, 2, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 1938 and the total_steps are 109729\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 3, 2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 3, 0, 1, 0, 2, 3, 0, 2, 2, 1, 2, 0, 2, 0, 1, 1, 2, 3, 3, 3, 1, 3, 1, 2, 2, 2, 2, 2, 1, 2, 3, 0, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 1939 and the total_steps are 109781\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 2, 1, 2, 0, 0, 3, 2, 1, 2, 3, 1, 1, 1, 0, 0, 1, 3, 0, 1, 2, 0, 3, 1, 1, 1, 2, 0, 3, 2, 0, 1, 3, 2, 0, 0, 3, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 44 and the episode is 1940 and the total_steps are 109825\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.5     |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1940     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3206     |\n",
      "|    total_timesteps  | 109825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.503    |\n",
      "|    n_updates        | 14956    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 0, 1, 0, 3, 2, 1, 0, 1, 3, 0, 2, 2, 0, 2, 1, 1, 0, 2, 0, 2, 2, 1, 2, 1, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 1941 and the total_steps are 109857\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 1, 1, 1, 3, 2, 0, 0, 1, 1, 3, 2, 1, 2, 1, 2, 2, 1, 1, 0, 1, 3, 0, 1, 1, 2, 2, 0, 0, 1, 3, 2, 2, 0, 0, 3, 3, 2, 0, 0, 2, 3, 3, 0, 0, 0, 0, 3, 2, 3, 1, 3, 0, 0, 1, 1, 1, 3, 2, 2, 1, 1, 0, 0, 3, 0, 0, 3, 1, 2, 0, 0, 2, 1, 2, 1, 3, 0, 2, 3, 1, 0, 3, 1, 3, 3, 0, 1, 3, 0, 2, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1056. And steps were 98 and the episode is 1942 and the total_steps are 109955\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 1, 3, 2, 3, 0, 0, 0, 0, 1, 3, 3, 2, 0, 1, 2, 3, 3, 3, 2, 2, 3, 0, 1, 2, 1, 3, 2, 0, 0, 2, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 38 and the episode is 1943 and the total_steps are 109993\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 2, 1, 2, 2, 0, 1, 3, 1, 0, 0, 1, 2, 0, 2, 3, 2, 0, 1, 3, 1, 2, 2, 1, 2, 1, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 1944 and the total_steps are 110026\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.5     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1944     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3214     |\n",
      "|    total_timesteps  | 110026   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64       |\n",
      "|    n_updates        | 15006    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 2, 0, 0, 0, 1, 2, 2, 0, 3, 2, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 18 and the episode is 1945 and the total_steps are 110044\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 0, 2, 3, 1, 0, 1, 0, 1, 2, 0, 0, 1, 2, 1, 0, 3, 2, 3, 3, 0, 3, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1946 and the total_steps are 110073\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 1, 2, 0, 1, 2, 0, 2, 3, 3, 2, 3, 2, 3, 2, 3, 3, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 1947 and the total_steps are 110097\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 0, 2, 1, 2, 2, 2, 1, 1, 3, 2, 0, 2, 1, 2, 0, 1, 0, 1, 1, 3, 3, 3, 1, 2, 3, 0, 1, 3, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 36 and the episode is 1948 and the total_steps are 110133\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.1     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1948     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3218     |\n",
      "|    total_timesteps  | 110133   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 15033    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 0, 2, 0, 1, 3, 1, 1, 1, 0, 2, 0, 2, 3, 2, 2, 0, 0, 1, 3, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 1949 and the total_steps are 110159\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 1, 1, 1, 3, 1, 2, 3, 2, 0, 3, 1, 3, 3, 2, 2, 0, 0, 2, 0, 3, 0, 3, 1, 1, 2, 2, 0, 1, 1, 1, 3, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 3, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 50 and the episode is 1950 and the total_steps are 110209\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 1, 2, 2, 2, 3, 3, 0, 2, 3, 3, 0, 0, 2, 2, 3, 1, 2, 2, 2, 1, 3, 0, 0, 2, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 1951 and the total_steps are 110241\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 0, 1, 2, 3, 0, 2, 2, 3, 1, 1, 1, 1, 1, 1, 3, 3, 1, 0, 2, 3, 0, 0, 2, 0, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 32 and the episode is 1952 and the total_steps are 110273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.4     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1952     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3224     |\n",
      "|    total_timesteps  | 110273   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.4     |\n",
      "|    n_updates        | 15068    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 3, 2, 0, 1, 1, 0, 0, 2, 0, 1, 1, 3, 0, 3, 0, 2, 2, 0, 2, 3, 2, 1, 0, 3, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 32 and the episode is 1953 and the total_steps are 110305\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 0, 0, 2, 3, 3, 1, 0, 1, 0, 2, 1, 1, 0, 0, 3, 1, 1, 0, 0, 2, 0, 3, 3, 2, 0, 3, 0, 2, 0, 0, 0, 2, 1, 0, 0, 1, 3, 3, 3, 1, 1, 3, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 3, 3, 3, 1, 0, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 66 and the episode is 1954 and the total_steps are 110371\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 3, 0, 1, 2, 3, 1, 3, 3, 2, 1, 2, 0, 3, 0, 2, 0, 0, 0, 2, 3, 0, 2, 3, 1, 1, 1, 2, 1, 2, 1, 0, 3, 2, 0, 2, 3, 1, 1, 0, 2, 2, 1, 0, 3, 0, 3, 2, 3, 1, 3, 1, 0, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 59 and the episode is 1955 and the total_steps are 110430\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 3, 1, 1, 3, 0, 2, 0, 1, 3, 2, 0, 2, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1017. And steps were 18 and the episode is 1956 and the total_steps are 110448\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.5     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1956     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3231     |\n",
      "|    total_timesteps  | 110448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 15111    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 2, 3, 2, 2, 2, 0, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 14 and the episode is 1957 and the total_steps are 110462\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 1, 3, 0, 2, 0, 1, 3, 3, 3, 1, 3, 0, 0, 1, 2, 3, 3, 3, 0, 2, 2, 2, 1, 3, 0, 1, 1, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 35 and the episode is 1958 and the total_steps are 110497\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 3, 2, 2, 1, 2, 2, 3, 0, 0, 1, 0, 2, 0, 2, 1, 0, 2, 0, 3, 3, 2, 3, 2, 0, 2, 0, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was 971. And steps were 32 and the episode is 1959 and the total_steps are 110529\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 1, 0, 1, 1, 1, 2, 2, 0, 3, 2, 2, 3, 1, 0, 3, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 23 and the episode is 1960 and the total_steps are 110552\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.9     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1960     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3235     |\n",
      "|    total_timesteps  | 110552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.23     |\n",
      "|    n_updates        | 15137    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 3, 3, 3, 1, 0, 0, 1, 0, 3, 2, 0, 2, 1, 3, 1, 1, 0, 0, 0, 3, 2, 1, 1, 0, 2, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 32 and the episode is 1961 and the total_steps are 110584\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 1, 1, 3, 1, 1, 0, 3, 0, 0, 1, 3, 2, 3, 1, 1, 1, 3, 3, 1, 2, 3, 0, 0, 1, 1, 0, 3, 0, 3, 1, 0, 1, 2, 0, 2, 3, 3, 3, 2, 2, 2, 3, 3, 0, 2, 0, 1, 0, 2, 2, 2, 1, 1, 0, 1, 1, 2, 1, 0, 2, 2, 1, 3, 3, 2, 3, 3, 1, 2, 2, 1, 0, 0, 2, 2, 3, 3, 2, 2, 1, 1, 1, 2, 3, 3, 1, 3, 0, 3, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -931. And steps were 97 and the episode is 1962 and the total_steps are 110681\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 1, 3, 2, 3, 1, 2, 2, 1, 1, 0, 3, 3, 2, 0, 2, 0, 2, 0, 0, 0, 3, 2, 3, 2, 0, 2, 2, 1, 2, 1, 3, 0, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 40 and the episode is 1963 and the total_steps are 110721\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 3, 1, 2, 0, 0, 2, 3, 3, 0, 0, 3, 2, 3, 2, 0, 0, 0, 0, 0, 1, 3, 1, 0, 3, 3, 2, 3, 0, 1, 1, 3, 3, 1, 2, 0, 1, 1, 1, 1, 3, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 48 and the episode is 1964 and the total_steps are 110769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.8     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1964     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3244     |\n",
      "|    total_timesteps  | 110769   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 37.1     |\n",
      "|    n_updates        | 15192    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 2, 2, 0, 0, 3, 0, 3, 3, 2, 2, 0, 2, 0, 0, 3, 2, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 24 and the episode is 1965 and the total_steps are 110793\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 2, 1, 3, 3, 1, 2, 2, 0, 3, 0, 2, 3, 0, 1, 0, 0, 0, 1, 0, 3, 3, 2, 0, 2, 0, 3, 1, 2, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 36 and the episode is 1966 and the total_steps are 110829\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 0, 2, 1, 1, 3, 2, 3, 0, 3, 1, 3, 2, 1, 3, 0, 3, 0, 1, 0, 3, 0, 0, 2, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 31 and the episode is 1967 and the total_steps are 110860\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 2, 3, 3, 3, 2, 0, 3, 3, 1, 3, 3, 3, 2, 0, 0, 2, 1, 1, 1, 2, 0, 0, 3, 3, 2, 1, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 1968 and the total_steps are 110894\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1968     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3249     |\n",
      "|    total_timesteps  | 110894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 15223    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 3, 1, 1, 0, 0, 0, 2, 0, 2, 2, 0, 1, 1, 3, 1, 0, 2, 2, 1, 2, 3, 2, 0, 1, 0, 0, 1, 3, 3, 0, 1, 0, 1, 0, 1, 1, 2, 2, 1, 0, 3, 3, 2, 0, 3, 2, 3, 0, 1, 0, 3, 1, 3, 0, 2, 2, 3, 3, 1, 0, 3, 0, 0, 0, 1, 3, 1, 2, 2, 2, 2, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 79 and the episode is 1969 and the total_steps are 110973\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 0, 1, 2, 3, 2, 3, 0, 2, 3, 0, 2, 1, 2, 0, 1, 1, 3, 1, 3, 2, 1, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 29 and the episode is 1970 and the total_steps are 111002\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 0, 0, 2, 1, 3, 3, 3, 3, 1, 3, 1, 2, 0, 2, 1, 2, 3, 1, 0, 3, 0, 2, 0, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 1971 and the total_steps are 111033\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 1, 2, 0, 1, 0, 0, 3, 1, 3, 3, 3, 1, 3, 2, 3, 0, 3, 3, 2, 0, 0, 3, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1026. And steps were 27 and the episode is 1972 and the total_steps are 111060\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1972     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3256     |\n",
      "|    total_timesteps  | 111060   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 15264    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 0, 3, 2, 0, 3, 3, 2, 3, 3, 3, 1, 3, 2, 1, 2, 1, 3, 3, 2, 0, 1, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 29 and the episode is 1973 and the total_steps are 111089\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 1, 0, 3, 2, 1, 2, 1, 3, 2, 1, 3, 0, 2, 2, 0, 2, 0, 3, 0, 1, 1, 2, 0, 3, 0, 0, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 3, 2, 0, 2, 1, 2, 1, 1, 0, 3, 1, 0, 2, 2, 3, 3, 3, 3, 2, 2, 2, 2, 0, 1, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -942. And steps were 68 and the episode is 1974 and the total_steps are 111157\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 0, 0, 1, 2, 0, 0, 2, 1, 0, 3, 1, 2, 3, 2, 2, 0, 3, 2, 0, 0, 3, 3, 2, 2, 2, 2, 2, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 1975 and the total_steps are 111192\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 2, 2, 2, 2, 0, 0, 2, 0, 3, 2, 2, 1, 2, 1, 2, 0, 1, 3, 1, 3, 3, 2, 2, 1, 2, 0, 0, 2, 3, 0, 3, 1, 0, 2, 0, 3, 1, 1, 3, 2, 0, 0, 0, 2, 0, 3, 2, 2, 3, 1, 1, 0, 3, 0, 2, 0, 0, 1, 3, 0, 2, 0, 3, 0, 2, 2, 1, 3, 1, 0, 0, 0, 0, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -927. And steps were 81 and the episode is 1976 and the total_steps are 111273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1976     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3265     |\n",
      "|    total_timesteps  | 111273   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.43     |\n",
      "|    n_updates        | 15318    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 0, 2, 3, 1, 1, 1, 3, 0, 3, 1, 0, 3, 1, 1, 0, 1, 1, 0, 2, 2, 2, 1, 1, 0, 1, 2, 2, 0, 2, 1, 3, 0, 1, 0, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 42 and the episode is 1977 and the total_steps are 111315\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 0, 2, 1, 2, 1, 0, 1, 2, 1, 2, 3, 0, 0, 1, 2, 3, 0, 1, 0, 2, 0, 2, 1, 1, 2, 3, 2, 3, 0, 0, 3, 2, 3, 1, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 42 and the episode is 1978 and the total_steps are 111357\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 1, 1, 3, 0, 2, 3, 3, 3, 0, 3, 1, 2, 1, 1, 0, 3, 1, 1, 2, 0, 2, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 1979 and the total_steps are 111386\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 2, 2, 0, 3, 0, 1, 3, 3, 1, 0, 2, 0, 2, 3, 0, 0, 0, 3, 0, 2, 1, 1, 3, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 31 and the episode is 1980 and the total_steps are 111417\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1980     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3270     |\n",
      "|    total_timesteps  | 111417   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.49     |\n",
      "|    n_updates        | 15354    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 2, 1, 3, 1, 0, 3, 3, 2, 2, 0, 3, 3, 3, 3, 1, 3, 3, 3, 0, 2, 1, 0, 0, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 31 and the episode is 1981 and the total_steps are 111448\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 3, 3, 3, 0, 3, 3, 0, 0, 3, 2, 1, 3, 2, 2, 1, 3, 0, 0, 2, 2, 2, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 29 and the episode is 1982 and the total_steps are 111477\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 0, 0, 0, 0, 2, 3, 0, 3, 3, 2, 3, 0, 0, 2, 1, 3, 3, 0, 1, 0, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 1983 and the total_steps are 111505\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 1, 2, 1, 1, 0, 3, 1, 1, 0, 1, 1, 3, 3, 1, 0, 0, 0, 2, 1, 0, 3, 3, 1, 1, 1, 2, 2, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 1984 and the total_steps are 111540\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1984     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3275     |\n",
      "|    total_timesteps  | 111540   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 15384    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 2, 1, 3, 2, 2, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 13 and the episode is 1985 and the total_steps are 111553\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 3, 2, 1, 0, 0, 3, 0, 2, 0, 2, 0, 1, 2, 1, 2, 2, 0, 3, 3, 0, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 28 and the episode is 1986 and the total_steps are 111581\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 0, 2, 1, 3, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 3, 3, 0, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 2, 1, 3, 1, 2, 1, 2, 2, 0, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 1987 and the total_steps are 111625\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 2, 3, 2, 0, 0, 3, 2, 3, 0, 0, 0, 0, 3, 0, 1, 0, 0, 2, 2, 3, 3, 0, 1, 2, 3, 1, 2, 3, 1, 1, 3, 1, 1, 2, 3, 0, 0, 3, 2, 0, 3, 1, 1, 1, 3, 2, 1, 0, 3, 0, 1, 2, 3, 2, 0, 2, 3, 0, 0, 0, 3, 2, 0, 3, 2, 0, 1, 0, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 76 and the episode is 1988 and the total_steps are 111701\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1988     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3282     |\n",
      "|    total_timesteps  | 111701   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 15425    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 0, 3, 1, 0, 3, 3, 2, 2, 2, 0, 0, 1, 0, 0, 3, 0, 2, 2, 0, 3, 1, 1, 0, 3, 2, 3, 2, 0, 2, 1, 2, 3, 0, 0, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 42 and the episode is 1989 and the total_steps are 111743\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 1, 0, 0, 1, 2, 2, 0, 3, 2, 1, 1, 3, 3, 2, 0, 0, 3, 3, 1, 3, 2, 2, 2, 3, 0, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 34 and the episode is 1990 and the total_steps are 111777\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 1, 0, 1, 0, 2, 2, 3, 0, 3, 0, 0, 1, 2, 3, 3, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 2, 0, 0, 3, 3, 3, 3, 2, 0, 3, 1, 0, 1, 2, 2, 2, 0, 1, 0, 0, 2, 0, 3, 1, 3, 3, 1, 2, 1, 3, 1, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 64 and the episode is 1991 and the total_steps are 111841\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 1, 0, 0, 2, 0, 0, 2, 3, 2, 1, 1, 3, 0, 3, 0, 0, 0, 3, 2, 2, 0, 0, 3, 3, 3, 0, 2, 0, 0, 1, 3, 2, 3, 1, 2, 3, 2, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 45 and the episode is 1992 and the total_steps are 111886\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1992     |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 3289     |\n",
      "|    total_timesteps  | 111886   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.3     |\n",
      "|    n_updates        | 15471    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 0, 0, 3, 2, 3, 3, 2, 1, 1, 1, 1, 3, 1, 3, 3, 3, 3, 0, 1, 3, 1, 2, 2, 1, 1, 3, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 1993 and the total_steps are 111920\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 1, 1, 3, 3, 0, 1, 3, 1, 1, 0, 3, 2, 3, 0, 0, 2, 3, 0, 3, 1, 0, 2, 3, 2, 1, 1, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 34 and the episode is 1994 and the total_steps are 111954\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 1, 0, 0, 2, 3, 1, 1, 3, 1, 0, 1, 2, 3, 0, 3, 0, 2, 2, 3, 1, 1, 2, 3, 0, 3, 3, 0, 1, 3, 2, 1, 2, 3, 0, 2, 0, 3, 2, 1, 0, 1, 2, 1, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 51 and the episode is 1995 and the total_steps are 112005\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 0, 2, 2, 1, 0, 1, 3, 0, 1, 3, 0, 1, 1, 3, 0, 0, 1, 0, 0, 1, 3, 0, 1, 2, 2, 0, 1, 3, 2, 1, 1, 1, 1, 2, 1, 2, 2, 0, 3, 2, 2, 3, 2, 1, 1, 0, 1, 2, 3, 2, 1, 1, 0, 3, 3, 2, 2, 1, 0, 0, 3, 3, 2, 1, 1, 3, 1, 2, 1, 3, 3, 3, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1078. And steps were 80 and the episode is 1996 and the total_steps are 112085\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1996     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3297     |\n",
      "|    total_timesteps  | 112085   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 15521    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 2, 1, 1, 0, 1, 3, 2, 1, 3, 1, 1, 3, 1, 0, 0, 1, 3, 2, 1, 1, 2, 2, 3, 3, 2, 2, 3, 2, 2, 3, 0, 3, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 40 and the episode is 1997 and the total_steps are 112125\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 3, 0, 3, 2, 0, 2, 3, 3, 0, 2, 0, 2, 1, 1, 1, 1, 0, 2, 3, 1, 2, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 29 and the episode is 1998 and the total_steps are 112154\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 0, 1, 1, 2, 2, 2, 3, 1, 0, 1, 2, 1, 3, 0, 1, 1, 0, 0, 2, 3, 3, 0, 0, 3, 3, 1, 0, 2, 0, 3, 1, 1, 2, 0, 2, 0, 3, 3, 3, 3, 1, 2, 0, 3, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 52 and the episode is 1999 and the total_steps are 112206\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 2, 3, 2, 3, 0, 3, 3, 1, 3, 0, 0, 3, 0, 3, 2, 3, 1, 2, 1, 0, 1, 1, 0, 1, 3, 2, 0, 3, 2, 2, 1, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 39 and the episode is 2000 and the total_steps are 112245\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3303     |\n",
      "|    total_timesteps  | 112245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.9     |\n",
      "|    n_updates        | 15561    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 1, 1, 3, 0, 3, 1, 2, 0, 3, 3, 1, 0, 2, 2, 2, 2, 1, 1, 0, 0, 3, 1, 2, 2, 1, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 34 and the episode is 2001 and the total_steps are 112279\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 2, 0, 2, 0, 2, 1, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 14 and the episode is 2002 and the total_steps are 112293\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 2, 0, 0, 2, 1, 0, 3, 1, 2, 3, 2, 3, 2, 2, 3, 2, 1, 2, 1, 2, 0, 2, 0, 1, 1, 0, 2, 1, 0, 2, 1, 2, 0, 0, 1, 2, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 44 and the episode is 2003 and the total_steps are 112337\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 2, 2, 3, 2, 1, 2, 3, 1, 0, 2, 2, 1, 1, 3, 0, 0, 0, 0, 0, 2, 1, 0, 3, 2, 1, 3, 3, 1, 3, 1, 3, 0, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 40 and the episode is 2004 and the total_steps are 112377\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2004     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3309     |\n",
      "|    total_timesteps  | 112377   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.08     |\n",
      "|    n_updates        | 15594    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 1, 0, 2, 1, 1, 2, 2, 3, 3, 1, 0, 2, 0, 3, 3, 1, 3, 0, 1, 1, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 2005 and the total_steps are 112405\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 1, 2, 1, 0, 2, 3, 0, 3, 3, 1, 2, 3, 1, 0, 2, 0, 0, 0, 2, 2, 3, 1, 3, 3, 0, 1, 1, 1, 0, 1, 0, 1, 2, 3, 3, 0, 0, 1, 3, 0, 3, 2, 3, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 51 and the episode is 2006 and the total_steps are 112456\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 1, 1, 0, 0, 3, 2, 0, 1, 3, 3, 1, 1, 3, 0, 2, 2, 0, 1, 0, 1, 3, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 29 and the episode is 2007 and the total_steps are 112485\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 1, 1, 3, 1, 1, 3, 2, 1, 1, 0, 3, 3, 1, 2, 3, 2, 0, 3, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 2008 and the total_steps are 112509\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -859     |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2008     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3315     |\n",
      "|    total_timesteps  | 112509   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 15627    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 1, 1, 0, 2, 2, 1, 0, 2, 1, 1, 2, 0, 1, 3, 2, 0, 2, 3, 0, 0, 3, 0, 0, 1, 2, 3, 1, 0, 2, 3, 0, 1, 2, 0, 2, 1, 0, 0, 0, 2, 3, 2, 1, 0, 2, 2, 3, 1, 3, 2, 2, 3, 2, 1, 3, 2, 2, 1, 3, 1, 0, 1, 2, 0, 0, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -939. And steps were 73 and the episode is 2009 and the total_steps are 112582\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 3, 3, 1, 0, 3, 3, 1, 3, 1, 0, 0, 2, 1, 0, 2, 1, 1, 0, 0, 1, 3, 2, 2, 3, 1, 3, 3, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 2010 and the total_steps are 112617\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 0, 0, 2, 3, 1, 0, 3, 3, 2, 2, 1, 1, 0, 3, 0, 1, 0, 0, 3, 0, 3, 2, 0, 1, 0, 1, 3, 0, 3, 3, 3, 2, 0, 3, 3, 1, 1, 2, 2, 1, 3, 3, 1, 0, 2, 1, 2, 2, 0, 0, 2, 3, 3, 0, 3, 0, 2, 0, 2, 0, 3, 3, 0, 0, 2, 2, 3, 0, 1, 2, 3, 0, 0, 3, 3, 3, 0, 1, 1, 2, 0, 3, 2, 0, 2, 3, 0, 1, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1062. And steps were 96 and the episode is 2011 and the total_steps are 112713\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 3, 2, 3, 3, 3, 3, 3, 2, 0, 1, 2, 2, 2, 3, 1, 3, 1, 0, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 2012 and the total_steps are 112737\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -839     |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2012     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3323     |\n",
      "|    total_timesteps  | 112737   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.5     |\n",
      "|    n_updates        | 15684    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 2, 0, 1, 1, 2, 2, 1, 3, 0, 3, 0, 3, 0, 2, 3, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 2013 and the total_steps are 112767\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 2, 3, 1, 2, 1, 3, 0, 2, 3, 1, 2, 2, 0, 0, 0, 3, 1, 2, 2, 0, 3, 3, 3, 3, 2, 0, 1, 0, 0, 0, 2, 3, 2, 0, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 42 and the episode is 2014 and the total_steps are 112809\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 1, 2, 1, 1, 3, 0, 1, 0, 0, 1, 2, 0, 0, 2, 3, 2, 2, 3, 3, 0, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2015 and the total_steps are 112837\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 2, 0, 1, 2, 2, 3, 3, 0, 2, 3, 3, 2, 1, 2, 2, 0, 3, 1, 3, 2, 1, 0, 2, 3, 2, 0, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 34 and the episode is 2016 and the total_steps are 112871\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -860     |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2016     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3329     |\n",
      "|    total_timesteps  | 112871   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 15717    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 1, 3, 0, 3, 0, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 0, 1, 2, 3, 1, 0, 0, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 31 and the episode is 2017 and the total_steps are 112902\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 1, 1, 2, 0, 2, 2, 0, 3, 1, 2, 0, 0, 1, 0, 1, 0, 3, 3, 1, 0, 0, 2, 1, 0, 1, 0, 2, 0, 2, 3, 3, 3, 3, 2, 2, 3, 0, 1, 3, 0, 2, 1, 1, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 51 and the episode is 2018 and the total_steps are 112953\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 2, 3, 0, 3, 1, 0, 0, 1, 3, 3, 0, 3, 3, 1, 3, 3, 0, 1, 2, 2, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2019 and the total_steps are 112981\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 0, 2, 1, 1, 2, 3, 2, 1, 1, 3, 1, 1, 3, 3, 0, 3, 3, 3, 3, 1, 3, 2, 1, 3, 2, 2, 1, 2, 3, 0, 2, 3, 3, 2, 2, 3, 0, 0, 3, 3, 0, 1, 2, 0, 2, 2, 3, 2, 1, 0, 2, 3, 2, 2, 2, 1, 1, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 65 and the episode is 2020 and the total_steps are 113046\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2020     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3337     |\n",
      "|    total_timesteps  | 113046   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.4     |\n",
      "|    n_updates        | 15761    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 0, 2, 1, 0, 1, 0, 3, 0, 1, 0, 0, 3, 3, 3, 2, 1, 1, 0, 2, 0, 0, 0, 3, 2, 1, 0, 1, 1, 2, 0, 0, 1, 3, 3, 1, 3, 2, 2, 0, 1, 0, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1047. And steps were 49 and the episode is 2021 and the total_steps are 113095\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 0, 3, 2, 3, 3, 2, 1, 3, 3, 3, 1, 2, 1, 3, 2, 0, 3, 0, 3, 0, 2, 1, 3, 3, 2, 3, 2, 2, 0, 0, 2, 0, 0, 2, 2, 1, 2, 1, 3, 1, 2, 3, 2, 3, 3, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 53 and the episode is 2022 and the total_steps are 113148\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 0, 3, 3, 3, 2, 3, 1, 1, 1, 1, 2, 1, 2, 3, 0, 2, 1, 0, 3, 3, 1, 2, 2, 0, 3, 1, 0, 1, 3, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 37 and the episode is 2023 and the total_steps are 113185\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 1, 1, 2, 2, 0, 1, 1, 1, 2, 2, 1, 3, 2, 2, 2, 0, 2, 1, 3, 3, 1, 2, 3, 2, 1, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 33 and the episode is 2024 and the total_steps are 113218\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2024     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3344     |\n",
      "|    total_timesteps  | 113218   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.8     |\n",
      "|    n_updates        | 15804    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 0, 0, 1, 3, 2, 0, 0, 3, 1, 3, 0, 2, 3, 0, 2, 0, 3, 3, 3, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 27 and the episode is 2025 and the total_steps are 113245\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 3, 0, 0, 2, 0, 3, 2, 1, 3, 1, 1, 0, 3, 0, 0, 1, 0, 3, 0, 2, 0, 2, 1, 3, 2, 0, 0, 2, 1, 3, 1, 0, 2, 2, 3, 2, 2, 0, 3, 2, 2, 3, 0, 0, 3, 3, 0, 1, 3, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 57 and the episode is 2026 and the total_steps are 113302\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 2, 2, 0, 0, 0, 0, 0, 2, 1, 2, 2, 2, 2, 0, 1, 2, 1, 0, 2, 0, 0, 0, 3, 1, 0, 1, 0, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 35 and the episode is 2027 and the total_steps are 113337\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 2, 2, 0, 3, 0, 1, 3, 0, 3, 2, 1, 2, 2, 3, 2, 2, 0, 2, 3, 0, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2028 and the total_steps are 113365\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -882     |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2028     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3350     |\n",
      "|    total_timesteps  | 113365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.505    |\n",
      "|    n_updates        | 15841    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 0, 0, 2, 3, 2, 0, 2, 3, 0, 0, 1, 0, 3, 3, 1, 3, 3, 3, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 26 and the episode is 2029 and the total_steps are 113391\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 3, 3, 2, 2, 2, 3, 0, 0, 3, 1, 3, 1, 3, 1, 2, 0, 0, 3, 3, 0, 2, 3, 3, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2030 and the total_steps are 113422\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 0, 2, 3, 1, 0, 1, 2, 0, 0, 1, 2, 1, 0, 1, 2, 3, 2, 2, 2, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 27 and the episode is 2031 and the total_steps are 113449\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 1, 1, 3, 0, 3, 0, 3, 0, 1, 3, 3, 3, 1, 3, 2, 2, 1, 1, 0, 2, 3, 3, 2, 2, 3, 1, 1, 2, 3, 2, 2, 1, 0, 2, 1, 0, 1, 0, 1, 2, 1, 2, 2, 2, 3, 2, 3, 3, 3, 3, 1, 1, 3, 3, 3, 1, 0, 1, 1, 3, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 68 and the episode is 2032 and the total_steps are 113517\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2032     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3356     |\n",
      "|    total_timesteps  | 113517   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.3     |\n",
      "|    n_updates        | 15879    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 0, 2, 3, 0, 2, 2, 3, 1, 3, 0, 2, 1, 0, 2, 2, 2, 2, 2, 3, 0, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2033 and the total_steps are 113545\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 2, 3, 0, 3, 3, 0, 0, 3, 0, 3, 2, 2, 2, 1, 3, 0, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 43 and the episode is 2034 and the total_steps are 113588\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 3, 3, 1, 0, 2, 0, 2, 3, 0, 0, 3, 2, 3, 0, 1, 2, 3, 0, 3, 0, 1, 2, 1, 1, 0, 0, 2, 2, 1, 3, 2, 1, 1, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 41 and the episode is 2035 and the total_steps are 113629\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 1, 1, 0, 1, 3, 1, 3, 0, 0, 2, 1, 0, 3, 3, 3, 2, 0, 0, 0, 2, 2, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 2036 and the total_steps are 113658\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2036     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3361     |\n",
      "|    total_timesteps  | 113658   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.7     |\n",
      "|    n_updates        | 15914    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 3, 0, 0, 1, 0, 2, 2, 3, 1, 0, 1, 3, 1, 0, 1, 2, 1, 2, 0, 3, 3, 1, 3, 3, 0, 0, 0, 3, 3, 2, 2, 2, 1, 1, 0, 1, 2, 1, 0, 2, 1, 2, 1, 2, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 52 and the episode is 2037 and the total_steps are 113710\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 0, 3, 3, 1, 1, 2, 0, 1, 0, 2, 2, 1, 3, 3, 3, 2, 3, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was 1022. And steps were 23 and the episode is 2038 and the total_steps are 113733\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 2, 0, 1, 3, 1, 2, 3, 0, 1, 3, 3, 2, 3, 0, 1, 1, 0, 0, 1, 2, 0, 3, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 2039 and the total_steps are 113763\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3, 3, 1, 0, 1, 0, 1, 3, 3, 1, 0, 1, 0, 3, 2, 2, 0, 1, 0, 0, 0, 2, 2, 3, 3, 1, 2, 2, 0, 1, 3, 0, 0, 3, 1, 2, 3, 0, 1, 3, 0, 1, 0, 3, 0, 1, 2, 1, 0, 1, 0, 3, 3, 0, 1, 0, 3, 1, 2, 3, 1, 0, 2, 1, 3, 0, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1062. And steps were 82 and the episode is 2040 and the total_steps are 113845\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -860     |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2040     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3369     |\n",
      "|    total_timesteps  | 113845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 15961    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 3, 3, 0, 1, 1, 3, 1, 0, 3, 2, 0, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 29 and the episode is 2041 and the total_steps are 113874\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 1, 3, 1, 0, 2, 1, 1, 1, 0, 3, 0, 1, 2, 1, 3, 2, 3, 0, 3, 3, 0, 2, 1, 1, 2, 1, 0, 2, 2, 1, 3, 1, 0, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 42 and the episode is 2042 and the total_steps are 113916\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 1, 1, 2, 3, 0, 0, 2, 2, 1, 1, 3, 2, 1, 0, 3, 2, 1, 0, 0, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 3, 3, 0, 1, 3, 0, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 45 and the episode is 2043 and the total_steps are 113961\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 3, 1, 2, 2, 0, 3, 0, 0, 2, 3, 1, 1, 2, 1, 1, 0, 0, 3, 3, 1, 1, 2, 3, 3, 0, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 33 and the episode is 2044 and the total_steps are 113994\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -859     |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2044     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3375     |\n",
      "|    total_timesteps  | 113994   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 15998    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 2, 1, 2, 0, 1, 2, 2, 2, 1, 3, 2, 2, 3, 1, 2, 1, 2, 3, 3, 2, 3, 2, 3, 0, 3, 0, 1, 0, 2, 0, 3, 2, 0, 3, 1, 0, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 43 and the episode is 2045 and the total_steps are 114037\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 3, 3, 1, 0, 1, 1, 0, 2, 2, 0, 0, 0, 3, 2, 3, 1, 0, 1, 0, 3, 2, 3, 2, 0, 1, 1, 2, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 2, 1, 3, 0, 3, 3, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 52 and the episode is 2046 and the total_steps are 114089\n",
      "Done condition: collision\n",
      "[3, 3, 3, 3, 2, 3, 2, 0, 1, 0, 0, 1, 2, 1, 2, 3, 3, 0, 1, 1, 1, 1, 2, 2, 1, 0, 0, 0, 0, 3, 2, 0, 3, 3, 0, 2, 3, 3, 0, 3, 0, 3, 2, 0, 0, 3, 2, 3, 1, 2, 1, 0, 3, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 57 and the episode is 2047 and the total_steps are 114146\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 1, 0, 3, 1, 3, 3, 1, 0, 2, 0, 3, 3, 1, 2, 0, 0, 2, 3, 2, 1, 1, 0, 1, 2, 1, 3, 3, 2, 3, 2, 1, 3, 2, 3, 1, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 43 and the episode is 2048 and the total_steps are 114189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2048     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3383     |\n",
      "|    total_timesteps  | 114189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.3      |\n",
      "|    n_updates        | 16047    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 1, 3, 3, 0, 2, 3, 3, 1, 2, 1, 2, 0, 2, 3, 2, 1, 0, 0, 1, 0, 3, 1, 2, 0, 1, 0, 1, 2, 3, 0, 0, 0, 3, 0, 1, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 43 and the episode is 2049 and the total_steps are 114232\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 3, 3, 2, 1, 0, 0, 2, 1, 1, 1, 0, 1, 2, 1, 1, 3, 2, 1, 0, 3, 3, 3, 2, 1, 0, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 2050 and the total_steps are 114265\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 2, 3, 2, 1, 1, 0, 3, 3, 1, 1, 2, 2, 3, 0, 0, 0, 1, 0, 3, 3, 0, 3, 3, 1, 3, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 2051 and the total_steps are 114298\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 2, 0, 3, 2, 2, 1, 3, 2, 2, 0, 3, 3, 0, 1, 1, 0, 2, 2, 1, 1, 1, 2, 1, 0, 3, 1, 1, 2, 1, 3, 0, 1, 1, 0, 1, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 43 and the episode is 2052 and the total_steps are 114341\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2052     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3389     |\n",
      "|    total_timesteps  | 114341   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 16085    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 1, 1, 3, 2, 2, 2, 0, 1, 2, 1, 0, 2, 0, 0, 0, 3, 1, 2, 1, 2, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was 1030. And steps were 31 and the episode is 2053 and the total_steps are 114372\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 1, 3, 0, 1, 1, 1, 2, 2, 1, 1, 0, 3, 2, 2, 1, 0, 2, 0, 2, 2, 2, 3, 1, 3, 2, 0, 3, 3, 0, 3, 2, 2, 3, 1, 2, 3, 1, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 45 and the episode is 2054 and the total_steps are 114417\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 0, 2, 1, 1, 2, 1, 3, 1, 1, 2, 3, 0, 2, 1, 3, 0, 2, 2, 1, 1, 0, 0, 3, 2, 0, 0, 3, 2, 0, 2, 3, 1, 1, 0, 3, 1, 3, 0, 0, 2, 0, 2, 2, 3, 3, 3, 3, 2, 2, 1, 0, 3, 1, 1, 2, 1, 0, 2, 1, 2, 1, 2, 3, 3, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 1, 3, 3, 0, 0, 2, 0, 0, 3, 1, 3, 2, 3, 0, 0, 3, 2, 2, 3, 3, 3, 3, 0, 3, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -896. And steps were 106 and the episode is 2055 and the total_steps are 114523\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 3, 2, 1, 3, 0, 3, 1, 0, 3, 2, 1, 3, 0, 1, 1, 2, 1, 2, 2, 0, 0, 3, 1, 0, 1, 1, 0, 2, 2, 0, 0, 3, 1, 2, 1, 3, 0, 0, 3, 1, 1, 2, 1, 1, 3, 0, 0, 3, 0, 0, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 58 and the episode is 2056 and the total_steps are 114581\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2056     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3398     |\n",
      "|    total_timesteps  | 114581   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.77     |\n",
      "|    n_updates        | 16145    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 0, 2, 3, 3, 2, 3, 2, 1, 1, 1, 3, 2, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 20 and the episode is 2057 and the total_steps are 114601\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 1, 1, 1, 3, 2, 0, 1, 0, 0, 3, 3, 2, 2, 0, 3, 2, 2, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 2058 and the total_steps are 114626\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 1, 2, 1, 2, 0, 1, 1, 3, 2, 2, 1, 3, 3, 3, 3, 1, 1, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 23 and the episode is 2059 and the total_steps are 114649\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 0, 2, 1, 1, 1, 1, 0, 2, 1, 0, 2, 3, 3, 3, 1, 3, 3, 1, 0, 3, 2, 2, 0, 2, 3, 3, 1, 1, 3, 3, 3, 0, 0, 0, 1, 2, 2, 0, 3, 3, 1, 0, 0, 3, 3, 2, 3, 3, 3, 2, 1, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 59 and the episode is 2060 and the total_steps are 114708\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2060     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3404     |\n",
      "|    total_timesteps  | 114708   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.649    |\n",
      "|    n_updates        | 16176    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 2, 3, 0, 0, 0, 0, 3, 2, 1, 3, 3, 2, 2, 1, 2, 2, 0, 2, 3, 3, 0, 2, 0, 3, 3, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 33 and the episode is 2061 and the total_steps are 114741\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 3, 3, 0, 2, 3, 3, 0, 3, 1, 1, 1, 3, 1, 3, 0, 0, 1, 3, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 2062 and the total_steps are 114765\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 0, 0, 2, 3, 1, 0, 2, 2, 0, 2, 0, 0, 1, 3, 1, 0, 3, 2, 0, 2, 3, 1, 1, 3, 3, 0, 3, 3, 2, 1, 1, 0, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 40 and the episode is 2063 and the total_steps are 114805\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 2, 1, 3, 3, 1, 2, 2, 0, 2, 0, 1, 0, 0, 2, 2, 3, 3, 2, 1, 0, 0, 0, 1, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 31 and the episode is 2064 and the total_steps are 114836\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2064     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3409     |\n",
      "|    total_timesteps  | 114836   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.9     |\n",
      "|    n_updates        | 16208    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 2, 1, 2, 0, 0, 0, 0, 0, 3, 3, 0, 1, 1, 0, 1, 2, 1, 1, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 26 and the episode is 2065 and the total_steps are 114862\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 2, 2, 0, 2, 0, 2, 3, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 15 and the episode is 2066 and the total_steps are 114877\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 0, 1, 1, 0, 1, 1, 3, 0, 3, 2, 0, 2, 2, 1, 0, 2, 3, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 25 and the episode is 2067 and the total_steps are 114902\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 1, 0, 3, 2, 0, 2, 3, 1, 0, 1, 1, 0, 3, 3, 3, 2, 2, 1, 3, 1, 2, 2, 3, 1, 2, 2, 1, 2, 0, 3, 1, 1, 1, 0, 3, 2, 1, 3, 2, 0, 1, 3, 1, 3, 1, 0, 3, 1, 0, 0, 3, 3, 2, 0, 1, 1, 0, 3, 3, 3, 3, 3, 2, 3, 0, 1, 1, 1, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 76 and the episode is 2068 and the total_steps are 114978\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2068     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3415     |\n",
      "|    total_timesteps  | 114978   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 16244    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 3, 0, 0, 0, 0, 2, 3, 0, 3, 3, 3, 1, 3, 3, 0, 2, 0, 2, 0, 3, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 2069 and the total_steps are 115006\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 3, 3, 1, 2, 3, 3, 0, 0, 1, 0, 0, 3, 2, 1, 2, 0, 0, 0, 2, 0, 0, 1, 1, 2, 3, 2, 3, 2, 3, 0, 2, 2, 2, 3, 1, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was 1040. And steps were 41 and the episode is 2070 and the total_steps are 115047\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 2, 0, 2, 2, 3, 3, 3, 3, 1, 2, 1, 3, 2, 2, 2, 2, 3, 3, 2, 2, 3, 2, 1, 0, 0, 1, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 2071 and the total_steps are 115081\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 3, 2, 3, 2, 0, 3, 3, 1, 1, 3, 0, 3, 2, 3, 0, 0, 2, 1, 3, 0, 1, 1, 0, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 31 and the episode is 2072 and the total_steps are 115112\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2072     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3421     |\n",
      "|    total_timesteps  | 115112   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 16277    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 1, 3, 0, 0, 0, 3, 0, 3, 2, 2, 3, 1, 1, 0, 1, 3, 1, 2, 3, 2, 0, 2, 2, 2, 0, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 33 and the episode is 2073 and the total_steps are 115145\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 2, 2, 1, 1, 0, 2, 2, 1, 1, 0, 2, 3, 1, 0, 1, 0, 2, 2, 2, 3, 0, 3, 1, 3, 2, 1, 1, 0, 1, 3, 1, 2, 3, 1, 1, 3, 0, 0, 1, 1, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 48 and the episode is 2074 and the total_steps are 115193\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 1, 2, 0, 0, 3, 0, 3, 3, 1, 1, 1, 0, 2, 2, 1, 2, 2, 1, 2, 0, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 28 and the episode is 2075 and the total_steps are 115221\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 1, 2, 2, 1, 1, 0, 0, 3, 3, 1, 2, 3, 3, 1, 2, 1, 1, 3, 0, 2, 1, 2, 2, 2, 1, 3, 2, 2, 0, 1, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 38 and the episode is 2076 and the total_steps are 115259\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2076     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3427     |\n",
      "|    total_timesteps  | 115259   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.389    |\n",
      "|    n_updates        | 16314    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 0, 1, 0, 3, 0, 3, 3, 0, 0, 1, 2, 3, 0, 2, 1, 3, 0, 0, 2, 1, 1, 2, 3, 2, 0, 3, 1, 2, 0, 3, 0, 1, 0, 2, 3, 3, 3, 2, 2, 2, 1, 0, 0, 1, 2, 2, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 54 and the episode is 2077 and the total_steps are 115313\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 0, 3, 2, 0, 0, 0, 2, 3, 0, 1, 1, 0, 1, 1, 0, 1, 3, 1, 2, 2, 0, 3, 0, 2, 1, 3, 3, 2, 2, 0, 1, 1, 3, 0, 0, 2, 0, 0, 0, 1, 3, 0, 3, 2, 3, 0, 3, 1, 2, 1, 3, 1, 1, 3, 1, 3, 1, 3, 3, 1, 2, 1, 2, 2, 3, 0, 2, 1, 1, 1, 1, 2, 1, 1, 3, 2, 3, 3, 0, 3, 0, 3, 2, 2, 2, 1, 1, 0, 2, 3, 2, 2, 3, 3, 3, 3, 0, 3, 2, 3, 0, 3, 2, 2, 3, 1, 0, 3, 2, 0, 0, 1, 2, 1, 0, 1, 2, 1, 1, 0, 0, 1, 3, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1075. And steps were 137 and the episode is 2078 and the total_steps are 115450\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 2, 0, 3, 3, 2, 2, 1, 2, 2, 0, 1, 0, 0, 1, 2, 2, 2, 1, 2, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 27 and the episode is 2079 and the total_steps are 115477\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 1, 1, 3, 0, 2, 2, 1, 3, 0, 0, 2, 1, 2, 2, 2, 3, 2, 0, 2, 3, 3, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 29 and the episode is 2080 and the total_steps are 115506\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2080     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3436     |\n",
      "|    total_timesteps  | 115506   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.44     |\n",
      "|    n_updates        | 16376    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 1, 1, 3, 0, 1, 3, 2, 2, 2, 3, 1, 3, 2, 0, 2, 2, 0, 2, 2, 3, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 2081 and the total_steps are 115534\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 3, 2, 2, 3, 0, 2, 0, 2, 2, 1, 1, 3, 2, 1, 2, 1, 1, 2, 2, 0, 0, 3, 1, 2, 2, 2, 2, 1, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 36 and the episode is 2082 and the total_steps are 115570\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 2, 0, 1, 2, 3, 2, 0, 1, 0, 3, 1, 3, 3, 2, 0, 2, 2, 0, 3, 2, 0, 3, 0, 1, 2, 0, 2, 2, 2, 3, 1, 0, 3, 0, 2, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1041. And steps were 43 and the episode is 2083 and the total_steps are 115613\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 3, 2, 0, 0, 3, 0, 3, 2, 2, 2, 1, 1, 3, 2, 3, 3, 1, 1, 3, 0, 0, 3, 3, 1, 2, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 33 and the episode is 2084 and the total_steps are 115646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2084     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3442     |\n",
      "|    total_timesteps  | 115646   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 16411    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 1, 0, 3, 2, 3, 1, 2, 0, 1, 1, 2, 0, 2, 3, 0, 2, 3, 1, 3, 1, 2, 3, 2, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 31 and the episode is 2085 and the total_steps are 115677\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 1, 3, 1, 1, 2, 0, 3, 1, 3, 2, 3, 3, 1, 0, 0, 2, 2, 0, 3, 3, 3, 0, 1, 0, 1, 2, 2, 2, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 36 and the episode is 2086 and the total_steps are 115713\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 3, 2, 0, 0, 3, 3, 0, 0, 1, 2, 1, 3, 3, 2, 2, 1, 0, 2, 0, 0, 3, 1, 0, 3, 3, 0, 2, 1, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 2087 and the total_steps are 115749\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 1, 3, 1, 0, 2, 2, 2, 3, 1, 1, 2, 3, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 2088 and the total_steps are 115769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2088     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3447     |\n",
      "|    total_timesteps  | 115769   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.8     |\n",
      "|    n_updates        | 16442    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 0, 0, 0, 0, 1, 1, 3, 3, 0, 0, 0, 1, 1, 3, 3, 2, 3, 1, 3, 2, 2, 3, 1, 1, 2, 0, 3, 3, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 2089 and the total_steps are 115805\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 3, 3, 3, 2, 2, 2, 3, 2, 2, 2, 0, 2, 0, 1, 1, 2, 1, 2, 3, 2, 2, 3, 0, 0, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 40 and the episode is 2090 and the total_steps are 115845\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 2, 1, 0, 3, 2, 0, 1, 2, 3, 1, 3, 0, 3, 2, 3, 3, 1, 2, 1, 1, 1, 2, 3, 3, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 3, 2, 2, 0, 0, 2, 3, 2, 3, 1, 3, 1, 2, 2, 1, 0, 1, 0, 0, 0, 0, 3, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -950. And steps were 64 and the episode is 2091 and the total_steps are 115909\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 1, 1, 1, 0, 0, 1, 0, 2, 0, 1, 3, 2, 1, 0, 3, 2, 1, 3, 3, 0, 1, 1, 3, 3, 3, 0, 1, 0, 3, 1, 1, 3, 0, 0, 2, 3, 3, 3, 0, 3, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 48 and the episode is 2092 and the total_steps are 115957\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2092     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3455     |\n",
      "|    total_timesteps  | 115957   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.56     |\n",
      "|    n_updates        | 16489    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 3, 1, 3, 3, 1, 3, 3, 1, 1, 1, 1, 0, 0, 1, 3, 1, 2, 0, 2, 3, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 2093 and the total_steps are 115985\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 0, 2, 3, 0, 0, 3, 0, 2, 1, 3, 0, 0, 3, 2, 2, 3, 3, 2, 2, 3, 1, 2, 1, 2, 0, 0, 3, 1, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 36 and the episode is 2094 and the total_steps are 116021\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 3, 2, 2, 3, 1, 0, 1, 3, 3, 2, 0, 1, 2, 0, 2, 3, 2, 1, 1, 2, 2, 3, 3, 1, 2, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 33 and the episode is 2095 and the total_steps are 116054\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 2, 0, 3, 3, 0, 1, 0, 0, 1, 2, 1, 0, 1, 0, 0, 3, 3, 2, 1, 0, 2, 0, 0, 3, 3, 3, 0, 1, 0, 0, 2, 0, 2, 1, 1, 2, 3, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 45 and the episode is 2096 and the total_steps are 116099\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -856     |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2096     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3461     |\n",
      "|    total_timesteps  | 116099   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 30.8     |\n",
      "|    n_updates        | 16524    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 3, 1, 3, 0, 3, 2, 0, 0, 2, 3, 1, 3, 0, 1, 3, 2, 3, 3, 1, 3, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2097 and the total_steps are 116127\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 1, 3, 0, 3, 2, 3, 3, 2, 2, 2, 1, 0, 2, 1, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 22 and the episode is 2098 and the total_steps are 116149\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 2, 1, 1, 3, 0, 0, 2, 1, 2, 3, 2, 2, 0, 1, 1, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 2099 and the total_steps are 116173\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 3, 0, 3, 3, 1, 2, 2, 0, 0, 3, 1, 3, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 2100 and the total_steps are 116193\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3465     |\n",
      "|    total_timesteps  | 116193   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 16548    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 0, 3, 1, 1, 1, 3, 3, 0, 3, 1, 3, 2, 3, 0, 2, 0, 0, 1, 1, 2, 2, 1, 1, 3, 3, 2, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 34 and the episode is 2101 and the total_steps are 116227\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 3, 3, 0, 0, 0, 3, 3, 3, 2, 0, 3, 2, 3, 3, 2, 1, 0, 2, 2, 3, 0, 1, 3, 1, 0, 3, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 34 and the episode is 2102 and the total_steps are 116261\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 1, 0, 0, 2, 2, 2, 3, 3, 0, 3, 3, 1, 3, 3, 0, 0, 1, 1, 1, 3, 1, 1, 3, 3, 0, 2, 1, 3, 0, 1, 0, 1, 1, 3, 0, 2, 2, 0, 0, 1, 2, 0, 0, 1, 1, 3, 1, 0, 3, 2, 0, 1, 0, 1, 3, 0, 0, 1, 3, 1, 2, 0, 3, 1, 2, 0, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 74 and the episode is 2103 and the total_steps are 116335\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 2, 2, 1, 2, 3, 1, 1, 0, 1, 2, 1, 0, 3, 2, 1, 1, 0, 0, 0, 0, 2, 1, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 2104 and the total_steps are 116365\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2104     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3472     |\n",
      "|    total_timesteps  | 116365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 94.1     |\n",
      "|    n_updates        | 16591    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 3, 1, 2, 2, 1, 1, 0, 2, 1, 2, 3, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 0, 3, 3, 0, 1, 2, 0, 3, 2, 3, 1, 3, 1, 0, 1, 2, 1, 2, 0, 1, 2, 1, 2, 0, 0, 0, 1, 0, 3, 0, 3, 2, 0, 1, 1, 3, 1, 3, 0, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 68 and the episode is 2105 and the total_steps are 116433\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 0, 0, 0, 3, 0, 2, 0, 2, 3, 0, 2, 3, 3, 0, 1, 0, 0, 2, 3, 3, 2, 1, 2, 2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 3, 3, 2, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 2106 and the total_steps are 116477\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 2, 3, 0, 2, 2, 0, 0, 3, 2, 0, 1, 3, 0, 0, 1, 2, 0, 0, 0, 2, 3, 2, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 30 and the episode is 2107 and the total_steps are 116507\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 3, 0, 0, 3, 2, 2, 1, 2, 3, 0, 2, 3, 0, 2, 1, 1, 0, 1, 2, 3, 1, 3, 1, 2, 0, 1, 0, 3, 2, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 37 and the episode is 2108 and the total_steps are 116544\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2108     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3479     |\n",
      "|    total_timesteps  | 116544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 16635    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 1, 1, 1, 2, 3, 2, 3, 3, 0, 1, 2, 1, 0, 3, 3, 1, 3, 2, 0, 2, 3, 1, 1, 1, 1, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 33 and the episode is 2109 and the total_steps are 116577\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 0, 1, 1, 3, 0, 2, 1, 1, 2, 0, 1, 1, 2, 0, 0, 1, 0, 1, 2, 1, 0, 3, 2, 3, 0, 3, 2, 2, 1, 2, 2, 3, 2, 3, 0, 2, 1, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 45 and the episode is 2110 and the total_steps are 116622\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 1, 0, 2, 3, 2, 3, 3, 0, 0, 1, 2, 2, 1, 2, 3, 2, 3, 2, 0, 1, 1, 0, 1, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 31 and the episode is 2111 and the total_steps are 116653\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 0, 3, 0, 0, 0, 1, 0, 1, 0, 3, 2, 2, 2, 0, 3, 3, 3, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 1, 0, 3, 1, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 39 and the episode is 2112 and the total_steps are 116692\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2112     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3486     |\n",
      "|    total_timesteps  | 116692   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.945    |\n",
      "|    n_updates        | 16672    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 1, 1, 1, 1, 3, 2, 0, 3, 0, 0, 1, 0, 2, 0, 1, 2, 2, 1, 1, 3, 3, 2, 0, 2, 1, 0, 0, 1, 3, 3, 2, 1, 2, 0, 0, 3, 1, 2, 1, 1, 1, 1, 0, 1, 0, 3, 0, 3, 1, 2, 1, 2, 2, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -949. And steps were 61 and the episode is 2113 and the total_steps are 116753\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 3, 3, 1, 3, 0, 2, 0, 0, 0, 3, 2, 1, 0, 3, 0, 1, 2, 2, 2, 1, 2, 3, 2, 0, 1, 1, 3, 3, 3, 0, 3, 2, 3, 0, 2, 3, 0, 0, 1, 0, 3, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 49 and the episode is 2114 and the total_steps are 116802\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 0, 1, 2, 0, 3, 0, 2, 1, 0, 0, 0, 2, 1, 1, 3, 2, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 31 and the episode is 2115 and the total_steps are 116833\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 3, 2, 3, 2, 2, 1, 3, 1, 3, 2, 3, 1, 1, 0, 1, 3, 2, 3, 3, 3, 1, 0, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 31 and the episode is 2116 and the total_steps are 116864\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2116     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3492     |\n",
      "|    total_timesteps  | 116864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.388    |\n",
      "|    n_updates        | 16715    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 2, 1, 3, 3, 0, 3, 3, 1, 1, 3, 2, 1, 0, 0, 2, 2, 1, 2, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 2117 and the total_steps are 116888\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 3, 3, 2, 0, 0, 2, 3, 2, 1, 2, 2, 2, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 2118 and the total_steps are 116908\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 1, 0, 2, 0, 1, 2, 2, 1, 2, 2, 3, 3, 3, 1, 0, 3, 1, 2, 0, 3, 1, 0, 3, 3, 2, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 33 and the episode is 2119 and the total_steps are 116941\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 2, 3, 3, 3, 0, 3, 0, 2, 0, 3, 1, 0, 0, 0, 2, 0, 1, 1, 3, 2, 0, 1, 2, 2, 1, 2, 0, 3, 2, 1, 3, 1, 0, 2, 1, 1, 2, 1, 2, 0, 2, 3, 2, 2, 3, 0, 3, 3, 3, 0, 1, 1, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 60 and the episode is 2120 and the total_steps are 117001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2120     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3498     |\n",
      "|    total_timesteps  | 117001   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 16750    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 0, 0, 1, 3, 0, 2, 0, 1, 2, 0, 2, 2, 2, 1, 2, 2, 0, 3, 2, 3, 0, 0, 0, 2, 2, 1, 1, 2, 3, 2, 3, 3, 1, 0, 2, 3, 3, 3, 0, 2, 3, 2, 0, 3, 0, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 53 and the episode is 2121 and the total_steps are 117054\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 3, 2, 1, 2, 0, 1, 0, 1, 0, 1, 1, 2, 2, 2, 1, 2, 3, 3, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 2122 and the total_steps are 117081\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 0, 1, 2, 2, 3, 1, 3, 1, 3, 0, 1, 2, 0, 1, 1, 3, 1, 2, 1, 2, 3, 2, 0, 3, 1, 1, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 34 and the episode is 2123 and the total_steps are 117115\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 3, 2, 0, 1, 3, 0, 3, 2, 1, 2, 3, 1, 1, 1, 0, 1, 0, 0, 0, 3, 3, 1, 3, 2, 2, 2, 0, 1, 0, 0, 3, 1, 3, 1, 1, 2, 1, 1, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 46 and the episode is 2124 and the total_steps are 117161\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2124     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3505     |\n",
      "|    total_timesteps  | 117161   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.87     |\n",
      "|    n_updates        | 16790    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 3, 1, 0, 3, 2, 2, 1, 1, 3, 1, 2, 0, 3, 2, 2, 3, 1, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 25 and the episode is 2125 and the total_steps are 117186\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 1, 2, 1, 1, 3, 2, 1, 3, 2, 0, 1, 3, 3, 1, 1, 1, 3, 2, 2, 0, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 2126 and the total_steps are 117214\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 3, 3, 0, 3, 2, 2, 3, 2, 1, 0, 3, 2, 0, 3, 1, 1, 0, 1, 1, 1, 2, 3, 0, 0, 0, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 2127 and the total_steps are 117247\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 0, 3, 0, 1, 1, 3, 1, 0, 2, 1, 1, 0, 2, 1, 0, 2, 3, 2, 0, 3, 0, 2, 1, 3, 0, 2, 3, 0, 1, 3, 1, 0, 2, 1, 3, 2, 0, 1, 0, 0, 1, 2, 1, 1, 1, 1, 1, 3, 2, 1, 3, 1, 0, 2, 0, 0, 1, 1, 0, 3, 1, 3, 3, 0, 0, 0, 1, 1, 3, 0, 2, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 79 and the episode is 2128 and the total_steps are 117326\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2128     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3512     |\n",
      "|    total_timesteps  | 117326   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 16831    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 1, 1, 1, 3, 0, 2, 1, 0, 3, 1, 0, 3, 3, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 20 and the episode is 2129 and the total_steps are 117346\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 0, 3, 1, 3, 2, 0, 0, 3, 2, 3, 0, 3, 0, 1, 2, 3, 1, 2, 0, 3, 1, 3, 1, 0, 1, 1, 1, 2, 0, 2, 1, 2, 0, 1, 1, 1, 0, 2, 0, 1, 2, 3, 3, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 51 and the episode is 2130 and the total_steps are 117397\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 1, 0, 3, 1, 0, 0, 0, 0, 1, 3, 1, 2, 2, 2, 3, 1, 3, 0, 3, 2, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 2131 and the total_steps are 117425\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 3, 3, 0, 3, 1, 1, 3, 0, 3, 1, 1, 0, 3, 2, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2132 and the total_steps are 117453\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2132     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3517     |\n",
      "|    total_timesteps  | 117453   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.7     |\n",
      "|    n_updates        | 16863    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 2, 3, 1, 3, 2, 2, 1, 2, 3, 0, 2, 3, 1, 0, 1, 3, 0, 3, 2, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 27 and the episode is 2133 and the total_steps are 117480\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 3, 2, 2, 3, 2, 0, 0, 2, 3, 0, 3, 3, 2, 1, 1, 0, 3, 2, 0, 3, 2, 3, 3, 1, 3, 1, 1, 3, 0, 1, 0, 0, 1, 0, 0, 3, 0, 3, 2, 1, 3, 3, 2, 0, 2, 2, 0, 3, 1, 0, 2, 0, 2, 0, 1, 0, 3, 3, 3, 3, 3, 2, 1, 2, 0, 2, 2, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 75 and the episode is 2134 and the total_steps are 117555\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 0, 3, 0, 3, 1, 1, 2, 3, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 36 and the episode is 2135 and the total_steps are 117591\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 2, 2, 1, 3, 2, 3, 1, 3, 1, 0, 2, 3, 1, 0, 1, 3, 0, 3, 1, 0, 1, 2, 0, 0, 2, 1, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 34 and the episode is 2136 and the total_steps are 117625\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2136     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3524     |\n",
      "|    total_timesteps  | 117625   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 16906    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 3, 3, 0, 2, 0, 0, 2, 2, 3, 0, 3, 3, 2, 3, 1, 0, 3, 3, 0, 3, 3, 0, 2, 0, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 32 and the episode is 2137 and the total_steps are 117657\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 0, 2, 2, 1, 1, 1, 1, 1, 0, 2, 3, 0, 3, 0, 1, 3, 2, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 2138 and the total_steps are 117682\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 2, 2, 1, 3, 1, 1, 1, 2, 2, 0, 3, 2, 0, 1, 1, 2, 1, 2, 3, 1, 1, 2, 0, 3, 1, 0, 1, 1, 3, 0, 1, 2, 1, 1, 1, 3, 2, 1, 0, 1, 3, 3, 0, 0, 0, 1, 0, 1, 0, 1, 0, 2, 0, 3, 1, 0, 3, 1, 1, 0, 3, 0, 0, 0, 2, 0, 0, 1, 2, 3, 3, 2, 1, 2, 0, 1, 3, 2, 3, 1, 2, 3, 2, 3, 0, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -929. And steps were 93 and the episode is 2139 and the total_steps are 117775\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 2, 3, 1, 1, 0, 0, 1, 0, 3, 2, 2, 1, 3, 2, 0, 1, 1, 3, 2, 1, 1, 0, 0, 0, 2, 1, 0, 0, 2, 2, 2, 3, 2, 2, 1, 0, 1, 2, 2, 0, 2, 0, 3, 1, 3, 2, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1052. And steps were 54 and the episode is 2140 and the total_steps are 117829\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2140     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3533     |\n",
      "|    total_timesteps  | 117829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.911    |\n",
      "|    n_updates        | 16957    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 1, 3, 0, 2, 2, 2, 2, 0, 2, 0, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 18 and the episode is 2141 and the total_steps are 117847\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 0, 2, 1, 2, 0, 3, 1, 0, 2, 3, 0, 2, 3, 2, 0, 0, 0, 1, 2, 3, 2, 0, 3, 1, 1, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 33 and the episode is 2142 and the total_steps are 117880\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 2, 1, 3, 0, 3, 2, 3, 3, 1, 3, 3, 1, 3, 1, 1, 2, 0, 0, 3, 0, 2, 2, 2, 0, 2, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 33 and the episode is 2143 and the total_steps are 117913\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 3, 3, 3, 3, 2, 3, 2, 1, 1, 3, 3, 0, 3, 1, 2, 1, 2, 1, 3, 1, 1, 1, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 30 and the episode is 2144 and the total_steps are 117943\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2144     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3537     |\n",
      "|    total_timesteps  | 117943   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 16985    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 3, 2, 1, 1, 2, 3, 0, 2, 3, 3, 1, 3, 2, 1, 0, 3, 3, 0, 2, 0, 0, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 2145 and the total_steps are 117984\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 2, 1, 3, 1, 1, 1, 1, 3, 1, 3, 0, 3, 2, 1, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 22 and the episode is 2146 and the total_steps are 118006\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 2, 0, 1, 2, 3, 0, 0, 0, 3, 1, 0, 2, 2, 2, 0, 3, 1, 1, 3, 3, 0, 0, 2, 2, 0, 0, 2, 2, 0, 3, 2, 2, 1, 2, 0, 0, 1, 2, 0, 3, 0, 3, 1, 3, 3, 3, 2, 0, 1, 3, 0, 3, 1, 3, 2, 2, 3, 1, 2, 2, 1, 0, 3, 3, 1, 1, 2, 2, 0, 3, 1, 1, 1, 3, 0, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -927. And steps were 83 and the episode is 2147 and the total_steps are 118089\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 0, 2, 2, 0, 0, 0, 3, 1, 3, 2, 3, 1, 1, 2, 2, 1, 0, 0, 2, 3, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 27 and the episode is 2148 and the total_steps are 118116\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2148     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3544     |\n",
      "|    total_timesteps  | 118116   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 17028    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 2, 0, 2, 3, 0, 2, 3, 2, 1, 1, 0, 2, 3, 3, 2, 1, 3, 2, 3, 1, 0, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 2149 and the total_steps are 118145\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 2, 3, 0, 1, 2, 0, 2, 2, 3, 0, 2, 2, 2, 0, 2, 0, 2, 1, 1, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 27 and the episode is 2150 and the total_steps are 118172\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 0, 2, 0, 3, 2, 0, 2, 3, 3, 1, 0, 3, 2, 3, 2, 1, 1, 1, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 26 and the episode is 2151 and the total_steps are 118198\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 3, 2, 2, 1, 0, 3, 2, 2, 3, 3, 1, 3, 0, 2, 0, 2, 3, 2, 0, 0, 3, 0, 0, 0, 1, 2, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 34 and the episode is 2152 and the total_steps are 118232\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -894     |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2152     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3549     |\n",
      "|    total_timesteps  | 118232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.6     |\n",
      "|    n_updates        | 17057    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 1, 0, 1, 0, 0, 2, 0, 0, 2, 1, 2, 3, 3, 0, 3, 3, 0, 3, 2, 1, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2153 and the total_steps are 118260\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 0, 1, 3, 2, 1, 2, 2, 1, 1, 1, 1, 3, 2, 1, 1, 3, 3, 1, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 26 and the episode is 2154 and the total_steps are 118286\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 3, 0, 1, 3, 2, 3, 2, 0, 3, 3, 2, 1, 3, 1, 3, 0, 3, 2, 0, 0, 0, 0, 2, 2, 0, 1, 3, 0, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 36 and the episode is 2155 and the total_steps are 118322\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 1, 3, 3, 1, 2, 0, 3, 2, 0, 3, 3, 2, 0, 1, 2, 3, 3, 0, 1, 3, 2, 0, 1, 2, 0, 1, 3, 3, 2, 0, 0, 2, 3, 0, 2, 0, 0, 1, 2, 3, 3, 2, 1, 1, 3, 2, 2, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 55 and the episode is 2156 and the total_steps are 118377\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2156     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3555     |\n",
      "|    total_timesteps  | 118377   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.748    |\n",
      "|    n_updates        | 17094    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 3, 2, 1, 2, 3, 1, 2, 1, 3, 0, 0, 0, 0, 1, 2, 1, 2, 0, 1, 1, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 28 and the episode is 2157 and the total_steps are 118405\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 3, 0, 1, 1, 0, 0, 0, 3, 0, 0, 1, 1, 1, 1, 2, 2, 1, 0, 0, 2, 1, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 29 and the episode is 2158 and the total_steps are 118434\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 2, 3, 0, 1, 1, 1, 2, 3, 2, 1, 1, 2, 2, 2, 1, 3, 0, 3, 3, 1, 2, 2, 0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 1, 1, 3, 0, 2, 2, 1, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 48 and the episode is 2159 and the total_steps are 118482\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 1, 2, 1, 1, 3, 1, 1, 2, 2, 3, 2, 0, 0, 0, 0, 0, 3, 0, 0, 1, 2, 1, 3, 2, 1, 0, 3, 2, 0, 3, 3, 3, 1, 3, 0, 3, 3, 3, 1, 3, 3, 2, 2, 2, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 51 and the episode is 2160 and the total_steps are 118533\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2160     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3561     |\n",
      "|    total_timesteps  | 118533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 17133    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 3, 2, 1, 2, 0, 0, 3, 0, 2, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 24 and the episode is 2161 and the total_steps are 118557\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 3, 0, 0, 0, 3, 1, 3, 1, 0, 2, 2, 0, 3, 3, 1, 3, 2, 1, 0, 0, 3, 1, 0, 2, 0, 1, 1, 1, 0, 0, 0, 0, 1, 3, 1, 3, 0, 1, 1, 0, 0, 1, 0, 0, 0, 3, 3, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 55 and the episode is 2162 and the total_steps are 118612\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 2, 1, 2, 3, 0, 0, 1, 1, 0, 2, 2, 3, 3, 0, 0, 1, 2, 0, 2, 3, 1, 2, 1, 3, 3, 3, 2, 1, 1, 3, 2, 1, 1, 1, 3, 2, 2, 3, 0, 2, 0, 2, 2, 0, 1, 3, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 54 and the episode is 2163 and the total_steps are 118666\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 2, 0, 3, 1, 2, 2, 2, 1, 0, 3, 1, 3, 1, 2, 0, 2, 3, 2, 0, 2, 2, 3, 2, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 31 and the episode is 2164 and the total_steps are 118697\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2164     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3568     |\n",
      "|    total_timesteps  | 118697   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 17174    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 1, 3, 3, 1, 2, 3, 1, 0, 2, 1, 2, 2, 2, 3, 2, 1, 1, 2, 3, 2, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2165 and the total_steps are 118725\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 0, 0, 1, 3, 3, 1, 1, 3, 0, 0, 3, 0, 1, 3, 0, 2, 3, 0, 1, 0, 2, 1, 3, 3, 3, 2, 3, 2, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 36 and the episode is 2166 and the total_steps are 118761\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 1, 3, 0, 3, 2, 1, 3, 0, 3, 0, 2, 3, 1, 1, 2, 3, 2, 0, 0, 1, 1, 3, 2, 0, 1, 0, 2, 2, 3, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 37 and the episode is 2167 and the total_steps are 118798\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 0, 1, 1, 0, 1, 0, 1, 3, 1, 0, 2, 0, 0, 1, 3, 0, 2, 1, 0, 1, 3, 0, 0, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2168 and the total_steps are 118829\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2168     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3574     |\n",
      "|    total_timesteps  | 118829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 17207    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 1, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 0, 2, 1, 1, 2, 3, 0, 1, 0, 0, 1, 1, 1, 0, 3, 3, 1, 2, 3, 3, 2, 0, 0, 2, 3, 3, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 45 and the episode is 2169 and the total_steps are 118874\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 3, 3, 0, 1, 2, 1, 1, 0, 3, 1, 3, 0, 1, 2, 0, 2, 1, 2, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 26 and the episode is 2170 and the total_steps are 118900\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 3, 2, 3, 1, 0, 2, 2, 0, 2, 0, 1, 2, 3, 2, 1, 1, 0, 1, 1, 2, 0, 0, 1, 1, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 32 and the episode is 2171 and the total_steps are 118932\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 2, 2, 2, 3, 2, 1, 0, 2, 2, 0, 0, 1, 3, 3, 0, 0, 3, 1, 0, 0, 1, 1, 1, 0, 3, 2, 1, 2, 2, 2, 3, 3, 0, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 41 and the episode is 2172 and the total_steps are 118973\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2172     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3579     |\n",
      "|    total_timesteps  | 118973   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.752    |\n",
      "|    n_updates        | 17243    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 0, 1, 1, 0, 0, 1, 1, 0, 0, 3, 1, 0, 3, 3, 0, 3, 2, 1, 0, 1, 2, 0, 3, 0, 3, 3, 1, 2, 1, 1, 3, 2, 2, 2, 3, 1, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 44 and the episode is 2173 and the total_steps are 119017\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 0, 3, 2, 2, 3, 2, 3, 3, 0, 1, 1, 2, 0, 3, 3, 0, 1, 0, 2, 2, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2174 and the total_steps are 119045\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 1, 0, 1, 1, 0, 0, 3, 2, 3, 2, 3, 2, 3, 2, 2, 3, 3, 1, 1, 0, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 2175 and the total_steps are 119073\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 3, 0, 0, 2, 0, 3, 0, 0, 1, 1, 0, 1, 2, 1, 0, 0, 0, 2, 1, 3, 0, 0, 2, 3, 1, 2, 3, 1, 2, 2, 0, 1, 1, 3, 0, 1, 3, 2, 0, 2, 0, 0, 1, 3, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 2176 and the total_steps are 119125\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2176     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3586     |\n",
      "|    total_timesteps  | 119125   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.481    |\n",
      "|    n_updates        | 17281    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 1, 1, 0, 2, 3, 1, 2, 2, 2, 3, 1, 0, 2, 0, 0, 0, 0, 2, 1, 2, 3, 2, 1, 1, 3, 1, 2, 3, 1, 3, 3, 1, 0, 2, 0, 1, 0, 2, 3, 0, 2, 2, 2, 2, 3, 0, 0, 1, 0, 0, 2, 3, 2, 0, 3, 2, 0, 0, 2, 1, 2, 2, 0, 3, 0, 2, 3, 0, 1, 2, 1, 0, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 80 and the episode is 2177 and the total_steps are 119205\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 3, 2, 2, 3, 1, 3, 0, 2, 0, 0, 3, 2, 2, 3, 2, 1, 0, 3, 3, 1, 3, 0, 2, 0, 3, 2, 3, 1, 2, 2, 2, 1, 2, 1, 0, 0, 0, 2, 0, 2, 2, 0, 0, 3, 1, 3, 1, 3, 0, 2, 1, 1, 1, 3, 0, 2, 0, 3, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 66 and the episode is 2178 and the total_steps are 119271\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 2, 3, 1, 1, 1, 0, 1, 0, 1, 1, 3, 2, 3, 1, 3, 1, 3, 1, 0, 2, 3, 0, 0, 2, 3, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 2179 and the total_steps are 119304\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 1, 3, 1, 0, 0, 0, 2, 1, 2, 0, 2, 2, 0, 2, 1, 2, 3, 2, 1, 1, 1, 3, 2, 3, 2, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 33 and the episode is 2180 and the total_steps are 119337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -978     |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2180     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3595     |\n",
      "|    total_timesteps  | 119337   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.46     |\n",
      "|    n_updates        | 17334    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 1, 0, 3, 1, 1, 2, 2, 0, 3, 2, 1, 1, 2, 0, 1, 0, 3, 2, 1, 2, 2, 2, 3, 3, 3, 3, 1, 3, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 2181 and the total_steps are 119373\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 2, 2, 2, 1, 0, 2, 3, 0, 3, 3, 0, 0, 0, 1, 1, 2, 3, 1, 3, 1, 1, 2, 0, 1, 0, 2, 0, 1, 2, 0, 0, 3, 3, 2, 3, 2, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 2182 and the total_steps are 119417\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 0, 0, 1, 0, 3, 0, 3, 0, 3, 3, 0, 0, 3, 3, 3, 1, 1, 0, 2, 1, 3, 1, 0, 3, 0, 2, 1, 1, 2, 1, 3, 2, 3, 2, 3, 1, 3, 0, 2, 3, 1, 1, 2, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 51 and the episode is 2183 and the total_steps are 119468\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 3, 3, 3, 0, 3, 1, 2, 1, 3, 2, 3, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 3, 0, 2, 2, 2, 3, 3, 1, 3, 3, 2, 2, 1, 2, 2, 1, 2, 3, 1, 0, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 49 and the episode is 2184 and the total_steps are 119517\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -979     |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2184     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3602     |\n",
      "|    total_timesteps  | 119517   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2        |\n",
      "|    n_updates        | 17379    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 2, 1, 2, 2, 2, 1, 0, 0, 3, 2, 0, 3, 0, 1, 0, 3, 1, 2, 1, 1, 0, 2, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 30 and the episode is 2185 and the total_steps are 119547\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 3, 1, 0, 2, 2, 3, 3, 0, 0, 3, 0, 3, 1, 1, 1, 0, 3, 2, 3, 0, 3, 1, 2, 3, 3, 1, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 34 and the episode is 2186 and the total_steps are 119581\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 0, 2, 1, 0, 3, 1, 3, 3, 1, 0, 1, 0, 1, 2, 3, 2, 3, 1, 1, 0, 1, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 2187 and the total_steps are 119610\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 0, 0, 1, 3, 1, 0, 3, 1, 2, 1, 2, 2, 3, 3, 1, 0, 1, 2, 3, 0, 0, 3, 0, 1, 3, 0, 3, 0, 1, 2, 0, 3, 2, 3, 0, 1, 1, 2, 1, 0, 0, 0, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 50 and the episode is 2188 and the total_steps are 119660\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -979     |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2188     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3608     |\n",
      "|    total_timesteps  | 119660   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.66     |\n",
      "|    n_updates        | 17414    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 1, 0, 0, 1, 3, 3, 1, 1, 0, 3, 1, 1, 3, 0, 0, 1, 0, 3, 1, 2, 1, 0, 0, 2, 3, 3, 0, 3, 2, 2, 3, 0, 1, 3, 0, 0, 0, 3, 0, 3, 1, 1, 0, 2, 3, 2, 1, 2, 1, 0, 3, 0, 0, 0, 2, 1, 1, 3, 0, 0, 2, 0, 1, 1, 3, 0, 3, 1, 2, 0, 0, 0, 2, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1087. And steps were 89 and the episode is 2189 and the total_steps are 119749\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 3, 3, 0, 0, 3, 3, 1, 1, 1, 1, 1, 0, 2, 0, 2, 2, 1, 0, 3, 2, 0, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 29 and the episode is 2190 and the total_steps are 119778\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 0, 3, 2, 2, 3, 3, 2, 0, 1, 3, 2, 1, 0, 1, 1, 1, 3, 3, 1, 1, 0, 3, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 30 and the episode is 2191 and the total_steps are 119808\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1, 1, 0, 3, 3, 3, 3, 0, 2, 3, 3, 2, 2, 0, 3, 1, 3, 2, 2, 0, 3, 0, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 37 and the episode is 2192 and the total_steps are 119845\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -980     |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2192     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3615     |\n",
      "|    total_timesteps  | 119845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.35     |\n",
      "|    n_updates        | 17461    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 3, 0, 3, 0, 0, 3, 0, 1, 1, 1, 1, 0, 3, 0, 0, 3, 1, 0, 0, 2, 2, 2, 0, 0, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2193 and the total_steps are 119877\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 3, 0, 2, 1, 0, 3, 3, 1, 0, 3, 0, 1, 3, 0, 2, 1, 2, 0, 3, 1, 2, 0, 0, 2, 0, 2, 1, 3, 1, 2, 3, 2, 1, 0, 3, 3, 2, 2, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 46 and the episode is 2194 and the total_steps are 119923\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 1, 1, 1, 0, 3, 0, 2, 2, 0, 3, 1, 0, 2, 0, 2, 1, 3, 3, 2, 0, 0, 0, 0, 2, 0, 3, 3, 1, 2, 2, 3, 3, 3, 1, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 42 and the episode is 2195 and the total_steps are 119965\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 3, 1, 1, 1, 3, 3, 2, 0, 1, 1, 1, 0, 3, 3, 2, 3, 0, 3, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 2196 and the total_steps are 119989\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2196     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3621     |\n",
      "|    total_timesteps  | 119989   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.59     |\n",
      "|    n_updates        | 17497    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 1, 3, 3, 3, 0, 1, 3, 3, 3, 1, 2, 0, 3, 3, 3, 1, 2, 2, 0, 3, 2, 3, 3, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 31 and the episode is 2197 and the total_steps are 120020\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 3, 3, 1, 0, 3, 0, 1, 3, 3, 2, 3, 1, 0, 1, 3, 0, 3, 3, 3, 0, 2, 1, 2, 2, 2, 1, 1, 0, 3, 3, 0, 2, 0, 0, 3, 3, 2, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 45 and the episode is 2198 and the total_steps are 120065\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 1, 2, 1, 3, 1, 2, 0, 2, 1, 1, 1, 1, 0, 1, 0, 3, 0, 1, 2, 1, 1, 1, 3, 0, 2, 2, 1, 0, 2, 1, 2, 0, 1, 3, 2, 2, 1, 0, 2, 3, 0, 3, 0, 1, 1, 0, 3, 3, 0, 2, 2, 0, 2, 0, 3, 3, 2, 3, 3, 0, 1, 3, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2, 1, 0, 1, 2, 3, 1, 2, 1, 2, 2, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -912. And steps were 92 and the episode is 2199 and the total_steps are 120157\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 2, 1, 1, 2, 0, 2, 3, 2, 3, 2, 2, 1, 0, 3, 3, 0, 3, 0, 0, 2, 1, 0, 0, 1, 0, 1, 2, 2, 1, 0, 2, 0, 1, 3, 0, 1, 1, 2, 3, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 47 and the episode is 2200 and the total_steps are 120204\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3630     |\n",
      "|    total_timesteps  | 120204   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.7     |\n",
      "|    n_updates        | 17550    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 1, 3, 1, 2, 0, 2, 3, 0, 2, 1, 0, 1, 2, 3, 2, 0, 0, 2, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 37 and the episode is 2201 and the total_steps are 120241\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 3, 1, 2, 3, 1, 3, 2, 1, 3, 2, 3, 2, 2, 1, 1, 2, 0, 3, 3, 3, 0, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2202 and the total_steps are 120269\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 2, 2, 3, 3, 2, 1, 3, 3, 2, 2, 0, 2, 2, 0, 1, 1, 3, 1, 0, 1, 1, 3, 1, 3, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 32 and the episode is 2203 and the total_steps are 120301\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 3, 0, 1, 1, 0, 0, 2, 2, 1, 0, 1, 3, 0, 0, 1, 1, 2, 3, 3, 0, 1, 2, 3, 1, 0, 2, 1, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 35 and the episode is 2204 and the total_steps are 120336\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2204     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3635     |\n",
      "|    total_timesteps  | 120336   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 17583    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 1, 2, 0, 3, 0, 1, 0, 3, 3, 0, 3, 1, 2, 2, 0, 3, 1, 3, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 2205 and the total_steps are 120362\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 3, 1, 1, 3, 0, 1, 3, 1, 0, 3, 2, 2, 3, 3, 3, 1, 2, 0, 3, 1, 2, 3, 3, 3, 1, 1, 2, 1, 2, 1, 3, 3, 1, 3, 0, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 43 and the episode is 2206 and the total_steps are 120405\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 1, 0, 0, 3, 1, 0, 3, 1, 0, 3, 2, 1, 0, 3, 1, 1, 0, 0, 0, 2, 1, 2, 2, 3, 2, 1, 0, 2, 3, 2, 2, 2, 0, 2, 2, 1, 1, 3, 1, 3, 1, 1, 3, 3, 0, 1, 1, 0, 1, 1, 0, 3, 3, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 62 and the episode is 2207 and the total_steps are 120467\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 3, 1, 3, 2, 3, 1, 0, 0, 3, 2, 2, 3, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 3, 0, 2, 2, 2, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 38 and the episode is 2208 and the total_steps are 120505\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2208     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3642     |\n",
      "|    total_timesteps  | 120505   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 17626    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 1, 1, 3, 2, 1, 1, 1, 3, 3, 1, 0, 1, 1, 2, 0, 3, 3, 0, 2, 0, 1, 0, 0, 0, 1, 2, 3, 0, 2, 3, 3, 1, 2, 2, 0, 2, 1, 0, 2, 3, 2, 0, 2, 1, 0, 3, 1, 1, 0, 2, 3, 1, 0, 3, 3, 3, 0, 0, 3, 3, 3, 1, 0, 3, 2, 3, 2, 1, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -926. And steps were 76 and the episode is 2209 and the total_steps are 120581\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 1, 1, 3, 1, 3, 0, 3, 1, 0, 2, 1, 0, 2, 0, 2, 1, 3, 0, 0, 0, 2, 1, 2, 2, 1, 0, 0, 1, 1, 1, 3, 2, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 40 and the episode is 2210 and the total_steps are 120621\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 0, 1, 1, 0, 0, 0, 0, 3, 0, 0, 0, 2, 3, 2, 1, 1, 1, 1, 2, 2, 2, 3, 2, 1, 0, 0, 1, 1, 0, 1, 3, 0, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 40 and the episode is 2211 and the total_steps are 120661\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 0, 2, 0, 2, 0, 2, 1, 1, 1, 0, 2, 2, 0, 3, 1, 1, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 2212 and the total_steps are 120685\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2212     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3649     |\n",
      "|    total_timesteps  | 120685   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 17671    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 1, 0, 2, 3, 2, 2, 0, 2, 2, 3, 3, 1, 2, 3, 0, 2, 1, 1, 3, 2, 2, 2, 2, 2, 0, 0, 0, 1, 1, 3, 1, 2, 0, 1, 3, 2, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 44 and the episode is 2213 and the total_steps are 120729\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 3, 2, 2, 0, 0, 1, 2, 2, 1, 2, 0, 3, 0, 0, 3, 3, 0, 2, 2, 2, 0, 0, 0, 1, 0, 2, 2, 0, 2, 0, 2, 1, 3, 0, 0, 2, 0, 1, 1, 2, 2, 1, 2, 1, 0, 1, 3, 0, 0, 0, 2, 0, 0, 0, 1, 0, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 64 and the episode is 2214 and the total_steps are 120793\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 0, 2, 3, 2, 1, 0, 1, 0, 0, 2, 3, 3, 2, 3, 1, 0, 3, 2, 0, 3, 2, 1, 3, 1, 1, 1, 1, 3, 1, 3, 1, 1, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 2215 and the total_steps are 120833\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 3, 3, 3, 3, 1, 2, 1, 3, 2, 3, 0, 3, 0, 2, 0, 1, 1, 2, 0, 1, 0, 0, 0, 2, 0, 2, 3, 0, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 2216 and the total_steps are 120869\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2216     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3657     |\n",
      "|    total_timesteps  | 120869   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 17717    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 1, 2, 2, 0, 3, 1, 0, 3, 0, 2, 0, 0, 1, 2, 2, 3, 2, 3, 2, 1, 3, 3, 3, 3, 1, 0, 2, 3, 3, 3, 0, 3, 3, 1, 3, 2, 2, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 44 and the episode is 2217 and the total_steps are 120913\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 1, 3, 1, 1, 3, 2, 3, 2, 2, 0, 2, 3, 1, 1, 3, 3, 1, 2, 1, 3, 3, 3, 1, 3, 2, 3, 1, 2, 3, 0, 2, 3, 3, 2, 3, 2, 0, 1, 3, 3, 1, 3, 3, 3, 0, 2, 3, 0, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1054. And steps were 56 and the episode is 2218 and the total_steps are 120969\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 1, 1, 1, 1, 3, 2, 2, 1, 0, 1, 3, 0, 2, 3, 0, 1, 0, 3, 3, 1, 1, 2, 3, 0, 0, 0, 0, 0, 0, 3, 1, 0, 3, 3, 0, 3, 3, 2, 1, 1, 3, 0, 2, 1, 2, 2, 1, 1, 0, 1, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 58 and the episode is 2219 and the total_steps are 121027\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 2, 3, 2, 3, 0, 3, 2, 3, 1, 0, 0, 3, 2, 2, 0, 0, 3, 0, 3, 1, 3, 2, 1, 0, 1, 1, 3, 2, 0, 2, 3, 2, 1, 0, 3, 3, 3, 1, 0, 1, 1, 1, 3, 0, 1, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 53 and the episode is 2220 and the total_steps are 121080\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -981     |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2220     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3665     |\n",
      "|    total_timesteps  | 121080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 17769    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 2, 1, 2, 0, 1, 3, 1, 0, 0, 2, 0, 1, 2, 2, 0, 2, 1, 0, 3, 0, 2, 3, 2, 0, 2, 0, 0, 3, 1, 3, 3, 1, 1, 3, 1, 2, 2, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 45 and the episode is 2221 and the total_steps are 121125\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 3, 2, 2, 3, 2, 1, 1, 3, 2, 2, 2, 3, 0, 3, 3, 2, 3, 2, 2, 2, 0, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 2222 and the total_steps are 121154\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 1, 3, 0, 0, 2, 1, 0, 1, 3, 2, 2, 1, 1, 3, 2, 2, 0, 2, 0, 2, 3, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 2223 and the total_steps are 121183\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 0, 0, 0, 1, 1, 3, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 3, 3, 0, 0, 0, 0, 2, 3, 2, 3, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 38 and the episode is 2224 and the total_steps are 121221\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -981     |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2224     |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 3671     |\n",
      "|    total_timesteps  | 121221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31       |\n",
      "|    n_updates        | 17805    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 0, 0, 1, 1, 2, 3, 3, 1, 0, 1, 0, 2, 1, 1, 1, 0, 2, 3, 1, 1, 1, 2, 2, 1, 1, 3, 0, 1, 3, 0, 2, 3, 1, 3, 2, 3, 0, 0, 1, 2, 2, 2, 0, 0, 2, 2, 3, 1, 2, 0, 2, 3, 0, 2, 3, 2, 1, 1, 3, 0, 1, 3, 2, 3, 0, 1, 2, 3, 0, 0, 1, 3, 1, 1, 0, 3, 1, 3, 3, 0, 3, 0, 3, 2, 2, 1, 1, 1, 1, 0, 3, 3, 2, 0, 3, 2, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 104 and the episode is 2225 and the total_steps are 121325\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 2, 0, 2, 0, 1, 1, 1, 1, 0, 1, 1, 2, 0, 0, 3, 2, 2, 1, 2, 1, 3, 2, 1, 1, 1, 0, 2, 2, 0, 2, 0, 0, 0, 3, 0, 0, 2, 2, 0, 3, 0, 2, 0, 1, 0, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1051. And steps were 53 and the episode is 2226 and the total_steps are 121378\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 1, 3, 0, 3, 0, 0, 0, 1, 1, 0, 2, 3, 1, 3, 0, 0, 0, 3, 3, 1, 0, 3, 2, 1, 2, 1, 3, 1, 3, 3, 2, 1, 0, 1, 3, 3, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 51 and the episode is 2227 and the total_steps are 121429\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 2, 2, 0, 3, 3, 1, 0, 2, 0, 2, 3, 2, 2, 0, 2, 2, 0, 2, 3, 2, 1, 0, 1, 0, 1, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 33 and the episode is 2228 and the total_steps are 121462\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -981     |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2228     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3681     |\n",
      "|    total_timesteps  | 121462   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.869    |\n",
      "|    n_updates        | 17865    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 3, 1, 2, 3, 2, 1, 2, 1, 0, 0, 0, 3, 0, 2, 0, 1, 3, 0, 0, 1, 3, 0, 3, 2, 2, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 2229 and the total_steps are 121495\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 2, 3, 1, 2, 1, 0, 1, 1, 1, 0, 0, 2, 2, 1, 2, 3, 3, 2, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 26 and the episode is 2230 and the total_steps are 121521\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 3, 0, 1, 1, 3, 2, 2, 0, 2, 3, 1, 1, 0, 3, 3, 0, 3, 1, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 26 and the episode is 2231 and the total_steps are 121547\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 2, 0, 0, 0, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 3, 3, 1, 0, 3, 0, 2, 3, 3, 2, 3, 0, 3, 3, 0, 1, 1, 1, 1, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 2232 and the total_steps are 121589\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -981     |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2232     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3686     |\n",
      "|    total_timesteps  | 121589   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.5      |\n",
      "|    n_updates        | 17897    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 3, 0, 3, 2, 2, 2, 0, 3, 0, 2, 2, 2, 1, 0, 2, 0, 0, 2, 0, 3, 0, 3, 1, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 31 and the episode is 2233 and the total_steps are 121620\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 0, 1, 2, 1, 1, 1, 2, 0, 1, 3, 3, 0, 0, 2, 2, 1, 2, 2, 1, 3, 2, 0, 2, 1, 3, 3, 2, 2, 0, 3, 1, 1, 3, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 2234 and the total_steps are 121661\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 1, 3, 1, 3, 0, 0, 1, 3, 2, 0, 1, 3, 0, 0, 2, 3, 2, 1, 2, 3, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 2235 and the total_steps are 121687\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 1, 2, 2, 1, 3, 1, 2, 1, 0, 3, 2, 0, 1, 1, 3, 1, 0, 1, 0, 2, 0, 1, 3, 0, 3, 1, 1, 1, 0, 2, 0, 0, 1, 2, 0, 3, 1, 3, 1, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 47 and the episode is 2236 and the total_steps are 121734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2236     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3692     |\n",
      "|    total_timesteps  | 121734   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.3     |\n",
      "|    n_updates        | 17933    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 2, 2, 2, 3, 1, 2, 1, 1, 0, 0, 3, 2, 2, 1, 1, 1, 1, 3, 2, 2, 2, 1, 3, 1, 1, 2, 0, 0, 1, 1, 2, 3, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 0, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1049. And steps were 51 and the episode is 2237 and the total_steps are 121785\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 0, 1, 1, 3, 0, 0, 1, 0, 1, 1, 0, 3, 3, 3, 2, 2, 0, 3, 0, 3, 0, 3, 2, 0, 2, 0, 0, 3, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 2238 and the total_steps are 121821\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 0, 1, 3, 3, 2, 0, 3, 2, 2, 2, 2, 3, 1, 3, 1, 3, 0, 2, 3, 3, 1, 0, 1, 0, 2, 1, 0, 3, 3, 3, 1, 0, 2, 3, 1, 3, 2, 2, 0, 1, 0, 0, 2, 3, 0, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 53 and the episode is 2239 and the total_steps are 121874\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 1, 2, 3, 1, 1, 1, 0, 2, 1, 3, 1, 0, 2, 2, 0, 2, 2, 0, 2, 3, 0, 1, 2, 0, 3, 0, 1, 0, 3, 3, 0, 0, 2, 2, 2, 2, 2, 1, 3, 0, 3, 0, 1, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 51 and the episode is 2240 and the total_steps are 121925\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -962     |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2240     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3700     |\n",
      "|    total_timesteps  | 121925   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 17981    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 0, 1, 2, 3, 1, 1, 2, 1, 3, 2, 0, 3, 1, 3, 1, 3, 1, 1, 0, 3, 1, 1, 2, 2, 1, 0, 2, 0, 3, 2, 3, 0, 2, 1, 1, 3, 2, 1, 3, 1, 0, 2, 2, 3, 3, 3, 0, 3, 2, 2, 1, 2, 2, 2, 0, 1, 0, 1, 3, 2, 0, 2, 2, 3, 2, 3, 1, 0, 1, 3, 2, 0, 2, 0, 3, 2, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 84 and the episode is 2241 and the total_steps are 122009\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 3, 1, 2, 0, 0, 1, 0, 1, 0, 0, 1, 3, 2, 1, 2, 2, 0, 2, 3, 1, 3, 0, 0, 3, 3, 3, 2, 3, 1, 3, 1, 3, 3, 3, 3, 2, 2, 1, 3, 1, 0, 2, 3, 2, 1, 1, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 1, 2, 3, 1, 2, 1, 0, 0, 2, 2, 3, 0, 2, 3, 1, 1, 0, 0, 2, 1, 3, 1, 1, 0, 2, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 89 and the episode is 2242 and the total_steps are 122098\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 1, 3, 1, 3, 1, 1, 3, 0, 3, 1, 3, 0, 3, 0, 0, 2, 2, 1, 0, 0, 2, 3, 0, 2, 0, 1, 3, 1, 1, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 37 and the episode is 2243 and the total_steps are 122135\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 1, 3, 1, 0, 3, 3, 0, 3, 2, 1, 1, 1, 3, 0, 1, 0, 0, 0, 3, 0, 3, 2, 1, 0, 3, 3, 2, 1, 0, 0, 0, 1, 2, 0, 0, 1, 1, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 45 and the episode is 2244 and the total_steps are 122180\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2244     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3710     |\n",
      "|    total_timesteps  | 122180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 18044    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 0, 2, 0, 3, 0, 2, 3, 2, 1, 1, 1, 0, 0, 1, 1, 3, 0, 2, 3, 1, 0, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 2245 and the total_steps are 122209\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 1, 3, 2, 2, 2, 0, 3, 3, 0, 3, 3, 3, 2, 1, 3, 1, 2, 0, 1, 3, 0, 1, 0, 3, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2246 and the total_steps are 122241\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 0, 0, 0, 0, 2, 0, 3, 0, 3, 2, 0, 0, 1, 2, 2, 0, 3, 0, 0, 2, 2, 0, 0, 2, 2, 1, 3, 1, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 36 and the episode is 2247 and the total_steps are 122277\n",
      "Done condition: collision\n",
      "[3, 0, 0, 1, 0, 0, 0, 0, 2, 3, 2, 1, 2, 3, 3, 2, 2, 0, 1, 0, 1, 1, 1, 1, 0, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 2248 and the total_steps are 122306\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -962     |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2248     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3715     |\n",
      "|    total_timesteps  | 122306   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.17     |\n",
      "|    n_updates        | 18076    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 2, 0, 1, 2, 1, 3, 2, 2, 1, 2, 0, 2, 1, 3, 2, 0, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 24 and the episode is 2249 and the total_steps are 122330\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 3, 3, 0, 1, 0, 3, 2, 0, 0, 3, 3, 2, 3, 3, 3, 2, 1, 1, 3, 1, 3, 2, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 2250 and the total_steps are 122360\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 0, 0, 1, 2, 3, 1, 0, 3, 0, 0, 0, 3, 3, 2, 0, 3, 0, 0, 3, 0, 2, 1, 1, 3, 2, 3, 0, 0, 1, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 37 and the episode is 2251 and the total_steps are 122397\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 3, 1, 2, 0, 3, 1, 2, 2, 3, 1, 1, 2, 3, 2, 1, 0, 2, 2, 1, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 2252 and the total_steps are 122424\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -963     |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2252     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3720     |\n",
      "|    total_timesteps  | 122424   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 18105    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 2, 3, 3, 3, 1, 2, 0, 1, 1, 0, 2, 0, 0, 2, 3, 1, 0, 1, 2, 1, 1, 2, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 30 and the episode is 2253 and the total_steps are 122454\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 1, 1, 3, 2, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 2254 and the total_steps are 122474\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 3, 2, 1, 2, 1, 0, 0, 0, 1, 3, 3, 2, 1, 1, 3, 0, 0, 3, 3, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 27 and the episode is 2255 and the total_steps are 122501\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 0, 3, 3, 3, 0, 1, 1, 3, 3, 3, 2, 3, 3, 2, 1, 3, 3, 1, 2, 1, 2, 0, 2, 1, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 2256 and the total_steps are 122533\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -963     |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2256     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3725     |\n",
      "|    total_timesteps  | 122533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.38     |\n",
      "|    n_updates        | 18133    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 1, 0, 2, 1, 0, 1, 3, 1, 1, 0, 0, 3, 2, 3, 1, 0, 3, 3, 0, 0, 2, 1, 2, 1, 3, 2, 2, 0, 1, 3, 2, 0, 0, 1, 2, 1, 0, 2, 2, 2, 0, 3, 3, 0, 1, 1, 0, 2, 1, 1, 2, 2, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 60 and the episode is 2257 and the total_steps are 122593\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 0, 2, 3, 2, 3, 0, 2, 2, 2, 0, 1, 0, 2, 0, 3, 1, 3, 2, 3, 1, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2258 and the total_steps are 122621\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 2, 1, 3, 3, 2, 1, 0, 2, 0, 2, 2, 3, 0, 3, 1, 0, 3, 1, 2, 1, 0, 2, 1, 3, 2, 2, 1, 2, 0, 0, 3, 2, 3, 2, 0, 2, 3, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 45 and the episode is 2259 and the total_steps are 122666\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 1, 1, 2, 2, 0, 2, 2, 1, 2, 0, 0, 3, 1, 3, 1, 0, 2, 2, 2, 3, 1, 0, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 30 and the episode is 2260 and the total_steps are 122696\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -962     |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2260     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3731     |\n",
      "|    total_timesteps  | 122696   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.01     |\n",
      "|    n_updates        | 18173    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 0, 3, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 20 and the episode is 2261 and the total_steps are 122716\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 1, 0, 1, 3, 3, 1, 2, 3, 3, 1, 1, 0, 0, 2, 0, 1, 2, 0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 3, 2, 0, 3, 2, 0, 3, 3, 2, 0, 2, 2, 0, 3, 2, 1, 0, 0, 3, 0, 3, 2, 0, 3, 1, 3, 2, 2, 0, 2, 1, 0, 1, 1, 0, 3, 0, 2, 0, 1, 2, 0, 3, 1, 3, 3, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -939. And steps were 81 and the episode is 2262 and the total_steps are 122797\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 2, 2, 0, 0, 1, 2, 1, 2, 3, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 2, 2, 1, 0, 3, 1, 1, 3, 1, 2, 0, 0, 2, 3, 0, 3, 1, 0, 3, 1, 0, 2, 1, 2, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 56 and the episode is 2263 and the total_steps are 122853\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 1, 3, 3, 2, 2, 2, 0, 3, 3, 0, 2, 2, 3, 0, 2, 3, 2, 3, 1, 0, 0, 0, 0, 0, 2, 2, 2, 3, 1, 0, 2, 3, 3, 1, 1, 0, 0, 0, 1, 2, 3, 1, 1, 2, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 52 and the episode is 2264 and the total_steps are 122905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -962     |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2264     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3740     |\n",
      "|    total_timesteps  | 122905   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 95.5     |\n",
      "|    n_updates        | 18226    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 3, 2, 0, 0, 1, 2, 3, 3, 3, 3, 2, 1, 0, 0, 1, 1, 2, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 2265 and the total_steps are 122937\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 2, 1, 3, 2, 1, 3, 2, 0, 0, 1, 2, 3, 2, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 27 and the episode is 2266 and the total_steps are 122964\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 3, 3, 1, 3, 2, 2, 2, 0, 2, 0, 3, 2, 1, 0, 3, 1, 0, 3, 1, 3, 0, 2, 3, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 31 and the episode is 2267 and the total_steps are 122995\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 2, 0, 0, 0, 0, 2, 3, 1, 1, 0, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 0, 0, 3, 2, 2, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 33 and the episode is 2268 and the total_steps are 123028\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2268     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3745     |\n",
      "|    total_timesteps  | 123028   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 18256    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 3, 1, 0, 0, 1, 2, 3, 0, 1, 0, 3, 3, 3, 0, 0, 2, 0, 1, 1, 2, 3, 2, 2, 1, 1, 2, 2, 1, 2, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 37 and the episode is 2269 and the total_steps are 123065\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 3, 1, 2, 0, 3, 1, 1, 3, 1, 3, 0, 1, 2, 0, 3, 0, 0, 3, 2, 0, 3, 0, 0, 2, 0, 1, 0, 0, 3, 3, 2, 2, 0, 1, 2, 3, 2, 2, 3, 1, 3, 0, 0, 2, 0, 1, 3, 3, 3, 3, 1, 2, 1, 2, 2, 3, 0, 2, 0, 0, 2, 3, 0, 1, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 72 and the episode is 2270 and the total_steps are 123137\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 3, 1, 1, 0, 0, 2, 1, 3, 0, 1, 0, 3, 2, 2, 3, 1, 1, 2, 0, 2, 3, 2, 0, 0, 3, 3, 2, 1, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 2271 and the total_steps are 123173\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 1, 3, 0, 3, 0, 3, 1, 3, 3, 3, 1, 3, 1, 1, 0, 2, 2, 3, 3, 3, 1, 3, 1, 3, 1, 2, 2, 2, 2, 1, 0, 2, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 40 and the episode is 2272 and the total_steps are 123213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2272     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3752     |\n",
      "|    total_timesteps  | 123213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.6     |\n",
      "|    n_updates        | 18303    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 3, 0, 2, 2, 1, 1, 2, 0, 2, 3, 2, 0, 1, 0, 2, 3, 2, 1, 2, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 27 and the episode is 2273 and the total_steps are 123240\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 2, 0, 3, 0, 3, 1, 2, 1, 3, 0, 0, 3, 0, 0, 3, 2, 3, 0, 3, 3, 1, 1, 3, 2, 0, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 2274 and the total_steps are 123273\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 1, 0, 0, 0, 3, 1, 3, 2, 3, 2, 3, 0, 3, 0, 2, 3, 0, 3, 2, 2, 0, 0, 1, 0, 3, 2, 1, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 1, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 48 and the episode is 2275 and the total_steps are 123321\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 0, 0, 3, 0, 3, 0, 2, 3, 1, 3, 3, 1, 1, 3, 3, 2, 2, 2, 0, 1, 1, 2, 2, 0, 0, 1, 2, 2, 0, 0, 2, 3, 3, 3, 1, 1, 1, 3, 3, 1, 3, 2, 0, 1, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 52 and the episode is 2276 and the total_steps are 123373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2276     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3759     |\n",
      "|    total_timesteps  | 123373   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 18343    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 2, 0, 1, 2, 2, 3, 3, 3, 0, 1, 1, 1, 2, 2, 2, 0, 3, 1, 1, 3, 1, 1, 2, 1, 3, 2, 0, 2, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 36 and the episode is 2277 and the total_steps are 123409\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 1, 3, 2, 0, 2, 3, 3, 1, 3, 0, 2, 3, 3, 0, 3, 1, 2, 0, 0, 2, 2, 0, 1, 3, 3, 1, 0, 3, 3, 0, 0, 0, 3, 2, 3, 1, 2, 2, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 56 and the episode is 2278 and the total_steps are 123465\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 0, 2, 2, 3, 2, 3, 0, 0, 3, 3, 0, 2, 1, 1, 2, 2, 1, 3, 1, 3, 3, 2, 3, 3, 1, 2, 0, 2, 3, 2, 3, 3, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 40 and the episode is 2279 and the total_steps are 123505\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 1, 2, 2, 2, 1, 3, 3, 3, 2, 3, 3, 2, 1, 1, 1, 2, 2, 1, 1, 1, 3, 1, 2, 0, 2, 1, 1, 1, 3, 0, 3, 2, 0, 0, 1, 0, 3, 1, 1, 3, 2, 1, 2, 0, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 52 and the episode is 2280 and the total_steps are 123557\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2280     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3766     |\n",
      "|    total_timesteps  | 123557   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.9     |\n",
      "|    n_updates        | 18389    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 2, 1, 1, 2, 3, 3, 3, 2, 3, 1, 3, 3, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 20 and the episode is 2281 and the total_steps are 123577\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 3, 1, 0, 2, 3, 3, 0, 3, 3, 1, 1, 1, 0, 3, 0, 0, 3, 0, 2, 2, 0, 0, 0, 3, 1, 0, 3, 2, 3, 3, 3, 2, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 40 and the episode is 2282 and the total_steps are 123617\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 0, 2, 0, 2, 3, 3, 1, 3, 2, 1, 3, 0, 2, 1, 2, 2, 1, 3, 3, 1, 1, 3, 2, 3, 0, 0, 1, 2, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 36 and the episode is 2283 and the total_steps are 123653\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 0, 0, 0, 1, 0, 2, 2, 0, 3, 2, 1, 0, 2, 1, 0, 2, 3, 1, 3, 0, 0, 2, 0, 1, 2, 1, 3, 0, 3, 1, 3, 0, 2, 3, 3, 2, 0, 1, 1, 2, 3, 2, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 50 and the episode is 2284 and the total_steps are 123703\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2284     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3772     |\n",
      "|    total_timesteps  | 123703   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.14     |\n",
      "|    n_updates        | 18425    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 3, 1, 2, 3, 2, 3, 2, 0, 0, 3, 1, 0, 1, 2, 3, 1, 0, 0, 0, 0, 0, 2, 3, 3, 1, 0, 1, 1, 3, 1, 1, 3, 1, 2, 0, 2, 0, 3, 1, 1, 0, 3, 0, 0, 1, 1, 2, 3, 2, 3, 0, 3, 0, 0, 3, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 63 and the episode is 2285 and the total_steps are 123766\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 2, 0, 3, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 3, 1, 0, 0, 3, 2, 1, 1, 1, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2286 and the total_steps are 123797\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 1, 2, 0, 3, 3, 0, 1, 0, 1, 2, 0, 1, 1, 1, 3, 1, 1, 3, 2, 3, 3, 2, 0, 2, 3, 0, 2, 2, 1, 1, 1, 0, 3, 2, 0, 1, 1, 0, 3, 2, 2, 3, 2, 0, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 2287 and the total_steps are 123849\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 3, 2, 1, 3, 0, 3, 2, 2, 1, 2, 2, 3, 0, 3, 3, 2, 3, 3, 0, 2, 3, 0, 0, 2, 1, 0, 1, 3, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 2288 and the total_steps are 123885\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2288     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3780     |\n",
      "|    total_timesteps  | 123885   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 18471    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 0, 3, 3, 1, 3, 3, 0, 2, 1, 1, 1, 3, 2, 1, 1, 0, 0, 2, 3, 0, 2, 2, 3, 3, 1, 1, 3, 2, 0, 0, 3, 0, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 40 and the episode is 2289 and the total_steps are 123925\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 0, 0, 1, 1, 3, 3, 3, 0, 2, 2, 0, 1, 3, 3, 3, 1, 2, 0, 0, 2, 3, 0, 1, 3, 1, 3, 2, 0, 2, 3, 0, 0, 1, 0, 2, 3, 0, 1, 0, 3, 0, 0, 3, 3, 1, 3, 0, 1, 3, 3, 3, 0, 2, 1, 1, 1, 3, 3, 2, 3, 2, 2, 1, 0, 2, 1, 3, 3, 1, 2, 0, 0, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 80 and the episode is 2290 and the total_steps are 124005\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 1, 2, 2, 2, 2, 0, 3, 0, 0, 1, 1, 1, 0, 1, 2, 0, 2, 0, 3, 0, 2, 1, 0, 3, 2, 3, 2, 3, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 52 and the episode is 2291 and the total_steps are 124057\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 1, 2, 2, 0, 1, 1, 1, 1, 1, 2, 2, 0, 3, 0, 1, 2, 3, 2, 3, 3, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 2292 and the total_steps are 124085\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2292     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3788     |\n",
      "|    total_timesteps  | 124085   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2        |\n",
      "|    n_updates        | 18521    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 0, 2, 3, 3, 2, 2, 3, 3, 0, 3, 2, 1, 3, 1, 3, 1, 1, 3, 2, 1, 3, 2, 1, 3, 3, 0, 2, 3, 0, 0, 2, 3, 2, 0, 0, 2, 1, 2, 3, 2, 1, 1, 1, 1, 0, 2, 0, 0, 3, 2, 2, 1, 1, 1, 0, 2, 3, 2, 3, 2, 2, 1, 3, 0, 1, 2, 3, 1, 2, 1, 0, 1, 0, 2, 0, 3, 0, 3, 2, 1, 2, 0, 3, 2, 2, 1, 3, 3, 2, 3, 3, 2, 2, 0, 2, 0, 3, 1, 2, 0, 1, 2, 2, 3, 0, 2, 2, 2, 3, 3, 0, 0, 1, 3, 0, 3, 2, 3, 0, 0, 0, 0, 2, 2, 2, 0, 2, 1, 1, 3, 0, 2, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 140 and the episode is 2293 and the total_steps are 124225\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 1, 1, 1, 2, 2, 0, 3, 2, 3, 1, 2, 1, 0, 3, 1, 2, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 2294 and the total_steps are 124249\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 0, 3, 1, 1, 1, 0, 1, 0, 2, 2, 0, 2, 0, 0, 1, 3, 3, 1, 2, 3, 0, 3, 1, 1, 0, 3, 1, 1, 1, 2, 2, 1, 1, 2, 3, 0, 3, 3, 1, 2, 3, 0, 0, 1, 2, 2, 0, 2, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 56 and the episode is 2295 and the total_steps are 124305\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 1, 2, 3, 3, 2, 1, 2, 1, 0, 3, 2, 2, 2, 1, 3, 3, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 22 and the episode is 2296 and the total_steps are 124327\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.4     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2296     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3798     |\n",
      "|    total_timesteps  | 124327   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 18581    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 1, 3, 3, 3, 1, 3, 2, 2, 1, 1, 1, 2, 2, 0, 1, 2, 1, 3, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 2297 and the total_steps are 124353\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 2, 0, 0, 2, 2, 1, 3, 0, 1, 2, 2, 1, 0, 1, 1, 2, 3, 2, 2, 1, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2298 and the total_steps are 124381\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 0, 2, 1, 3, 2, 0, 3, 0, 0, 0, 1, 2, 2, 1, 1, 1, 0, 2, 3, 1, 0, 3, 3, 2, 3, 3, 1, 2, 1, 2, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 38 and the episode is 2299 and the total_steps are 124419\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 1, 1, 3, 1, 1, 0, 3, 0, 2, 2, 3, 2, 1, 3, 2, 1, 1, 2, 1, 3, 2, 1, 0, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 30 and the episode is 2300 and the total_steps are 124449\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2300     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3803     |\n",
      "|    total_timesteps  | 124449   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 18612    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 3, 1, 1, 3, 1, 3, 0, 1, 1, 0, 2, 3, 2, 0, 0, 2, 3, 3, 1, 1, 0, 1, 3, 1, 3, 0, 3, 2, 2, 2, 0, 3, 3, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 48 and the episode is 2301 and the total_steps are 124497\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 2, 0, 1, 2, 2, 2, 3, 2, 2, 2, 0, 2, 0, 1, 0, 1, 0, 2, 2, 3, 3, 1, 0, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 32 and the episode is 2302 and the total_steps are 124529\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 2, 1, 0, 1, 0, 0, 0, 2, 0, 0, 3, 1, 3, 1, 3, 1, 3, 0, 3, 2, 2, 1, 0, 2, 2, 0, 3, 0, 3, 1, 0, 3, 1, 2, 1, 3, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 2303 and the total_steps are 124573\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 1, 2, 1, 2, 2, 1, 3, 1, 0, 1, 3, 0, 3, 0, 3, 1, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 24 and the episode is 2304 and the total_steps are 124597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.6     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2304     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3809     |\n",
      "|    total_timesteps  | 124597   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 18649    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 0, 0, 3, 2, 2, 3, 0, 3, 2, 1, 2, 3, 3, 2, 2, 1, 3, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 25 and the episode is 2305 and the total_steps are 124622\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 2, 3, 3, 0, 1, 3, 3, 3, 1, 0, 2, 3, 0, 3, 0, 3, 2, 0, 0, 2, 2, 1, 1, 2, 1, 2, 3, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 35 and the episode is 2306 and the total_steps are 124657\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 2, 3, 1, 1, 2, 0, 0, 3, 1, 1, 2, 0, 3, 0, 0, 3, 0, 3, 0, 1, 3, 1, 1, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 40 and the episode is 2307 and the total_steps are 124697\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 2, 0, 0, 1, 2, 1, 1, 1, 0, 3, 2, 3, 1, 2, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2308 and the total_steps are 124725\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2308     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3815     |\n",
      "|    total_timesteps  | 124725   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 18681    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 3, 0, 2, 3, 1, 3, 3, 3, 2, 2, 1, 3, 2, 2, 1, 3, 0, 3, 2, 1, 2, 0, 2, 1, 0, 1, 1, 2, 2, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 37 and the episode is 2309 and the total_steps are 124762\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 0, 2, 2, 2, 3, 2, 1, 3, 0, 2, 0, 0, 3, 0, 3, 0, 0, 0, 2, 2, 3, 3, 1, 2, 1, 0, 2, 2, 2, 0, 2, 0, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 40 and the episode is 2310 and the total_steps are 124802\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 1, 0, 2, 0, 2, 0, 1, 1, 2, 2, 3, 1, 0, 2, 1, 1, 1, 2, 0, 0, 1, 1, 1, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 31 and the episode is 2311 and the total_steps are 124833\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 2, 0, 1, 3, 3, 1, 1, 0, 1, 0, 3, 0, 0, 0, 0, 2, 2, 1, 0, 1, 1, 3, 3, 1, 3, 0, 1, 0, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 36 and the episode is 2312 and the total_steps are 124869\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2312     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3821     |\n",
      "|    total_timesteps  | 124869   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.62     |\n",
      "|    n_updates        | 18717    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 0, 3, 1, 2, 0, 3, 0, 3, 0, 1, 1, 1, 1, 1, 3, 3, 2, 0, 3, 0, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2313 and the total_steps are 124897\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 1, 1, 0, 3, 2, 1, 3, 1, 2, 0, 3, 3, 0, 3, 0, 0, 0, 3, 1, 2, 2, 1, 0, 3, 2, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 2314 and the total_steps are 124929\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 3, 0, 0, 1, 3, 1, 2, 2, 1, 0, 0, 1, 3, 0, 3, 1, 0, 0, 0, 3, 0, 0, 0, 3, 2, 0, 2, 1, 3, 0, 0, 0, 3, 2, 2, 0, 1, 1, 0, 0, 0, 1, 1, 3, 3, 2, 1, 3, 1, 3, 3, 0, 1, 3, 3, 2, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 64 and the episode is 2315 and the total_steps are 124993\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 0, 3, 2, 1, 0, 1, 1, 3, 0, 0, 3, 2, 1, 0, 1, 2, 3, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 25 and the episode is 2316 and the total_steps are 125018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2316     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3827     |\n",
      "|    total_timesteps  | 125018   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 18754    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 2, 0, 0, 2, 3, 0, 2, 3, 0, 2, 2, 3, 1, 3, 2, 2, 1, 0, 0, 3, 3, 0, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 1, 3, 3, 0, 2, 2, 0, 0, 0, 0, 1, 2, 1, 3, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1053. And steps were 55 and the episode is 2317 and the total_steps are 125073\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 2, 0, 2, 1, 1, 3, 1, 1, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 0, 1, 3, 3, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 2318 and the total_steps are 125108\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 3, 0, 0, 1, 0, 2, 0, 0, 3, 1, 1, 1, 1, 1, 3, 1, 0, 1, 3, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 2319 and the total_steps are 125133\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 1, 2, 3, 1, 2, 3, 3, 2, 3, 3, 3, 0, 0, 0, 1, 3, 3, 2, 2, 0, 3, 3, 2, 3, 0, 3, 3, 3, 2, 3, 1, 1, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 2320 and the total_steps are 125173\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2320     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3833     |\n",
      "|    total_timesteps  | 125173   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.12     |\n",
      "|    n_updates        | 18793    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 1, 0, 1, 1, 0, 3, 3, 0, 2, 1, 2, 2, 0, 1, 2, 1, 2, 0, 2, 1, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 2321 and the total_steps are 125201\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 1, 1, 2, 1, 3, 2, 3, 0, 1, 2, 0, 1, 3, 0, 0, 0, 3, 2, 2, 2, 3, 0, 3, 1, 2, 0, 2, 3, 2, 1, 1, 0, 0, 0, 0, 2, 0, 0, 3, 3, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 48 and the episode is 2322 and the total_steps are 125249\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 3, 1, 1, 2, 2, 0, 2, 2, 2, 0, 3, 0, 3, 3, 2, 2, 3, 1, 3, 3, 0, 1, 1, 0, 1, 0, 3, 0, 3, 3, 2, 1, 3, 1, 3, 1, 2, 0, 3, 1, 1, 0, 0, 3, 3, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 53 and the episode is 2323 and the total_steps are 125302\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 3, 3, 0, 2, 3, 2, 1, 3, 3, 1, 2, 1, 0, 1, 3, 1, 0, 3, 1, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 27 and the episode is 2324 and the total_steps are 125329\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2324     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3840     |\n",
      "|    total_timesteps  | 125329   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.4     |\n",
      "|    n_updates        | 18832    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 0, 3, 1, 2, 2, 1, 2, 1, 1, 0, 0, 0, 1, 2, 0, 0, 3, 0, 0, 0, 1, 0, 1, 3, 1, 2, 1, 3, 0, 2, 1, 1, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 40 and the episode is 2325 and the total_steps are 125369\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 0, 1, 1, 0, 1, 2, 2, 0, 2, 1, 1, 0, 1, 0, 2, 2, 1, 2, 3, 2, 1, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 29 and the episode is 2326 and the total_steps are 125398\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 2, 0, 0, 3, 3, 3, 3, 0, 1, 0, 3, 3, 1, 2, 0, 2, 0, 3, 2, 3, 2, 0, 3, 0, 3, 1, 2, 2, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 2327 and the total_steps are 125434\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 2, 0, 1, 0, 3, 0, 0, 3, 3, 0, 0, 0, 0, 1, 3, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 23 and the episode is 2328 and the total_steps are 125457\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2328     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3845     |\n",
      "|    total_timesteps  | 125457   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.9     |\n",
      "|    n_updates        | 18864    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 3, 3, 1, 2, 3, 0, 0, 3, 2, 0, 0, 1, 1, 0, 1, 1, 1, 3, 0, 1, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 2329 and the total_steps are 125485\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 0, 0, 3, 2, 0, 2, 0, 3, 2, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 2, 0, 3, 3, 3, 3, 3, 3, 0, 1, 3, 1, 3, 2, 2, 3, 1, 2, 1, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 48 and the episode is 2330 and the total_steps are 125533\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 1, 2, 0, 0, 0, 0, 3, 3, 0, 3, 3, 0, 0, 3, 1, 3, 3, 1, 1, 2, 0, 2, 2, 2, 2, 0, 1, 2, 0, 0, 2, 0, 2, 1, 3, 0, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 44 and the episode is 2331 and the total_steps are 125577\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 1, 2, 3, 2, 0, 0, 0, 1, 1, 1, 2, 3, 2, 3, 0, 0, 3, 3, 0, 3, 2, 2, 1, 1, 2, 1, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 34 and the episode is 2332 and the total_steps are 125611\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2332     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3851     |\n",
      "|    total_timesteps  | 125611   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.08     |\n",
      "|    n_updates        | 18902    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 0, 1, 1, 3, 2, 1, 0, 3, 3, 2, 2, 1, 1, 1, 2, 1, 2, 2, 0, 3, 1, 0, 3, 3, 1, 0, 2, 3, 2, 0, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 2333 and the total_steps are 125649\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 3, 0, 2, 1, 0, 3, 1, 3, 0, 2, 3, 2, 0, 2, 1, 2, 3, 0, 3, 2, 2, 3, 2, 1, 2, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 33 and the episode is 2334 and the total_steps are 125682\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 3, 3, 3, 2, 3, 0, 1, 0, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 3, 2, 2, 0, 1, 0, 2, 3, 0, 1, 3, 3, 0, 0, 0, 3, 3, 0, 0, 2, 3, 1, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 59 and the episode is 2335 and the total_steps are 125741\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 2, 3, 0, 0, 1, 1, 1, 3, 3, 1, 1, 2, 3, 0, 0, 2, 1, 2, 1, 0, 2, 0, 2, 1, 1, 3, 2, 2, 3, 1, 3, 3, 0, 3, 3, 2, 3, 3, 3, 3, 0, 2, 1, 2, 0, 0, 1, 3, 1, 2, 3, 2, 1, 0, 1, 0, 3, 2, 1, 0, 2, 3, 1, 0, 1, 3, 1, 2, 2, 1, 3, 1, 3, 3, 2, 0, 2, 1, 3, 2, 2, 0, 2, 2, 1, 3, 3, 0, 1, 3, 2, 0, 2, 1, 1, 1, 1, 3, 1, 3, 2, 1, 1, 1, 2, 0, 0, 2, 1, 3, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1080. And steps were 118 and the episode is 2336 and the total_steps are 125859\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2336     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3861     |\n",
      "|    total_timesteps  | 125859   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.39     |\n",
      "|    n_updates        | 18964    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 2, 0, 1, 2, 3, 2, 3, 1, 1, 0, 0, 1, 3, 1, 3, 0, 0, 0, 1, 1, 0, 0, 1, 3, 2, 1, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 34 and the episode is 2337 and the total_steps are 125893\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 2, 3, 1, 2, 1, 3, 0, 0, 3, 1, 2, 3, 3, 3, 0, 0, 1, 0, 2, 3, 0, 0, 0, 1, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2338 and the total_steps are 125925\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 3, 0, 0, 1, 0, 3, 1, 0, 2, 1, 2, 3, 1, 0, 3, 1, 2, 3, 0, 2, 0, 2, 2, 0, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 2339 and the total_steps are 125957\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 0, 3, 3, 1, 1, 0, 0, 0, 1, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 2, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2340 and the total_steps are 125985\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2340     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3866     |\n",
      "|    total_timesteps  | 125985   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.5     |\n",
      "|    n_updates        | 18996    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 3, 0, 2, 2, 3, 0, 0, 3, 2, 3, 0, 0, 3, 3, 2, 3, 3, 1, 0, 0, 3, 2, 0, 1, 0, 3, 2, 2, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 2341 and the total_steps are 126021\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 3, 0, 3, 0, 2, 3, 2, 3, 1, 2, 0, 2, 0, 3, 2, 1, 0, 2, 2, 3, 3, 2, 1, 0, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 2342 and the total_steps are 126053\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 2, 0, 0, 1, 1, 1, 3, 3, 0, 0, 2, 2, 1, 1, 3, 3, 1, 3, 3, 0, 0, 2, 2, 1, 0, 3, 3, 1, 3, 2, 3, 2, 0, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 41 and the episode is 2343 and the total_steps are 126094\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 2, 1, 3, 2, 3, 2, 2, 0, 1, 1, 3, 0, 2, 2, 1, 3, 2, 1, 2, 0, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 2344 and the total_steps are 126122\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2344     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3873     |\n",
      "|    total_timesteps  | 126122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 19030    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 2, 0, 1, 2, 0, 2, 2, 2, 3, 0, 0, 1, 2, 0, 3, 2, 3, 2, 1, 0, 2, 2, 0, 3, 2, 2, 0, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 35 and the episode is 2345 and the total_steps are 126157\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 3, 1, 0, 1, 3, 0, 2, 0, 2, 1, 1, 2, 1, 1, 0, 3, 2, 1, 1, 1, 0, 1, 0, 3, 3, 0, 2, 3, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 36 and the episode is 2346 and the total_steps are 126193\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 2, 1, 0, 0, 2, 1, 0, 2, 2, 0, 1, 2, 1, 3, 3, 2, 0, 2, 3, 0, 0, 0, 0, 2, 1, 0, 0, 3, 2, 3, 0, 3, 0, 3, 3, 2, 2, 0, 1, 0, 3, 3, 0, 2, 0, 3, 3, 2, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 56 and the episode is 2347 and the total_steps are 126249\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 0, 2, 3, 3, 0, 0, 2, 3, 2, 2, 3, 2, 1, 2, 3, 2, 0, 2, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 26 and the episode is 2348 and the total_steps are 126275\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2348     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3879     |\n",
      "|    total_timesteps  | 126275   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.48     |\n",
      "|    n_updates        | 19068    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 1, 1, 3, 3, 1, 2, 1, 0, 3, 0, 2, 0, 2, 0, 2, 3, 3, 3, 2, 2, 0, 1, 3, 0, 3, 1, 1, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 2349 and the total_steps are 126317\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 2, 0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 3, 3, 3, 3, 2, 1, 0, 1, 0, 3, 2, 2, 3, 2, 1, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 34 and the episode is 2350 and the total_steps are 126351\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 1, 3, 3, 1, 0, 1, 0, 2, 0, 3, 3, 0, 2, 1, 3, 3, 0, 0, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 2351 and the total_steps are 126377\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 1, 2, 2, 2, 3, 3, 0, 1, 0, 1, 0, 0, 1, 3, 0, 2, 2, 3, 1, 2, 1, 3, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 30 and the episode is 2352 and the total_steps are 126407\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2352     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3884     |\n",
      "|    total_timesteps  | 126407   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 19101    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 3, 2, 1, 0, 2, 1, 2, 1, 1, 0, 3, 2, 3, 1, 0, 3, 1, 2, 0, 1, 2, 2, 3, 0, 1, 3, 0, 2, 0, 2, 3, 3, 0, 3, 3, 1, 3, 0, 2, 0, 2, 2, 2, 0, 2, 3, 3, 2, 3, 3, 1, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 58 and the episode is 2353 and the total_steps are 126465\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 2, 1, 3, 1, 1, 3, 1, 3, 2, 1, 1, 0, 1, 1, 2, 3, 3, 2, 2, 0, 0, 0, 1, 2, 1, 3, 1, 0, 2, 1, 2, 3, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 2354 and the total_steps are 126505\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 2, 2, 2, 1, 2, 2, 1, 0, 3, 1, 0, 2, 2, 1, 0, 1, 0, 1, 3, 2, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2355 and the total_steps are 126533\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 2, 1, 0, 3, 3, 0, 1, 2, 1, 1, 1, 2, 3, 3, 2, 3, 2, 3, 0, 1, 2, 3, 0, 1, 3, 1, 1, 2, 3, 1, 3, 2, 2, 1, 3, 2, 0, 3, 3, 3, 0, 0, 0, 3, 3, 1, 3, 0, 3, 0, 2, 0, 1, 0, 1, 3, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 64 and the episode is 2356 and the total_steps are 126597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2356     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3892     |\n",
      "|    total_timesteps  | 126597   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 19149    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 2, 0, 1, 1, 0, 1, 3, 3, 2, 2, 2, 0, 2, 2, 3, 3, 0, 0, 3, 2, 1, 1, 0, 2, 2, 3, 1, 2, 0, 3, 0, 3, 1, 1, 0, 3, 3, 1, 1, 3, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 48 and the episode is 2357 and the total_steps are 126645\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 1, 2, 2, 3, 2, 2, 0, 1, 3, 1, 3, 2, 0, 0, 2, 2, 3, 0, 0, 2, 2, 0, 2, 2, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 2358 and the total_steps are 126677\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 1, 3, 1, 3, 3, 3, 3, 0, 2, 0, 2, 0, 2, 2, 0, 1, 2, 0, 1, 3, 3, 1, 1, 0, 1, 3, 1, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 3, 1, 0, 2, 2, 2, 0, 2, 3, 1, 3, 0, 1, 3, 2, 3, 2, 2, 2, 1, 1, 3, 3, 0, 2, 0, 3, 3, 1, 1, 1, 1, 3, 3, 0, 3, 0, 2, 2, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -942. And steps were 84 and the episode is 2359 and the total_steps are 126761\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 2, 0, 0, 1, 3, 0, 3, 0, 2, 1, 0, 2, 0, 3, 3, 3, 2, 3, 2, 3, 1, 0, 2, 0, 3, 3, 2, 3, 3, 2, 1, 1, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 40 and the episode is 2360 and the total_steps are 126801\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2360     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3901     |\n",
      "|    total_timesteps  | 126801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.02     |\n",
      "|    n_updates        | 19200    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 1, 0, 2, 1, 1, 0, 2, 2, 2, 2, 1, 0, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 20 and the episode is 2361 and the total_steps are 126821\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 2, 2, 2, 0, 1, 0, 3, 3, 1, 1, 1, 0, 2, 2, 2, 3, 2, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 25 and the episode is 2362 and the total_steps are 126846\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 3, 1, 2, 2, 2, 3, 0, 3, 3, 2, 1, 1, 1, 0, 3, 0, 2, 1, 0, 1, 2, 3, 2, 2, 0, 3, 0, 0, 3, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 3, 1, 0, 0, 1, 0, 1, 2, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 59 and the episode is 2363 and the total_steps are 126905\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 3, 1, 3, 0, 3, 3, 3, 0, 3, 3, 1, 1, 1, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 3, 0, 0, 2, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 39 and the episode is 2364 and the total_steps are 126944\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2364     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3907     |\n",
      "|    total_timesteps  | 126944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 19235    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 2, 3, 0, 1, 1, 2, 1, 1, 1, 3, 3, 3, 1, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 2365 and the total_steps are 126973\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 1, 3, 3, 2, 1, 3, 3, 2, 2, 1, 1, 3, 0, 2, 2, 3, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 2366 and the total_steps are 126997\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 1, 0, 3, 0, 0, 3, 3, 3, 1, 0, 1, 2, 3, 0, 3, 3, 0, 0, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 2367 and the total_steps are 127021\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 1, 0, 2, 0, 3, 0, 0, 0, 0, 3, 2, 1, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 2, 2, 3, 0, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 2368 and the total_steps are 127056\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2368     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3911     |\n",
      "|    total_timesteps  | 127056   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 36.9     |\n",
      "|    n_updates        | 19263    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 0, 2, 2, 0, 2, 0, 3, 0, 3, 0, 3, 2, 2, 1, 2, 2, 0, 3, 0, 3, 3, 2, 3, 0, 0, 0, 2, 1, 1, 3, 2, 3, 1, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 41 and the episode is 2369 and the total_steps are 127097\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 1, 3, 0, 2, 1, 0, 1, 0, 3, 0, 1, 2, 0, 1, 1, 0, 0, 0, 2, 1, 3, 0, 0, 1, 3, 1, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 34 and the episode is 2370 and the total_steps are 127131\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 2, 1, 0, 2, 2, 3, 2, 2, 3, 2, 0, 1, 1, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 21 and the episode is 2371 and the total_steps are 127152\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 3, 1, 2, 1, 0, 3, 2, 1, 3, 3, 2, 3, 0, 1, 0, 1, 3, 0, 0, 1, 1, 3, 3, 3, 0, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 33 and the episode is 2372 and the total_steps are 127185\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2372     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3917     |\n",
      "|    total_timesteps  | 127185   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 128      |\n",
      "|    n_updates        | 19296    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 0, 0, 3, 0, 3, 1, 3, 3, 2, 0, 2, 3, 1, 0, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was 1019. And steps were 20 and the episode is 2373 and the total_steps are 127205\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 3, 1, 1, 1, 1, 3, 0, 0, 1, 1, 2, 2, 2, 0, 2, 2, 3, 2, 3, 1, 2, 3, 2, 3, 0, 1, 1, 1, 2, 2, 3, 0, 0, 1, 2, 0, 1, 0, 3, 1, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 48 and the episode is 2374 and the total_steps are 127253\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 1, 2, 2, 0, 0, 2, 0, 2, 3, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 28 and the episode is 2375 and the total_steps are 127281\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 1, 3, 0, 0, 1, 1, 0, 1, 3, 3, 3, 1, 2, 1, 0, 0, 2, 2, 3, 3, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 2376 and the total_steps are 127309\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2376     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3922     |\n",
      "|    total_timesteps  | 127309   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.883    |\n",
      "|    n_updates        | 19327    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 2, 1, 1, 0, 0, 3, 3, 3, 3, 1, 1, 0, 1, 1, 1, 3, 1, 3, 0, 3, 3, 1, 0, 0, 0, 3, 0, 2, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 2, 2, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 48 and the episode is 2377 and the total_steps are 127357\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 3, 0, 1, 3, 0, 3, 0, 3, 2, 0, 1, 1, 2, 1, 3, 3, 3, 0, 0, 2, 1, 2, 2, 1, 3, 2, 2, 1, 0, 0, 2, 3, 1, 1, 1, 3, 0, 3, 3, 0, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 48 and the episode is 2378 and the total_steps are 127405\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 1, 0, 2, 1, 3, 2, 2, 0, 2, 1, 3, 0, 0, 3, 1, 0, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 24 and the episode is 2379 and the total_steps are 127429\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 2, 2, 3, 0, 2, 0, 0, 2, 3, 1, 2, 0, 1, 2, 0, 0, 1, 0, 2, 2, 3, 1, 1, 3, 3, 1, 3, 0, 2, 0, 1, 3, 1, 1, 1, 3, 0, 0, 1, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 1, 3, 3, 1, 1, 0, 0, 2, 2, 2, 2, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -944. And steps were 68 and the episode is 2380 and the total_steps are 127497\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2380     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3930     |\n",
      "|    total_timesteps  | 127497   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 19374    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 0, 0, 3, 3, 1, 1, 0, 3, 3, 1, 2, 3, 0, 0, 3, 1, 3, 2, 3, 1, 2, 3, 0, 2, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 32 and the episode is 2381 and the total_steps are 127529\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 3, 1, 1, 2, 2, 0, 1, 2, 1, 1, 0, 3, 2, 0, 3, 1, 1, 0, 2, 1, 1, 0, 0, 0, 1, 0, 3, 3, 2, 2, 2, 0, 0, 2, 3, 3, 3, 3, 0, 2, 2, 3, 1, 3, 3, 2, 3, 3, 0, 3, 3, 3, 0, 1, 2, 3, 3, 0, 0, 0, 3, 1, 0, 2, 0, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 73 and the episode is 2382 and the total_steps are 127602\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 3, 2, 3, 3, 3, 0, 2, 0, 2, 1, 2, 3, 3, 1, 2, 3, 2, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1022. And steps were 23 and the episode is 2383 and the total_steps are 127625\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 0, 3, 0, 1, 3, 3, 0, 2, 3, 3, 3, 2, 1, 2, 3, 0, 2, 2, 2, 3, 0, 1, 2, 1, 3, 3, 1, 2, 1, 0, 0, 2, 0, 1, 2, 3, 0, 2, 1, 0, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 2384 and the total_steps are 127673\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2384     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3937     |\n",
      "|    total_timesteps  | 127673   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 19418    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 1, 2, 3, 1, 0, 3, 2, 3, 2, 0, 3, 2, 3, 3, 0, 2, 1, 0, 0, 2, 3, 1, 0, 3, 2, 1, 2, 3, 0, 3, 3, 0, 0, 1, 0, 1, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 44 and the episode is 2385 and the total_steps are 127717\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 3, 0, 1, 3, 3, 0, 2, 1, 0, 1, 1, 0, 0, 2, 1, 2, 3, 2, 2, 1, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2386 and the total_steps are 127745\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 2, 3, 2, 1, 3, 3, 0, 1, 3, 0, 0, 0, 3, 0, 1, 1, 0, 0, 0, 0, 1, 3, 2, 1, 1, 3, 2, 0, 0, 0, 0, 3, 1, 1, 2, 0, 3, 0, 0, 0, 3, 3, 0, 1, 1, 1, 3, 1, 2, 1, 0, 3, 2, 0, 0, 3, 3, 3, 3, 2, 1, 1, 3, 0, 3, 3, 3, 2, 1, 3, 2, 0, 0, 1, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 88 and the episode is 2387 and the total_steps are 127833\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 1, 1, 0, 2, 1, 0, 1, 3, 2, 1, 1, 0, 3, 1, 3, 3, 3, 3, 1, 2, 0, 3, 1, 3, 2, 1, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 2388 and the total_steps are 127867\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2388     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3945     |\n",
      "|    total_timesteps  | 127867   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.852    |\n",
      "|    n_updates        | 19466    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 1, 3, 1, 2, 3, 3, 1, 1, 1, 0, 3, 2, 2, 2, 3, 0, 3, 3, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 2389 and the total_steps are 127893\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 0, 1, 1, 0, 1, 1, 0, 0, 3, 3, 0, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 3, 2, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 44 and the episode is 2390 and the total_steps are 127937\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 3, 0, 0, 1, 0, 1, 3, 3, 2, 2, 1, 0, 1, 1, 0, 0, 0, 2, 3, 0, 1, 0, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0, 3, 3, 3, 0, 1, 2, 2, 0, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 48 and the episode is 2391 and the total_steps are 127985\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 3, 0, 3, 3, 3, 1, 2, 0, 3, 0, 0, 1, 2, 0, 0, 0, 2, 2, 0, 2, 3, 0, 0, 3, 2, 0, 0, 2, 2, 0, 1, 0, 1, 3, 0, 2, 1, 0, 0, 2, 0, 3, 2, 0, 2, 1, 3, 1, 1, 1, 0, 3, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -942. And steps were 60 and the episode is 2392 and the total_steps are 128045\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2392     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3953     |\n",
      "|    total_timesteps  | 128045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.882    |\n",
      "|    n_updates        | 19511    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 3, 1, 1, 0, 2, 3, 2, 2, 0, 1, 2, 3, 2, 2, 3, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 31 and the episode is 2393 and the total_steps are 128076\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 3, 3, 3, 1, 1, 2, 2, 0, 2, 1, 0, 1, 3, 1, 2, 3, 0, 1, 0, 1, 0, 3, 1, 2, 1, 2, 3, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 35 and the episode is 2394 and the total_steps are 128111\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 3, 2, 0, 1, 0, 2, 3, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 2, 0, 2, 0, 1, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 31 and the episode is 2395 and the total_steps are 128142\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 1, 0, 0, 1, 2, 3, 1, 3, 0, 0, 2, 1, 3, 1, 0, 1, 1, 2, 1, 3, 0, 2, 2, 1, 3, 3, 3, 3, 2, 3, 0, 3, 3, 2, 3, 2, 1, 2, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was 991. And steps were 44 and the episode is 2396 and the total_steps are 128186\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2396     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3959     |\n",
      "|    total_timesteps  | 128186   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 93.6     |\n",
      "|    n_updates        | 19546    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 1, 3, 1, 2, 1, 1, 2, 3, 3, 2, 3, 2, 0, 1, 2, 2, 2, 1, 2, 1, 2, 3, 1, 2, 2, 1, 0, 3, 0, 2, 2, 2, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 40 and the episode is 2397 and the total_steps are 128226\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 0, 2, 3, 2, 1, 1, 1, 2, 2, 3, 0, 0, 0, 3, 2, 3, 1, 1, 0, 3, 1, 1, 3, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 31 and the episode is 2398 and the total_steps are 128257\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 1, 0, 3, 3, 3, 0, 2, 0, 2, 1, 0, 2, 1, 1, 3, 0, 2, 2, 1, 0, 0, 0, 2, 3, 3, 1, 3, 3, 0, 1, 0, 3, 3, 3, 0, 0, 1, 0, 3, 2, 2, 3, 1, 2, 0, 3, 1, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 55 and the episode is 2399 and the total_steps are 128312\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 1, 3, 3, 0, 2, 2, 0, 3, 0, 3, 0, 2, 3, 2, 0, 1, 0, 2, 3, 2, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 28 and the episode is 2400 and the total_steps are 128340\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2400     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3965     |\n",
      "|    total_timesteps  | 128340   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 19584    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 1, 2, 0, 2, 1, 2, 3, 2, 3, 3, 1, 3, 1, 3, 0, 2, 3, 2, 0, 3, 3, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 2401 and the total_steps are 128369\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 1, 0, 2, 3, 0, 3, 2, 1, 2, 3, 1, 0, 0, 1, 2, 1, 0, 3, 2, 3, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 2402 and the total_steps are 128397\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 1, 1, 3, 3, 0, 3, 3, 3, 0, 1, 3, 2, 3, 3, 3, 3, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 24 and the episode is 2403 and the total_steps are 128421\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 0, 1, 0, 2, 0, 3, 0, 3, 1, 0, 2, 0, 2, 1, 0, 0, 2, 2, 3, 3, 3, 1, 2, 3, 1, 2, 0, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 35 and the episode is 2404 and the total_steps are 128456\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2404     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3970     |\n",
      "|    total_timesteps  | 128456   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 19613    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 2, 1, 3, 3, 3, 3, 1, 3, 3, 2, 3, 2, 0, 1, 0, 0, 0, 1, 0, 3, 0, 3, 1, 0, 2, 0, 1, 3, 2, 1, 0, 3, 0, 2, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 42 and the episode is 2405 and the total_steps are 128498\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 2, 1, 1, 3, 2, 1, 2, 3, 2, 0, 2, 1, 0, 2, 2, 0, 1, 2, 2, 2, 3, 3, 1, 1, 0, 0, 0, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 35 and the episode is 2406 and the total_steps are 128533\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 1, 2, 0, 3, 0, 1, 0, 2, 2, 2, 2, 0, 0, 0, 3, 1, 2, 2, 2, 2, 2, 3, 0, 0, 0, 2, 1, 1, 3, 1, 1, 2, 0, 3, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 42 and the episode is 2407 and the total_steps are 128575\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 2, 3, 3, 2, 2, 3, 3, 2, 0, 3, 1, 3, 2, 3, 1, 3, 3, 1, 3, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 2408 and the total_steps are 128602\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2408     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3977     |\n",
      "|    total_timesteps  | 128602   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.25     |\n",
      "|    n_updates        | 19650    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 1, 2, 3, 2, 0, 3, 2, 2, 3, 2, 3, 1, 1, 3, 3, 2, 1, 0, 1, 2, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 28 and the episode is 2409 and the total_steps are 128630\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 0, 3, 1, 2, 3, 0, 0, 0, 0, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 2, 2, 3, 0, 0, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 2410 and the total_steps are 128665\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 0, 3, 2, 0, 2, 1, 3, 2, 2, 0, 1, 1, 1, 3, 3, 2, 2, 2, 1, 3, 3, 0, 0, 1, 3, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 2411 and the total_steps are 128698\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 3, 2, 2, 3, 2, 3, 3, 0, 2, 0, 2, 1, 0, 0, 1, 0, 2, 1, 2, 0, 2, 2, 3, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 31 and the episode is 2412 and the total_steps are 128729\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2412     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3982     |\n",
      "|    total_timesteps  | 128729   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.54     |\n",
      "|    n_updates        | 19682    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 3, 0, 3, 2, 1, 3, 1, 0, 1, 2, 3, 1, 2, 0, 0, 2, 0, 0, 0, 3, 0, 3, 1, 3, 1, 3, 0, 1, 0, 0, 2, 3, 0, 3, 0, 2, 0, 2, 2, 2, 2, 0, 3, 1, 2, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 53 and the episode is 2413 and the total_steps are 128782\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 2, 3, 1, 1, 0, 3, 0, 1, 0, 3, 1, 2, 0, 1, 3, 1, 3, 0, 1, 1, 2, 2, 1, 0, 0, 0, 0, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 35 and the episode is 2414 and the total_steps are 128817\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 2, 0, 2, 0, 1, 3, 2, 3, 3, 2, 1, 1, 3, 1, 0, 3, 1, 3, 1, 0, 2, 0, 0, 0, 3, 2, 1, 2, 2, 0, 0, 3, 0, 2, 3, 3, 0, 1, 2, 0, 1, 2, 1, 3, 3, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 53 and the episode is 2415 and the total_steps are 128870\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 3, 3, 1, 3, 2, 3, 0, 2, 0, 1, 0, 3, 1, 0, 1, 2, 3, 3, 2, 0, 3, 1, 0, 2, 1, 1, 3, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 35 and the episode is 2416 and the total_steps are 128905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2416     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3989     |\n",
      "|    total_timesteps  | 128905   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.958    |\n",
      "|    n_updates        | 19726    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 3, 1, 3, 2, 2, 1, 0, 0, 1, 1, 3, 3, 1, 0, 2, 1, 3, 2, 1, 3, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 2417 and the total_steps are 128931\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 1, 1, 3, 2, 1, 1, 0, 0, 1, 1, 3, 2, 1, 2, 3, 2, 2, 2, 2, 0, 1, 2, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 30 and the episode is 2418 and the total_steps are 128961\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 2, 1, 1, 3, 1, 0, 3, 1, 1, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 2, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 28 and the episode is 2419 and the total_steps are 128989\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 0, 3, 3, 1, 0, 3, 3, 3, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 3, 0, 0, 1, 0, 1, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 2420 and the total_steps are 129021\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2420     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 3994     |\n",
      "|    total_timesteps  | 129021   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 19755    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 0, 0, 0, 3, 1, 3, 3, 0, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 1, 3, 0, 0, 2, 1, 2, 1, 0, 3, 2, 2, 3, 2, 0, 3, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 43 and the episode is 2421 and the total_steps are 129064\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 1, 1, 3, 0, 0, 0, 3, 2, 0, 0, 3, 2, 1, 3, 1, 2, 0, 3, 2, 1, 3, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 29 and the episode is 2422 and the total_steps are 129093\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 0, 0, 1, 0, 1, 0, 3, 0, 2, 0, 1, 0, 0, 0, 0, 2, 2, 0, 3, 3, 0, 1, 2, 2, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 2423 and the total_steps are 129125\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 0, 0, 0, 1, 1, 1, 2, 2, 3, 1, 1, 1, 2, 0, 0, 1, 2, 2, 0, 0, 3, 0, 3, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2, 2, 1, 2, 3, 2, 1, 1, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 49 and the episode is 2424 and the total_steps are 129174\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2424     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4000     |\n",
      "|    total_timesteps  | 129174   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.9     |\n",
      "|    n_updates        | 19793    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 3, 3, 1, 3, 1, 3, 1, 0, 0, 3, 3, 1, 0, 0, 1, 0, 0, 1, 3, 2, 1, 3, 1, 1, 3, 3, 3, 2, 1, 0, 1, 2, 1, 0, 2, 3, 0, 3, 0, 1, 3, 2, 2, 1, 3, 1, 2, 2, 2, 3, 3, 2, 2, 3, 1, 2, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 64 and the episode is 2425 and the total_steps are 129238\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 0, 1, 0, 1, 3, 3, 3, 3, 1, 0, 3, 3, 1, 2, 0, 2, 1, 1, 1, 0, 1, 1, 1, 3, 1, 0, 1, 2, 2, 3, 2, 0, 2, 3, 2, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 43 and the episode is 2426 and the total_steps are 129281\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 2, 3, 2, 1, 0, 3, 3, 2, 0, 0, 1, 1, 3, 2, 3, 0, 3, 0, 3, 1, 1, 1, 2, 1, 3, 3, 2, 3, 2, 3, 3, 3, 0, 0, 2, 3, 2, 2, 2, 2, 1, 3, 0, 3, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 52 and the episode is 2427 and the total_steps are 129333\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 3, 3, 2, 3, 2, 0, 2, 3, 0, 3, 1, 2, 3, 2, 1, 0, 3, 3, 1, 2, 1, 0, 0, 0, 0, 3, 1, 1, 2, 2, 1, 1, 2, 3, 2, 2, 2, 2, 1, 0, 3, 3, 1, 0, 3, 0, 2, 1, 3, 2, 2, 1, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was 945. And steps were 58 and the episode is 2428 and the total_steps are 129391\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2428     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4009     |\n",
      "|    total_timesteps  | 129391   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 19847    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 0, 3, 2, 0, 2, 3, 1, 2, 1, 2, 3, 3, 1, 2, 0, 0, 3, 2, 2, 2, 2, 3, 0, 0, 0, 0, 2, 2, 3, 3, 0, 2, 2, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 42 and the episode is 2429 and the total_steps are 129433\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 2, 1, 3, 0, 1, 0, 3, 1, 2, 2, 3, 0, 3, 2, 1, 3, 0, 3, 2, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 2430 and the total_steps are 129461\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 2, 1, 2, 3, 3, 2, 0, 2, 0, 1, 3, 1, 1, 2, 0, 2, 3, 1, 3, 2, 2, 1, 0, 3, 3, 1, 1, 3, 2, 0, 1, 1, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 40 and the episode is 2431 and the total_steps are 129501\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 1, 1, 1, 0, 0, 1, 3, 3, 0, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 2432 and the total_steps are 129527\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2432     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4015     |\n",
      "|    total_timesteps  | 129527   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 19881    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 3, 0, 2, 0, 1, 2, 2, 2, 0, 3, 1, 0, 1, 2, 2, 2, 0, 3, 2, 1, 2, 3, 1, 3, 1, 0, 0, 1, 0, 2, 1, 1, 1, 0, 3, 0, 0, 2, 1, 0, 0, 3, 2, 3, 0, 2, 1, 1, 2, 0, 2, 2, 3, 0, 1, 3, 2, 2, 3, 2, 3, 1, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1068. And steps were 70 and the episode is 2433 and the total_steps are 129597\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 3, 0, 0, 3, 3, 0, 2, 0, 2, 2, 3, 1, 3, 3, 1, 2, 3, 3, 2, 1, 0, 3, 0, 0, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was 1009. And steps were 30 and the episode is 2434 and the total_steps are 129627\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 3, 3, 2, 0, 2, 1, 0, 1, 3, 0, 2, 3, 0, 1, 2, 3, 0, 1, 3, 1, 1, 1, 2, 0, 3, 2, 1, 3, 2, 3, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 38 and the episode is 2435 and the total_steps are 129665\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 2, 2, 3, 2, 2, 3, 3, 2, 0, 1, 0, 1, 1, 3, 1, 2, 0, 1, 1, 2, 1, 0, 2, 3, 1, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 33 and the episode is 2436 and the total_steps are 129698\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.4     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2436     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4021     |\n",
      "|    total_timesteps  | 129698   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 19924    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 0, 1, 2, 3, 3, 1, 0, 3, 3, 0, 2, 0, 1, 2, 2, 3, 1, 1, 3, 3, 3, 0, 3, 2, 2, 1, 0, 2, 2, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1035. And steps were 37 and the episode is 2437 and the total_steps are 129735\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 1, 2, 2, 2, 3, 3, 0, 2, 2, 2, 1, 0, 3, 2, 3, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 23 and the episode is 2438 and the total_steps are 129758\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 1, 1, 0, 1, 2, 3, 2, 3, 0, 2, 3, 2, 1, 0, 0, 1, 2, 1, 1, 1, 3, 2, 3, 1, 0, 1, 3, 0, 2, 2, 1, 0, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 40 and the episode is 2439 and the total_steps are 129798\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 0, 1, 2, 1, 2, 2, 0, 0, 0, 3, 2, 3, 3, 3, 3, 0, 0, 3, 1, 0, 3, 0, 3, 0, 1, 0, 2, 1, 2, 0, 3, 1, 2, 3, 2, 1, 2, 1, 3, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 47 and the episode is 2440 and the total_steps are 129845\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -856     |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2440     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4028     |\n",
      "|    total_timesteps  | 129845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 19961    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 0, 2, 3, 2, 1, 1, 1, 3, 1, 1, 0, 3, 3, 0, 2, 3, 0, 0, 2, 3, 2, 2, 1, 3, 3, 3, 0, 3, 0, 3, 2, 1, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 40 and the episode is 2441 and the total_steps are 129885\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 0, 1, 3, 1, 1, 2, 3, 0, 1, 0, 0, 3, 0, 0, 0, 0, 1, 1, 2, 0, 0, 3, 0, 0, 2, 0, 3, 1, 2, 1, 3, 1, 1, 2, 0, 3, 1, 2, 3, 3, 0, 0, 3, 0, 0, 3, 0, 2, 3, 2, 0, 1, 2, 0, 2, 2, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1062. And steps were 64 and the episode is 2442 and the total_steps are 129949\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 1, 3, 0, 2, 3, 3, 1, 0, 1, 1, 3, 1, 0, 3, 1, 0, 1, 3, 0, 0, 0, 0, 3, 2, 2, 3, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 2, 0, 1, 0, 0, 3, 0, 3, 1, 3, 2, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 56 and the episode is 2443 and the total_steps are 130005\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 3, 2, 2, 0, 2, 1, 0, 2, 2, 1, 3, 1, 2, 1, 3, 1, 1, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 25 and the episode is 2444 and the total_steps are 130030\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2444     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4035     |\n",
      "|    total_timesteps  | 130030   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.94     |\n",
      "|    n_updates        | 20007    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 3, 3, 2, 3, 3, 1, 0, 3, 3, 1, 3, 3, 3, 0, 1, 2, 0, 3, 0, 3, 3, 2, 2, 3, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 2445 and the total_steps are 130062\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 1, 1, 3, 3, 2, 3, 0, 3, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 2446 and the total_steps are 130078\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 1, 2, 1, 3, 0, 2, 1, 3, 0, 3, 1, 3, 2, 1, 2, 1, 0, 1, 1, 3, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 28 and the episode is 2447 and the total_steps are 130106\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 0, 1, 1, 0, 0, 1, 2, 2, 1, 0, 0, 3, 1, 0, 1, 2, 1, 2, 0, 1, 1, 3, 0, 2, 1, 3, 3, 2, 0, 0, 3, 0, 2, 3, 2, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 43 and the episode is 2448 and the total_steps are 130149\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2448     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4040     |\n",
      "|    total_timesteps  | 130149   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.1     |\n",
      "|    n_updates        | 20037    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 0, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 2449 and the total_steps are 130165\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 0, 2, 0, 0, 1, 0, 1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 0, 2, 1, 1, 3, 0, 0, 1, 3, 2, 3, 3, 2, 1, 1, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 39 and the episode is 2450 and the total_steps are 130204\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 3, 1, 1, 0, 1, 0, 0, 0, 2, 0, 3, 2, 1, 3, 1, 1, 3, 3, 1, 1, 1, 3, 0, 2, 3, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 33 and the episode is 2451 and the total_steps are 130237\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 3, 1, 1, 2, 0, 2, 0, 0, 0, 1, 1, 2, 3, 2, 2, 1, 0, 0, 1, 3, 0, 2, 2, 0, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 32 and the episode is 2452 and the total_steps are 130269\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -856     |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2452     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4045     |\n",
      "|    total_timesteps  | 130269   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57     |\n",
      "|    n_updates        | 20067    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 0, 2, 2, 2, 0, 1, 2, 0, 2, 3, 1, 3, 1, 3, 3, 2, 0, 3, 1, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1008. And steps were 25 and the episode is 2453 and the total_steps are 130294\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 0, 0, 3, 1, 2, 0, 3, 2, 0, 1, 3, 0, 3, 0, 2, 2, 0, 2, 3, 1, 0, 0, 3, 1, 1, 0, 2, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 35 and the episode is 2454 and the total_steps are 130329\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 1, 0, 3, 0, 2, 2, 2, 3, 3, 1, 2, 0, 1, 2, 0, 1, 2, 3, 3, 3, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 28 and the episode is 2455 and the total_steps are 130357\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 1, 0, 3, 3, 0, 3, 1, 3, 1, 2, 1, 0, 2, 2, 2, 0, 2, 2, 3, 1, 2, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 29 and the episode is 2456 and the total_steps are 130386\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -836     |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2456     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4050     |\n",
      "|    total_timesteps  | 130386   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.8     |\n",
      "|    n_updates        | 20096    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 1, 0, 0, 2, 2, 1, 1, 3, 3, 2, 2, 1, 2, 1, 1, 1, 2, 3, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 2457 and the total_steps are 130412\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 1, 2, 3, 0, 1, 0, 1, 3, 0, 2, 0, 2, 2, 3, 0, 3, 2, 1, 1, 3, 0, 0, 3, 1, 3, 0, 0, 2, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 36 and the episode is 2458 and the total_steps are 130448\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 3, 1, 2, 2, 2, 3, 0, 0, 0, 2, 3, 3, 3, 0, 1, 3, 3, 3, 2, 1, 3, 3, 1, 3, 1, 3, 3, 2, 1, 0, 3, 1, 0, 1, 3, 3, 3, 1, 1, 3, 3, 3, 1, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1049. And steps were 51 and the episode is 2459 and the total_steps are 130499\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 1, 3, 2, 1, 1, 1, 1, 0, 3, 0, 1, 1, 2, 1, 3, 1, 3, 3, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 26 and the episode is 2460 and the total_steps are 130525\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.2     |\n",
      "|    ep_rew_mean      | -838     |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2460     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4056     |\n",
      "|    total_timesteps  | 130525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 20131    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 3, 0, 1, 1, 0, 3, 0, 2, 3, 1, 0, 0, 2, 3, 1, 3, 0, 2, 2, 2, 1, 0, 3, 0, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 0, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 44 and the episode is 2461 and the total_steps are 130569\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 1, 1, 1, 1, 3, 2, 0, 2, 2, 3, 3, 2, 3, 2, 1, 3, 0, 3, 2, 1, 0, 2, 3, 2, 0, 3, 2, 2, 0, 0, 0, 0, 2, 3, 2, 0, 3, 2, 2, 0, 2, 3, 0, 2, 3, 3, 3, 1, 0, 2, 2, 0, 2, 3, 0, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -953. And steps were 63 and the episode is 2462 and the total_steps are 130632\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 1, 1, 1, 3, 3, 1, 0, 1, 1, 2, 2, 0, 0, 2, 0, 2, 1, 3, 3, 1, 2, 2, 0, 2, 3, 1, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 34 and the episode is 2463 and the total_steps are 130666\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 0, 0, 1, 2, 3, 3, 2, 3, 0, 2, 3, 2, 1, 1, 0, 0, 0, 3, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 25 and the episode is 2464 and the total_steps are 130691\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -838     |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2464     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4063     |\n",
      "|    total_timesteps  | 130691   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 20172    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 2, 2, 1, 2, 0, 1, 0, 3, 1, 0, 2, 0, 0, 0, 0, 1, 2, 3, 0, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 27 and the episode is 2465 and the total_steps are 130718\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 3, 1, 2, 2, 2, 0, 3, 0, 0, 2, 2, 3, 1, 0, 1, 0, 0, 1, 1, 2, 3, 2, 3, 3, 2, 3, 2, 1, 0, 3, 1, 0, 3, 2, 0, 1, 1, 0, 2, 3, 0, 1, 0, 1, 0, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 53 and the episode is 2466 and the total_steps are 130771\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 0, 2, 0, 3, 0, 2, 2, 1, 2, 2, 2, 1, 3, 0, 0, 2, 2, 3, 2, 1, 1, 1, 1, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 31 and the episode is 2467 and the total_steps are 130802\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 0, 3, 1, 0, 3, 3, 1, 1, 2, 2, 1, 0, 3, 2, 3, 2, 2, 1, 3, 1, 1, 1, 0, 0, 0, 3, 2, 2, 3, 2, 1, 3, 2, 0, 3, 2, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 44 and the episode is 2468 and the total_steps are 130846\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2468     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4069     |\n",
      "|    total_timesteps  | 130846   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.6     |\n",
      "|    n_updates        | 20211    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 3, 3, 3, 3, 2, 0, 0, 1, 0, 2, 3, 3, 1, 3, 3, 0, 2, 0, 0, 3, 3, 2, 1, 0, 0, 1, 3, 0, 3, 3, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 38 and the episode is 2469 and the total_steps are 130884\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 3, 1, 1, 0, 3, 1, 2, 1, 2, 0, 1, 2, 2, 1, 0, 0, 0, 0, 2, 0, 1, 1, 2, 2, 0, 1, 0, 2, 1, 2, 0, 1, 1, 0, 2, 3, 1, 3, 3, 2, 2, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 49 and the episode is 2470 and the total_steps are 130933\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 0, 3, 1, 3, 3, 1, 1, 1, 2, 3, 3, 3, 1, 3, 0, 2, 3, 2, 1, 0, 0, 2, 1, 1, 2, 0, 3, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 35 and the episode is 2471 and the total_steps are 130968\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 0, 1, 0, 1, 0, 2, 0, 0, 0, 1, 1, 1, 3, 0, 1, 1, 1, 0, 1, 2, 3, 2, 1, 0, 3, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 33 and the episode is 2472 and the total_steps are 131001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2472     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4076     |\n",
      "|    total_timesteps  | 131001   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.3     |\n",
      "|    n_updates        | 20250    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 0, 0, 0, 3, 2, 3, 0, 3, 0, 0, 0, 2, 0, 3, 0, 0, 1, 1, 2, 2, 1, 2, 3, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2473 and the total_steps are 131032\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 3, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 0, 1, 3, 3, 0, 0, 0, 2, 2, 3, 0, 0, 1, 1, 1, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 37 and the episode is 2474 and the total_steps are 131069\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 3, 0, 3, 2, 2, 2, 1, 1, 0, 2, 1, 0, 2, 0, 1, 1, 0, 0, 0, 2, 1, 3, 3, 1, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2475 and the total_steps are 131101\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 3, 1, 2, 1, 1, 3, 1, 0, 1, 0, 2, 1, 0, 0, 3, 3, 1, 1, 2, 3, 3, 3, 3, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 30 and the episode is 2476 and the total_steps are 131131\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2476     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4081     |\n",
      "|    total_timesteps  | 131131   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 20282    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 3, 3, 2, 3, 0, 3, 2, 2, 3, 3, 1, 2, 2, 2, 0, 1, 2, 3, 3, 2, 0, 2, 2, 3, 3, 1, 0, 0, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 36 and the episode is 2477 and the total_steps are 131167\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 0, 2, 2, 2, 0, 3, 2, 2, 2, 3, 3, 3, 3, 0, 3, 3, 2, 0, 2, 3, 3, 3, 1, 2, 3, 3, 3, 0, 2, 2, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 2478 and the total_steps are 131205\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 3, 3, 0, 2, 1, 1, 2, 1, 2, 3, 2, 3, 2, 0, 2, 1, 3, 3, 3, 2, 3, 3, 2, 1, 1, 0, 0, 1, 3, 2, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 2479 and the total_steps are 131243\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 2, 0, 0, 2, 3, 2, 2, 3, 0, 3, 0, 3, 2, 0, 2, 1, 3, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 34 and the episode is 2480 and the total_steps are 131277\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2480     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4087     |\n",
      "|    total_timesteps  | 131277   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.641    |\n",
      "|    n_updates        | 20319    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 2, 0, 3, 1, 0, 3, 2, 0, 0, 2, 0, 0, 2, 1, 0, 2, 0, 0, 3, 0, 3, 1, 2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 3, 1, 3, 1, 1, 1, 2, 3, 0, 3, 1, 3, 1, 3, 2, 1, 2, 1, 1, 0, 2, 2, 3, 1, 0, 2, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 66 and the episode is 2481 and the total_steps are 131343\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 3, 3, 1, 1, 0, 0, 1, 2, 3, 1, 1, 1, 0, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 3, 2, 3, 0, 1, 2, 3, 0, 3, 1, 2, 0, 0, 0, 1, 3, 2, 2, 0, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 50 and the episode is 2482 and the total_steps are 131393\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 3, 0, 0, 2, 2, 3, 2, 0, 3, 3, 3, 1, 3, 2, 1, 0, 3, 0, 0, 0, 1, 2, 2, 1, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2483 and the total_steps are 131425\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 2, 2, 1, 3, 0, 1, 2, 3, 3, 3, 1, 1, 3, 3, 2, 0, 2, 1, 3, 2, 0, 3, 3, 3, 2, 2, 2, 0, 3, 2, 3, 2, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 40 and the episode is 2484 and the total_steps are 131465\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2484     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4096     |\n",
      "|    total_timesteps  | 131465   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.5     |\n",
      "|    n_updates        | 20366    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 0, 1, 1, 3, 0, 1, 2, 1, 3, 2, 0, 3, 2, 3, 0, 0, 3, 1, 3, 2, 0, 2, 2, 2, 0, 0, 3, 3, 3, 1, 0, 3, 3, 3, 3, 1, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 52 and the episode is 2485 and the total_steps are 131517\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 1, 1, 2, 0, 0, 0, 3, 3, 1, 0, 2, 1, 1, 0, 1, 3, 1, 3, 1, 3, 0, 1, 0, 3, 0, 0, 2, 3, 1, 1, 0, 2, 3, 0, 0, 0, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 2486 and the total_steps are 131561\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 3, 3, 1, 3, 0, 1, 0, 0, 3, 1, 3, 1, 2, 2, 3, 1, 2, 3, 0, 3, 0, 1, 0, 2, 2, 2, 2, 2, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 36 and the episode is 2487 and the total_steps are 131597\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 3, 3, 3, 3, 0, 2, 0, 0, 3, 1, 0, 0, 2, 2, 0, 2, 3, 1, 3, 0, 0, 1, 3, 0, 1, 2, 0, 3, 2, 0, 1, 0, 1, 1, 0, 2, 2, 2, 3, 2, 0, 0, 3, 3, 0, 0, 1, 1, 3, 1, 0, 3, 0, 3, 2, 3, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 64 and the episode is 2488 and the total_steps are 131661\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2488     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4103     |\n",
      "|    total_timesteps  | 131661   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.02     |\n",
      "|    n_updates        | 20415    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 1, 0, 3, 3, 1, 0, 1, 2, 2, 3, 2, 1, 3, 3, 2, 2, 1, 1, 1, 2, 3, 1, 0, 3, 0, 0, 1, 1, 0, 3, 2, 0, 1, 0, 1, 2, 3, 2, 0, 0, 2, 1, 1, 3, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 52 and the episode is 2489 and the total_steps are 131713\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 1, 3, 0, 3, 2, 1, 2, 2, 0, 0, 2, 2, 2, 1, 1, 3, 0, 0, 3, 0, 3, 0, 0, 3, 1, 0, 3, 2, 0, 3, 1, 3, 0, 0, 1, 1, 1, 2, 0, 2, 3, 3, 3, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 51 and the episode is 2490 and the total_steps are 131764\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 0, 3, 0, 2, 3, 0, 0, 1, 3, 1, 0, 2, 3, 3, 0, 2, 1, 1, 2, 3, 2, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 2491 and the total_steps are 131793\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 3, 0, 1, 1, 0, 2, 3, 1, 0, 3, 1, 3, 0, 3, 2, 1, 1, 0, 1, 2, 3, 1, 0, 0, 3, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 2492 and the total_steps are 131827\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2492     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4110     |\n",
      "|    total_timesteps  | 131827   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.1     |\n",
      "|    n_updates        | 20456    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 3, 2, 3, 2, 3, 3, 3, 3, 2, 3, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 0, 2, 0, 2, 3, 3, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 43 and the episode is 2493 and the total_steps are 131870\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 0, 3, 3, 3, 2, 3, 3, 2, 2, 2, 3, 1, 2, 0, 1, 1, 3, 1, 3, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 27 and the episode is 2494 and the total_steps are 131897\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 2, 2, 1, 3, 0, 0, 0, 1, 2, 0, 1, 2, 3, 0, 2, 3, 2, 1, 0, 0, 0, 1, 1, 0, 3, 3, 0, 2, 0, 3, 1, 0, 1, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 2495 and the total_steps are 131938\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 0, 3, 3, 1, 3, 0, 1, 0, 0, 2, 2, 1, 3, 2, 2, 3, 3, 2, 3, 2, 3, 3, 0, 0, 0, 2, 0, 3, 3, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 37 and the episode is 2496 and the total_steps are 131975\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2496     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4116     |\n",
      "|    total_timesteps  | 131975   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 20493    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 3, 3, 3, 2, 3, 3, 1, 2, 3, 1, 1, 3, 1, 3, 1, 1, 2, 3, 3, 2, 2, 2, 2, 3, 1, 0, 1, 0, 1, 1, 3, 1, 2, 0, 0, 3, 0, 3, 1, 3, 3, 2, 3, 0, 0, 3, 3, 3, 2, 3, 2, 0, 3, 2, 0, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 63 and the episode is 2497 and the total_steps are 132038\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 3, 3, 3, 2, 3, 0, 0, 2, 0, 3, 2, 2, 2, 1, 2, 2, 0, 2, 0, 0, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 2498 and the total_steps are 132066\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 3, 3, 0, 1, 1, 0, 1, 2, 2, 2, 2, 1, 0, 3, 2, 1, 3, 3, 3, 0, 2, 2, 1, 1, 0, 3, 2, 0, 3, 0, 2, 0, 0, 1, 3, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 43 and the episode is 2499 and the total_steps are 132109\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 0, 2, 0, 3, 0, 1, 2, 3, 3, 0, 2, 0, 0, 3, 0, 2, 0, 0, 3, 2, 0, 2, 3, 0, 0, 0, 1, 1, 2, 3, 0, 1, 2, 3, 0, 3, 0, 3, 0, 0, 2, 0, 0, 3, 1, 1, 2, 0, 1, 0, 3, 0, 0, 3, 3, 0, 2, 1, 0, 3, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 68 and the episode is 2500 and the total_steps are 132177\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.4     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2500     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4125     |\n",
      "|    total_timesteps  | 132177   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.5     |\n",
      "|    n_updates        | 20544    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 3, 0, 0, 3, 2, 3, 3, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 3, 3, 3, 3, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 29 and the episode is 2501 and the total_steps are 132206\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 0, 3, 0, 1, 0, 0, 1, 3, 3, 2, 3, 0, 2, 0, 3, 0, 0, 1, 0, 1, 1, 2, 2, 2, 1, 1, 2, 3, 0, 1, 0, 1, 1, 3, 0, 3, 1, 2, 1, 1, 2, 2, 3, 3, 0, 3, 0, 0, 0, 0, 3, 0, 1, 2, 2, 2, 1, 3, 3, 3, 1, 3, 3, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 70 and the episode is 2502 and the total_steps are 132276\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 2, 2, 2, 3, 1, 2, 3, 2, 0, 3, 2, 1, 0, 0, 3, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 23 and the episode is 2503 and the total_steps are 132299\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 1, 2, 0, 3, 3, 0, 1, 0, 3, 2, 3, 0, 1, 3, 2, 2, 1, 3, 2, 0, 3, 0, 0, 2, 3, 0, 3, 1, 1, 1, 3, 2, 2, 2, 3, 3, 0, 0, 3, 0, 2, 3, 1, 0, 2, 3, 0, 0, 2, 3, 3, 1, 3, 1, 1, 0, 0, 2, 0, 2, 1, 3, 2, 0, 3, 0, 0, 3, 3, 0, 2, 3, 3, 0, 3, 1, 2, 0, 0, 2, 3, 1, 0, 3, 2, 2, 1, 0, 0, 2, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -942. And steps were 98 and the episode is 2504 and the total_steps are 132397\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2504     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4134     |\n",
      "|    total_timesteps  | 132397   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.2     |\n",
      "|    n_updates        | 20599    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 1, 2, 2, 1, 0, 1, 2, 2, 3, 3, 3, 3, 0, 3, 2, 1, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 24 and the episode is 2505 and the total_steps are 132421\n",
      "Done condition: collision\n",
      "[3, 1, 3, 1, 0, 0, 2, 2, 1, 1, 2, 2, 1, 3, 3, 3, 1, 2, 2, 2, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 24 and the episode is 2506 and the total_steps are 132445\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 1, 0, 0, 1, 0, 3, 0, 0, 1, 0, 3, 1, 0, 3, 0, 2, 1, 0, 2, 1, 1, 0, 3, 3, 3, 1, 2, 2, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 2507 and the total_steps are 132481\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 0, 0, 3, 0, 0, 0, 2, 2, 3, 1, 3, 1, 2, 2, 3, 2, 0, 2, 0, 1, 1, 0, 0, 2, 3, 1, 1, 3, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 1, 0, 3, 1, 0, 2, 2, 2, 3, 1, 1, 0, 0, 2, 3, 2, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 63 and the episode is 2508 and the total_steps are 132544\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2508     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4140     |\n",
      "|    total_timesteps  | 132544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.61     |\n",
      "|    n_updates        | 20635    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 2, 0, 2, 3, 1, 0, 2, 1, 0, 3, 0, 3, 0, 0, 2, 0, 3, 3, 3, 2, 1, 1, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 30 and the episode is 2509 and the total_steps are 132574\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 2, 1, 0, 2, 0, 0, 3, 2, 3, 3, 3, 3, 1, 3, 1, 3, 3, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 25 and the episode is 2510 and the total_steps are 132599\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 1, 1, 0, 3, 3, 1, 1, 2, 0, 3, 3, 3, 0, 1, 0, 1, 0, 0, 3, 3, 3, 0, 1, 1, 1, 0, 2, 2, 0, 3, 0, 2, 1, 1, 2, 1, 3, 2, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 46 and the episode is 2511 and the total_steps are 132645\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 1, 3, 0, 1, 1, 3, 0, 2, 0, 3, 0, 0, 3, 1, 1, 0, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 24 and the episode is 2512 and the total_steps are 132669\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2512     |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4145     |\n",
      "|    total_timesteps  | 132669   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 20667    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 1, 3, 1, 1, 1, 2, 2, 2, 1, 2, 0, 3, 0, 0, 2, 3, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 22 and the episode is 2513 and the total_steps are 132691\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 3, 2, 3, 2, 0, 2, 0, 0, 0, 2, 1, 3, 2, 0, 3, 3, 3, 0, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 2514 and the total_steps are 132717\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 3, 0, 2, 0, 2, 0, 0, 1, 3, 2, 2, 2, 1, 1, 3, 3, 1, 0, 1, 3, 0, 2, 1, 1, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 32 and the episode is 2515 and the total_steps are 132749\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 1, 3, 2, 1, 2, 1, 0, 0, 1, 0, 2, 3, 3, 2, 0, 2, 0, 0, 3, 3, 2, 1, 2, 1, 1, 0, 3, 3, 0, 3, 0, 0, 2, 2, 1, 2, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 44 and the episode is 2516 and the total_steps are 132793\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2516     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4151     |\n",
      "|    total_timesteps  | 132793   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 20698    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 3, 2, 1, 2, 1, 0, 0, 1, 3, 0, 0, 3, 2, 1, 2, 3, 2, 0, 1, 1, 2, 0, 2, 1, 1, 3, 2, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 2, 3, 1, 0, 0, 2, 0, 3, 3, 3, 0, 0, 3, 3, 2, 1, 3, 2, 2, 1, 3, 1, 0, 2, 3, 0, 1, 2, 0, 3, 0, 2, 1, 3, 2, 3, 2, 2, 3, 2, 1, 1, 1, 0, 3, 1, 1, 0, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 96 and the episode is 2517 and the total_steps are 132889\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 2, 1, 0, 1, 0, 3, 1, 2, 2, 3, 3, 1, 1, 2, 1, 3, 2, 3, 1, 2, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 2518 and the total_steps are 132917\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 0, 0, 2, 1, 3, 0, 0, 0, 3, 1, 2, 3, 2, 2, 2, 2, 1, 2, 0, 3, 0, 1, 0, 3, 3, 3, 0, 3, 3, 2, 0, 0, 2, 0, 0, 1, 2, 1, 1, 3, 1, 0, 0, 2, 1, 1, 3, 3, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 56 and the episode is 2519 and the total_steps are 132973\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 0, 1, 3, 0, 1, 2, 0, 1, 2, 2, 3, 0, 2, 2, 0, 3, 0, 0, 2, 3, 1, 1, 2, 3, 1, 2, 2, 0, 2, 0, 1, 2, 3, 0, 0, 1, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 44 and the episode is 2520 and the total_steps are 133017\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2520     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4160     |\n",
      "|    total_timesteps  | 133017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.864    |\n",
      "|    n_updates        | 20754    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 2, 3, 1, 3, 2, 2, 2, 2, 2, 3, 0, 1, 2, 2, 0, 2, 3, 0, 2, 3, 2, 1, 0, 1, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2521 and the total_steps are 133049\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 2, 1, 2, 1, 3, 3, 0, 3, 2, 3, 0, 0, 1, 3, 3, 2, 3, 0, 0, 2, 3, 0, 0, 3, 0, 3, 0, 2, 1, 0, 2, 3, 0, 0, 3, 2, 2, 1, 2, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 47 and the episode is 2522 and the total_steps are 133096\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 3, 3, 0, 3, 0, 1, 3, 3, 2, 3, 0, 0, 1, 3, 0, 1, 1, 0, 2, 0, 0, 3, 2, 1, 3, 2, 2, 2, 2, 3, 1, 0, 3, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 2523 and the total_steps are 133137\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 1, 1, 3, 0, 2, 3, 0, 2, 0, 3, 0, 2, 1, 1, 0, 1, 1, 2, 0, 0, 1, 2, 2, 3, 3, 2, 1, 0, 2, 2, 0, 1, 0, 3, 2, 1, 3, 2, 1, 0, 2, 2, 1, 0, 0, 2, 0, 0, 1, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 57 and the episode is 2524 and the total_steps are 133194\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2524     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4167     |\n",
      "|    total_timesteps  | 133194   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.14     |\n",
      "|    n_updates        | 20798    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 1, 1, 1, 0, 3, 2, 0, 1, 2, 1, 1, 2, 1, 0, 3, 2, 2, 1, 2, 1, 1, 3, 1, 1, 3, 1, 1, 2, 0, 2, 2, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 39 and the episode is 2525 and the total_steps are 133233\n",
      "Done condition: collision\n",
      "[0, 0, 1, 2, 2, 2, 2, 3, 2, 0, 1, 1, 0, 3, 1, 3, 0, 3, 0, 3, 2, 3, 0, 2, 3, 2, 3, 3, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 32 and the episode is 2526 and the total_steps are 133265\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 0, 2, 1, 1, 1, 0, 1, 3, 1, 2, 1, 1, 1, 0, 2, 2, 0, 3, 2, 1, 3, 2, 3, 1, 0, 0, 2, 0, 1, 0, 2, 3, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 2527 and the total_steps are 133305\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 3, 2, 0, 2, 2, 2, 3, 2, 1, 2, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2528 and the total_steps are 133333\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2528     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4172     |\n",
      "|    total_timesteps  | 133333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 20833    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 3, 1, 2, 1, 0, 1, 3, 0, 3, 3, 3, 0, 0, 1, 0, 1, 0, 2, 0, 1, 2, 1, 0, 1, 3, 2, 0, 3, 0, 1, 1, 1, 0, 3, 3, 2, 3, 3, 1, 1, 3, 0, 2, 2, 3, 3, 1, 1, 2, 2, 0, 3, 1, 1, 3, 3, 2, 3, 2, 0, 2, 3, 1, 1, 2, 2, 1, 3, 2, 2, 1, 0, 1, 3, 3, 3, 3, 3, 3, 0, 2, 2, 3, 0, 2, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1055. And steps were 93 and the episode is 2529 and the total_steps are 133426\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 1, 0, 3, 1, 2, 1, 1, 3, 1, 2, 2, 3, 3, 3, 2, 0, 3, 0, 2, 0, 1, 0, 3, 2, 0, 2, 0, 0, 1, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 37 and the episode is 2530 and the total_steps are 133463\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 3, 0, 3, 3, 3, 3, 0, 0, 0, 2, 3, 0, 0, 1, 1, 1, 1, 2, 1, 2, 3, 2, 0, 2, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 32 and the episode is 2531 and the total_steps are 133495\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 2, 0, 1, 0, 0, 3, 1, 1, 2, 1, 1, 3, 3, 2, 3, 2, 0, 1, 2, 3, 2, 0, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 2532 and the total_steps are 133525\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -944     |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2532     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4180     |\n",
      "|    total_timesteps  | 133525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63       |\n",
      "|    n_updates        | 20881    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 0, 0, 1, 2, 0, 2, 1, 0, 2, 1, 1, 0, 0, 2, 0, 3, 0, 0, 0, 0, 3, 3, 0, 3, 1, 1, 2, 0, 0, 1, 0, 3, 2, 3, 2, 3, 2, 0, 2, 2, 3, 1, 0, 0, 0, 1, 0, 1, 3, 2, 3, 0, 2, 1, 0, 0, 2, 2, 3, 0, 2, 0, 3, 3, 0, 1, 1, 0, 2, 1, 3, 2, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 80 and the episode is 2533 and the total_steps are 133605\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 3, 3, 0, 1, 3, 0, 1, 3, 0, 3, 1, 1, 3, 2, 2, 1, 1, 3, 0, 0, 2, 2, 2, 0, 0, 1, 2, 2, 0, 2, 3, 0, 1, 0, 1, 3, 2, 0, 1, 1, 2, 2, 1, 3, 0, 0, 1, 2, 3, 2, 2, 1, 3, 1, 2, 0, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 3, 2, 3, 0, 3, 2, 1, 1, 0, 3, 3, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -951. And steps were 99 and the episode is 2534 and the total_steps are 133704\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 1, 2, 1, 1, 2, 1, 3, 2, 1, 2, 3, 3, 0, 0, 3, 1, 3, 1, 2, 2, 0, 3, 3, 0, 1, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 33 and the episode is 2535 and the total_steps are 133737\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 2, 2, 0, 2, 0, 2, 3, 3, 3, 0, 0, 0, 2, 2, 1, 3, 0, 1, 1, 0, 3, 2, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 2536 and the total_steps are 133767\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -963     |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2536     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4190     |\n",
      "|    total_timesteps  | 133767   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 20941    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 1, 3, 1, 2, 2, 2, 2, 0, 0, 0, 1, 3, 3, 0, 3, 1, 3, 2, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 26 and the episode is 2537 and the total_steps are 133793\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 1, 1, 3, 0, 2, 2, 3, 2, 2, 1, 3, 3, 1, 3, 0, 3, 2, 3, 2, 0, 2, 1, 2, 3, 0, 3, 1, 1, 2, 3, 0, 0, 2, 1, 2, 2, 0, 0, 3, 3, 2, 1, 3, 0, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 52 and the episode is 2538 and the total_steps are 133845\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 1, 0, 0, 0, 0, 3, 3, 3, 0, 0, 3, 0, 3, 2, 0, 3, 1, 3, 0, 2, 1, 3, 1, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 2539 and the total_steps are 133877\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 1, 3, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 2, 1, 1, 0, 2, 3, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2540 and the total_steps are 133905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -964     |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2540     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4195     |\n",
      "|    total_timesteps  | 133905   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 92.1     |\n",
      "|    n_updates        | 20976    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 1, 1, 1, 2, 1, 2, 3, 3, 2, 1, 3, 3, 0, 3, 0, 1, 0, 3, 1, 3, 1, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 2541 and the total_steps are 133934\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 0, 3, 1, 3, 2, 3, 1, 2, 3, 0, 2, 1, 3, 2, 1, 0, 3, 0, 0, 1, 3, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was 976. And steps were 27 and the episode is 2542 and the total_steps are 133961\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 0, 0, 0, 3, 3, 0, 0, 0, 2, 1, 3, 2, 2, 1, 2, 3, 2, 2, 3, 1, 0, 3, 3, 0, 2, 1, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 34 and the episode is 2543 and the total_steps are 133995\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 2, 0, 3, 2, 1, 3, 1, 0, 3, 2, 0, 3, 3, 0, 0, 2, 0, 1, 1, 2, 3, 2, 0, 0, 1, 2, 3, 1, 1, 0, 3, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 39 and the episode is 2544 and the total_steps are 134034\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2544     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4201     |\n",
      "|    total_timesteps  | 134034   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.8     |\n",
      "|    n_updates        | 21008    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 3, 3, 1, 2, 0, 2, 1, 1, 2, 3, 1, 2, 0, 1, 0, 0, 0, 1, 3, 2, 1, 1, 2, 1, 0, 1, 1, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 2545 and the total_steps are 134069\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 2, 1, 3, 2, 1, 2, 1, 0, 0, 2, 0, 0, 3, 2, 1, 0, 0, 0, 0, 2, 0, 2, 2, 0, 1, 0, 1, 1, 1, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 37 and the episode is 2546 and the total_steps are 134106\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 2, 2, 3, 2, 1, 3, 1, 3, 1, 1, 2, 0, 2, 2, 1, 0, 0, 0, 1, 0, 0, 3, 2, 3, 1, 3, 0, 0, 0, 3, 2, 2, 3, 3, 0, 0, 1, 3, 3, 3, 3, 0, 1, 3, 0, 0, 2, 2, 3, 3, 1, 1, 3, 0, 3, 0, 1, 0, 2, 2, 2, 1, 1, 0, 2, 0, 1, 2, 3, 1, 0, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 79 and the episode is 2547 and the total_steps are 134185\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 3, 1, 1, 3, 3, 1, 2, 2, 3, 2, 3, 1, 1, 2, 2, 1, 0, 0, 0, 1, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2548 and the total_steps are 134213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -944     |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2548     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4208     |\n",
      "|    total_timesteps  | 134213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 21053    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 1, 3, 2, 3, 3, 1, 1, 3, 3, 3, 0, 3, 3, 2, 2, 1, 3, 3, 1, 2, 3, 3, 1, 2, 1, 0, 3, 0, 0, 1, 1, 2, 0, 2, 1, 2, 3, 0, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 0, 0, 1, 1, 0, 0, 1, 2, 2, 1, 0, 2, 1, 1, 3, 3, 3, 2, 1, 0, 3, 0, 3, 0, 0, 3, 1, 3, 3, 0, 3, 1, 0, 3, 0, 0, 1, 3, 1, 0, 0, 1, 1, 0, 1, 2, 3, 0, 1, 1, 3, 0, 3, 2, 3, 3, 0, 3, 0, 1, 0, 1, 1, 2, 3, 0, 0, 3, 1, 3, 2, 2, 3, 3, 1, 0, 3, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 2, 2, 0, 0, 3, 1, 0, 2, 0, 3, 1, 0, 0, 0, 1, 0, 1, 3, 2, 0, 1, 3, 0, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1164. And steps were 166 and the episode is 2549 and the total_steps are 134379\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 1, 2, 2, 0, 3, 3, 0, 0, 1, 1, 1, 0, 3, 3, 1, 2, 3, 0, 0, 0, 3, 2, 0, 2, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 2550 and the total_steps are 134411\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 1, 3, 1, 2, 0, 1, 1, 0, 0, 3, 3, 0, 2, 2, 1, 2, 3, 2, 3, 1, 3, 1, 0, 1, 0, 1, 3, 1, 2, 1, 2, 0, 2, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 3, 1, 3, 2, 1, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1053. And steps were 73 and the episode is 2551 and the total_steps are 134484\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 3, 1, 2, 0, 2, 1, 3, 0, 2, 3, 1, 2, 3, 2, 2, 2, 0, 3, 1, 1, 3, 3, 0, 1, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 32 and the episode is 2552 and the total_steps are 134516\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | -946     |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2552     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4220     |\n",
      "|    total_timesteps  | 134516   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.687    |\n",
      "|    n_updates        | 21128    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 2, 3, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 2, 1, 1, 2, 0, 0, 2, 3, 1, 2, 0, 0, 0, 2, 0, 0, 1, 3, 2, 0, 0, 0, 1, 0, 0, 2, 2, 1, 2, 0, 0, 1, 3, 1, 2, 1, 1, 3, 3, 1, 1, 1, 3, 2, 2, 0, 0, 2, 2, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1047. And steps were 81 and the episode is 2553 and the total_steps are 134597\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 2, 2, 0, 0, 1, 1, 0, 3, 0, 3, 2, 0, 2, 1, 3, 2, 0, 3, 1, 1, 0, 3, 1, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 31 and the episode is 2554 and the total_steps are 134628\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 0, 2, 2, 0, 2, 3, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 1, 0, 3, 3, 2, 1, 3, 1, 0, 1, 1, 2, 0, 2, 0, 3, 0, 3, 2, 3, 0, 3, 1, 1, 3, 1, 2, 3, 2, 0, 2, 0, 1, 2, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 58 and the episode is 2555 and the total_steps are 134686\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 0, 2, 1, 1, 2, 3, 0, 3, 3, 0, 3, 2, 2, 1, 2, 3, 2, 0, 3, 3, 0, 1, 3, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2556 and the total_steps are 134717\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.3     |\n",
      "|    ep_rew_mean      | -967     |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2556     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4228     |\n",
      "|    total_timesteps  | 134717   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 21179    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 1, 1, 3, 1, 2, 0, 0, 0, 3, 3, 2, 0, 2, 0, 3, 0, 0, 2, 3, 1, 3, 0, 1, 0, 0, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 33 and the episode is 2557 and the total_steps are 134750\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 3, 0, 2, 0, 1, 0, 1, 1, 2, 0, 1, 2, 2, 2, 1, 0, 1, 3, 1, 0, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 28 and the episode is 2558 and the total_steps are 134778\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 3, 1, 1, 0, 2, 0, 2, 0, 3, 2, 0, 0, 0, 1, 0, 1, 1, 0, 1, 3, 0, 1, 0, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 31 and the episode is 2559 and the total_steps are 134809\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 1, 2, 3, 2, 3, 0, 3, 3, 3, 0, 2, 0, 0, 0, 3, 1, 3, 3, 1, 1, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 2560 and the total_steps are 134837\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.1     |\n",
      "|    ep_rew_mean      | -967     |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2560     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4233     |\n",
      "|    total_timesteps  | 134837   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.4     |\n",
      "|    n_updates        | 21209    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 1, 0, 0, 3, 0, 3, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 0, 3, 1, 3, 2, 2, 3, 2, 0, 2, 1, 3, 3, 1, 2, 1, 0, 0, 2, 2, 2, 0, 1, 1, 0, 1, 3, 3, 0, 0, 3, 0, 1, 3, 3, 2, 1, 1, 2, 3, 1, 0, 3, 2, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 68 and the episode is 2561 and the total_steps are 134905\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 2, 1, 1, 0, 2, 0, 2, 1, 1, 2, 0, 1, 2, 1, 3, 2, 3, 3, 2, 0, 1, 3, 2, 2, 3, 2, 0, 2, 0, 0, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 38 and the episode is 2562 and the total_steps are 134943\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 3, 0, 0, 3, 3, 3, 1, 1, 3, 0, 0, 0, 2, 3, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 22 and the episode is 2563 and the total_steps are 134965\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 0, 3, 1, 1, 2, 2, 1, 0, 1, 1, 2, 3, 1, 0, 0, 3, 0, 0, 0, 3, 2, 2, 0, 2, 0, 0, 3, 2, 0, 1, 2, 3, 2, 1, 2, 1, 2, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 45 and the episode is 2564 and the total_steps are 135010\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.2     |\n",
      "|    ep_rew_mean      | -966     |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2564     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4240     |\n",
      "|    total_timesteps  | 135010   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.2     |\n",
      "|    n_updates        | 21252    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 1, 0, 3, 0, 3, 1, 1, 2, 1, 0, 0, 0, 0, 3, 0, 0, 0, 2, 3, 1, 0, 2, 1, 2, 3, 3, 2, 2, 3, 3, 0, 3, 0, 2, 2, 0, 3, 2, 3, 2, 3, 2, 1, 3, 0, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 53 and the episode is 2565 and the total_steps are 135063\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 3, 0, 0, 3, 3, 0, 2, 0, 1, 0, 1, 2, 3, 1, 2, 3, 2, 2, 3, 0, 2, 2, 3, 3, 3, 3, 1, 2, 1, 1, 3, 1, 0, 0, 3, 3, 2, 1, 3, 2, 3, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 49 and the episode is 2566 and the total_steps are 135112\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 3, 3, 1, 1, 0, 1, 0, 0, 0, 3, 2, 2, 0, 3, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 2, 2, 1, 0, 2, 2, 0, 0, 2, 0, 0, 1, 2, 2, 2, 3, 0, 0, 1, 1, 0, 0, 2, 3, 0, 2, 1, 0, 3, 0, 1, 3, 0, 3, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1048. And steps were 66 and the episode is 2567 and the total_steps are 135178\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 2, 3, 0, 2, 1, 1, 3, 3, 1, 3, 2, 3, 2, 3, 1, 2, 2, 1, 0, 0, 3, 3, 2, 0, 3, 3, 3, 1, 3, 2, 3, 1, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 2568 and the total_steps are 135218\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.7     |\n",
      "|    ep_rew_mean      | -967     |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2568     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4249     |\n",
      "|    total_timesteps  | 135218   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 21304    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 1, 2, 3, 0, 0, 1, 0, 1, 3, 1, 1, 2, 0, 2, 0, 2, 2, 1, 0, 0, 3, 0, 1, 3, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 2569 and the total_steps are 135250\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 1, 2, 3, 0, 0, 2, 2, 0, 2, 0, 2, 1, 0, 1, 1, 2, 1, 3, 1, 2, 0, 3, 3, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2570 and the total_steps are 135281\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 1, 0, 1, 0, 3, 1, 2, 3, 1, 2, 0, 1, 3, 1, 0, 3, 2, 2, 1, 3, 0, 2, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 30 and the episode is 2571 and the total_steps are 135311\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 1, 0, 1, 0, 1, 3, 2, 1, 2, 2, 0, 0, 0, 2, 0, 2, 1, 3, 2, 0, 1, 0, 3, 2, 3, 2, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 34 and the episode is 2572 and the total_steps are 135345\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.4     |\n",
      "|    ep_rew_mean      | -967     |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2572     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4254     |\n",
      "|    total_timesteps  | 135345   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 21336    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 2, 0, 2, 1, 3, 1, 3, 2, 0, 1, 3, 3, 3, 1, 1, 1, 0, 1, 0, 3, 3, 3, 1, 3, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 2573 and the total_steps are 135377\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 2, 1, 1, 1, 2, 2, 0, 3, 2, 0, 1, 1, 2, 0, 3, 2, 0, 1, 2, 2, 3, 0, 1, 0, 3, 2, 1, 0, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 36 and the episode is 2574 and the total_steps are 135413\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 3, 1, 0, 1, 1, 2, 3, 1, 3, 0, 1, 3, 2, 1, 1, 0, 1, 3, 2, 3, 1, 0, 2, 2, 2, 1, 3, 2, 1, 1, 1, 1, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 40 and the episode is 2575 and the total_steps are 135453\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 3, 0, 0, 0, 3, 0, 1, 2, 1, 1, 3, 0, 3, 3, 0, 0, 3, 2, 2, 3, 1, 0, 3, 2, 2, 0, 3, 0, 0, 0, 2, 1, 3, 2, 1, 2, 0, 2, 0, 2, 1, 2, 3, 3, 1, 3, 0, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 55 and the episode is 2576 and the total_steps are 135508\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.8     |\n",
      "|    ep_rew_mean      | -966     |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2576     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4261     |\n",
      "|    total_timesteps  | 135508   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.413    |\n",
      "|    n_updates        | 21376    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 2, 2, 1, 0, 0, 0, 1, 2, 3, 1, 3, 2, 0, 3, 3, 3, 2, 1, 2, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 2, 1, 0, 0, 3, 1, 2, 3, 2, 2, 3, 0, 1, 1, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 52 and the episode is 2577 and the total_steps are 135560\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 1, 0, 1, 2, 0, 2, 3, 3, 3, 2, 2, 0, 0, 3, 1, 2, 2, 1, 2, 2, 0, 3, 3, 2, 3, 2, 2, 3, 1, 3, 0, 3, 3, 3, 2, 0, 3, 0, 3, 0, 2, 0, 2, 1, 1, 1, 0, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 55 and the episode is 2578 and the total_steps are 135615\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 2, 0, 3, 0, 3, 0, 0, 1, 0, 2, 1, 0, 2, 0, 2, 1, 3, 2, 0, 2, 3, 1, 1, 1, 2, 2, 2, 2, 0, 1, 2, 2, 2, 0, 2, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 43 and the episode is 2579 and the total_steps are 135658\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 3, 1, 1, 1, 2, 1, 2, 2, 0, 0, 3, 3, 3, 2, 3, 2, 3, 1, 1, 0, 0, 0, 1, 2, 1, 0, 0, 1, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 2580 and the total_steps are 135694\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.2     |\n",
      "|    ep_rew_mean      | -965     |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2580     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4269     |\n",
      "|    total_timesteps  | 135694   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 21423    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 2, 3, 2, 1, 3, 1, 3, 0, 2, 3, 3, 3, 0, 2, 2, 0, 1, 1, 2, 2, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 28 and the episode is 2581 and the total_steps are 135722\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 3, 0, 0, 3, 2, 3, 1, 2, 0, 0, 1, 3, 3, 0, 3, 1, 2, 2, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 2582 and the total_steps are 135748\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 2, 0, 2, 3, 2, 0, 2, 3, 2, 2, 0, 1, 3, 2, 0, 0, 0, 3, 0, 1, 1, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 29 and the episode is 2583 and the total_steps are 135777\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 0, 3, 3, 3, 2, 1, 2, 1, 1, 1, 2, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 19 and the episode is 2584 and the total_steps are 135796\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.3     |\n",
      "|    ep_rew_mean      | -966     |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2584     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4273     |\n",
      "|    total_timesteps  | 135796   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.8     |\n",
      "|    n_updates        | 21448    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 2, 0, 3, 2, 3, 2, 3, 3, 2, 2, 0, 3, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 19 and the episode is 2585 and the total_steps are 135815\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 1, 1, 3, 2, 2, 1, 1, 3, 0, 3, 1, 2, 2, 0, 2, 1, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 24 and the episode is 2586 and the total_steps are 135839\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 2, 3, 2, 3, 2, 1, 0, 2, 0, 0, 1, 0, 3, 3, 2, 0, 0, 1, 0, 1, 3, 2, 1, 1, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 2587 and the total_steps are 135871\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 1, 3, 1, 2, 3, 3, 1, 2, 0, 1, 3, 1, 1, 1, 2, 2, 2, 0, 0, 1, 1, 3, 2, 1, 1, 2, 3, 2, 1, 2, 2, 2, 3, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 41 and the episode is 2588 and the total_steps are 135912\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | -964     |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2588     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4278     |\n",
      "|    total_timesteps  | 135912   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.17     |\n",
      "|    n_updates        | 21477    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 3, 2, 3, 2, 0, 2, 1, 1, 2, 0, 1, 2, 2, 3, 1, 0, 0, 0, 1, 2, 0, 1, 0, 2, 1, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 33 and the episode is 2589 and the total_steps are 135945\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 3, 1, 1, 3, 1, 3, 0, 2, 0, 3, 2, 1, 2, 2, 2, 1, 2, 3, 2, 1, 1, 0, 2, 1, 0, 3, 0, 2, 2, 3, 1, 3, 1, 2, 2, 3, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 44 and the episode is 2590 and the total_steps are 135989\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 1, 3, 1, 1, 3, 3, 0, 1, 2, 3, 0, 1, 3, 3, 3, 3, 3, 0, 2, 0, 2, 2, 0, 1, 1, 3, 1, 1, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 2591 and the total_steps are 136025\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 3, 3, 0, 2, 3, 3, 1, 3, 1, 2, 0, 0, 2, 2, 1, 2, 2, 2, 3, 1, 3, 0, 3, 1, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 32 and the episode is 2592 and the total_steps are 136057\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | -963     |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2592     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4284     |\n",
      "|    total_timesteps  | 136057   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.813    |\n",
      "|    n_updates        | 21514    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 1, 0, 2, 2, 1, 1, 3, 3, 1, 3, 2, 1, 2, 1, 3, 1, 0, 3, 1, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 2593 and the total_steps are 136084\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 3, 2, 3, 0, 3, 0, 0, 1, 1, 3, 1, 2, 3, 0, 3, 0, 0, 3, 0, 2, 1, 3, 3, 2, 2, 0, 1, 0, 2, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 37 and the episode is 2594 and the total_steps are 136121\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 2, 0, 2, 3, 3, 2, 0, 0, 0, 0, 2, 0, 1, 2, 0, 2, 3, 3, 1, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was 1000. And steps were 25 and the episode is 2595 and the total_steps are 136146\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 1, 1, 0, 0, 1, 3, 0, 3, 2, 3, 2, 1, 0, 2, 3, 3, 2, 1, 0, 1, 0, 3, 1, 2, 2, 1, 1, 2, 0, 0, 3, 2, 0, 0, 0, 2, 1, 1, 3, 2, 1, 0, 3, 0, 3, 2, 1, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 55 and the episode is 2596 and the total_steps are 136201\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2596     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4290     |\n",
      "|    total_timesteps  | 136201   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.57     |\n",
      "|    n_updates        | 21550    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 0, 3, 2, 2, 3, 0, 0, 1, 3, 0, 0, 1, 0, 1, 1, 3, 1, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 2597 and the total_steps are 136241\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 2, 1, 0, 2, 3, 0, 1, 3, 1, 1, 0, 2, 2, 1, 2, 3, 3, 1, 2, 1, 2, 0, 1, 1, 1, 3, 0, 2, 0, 1, 2, 0, 1, 0, 0, 3, 0, 2, 1, 2, 2, 2, 3, 1, 1, 0, 0, 1, 2, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 57 and the episode is 2598 and the total_steps are 136298\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 2, 0, 3, 1, 2, 1, 0, 2, 0, 2, 1, 2, 0, 1, 3, 1, 2, 3, 0, 0, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0, 2, 0, 1, 1, 3, 1, 0, 3, 0, 2, 3, 2, 0, 3, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 52 and the episode is 2599 and the total_steps are 136350\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 3, 0, 1, 2, 2, 3, 3, 2, 2, 0, 2, 1, 1, 0, 0, 0, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 24 and the episode is 2600 and the total_steps are 136374\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | -944     |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2600     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4298     |\n",
      "|    total_timesteps  | 136374   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 35.6     |\n",
      "|    n_updates        | 21593    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 3, 0, 3, 0, 3, 3, 0, 3, 2, 1, 2, 0, 2, 0, 2, 3, 3, 0, 0, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 2601 and the total_steps are 136401\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 3, 3, 0, 2, 3, 3, 2, 3, 2, 0, 3, 1, 0, 2, 3, 2, 2, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 25 and the episode is 2602 and the total_steps are 136426\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 3, 0, 3, 1, 3, 0, 2, 0, 1, 1, 1, 0, 2, 1, 1, 2, 3, 0, 0, 0, 0, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 2603 and the total_steps are 136455\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 2, 0, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 3, 2, 2, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 23 and the episode is 2604 and the total_steps are 136478\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -946     |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2604     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4303     |\n",
      "|    total_timesteps  | 136478   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.22     |\n",
      "|    n_updates        | 21619    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 2, 0, 3, 3, 3, 3, 3, 0, 2, 0, 2, 2, 3, 1, 1, 3, 1, 3, 1, 2, 1, 2, 2, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 31 and the episode is 2605 and the total_steps are 136509\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 0, 0, 1, 3, 1, 3, 3, 3, 2, 1, 0, 0, 2, 0, 2, 0, 3, 2, 1, 3, 0, 0, 0, 2, 0, 2, 2, 1, 1, 0, 3, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 39 and the episode is 2606 and the total_steps are 136548\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 3, 1, 2, 1, 2, 2, 0, 1, 3, 3, 3, 3, 3, 2, 1, 2, 3, 0, 2, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was 1010. And steps were 25 and the episode is 2607 and the total_steps are 136573\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 1, 2, 0, 3, 3, 1, 2, 1, 0, 2, 0, 1, 3, 2, 0, 2, 2, 1, 3, 1, 3, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 3, 0, 3, 3, 0, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 2608 and the total_steps are 136617\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -926     |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2608     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4309     |\n",
      "|    total_timesteps  | 136617   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 21654    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 0, 2, 3, 1, 1, 1, 3, 2, 0, 3, 3, 1, 2, 0, 0, 1, 2, 2, 1, 1, 0, 2, 2, 2, 0, 0, 2, 0, 3, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 37 and the episode is 2609 and the total_steps are 136654\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 3, 3, 0, 3, 1, 2, 1, 1, 0, 1, 2, 3, 0, 0, 0, 1, 2, 1, 2, 0, 2, 1, 1, 1, 2, 0, 2, 3, 0, 2, 1, 2, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 48 and the episode is 2610 and the total_steps are 136702\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 0, 0, 2, 3, 2, 0, 1, 3, 1, 3, 2, 0, 1, 2, 1, 2, 2, 1, 2, 0, 3, 2, 2, 2, 0, 0, 3, 2, 2, 1, 3, 2, 2, 2, 2, 3, 0, 1, 1, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 47 and the episode is 2611 and the total_steps are 136749\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 2, 3, 1, 3, 0, 2, 0, 1, 1, 3, 0, 3, 2, 1, 2, 3, 3, 3, 2, 2, 0, 3, 1, 2, 1, 1, 1, 3, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 36 and the episode is 2612 and the total_steps are 136785\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -925     |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2612     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4315     |\n",
      "|    total_timesteps  | 136785   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.954    |\n",
      "|    n_updates        | 21696    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 1, 3, 3, 1, 2, 3, 2, 1, 0, 1, 3, 0, 2, 0, 0, 1, 3, 3, 1, 1, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 2613 and the total_steps are 136813\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 0, 0, 3, 1, 2, 0, 3, 0, 3, 3, 3, 0, 2, 1, 2, 3, 0, 1, 2, 3, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 2614 and the total_steps are 136841\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 1, 2, 0, 1, 3, 0, 0, 0, 3, 0, 0, 0, 1, 3, 3, 3, 3, 1, 1, 1, 2, 2, 2, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2615 and the total_steps are 136873\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 3, 1, 3, 1, 0, 3, 3, 1, 1, 0, 0, 3, 2, 1, 0, 2, 3, 1, 3, 0, 2, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 29 and the episode is 2616 and the total_steps are 136902\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -945     |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2616     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4320     |\n",
      "|    total_timesteps  | 136902   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.3     |\n",
      "|    n_updates        | 21725    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 0, 0, 1, 1, 1, 0, 3, 0, 1, 0, 1, 2, 3, 3, 1, 0, 2, 0, 3, 0, 0, 2, 1, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 31 and the episode is 2617 and the total_steps are 136933\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 3, 0, 3, 1, 1, 3, 3, 2, 3, 0, 1, 3, 3, 2, 0, 2, 2, 1, 1, 0, 3, 3, 1, 1, 3, 0, 2, 3, 3, 2, 0, 2, 1, 3, 0, 3, 3, 0, 2, 3, 1, 2, 3, 0, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 2618 and the total_steps are 136985\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 1, 2, 1, 2, 3, 0, 2, 2, 3, 2, 3, 1, 2, 0, 3, 2, 2, 3, 2, 1, 2, 0, 0, 3, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0, 1, 3, 3, 3, 2, 2, 1, 2, 1, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 51 and the episode is 2619 and the total_steps are 137036\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 3, 2, 2, 0, 2, 1, 0, 3, 3, 0, 2, 0, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 21 and the episode is 2620 and the total_steps are 137057\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -947     |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2620     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4327     |\n",
      "|    total_timesteps  | 137057   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.81     |\n",
      "|    n_updates        | 21764    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 1, 0, 3, 0, 2, 0, 2, 2, 1, 0, 1, 2, 0, 2, 0, 2, 2, 1, 2, 1, 3, 2, 2, 0, 3, 2, 2, 0, 2, 3, 1, 2, 0, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 2621 and the total_steps are 137098\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 1, 1, 0, 2, 0, 2, 1, 3, 1, 2, 0, 3, 0, 1, 0, 0, 3, 1, 0, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 27 and the episode is 2622 and the total_steps are 137125\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 2, 2, 2, 3, 0, 1, 3, 1, 2, 3, 3, 3, 0, 0, 1, 2, 3, 2, 1, 2, 2, 3, 0, 0, 0, 3, 3, 1, 0, 3, 1, 2, 2, 1, 0, 0, 3, 2, 3, 3, 1, 0, 2, 2, 3, 0, 2, 2, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 56 and the episode is 2623 and the total_steps are 137181\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 1, 0, 2, 2, 3, 1, 3, 1, 0, 3, 2, 3, 3, 2, 1, 1, 2, 2, 2, 3, 1, 1, 1, 1, 0, 3, 0, 0, 2, 0, 2, 2, 3, 1, 0, 2, 0, 3, 0, 3, 3, 3, 0, 1, 0, 3, 0, 1, 0, 3, 3, 0, 1, 2, 3, 2, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 64 and the episode is 2624 and the total_steps are 137245\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -945     |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2624     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4334     |\n",
      "|    total_timesteps  | 137245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 21811    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 3, 0, 0, 3, 2, 2, 0, 1, 0, 1, 1, 0, 0, 2, 1, 0, 2, 1, 1, 2, 2, 2, 3, 0, 1, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 33 and the episode is 2625 and the total_steps are 137278\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 2, 0, 2, 2, 3, 1, 1, 3, 2, 0, 2, 3, 0, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 25 and the episode is 2626 and the total_steps are 137303\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 2, 3, 2, 2, 0, 3, 3, 2, 1, 2, 0, 3, 2, 1, 3, 2, 3, 3, 3, 3, 2, 0, 0, 1, 2, 3, 0, 0, 0, 1, 1, 2, 2, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 41 and the episode is 2627 and the total_steps are 137344\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 2, 3, 2, 1, 2, 0, 1, 3, 1, 2, 1, 1, 0, 2, 2, 2, 2, 3, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 2628 and the total_steps are 137368\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -924     |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2628     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4339     |\n",
      "|    total_timesteps  | 137368   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.1     |\n",
      "|    n_updates        | 21841    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 3, 3, 3, 0, 2, 2, 3, 3, 0, 0, 0, 0, 0, 1, 0, 1, 0, 3, 1, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 27 and the episode is 2629 and the total_steps are 137395\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 1, 1, 0, 0, 0, 2, 0, 3, 0, 2, 3, 3, 2, 2, 0, 1, 0, 3, 1, 2, 2, 1, 2, 2, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 32 and the episode is 2630 and the total_steps are 137427\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 1, 2, 0, 2, 3, 3, 0, 0, 2, 1, 0, 2, 3, 1, 2, 0, 2, 2, 1, 1, 3, 2, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 2631 and the total_steps are 137457\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 2, 3, 0, 1, 1, 1, 3, 2, 1, 3, 3, 2, 1, 3, 0, 3, 0, 0, 3, 2, 0, 2, 0, 0, 0, 3, 3, 3, 2, 1, 2, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 40 and the episode is 2632 and the total_steps are 137497\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -924     |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2632     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4345     |\n",
      "|    total_timesteps  | 137497   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 126      |\n",
      "|    n_updates        | 21874    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 2, 0, 2, 0, 3, 1, 0, 1, 2, 1, 1, 3, 3, 1, 2, 3, 2, 0, 2, 2, 2, 1, 1, 2, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 32 and the episode is 2633 and the total_steps are 137529\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 1, 3, 2, 1, 0, 3, 3, 3, 0, 3, 0, 3, 3, 1, 0, 1, 0, 2, 0, 0, 2, 1, 1, 2, 2, 1, 2, 2, 3, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 37 and the episode is 2634 and the total_steps are 137566\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 0, 0, 0, 2, 2, 1, 2, 2, 0, 1, 0, 1, 2, 0, 0, 3, 3, 1, 0, 3, 0, 3, 0, 1, 2, 2, 3, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 3, 3, 1, 3, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 50 and the episode is 2635 and the total_steps are 137616\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 0, 2, 1, 0, 0, 1, 2, 0, 0, 2, 2, 2, 2, 2, 3, 1, 1, 2, 1, 1, 0, 0, 3, 2, 2, 2, 0, 1, 2, 2, 0, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 39 and the episode is 2636 and the total_steps are 137655\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -923     |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2636     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4351     |\n",
      "|    total_timesteps  | 137655   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 21913    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 3, 1, 0, 3, 1, 1, 0, 3, 3, 2, 3, 2, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 20 and the episode is 2637 and the total_steps are 137675\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 0, 2, 2, 3, 0, 1, 1, 3, 0, 3, 2, 3, 1, 2, 1, 3, 0, 0, 3, 1, 1, 2, 1, 0, 2, 0, 1, 0, 0, 3, 2, 3, 2, 0, 3, 1, 1, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 46 and the episode is 2638 and the total_steps are 137721\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 1, 0, 0, 0, 1, 2, 3, 2, 3, 3, 0, 3, 2, 3, 2, 0, 0, 3, 3, 3, 1, 3, 0, 1, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 32 and the episode is 2639 and the total_steps are 137753\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 2, 1, 2, 2, 2, 3, 1, 1, 0, 0, 2, 2, 2, 0, 0, 3, 0, 2, 1, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 2640 and the total_steps are 137778\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -903     |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2640     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4357     |\n",
      "|    total_timesteps  | 137778   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.871    |\n",
      "|    n_updates        | 21944    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 0, 0, 0, 3, 1, 0, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 2, 2, 3, 1, 1, 0, 0, 2, 1, 2, 3, 3, 3, 2, 1, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 40 and the episode is 2641 and the total_steps are 137818\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 3, 3, 2, 3, 1, 0, 3, 1, 1, 3, 2, 1, 2, 3, 1, 2, 3, 0, 1, 0, 3, 1, 1, 3, 0, 2, 2, 1, 1, 3, 2, 1, 3, 3, 1, 0, 3, 0, 3, 1, 3, 2, 0, 0, 3, 3, 0, 1, 0, 0, 2, 0, 0, 1, 0, 0, 2, 1, 0, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 67 and the episode is 2642 and the total_steps are 137885\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 1, 1, 1, 3, 1, 3, 2, 3, 2, 2, 0, 2, 2, 3, 1, 1, 1, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 25 and the episode is 2643 and the total_steps are 137910\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 3, 0, 2, 1, 3, 0, 2, 0, 3, 1, 0, 2, 2, 1, 3, 1, 2, 1, 2, 0, 0, 0, 2, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2644 and the total_steps are 137941\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -923     |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2644     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4363     |\n",
      "|    total_timesteps  | 137941   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 21985    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 2, 3, 1, 2, 2, 1, 3, 2, 3, 1, 0, 3, 2, 3, 3, 3, 1, 1, 2, 0, 1, 2, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 2645 and the total_steps are 137971\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 2, 0, 3, 1, 3, 3, 3, 0, 2, 3, 2, 3, 1, 0, 1, 2, 1, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 25 and the episode is 2646 and the total_steps are 137996\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 3, 0, 2, 3, 1, 3, 3, 1, 3, 2, 0, 3, 3, 0, 1, 3, 1, 1, 3, 0, 0, 1, 0, 1, 0, 2, 0, 2, 0, 0, 3, 3, 2, 1, 0, 3, 1, 3, 0, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 47 and the episode is 2647 and the total_steps are 138043\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 0, 1, 0, 0, 1, 3, 2, 1, 2, 3, 1, 0, 1, 0, 0, 1, 2, 2, 3, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 2648 and the total_steps are 138070\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -923     |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2648     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4369     |\n",
      "|    total_timesteps  | 138070   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 22017    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 2, 3, 2, 1, 2, 0, 2, 0, 1, 2, 3, 0, 0, 3, 1, 0, 3, 1, 1, 3, 0, 3, 1, 1, 1, 2, 2, 2, 0, 2, 3, 2, 3, 3, 0, 1, 1, 2, 0, 0, 2, 2, 1, 1, 2, 0, 2, 3, 0, 0, 1, 1, 2, 2, 2, 3, 2, 0, 2, 1, 1, 0, 1, 0, 2, 1, 1, 0, 3, 3, 2, 0, 3, 1, 3, 3, 0, 0, 2, 3, 0, 3, 3, 1, 0, 1, 3, 2, 3, 3, 3, 3, 3, 2, 2, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 103 and the episode is 2649 and the total_steps are 138173\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 3, 0, 0, 3, 0, 0, 1, 1, 0, 2, 3, 1, 1, 3, 0, 3, 0, 2, 3, 3, 3, 0, 1, 2, 0, 1, 3, 2, 2, 0, 3, 2, 1, 1, 0, 3, 2, 3, 0, 3, 2, 3, 0, 1, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 2650 and the total_steps are 138225\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 3, 1, 0, 0, 3, 0, 2, 0, 0, 2, 3, 0, 1, 3, 0, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1004. And steps were 21 and the episode is 2651 and the total_steps are 138246\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 2, 3, 1, 1, 0, 1, 3, 0, 0, 3, 0, 3, 2, 2, 2, 3, 1, 3, 2, 3, 1, 1, 1, 3, 2, 3, 3, 1, 0, 3, 0, 1, 1, 1, 2, 1, 2, 2, 3, 3, 2, 0, 1, 0, 2, 1, 0, 0, 1, 2, 0, 2, 0, 0, 3, 3, 1, 1, 3, 0, 3, 2, 1, 1, 3, 1, 3, 0, 2, 0, 0, 2, 1, 2, 0, 2, 0, 2, 2, 3, 2, 1, 1, 0, 2, 1, 1, 1, 2, 0, 3, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -919. And steps were 99 and the episode is 2652 and the total_steps are 138345\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2652     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4380     |\n",
      "|    total_timesteps  | 138345   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 22086    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 1, 1, 0, 1, 2, 2, 3, 2, 1, 0, 1, 2, 0, 0, 0, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 1, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 34 and the episode is 2653 and the total_steps are 138379\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 3, 0, 1, 3, 0, 1, 0, 2, 0, 2, 0, 0, 1, 3, 3, 0, 2, 0, 3, 2, 0, 2, 3, 2, 0, 1, 3, 2, 1, 3, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 38 and the episode is 2654 and the total_steps are 138417\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 1, 1, 1, 3, 3, 1, 1, 0, 1, 1, 0, 2, 1, 0, 0, 1, 1, 2, 0, 0, 0, 3, 0, 3, 1, 2, 2, 1, 0, 0, 3, 2, 3, 1, 3, 1, 3, 0, 0, 2, 2, 3, 2, 1, 2, 1, 3, 3, 3, 0, 3, 3, 0, 1, 1, 0, 3, 0, 3, 1, 3, 1, 2, 0, 1, 1, 1, 0, 3, 2, 0, 3, 3, 1, 2, 2, 1, 2, 2, 3, 3, 2, 1, 2, 1, 2, 3, 1, 0, 1, 2, 1, 0, 3, 2, 3, 2, 1, 3, 2, 0, 2, 0, 3, 3, 1, 0, 0, 2, 0, 3, 3, 0, 0, 1, 3, 1, 2, 1, 2, 3, 1, 0, 3, 3, 1, 0, 0, 3, 1, 0, 3, 3, 2, 2, 1, 1, 1, 2, 1, 3, 1, 0, 0, 2, 0, 1, 3, 1, 3, 1, 1, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1122. And steps were 160 and the episode is 2655 and the total_steps are 138577\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 2, 2, 2, 2, 3, 2, 2, 3, 0, 3, 3, 2, 1, 3, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 0, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 40 and the episode is 2656 and the total_steps are 138617\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2656     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4391     |\n",
      "|    total_timesteps  | 138617   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.3     |\n",
      "|    n_updates        | 22154    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 0, 2, 0, 0, 3, 2, 0, 0, 3, 2, 1, 2, 1, 2, 3, 3, 1, 3, 0, 2, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 2657 and the total_steps are 138645\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 3, 3, 1, 3, 1, 3, 2, 2, 3, 1, 0, 2, 0, 3, 1, 2, 2, 1, 3, 0, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 28 and the episode is 2658 and the total_steps are 138673\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 0, 1, 1, 1, 3, 3, 2, 0, 1, 1, 2, 0, 2, 3, 1, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 3, 3, 1, 3, 3, 2, 3, 3, 1, 3, 3, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 50 and the episode is 2659 and the total_steps are 138723\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 0, 3, 2, 1, 1, 3, 3, 3, 1, 0, 2, 2, 0, 1, 3, 2, 1, 2, 0, 1, 2, 2, 2, 1, 2, 2, 1, 3, 2, 2, 1, 2, 0, 3, 0, 2, 0, 3, 0, 3, 0, 3, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 50 and the episode is 2660 and the total_steps are 138773\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2660     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4397     |\n",
      "|    total_timesteps  | 138773   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.58     |\n",
      "|    n_updates        | 22193    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 1, 2, 0, 1, 1, 2, 0, 2, 2, 0, 0, 2, 1, 3, 0, 2, 2, 3, 0, 3, 0, 1, 1, 2, 1, 0, 3, 0, 2, 2, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 38 and the episode is 2661 and the total_steps are 138811\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 3, 1, 0, 1, 1, 0, 1, 2, 2, 3, 2, 1, 0, 3, 3, 1, 3, 1, 2, 3, 2, 1, 2, 2, 3, 0, 1, 0, 1, 0, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 38 and the episode is 2662 and the total_steps are 138849\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 3, 0, 3, 3, 1, 1, 2, 3, 1, 0, 3, 0, 1, 3, 3, 2, 1, 2, 3, 0, 3, 1, 0, 3, 2, 3, 2, 1, 3, 0, 2, 0, 2, 2, 1, 2, 1, 0, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 46 and the episode is 2663 and the total_steps are 138895\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 3, 2, 1, 3, 1, 2, 2, 2, 1, 0, 1, 1, 1, 1, 2, 3, 0, 1, 2, 0, 1, 0, 3, 1, 3, 0, 1, 0, 0, 1, 1, 1, 2, 1, 2, 2, 2, 3, 2, 3, 2, 3, 3, 3, 2, 3, 1, 0, 3, 3, 2, 3, 1, 2, 0, 2, 3, 3, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 66 and the episode is 2664 and the total_steps are 138961\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2664     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4405     |\n",
      "|    total_timesteps  | 138961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 22240    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 2, 2, 1, 3, 1, 1, 2, 1, 0, 1, 1, 3, 2, 2, 1, 2, 0, 3, 2, 3, 3, 1, 3, 1, 0, 3, 3, 1, 2, 2, 0, 2, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 46 and the episode is 2665 and the total_steps are 139007\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 2, 0, 0, 1, 1, 2, 0, 2, 0, 1, 1, 2, 1, 1, 3, 1, 2, 3, 2, 2, 2, 1, 0, 0, 1, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 33 and the episode is 2666 and the total_steps are 139040\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 0, 3, 0, 2, 3, 3, 2, 2, 0, 2, 1, 3, 1, 1, 0, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 2667 and the total_steps are 139061\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 0, 0, 0, 0, 3, 0, 2, 2, 3, 0, 3, 2, 0, 3, 1, 2, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 2, 1, 0, 1, 3, 0, 0, 2, 2, 3, 2, 0, 1, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 52 and the episode is 2668 and the total_steps are 139113\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2668     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4411     |\n",
      "|    total_timesteps  | 139113   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65       |\n",
      "|    n_updates        | 22278    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 2, 2, 3, 1, 3, 1, 0, 2, 0, 0, 2, 3, 1, 1, 2, 1, 3, 2, 3, 2, 0, 0, 0, 3, 2, 2, 1, 0, 2, 1, 0, 2, 2, 0, 3, 1, 3, 2, 3, 3, 2, 2, 1, 2, 0, 1, 3, 0, 2, 1, 0, 2, 1, 1, 0, 3, 2, 2, 1, 3, 2, 1, 3, 1, 3, 1, 3, 0, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 76 and the episode is 2669 and the total_steps are 139189\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 0, 0, 3, 3, 1, 3, 0, 0, 1, 2, 0, 2, 3, 0, 1, 1, 0, 3, 2, 3, 2, 3, 1, 2, 0, 0, 3, 3, 3, 1, 0, 3, 2, 0, 2, 3, 1, 2, 1, 1, 0, 0, 0, 3, 1, 1, 2, 3, 2, 3, 3, 3, 2, 1, 3, 2, 3, 1, 2, 3, 1, 0, 0, 3, 2, 0, 0, 3, 0, 0, 0, 3, 3, 0, 2, 2, 0, 3, 2, 2, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -932. And steps were 88 and the episode is 2670 and the total_steps are 139277\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 3, 1, 2, 3, 1, 3, 3, 0, 0, 0, 1, 2, 2, 3, 1, 1, 2, 0, 0, 0, 0, 1, 2, 3, 3, 2, 1, 3, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 2671 and the total_steps are 139313\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 1, 1, 3, 2, 0, 2, 0, 3, 0, 1, 0, 0, 2, 1, 2, 0, 3, 3, 0, 1, 0, 2, 3, 2, 2, 1, 1, 0, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 2672 and the total_steps are 139349\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2672     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4421     |\n",
      "|    total_timesteps  | 139349   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.57     |\n",
      "|    n_updates        | 22337    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 1, 1, 1, 1, 0, 2, 0, 2, 1, 0, 3, 2, 2, 3, 0, 0, 3, 2, 3, 0, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 28 and the episode is 2673 and the total_steps are 139377\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 1, 3, 3, 3, 2, 1, 2, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2, 0, 1, 3, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 2674 and the total_steps are 139405\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 2, 3, 3, 3, 1, 1, 2, 0, 2, 3, 0, 1, 3, 2, 2, 2, 0, 2, 0, 3, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 2675 and the total_steps are 139433\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 2, 1, 3, 1, 1, 2, 3, 3, 3, 2, 0, 2, 2, 3, 0, 3, 2, 0, 2, 1, 3, 0, 3, 0, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 32 and the episode is 2676 and the total_steps are 139465\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -882     |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2676     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4426     |\n",
      "|    total_timesteps  | 139465   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.55     |\n",
      "|    n_updates        | 22366    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 0, 1, 2, 2, 3, 3, 2, 1, 1, 2, 2, 1, 1, 2, 0, 3, 1, 2, 3, 3, 2, 0, 3, 3, 0, 0, 3, 0, 3, 1, 2, 0, 3, 3, 0, 2, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 44 and the episode is 2677 and the total_steps are 139509\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 0, 2, 3, 2, 3, 3, 1, 2, 2, 3, 1, 0, 2, 1, 2, 3, 2, 0, 3, 3, 0, 0, 2, 1, 3, 2, 0, 2, 1, 3, 0, 3, 2, 3, 1, 1, 0, 0, 0, 3, 3, 1, 3, 3, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 52 and the episode is 2678 and the total_steps are 139561\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 2, 2, 2, 2, 2, 0, 2, 3, 0, 3, 1, 0, 1, 3, 3, 3, 2, 2, 0, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 2679 and the total_steps are 139586\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 2, 2, 2, 2, 0, 2, 0, 1, 1, 2, 2, 0, 3, 2, 0, 0, 0, 1, 0, 0, 3, 1, 0, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2680 and the total_steps are 139617\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -862     |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2680     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4432     |\n",
      "|    total_timesteps  | 139617   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 22404    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 0, 2, 1, 2, 3, 2, 3, 3, 3, 2, 2, 3, 2, 1, 0, 2, 2, 1, 0, 2, 2, 3, 1, 2, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 2681 and the total_steps are 139649\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 1, 3, 2, 1, 3, 3, 0, 2, 3, 1, 1, 0, 2, 0, 3, 3, 0, 2, 1, 0, 1, 3, 3, 2, 0, 1, 1, 0, 0, 3, 1, 0, 2, 0, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 42 and the episode is 2682 and the total_steps are 139691\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 3, 0, 1, 3, 2, 2, 1, 3, 1, 1, 3, 2, 3, 0, 3, 0, 0, 1, 0, 2, 2, 1, 2, 0, 0, 3, 2, 3, 0, 3, 0, 3, 2, 2, 1, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 43 and the episode is 2683 and the total_steps are 139734\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 0, 3, 1, 3, 3, 2, 1, 0, 3, 1, 0, 0, 1, 2, 3, 0, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 2684 and the total_steps are 139758\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -862     |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2684     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4438     |\n",
      "|    total_timesteps  | 139758   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 22439    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 2, 2, 0, 1, 2, 1, 1, 2, 3, 0, 2, 0, 1, 0, 2, 3, 2, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 23 and the episode is 2685 and the total_steps are 139781\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 0, 1, 1, 0, 0, 3, 2, 3, 0, 1, 2, 1, 1, 2, 1, 1, 0, 3, 3, 3, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 2686 and the total_steps are 139809\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 2, 2, 3, 2, 1, 0, 3, 2, 0, 1, 0, 2, 3, 3, 2, 0, 3, 2, 2, 2, 1, 2, 2, 0, 2, 0, 0, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 35 and the episode is 2687 and the total_steps are 139844\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 0, 2, 1, 2, 0, 2, 1, 3, 3, 3, 3, 3, 0, 3, 1, 1, 0, 1, 3, 3, 3, 1, 0, 3, 0, 2, 1, 1, 0, 2, 1, 0, 1, 3, 3, 3, 3, 2, 2, 2, 3, 2, 1, 2, 0, 3, 1, 1, 3, 1, 3, 0, 0, 1, 0, 1, 1, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -941. And steps were 65 and the episode is 2688 and the total_steps are 139909\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -842     |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2688     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4445     |\n",
      "|    total_timesteps  | 139909   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.5     |\n",
      "|    n_updates        | 22477    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 0, 1, 1, 3, 1, 1, 2, 2, 3, 1, 2, 3, 2, 2, 2, 3, 3, 3, 1, 2, 0, 0, 0, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 31 and the episode is 2689 and the total_steps are 139940\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 1, 3, 3, 2, 0, 0, 0, 3, 0, 3, 2, 1, 1, 3, 0, 3, 3, 0, 1, 1, 3, 0, 3, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 31 and the episode is 2690 and the total_steps are 139971\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 2, 1, 2, 3, 1, 0, 1, 2, 0, 1, 0, 3, 0, 2, 0, 3, 3, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 3, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 37 and the episode is 2691 and the total_steps are 140008\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 3, 1, 3, 2, 0, 2, 1, 1, 2, 1, 0, 3, 0, 3, 3, 1, 2, 2, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 26 and the episode is 2692 and the total_steps are 140034\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -842     |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2692     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4450     |\n",
      "|    total_timesteps  | 140034   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.1     |\n",
      "|    n_updates        | 22508    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 2, 3, 2, 0, 0, 2, 3, 2, 3, 3, 3, 0, 1, 3, 1, 1, 2, 3, 1, 3, 2, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 37 and the episode is 2693 and the total_steps are 140071\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 2, 1, 3, 2, 2, 0, 3, 1, 0, 3, 3, 3, 2, 2, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 22 and the episode is 2694 and the total_steps are 140093\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 0, 0, 0, 1, 3, 0, 2, 0, 2, 0, 2, 3, 1, 3, 0, 1, 3, 2, 2, 1, 0, 1, 2, 1, 3, 1, 0, 1, 3, 0, 0, 3, 3, 1, 1, 2, 1, 1, 2, 1, 3, 0, 1, 3, 0, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 53 and the episode is 2695 and the total_steps are 140146\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 2, 3, 3, 1, 1, 3, 1, 3, 1, 0, 2, 0, 3, 0, 0, 2, 3, 3, 1, 3, 2, 1, 0, 0, 3, 2, 3, 3, 0, 3, 1, 3, 0, 0, 0, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 43 and the episode is 2696 and the total_steps are 140189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -862     |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2696     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4456     |\n",
      "|    total_timesteps  | 140189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.9     |\n",
      "|    n_updates        | 22547    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 0, 3, 0, 3, 1, 3, 0, 3, 1, 2, 3, 3, 2, 2, 1, 2, 3, 0, 1, 0, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 28 and the episode is 2697 and the total_steps are 140217\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 3, 1, 2, 1, 1, 0, 1, 2, 1, 0, 3, 2, 1, 2, 0, 0, 1, 3, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 2698 and the total_steps are 140241\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 3, 0, 0, 3, 0, 3, 0, 2, 1, 0, 0, 2, 3, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 32 and the episode is 2699 and the total_steps are 140273\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 3, 0, 1, 3, 2, 0, 2, 3, 2, 3, 2, 3, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 20 and the episode is 2700 and the total_steps are 140293\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -841     |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2700     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4461     |\n",
      "|    total_timesteps  | 140293   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.98     |\n",
      "|    n_updates        | 22573    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 0, 0, 0, 3, 2, 2, 0, 0, 3, 0, 2, 3, 0, 1, 1, 3, 0, 2, 2, 0, 0, 0, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 30 and the episode is 2701 and the total_steps are 140323\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 3, 0, 3, 3, 3, 0, 2, 2, 3, 0, 1, 1, 1, 3, 0, 1, 3, 1, 0, 1, 2, 0, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 30 and the episode is 2702 and the total_steps are 140353\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 3, 1, 2, 1, 1, 1, 0, 3, 2, 3, 3, 3, 1, 0, 1, 2, 2, 2, 1, 1, 0, 2, 1, 1, 2, 1, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 34 and the episode is 2703 and the total_steps are 140387\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 3, 0, 3, 2, 2, 3, 0, 2, 0, 2, 2, 2, 0, 1, 3, 3, 0, 3, 0, 0, 3, 2, 2, 2, 1, 1, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 34 and the episode is 2704 and the total_steps are 140421\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -840     |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2704     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4466     |\n",
      "|    total_timesteps  | 140421   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 22605    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 3, 3, 1, 0, 2, 3, 0, 0, 0, 2, 1, 3, 1, 2, 3, 1, 3, 3, 2, 2, 3, 2, 0, 0, 2, 3, 1, 3, 1, 1, 3, 0, 3, 0, 2, 2, 1, 2, 3, 0, 3, 1, 0, 0, 0, 0, 0, 3, 0, 2, 2, 1, 3, 1, 2, 0, 1, 0, 1, 2, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 68 and the episode is 2705 and the total_steps are 140489\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 3, 1, 3, 2, 0, 3, 2, 0, 1, 3, 1, 2, 3, 3, 3, 3, 1, 2, 2, 3, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2706 and the total_steps are 140517\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 3, 0, 3, 3, 2, 1, 1, 1, 1, 3, 2, 2, 0, 0, 1, 2, 3, 2, 0, 3, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 2707 and the total_steps are 140545\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 3, 0, 1, 0, 3, 1, 1, 2, 0, 3, 1, 2, 0, 1, 3, 2, 1, 2, 2, 0, 0, 2, 2, 2, 1, 0, 2, 2, 0, 0, 3, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 39 and the episode is 2708 and the total_steps are 140584\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -860     |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2708     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4473     |\n",
      "|    total_timesteps  | 140584   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.4     |\n",
      "|    n_updates        | 22645    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 2, 1, 2, 2, 1, 0, 2, 3, 2, 3, 1, 2, 0, 1, 0, 2, 1, 2, 1, 1, 2, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 29 and the episode is 2709 and the total_steps are 140613\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 3, 0, 2, 3, 0, 3, 1, 3, 3, 2, 1, 0, 1, 1, 0, 0, 1, 1, 2, 2, 0, 3, 2, 1, 0, 2, 0, 0, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 36 and the episode is 2710 and the total_steps are 140649\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 1, 3, 2, 1, 2, 0, 2, 3, 0, 1, 3, 3, 0, 2, 3, 3, 1, 1, 3, 3, 0, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 29 and the episode is 2711 and the total_steps are 140678\n",
      "Done condition: collision\n",
      "[3, 1, 3, 1, 1, 2, 0, 3, 0, 3, 2, 3, 1, 3, 3, 0, 2, 1, 0, 1, 0, 0, 1, 1, 3, 0, 2, 3, 3, 2, 2, 0, 0, 3, 2, 0, 1, 0, 0, 1, 1, 3, 2, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 47 and the episode is 2712 and the total_steps are 140725\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -860     |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2712     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4479     |\n",
      "|    total_timesteps  | 140725   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.8     |\n",
      "|    n_updates        | 22681    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 0, 3, 0, 1, 1, 1, 3, 3, 0, 1, 3, 1, 2, 2, 2, 3, 0, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 2713 and the total_steps are 140751\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 3, 1, 3, 1, 3, 3, 2, 3, 3, 0, 3, 2, 1, 1, 2, 0, 2, 2, 1, 3, 3, 1, 0, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 31 and the episode is 2714 and the total_steps are 140782\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 1, 2, 0, 0, 3, 1, 1, 1, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 3, 0, 1, 2, 3, 2, 3, 3, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 37 and the episode is 2715 and the total_steps are 140819\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 0, 3, 1, 3, 1, 0, 0, 3, 1, 2, 1, 0, 2, 3, 1, 0, 1, 3, 0, 3, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 2716 and the total_steps are 140847\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -859     |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2716     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4484     |\n",
      "|    total_timesteps  | 140847   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.07     |\n",
      "|    n_updates        | 22711    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 1, 0, 2, 3, 3, 0, 0, 2, 3, 3, 1, 3, 1, 3, 2, 1, 1, 1, 1, 0, 2, 0, 0, 2, 1, 2, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 34 and the episode is 2717 and the total_steps are 140881\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 1, 0, 0, 3, 1, 3, 3, 0, 3, 0, 0, 2, 3, 0, 2, 2, 0, 2, 2, 1, 2, 3, 0, 3, 3, 3, 0, 1, 3, 1, 0, 0, 0, 3, 0, 2, 0, 2, 3, 1, 0, 0, 2, 0, 3, 1, 0, 3, 0, 0, 3, 2, 1, 3, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 62 and the episode is 2718 and the total_steps are 140943\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 0, 0, 2, 3, 3, 3, 0, 3, 2, 3, 0, 2, 3, 0, 3, 2, 0, 0, 3, 0, 1, 2, 3, 1, 2, 0, 0, 0, 3, 0, 2, 0, 3, 1, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 42 and the episode is 2719 and the total_steps are 140985\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 0, 3, 3, 1, 3, 0, 3, 0, 2, 0, 2, 0, 2, 1, 3, 2, 2, 0, 1, 1, 3, 2, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 2720 and the total_steps are 141015\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2720     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4491     |\n",
      "|    total_timesteps  | 141015   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 22753    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 2, 1, 0, 2, 1, 2, 2, 1, 3, 0, 0, 2, 1, 0, 2, 0, 0, 2, 1, 0, 3, 2, 3, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 31 and the episode is 2721 and the total_steps are 141046\n",
      "Done condition: collision\n",
      "[3, 0, 0, 3, 1, 2, 3, 0, 3, 2, 1, 1, 0, 1, 3, 0, 1, 2, 3, 0, 2, 0, 1, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 27 and the episode is 2722 and the total_steps are 141073\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 1, 3, 3, 1, 0, 3, 3, 0, 3, 3, 0, 2, 2, 2, 0, 0, 1, 3, 0, 3, 1, 2, 1, 0, 1, 3, 3, 3, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 36 and the episode is 2723 and the total_steps are 141109\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 2, 3, 0, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 2, 0, 3, 0, 0, 2, 0, 2, 3, 0, 3, 3, 0, 0, 1, 2, 2, 0, 2, 3, 0, 1, 0, 2, 2, 3, 2, 1, 2, 1, 0, 2, 2, 2, 0, 0, 1, 3, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -945. And steps were 63 and the episode is 2724 and the total_steps are 141172\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2724     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4498     |\n",
      "|    total_timesteps  | 141172   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 22792    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 1, 2, 0, 1, 0, 3, 0, 3, 0, 3, 3, 3, 0, 3, 0, 0, 1, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 25 and the episode is 2725 and the total_steps are 141197\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 3, 0, 1, 3, 2, 0, 0, 1, 1, 1, 2, 1, 3, 3, 1, 1, 0, 1, 2, 3, 3, 1, 3, 2, 1, 0, 0, 1, 2, 1, 2, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 39 and the episode is 2726 and the total_steps are 141236\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 3, 1, 0, 1, 1, 1, 3, 1, 1, 1, 0, 2, 1, 3, 0, 0, 1, 0, 1, 3, 0, 3, 2, 2, 3, 2, 1, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 3, 2, 2, 3, 1, 1, 0, 0, 3, 1, 0, 0, 2, 1, 2, 2, 1, 1, 1, 3, 3, 2, 1, 1, 1, 0, 0, 1, 0, 0, 1, 2, 2, 1, 1, 3, 1, 0, 3, 1, 1, 1, 2, 2, 0, 2, 2, 2, 1, 0, 1, 0, 3, 3, 1, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -920. And steps were 100 and the episode is 2727 and the total_steps are 141336\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 2, 0, 2, 3, 0, 2, 0, 0, 1, 0, 0, 3, 1, 2, 3, 1, 0, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 25 and the episode is 2728 and the total_steps are 141361\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2728     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4505     |\n",
      "|    total_timesteps  | 141361   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 22840    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 2, 3, 2, 1, 2, 2, 0, 1, 1, 0, 0, 1, 2, 2, 1, 2, 3, 3, 2, 3, 1, 1, 2, 3, 2, 2, 0, 2, 3, 1, 0, 3, 1, 0, 1, 2, 3, 2, 1, 3, 3, 2, 2, 2, 0, 0, 1, 2, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 56 and the episode is 2729 and the total_steps are 141417\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 2, 1, 2, 2, 0, 3, 0, 3, 2, 1, 1, 0, 1, 0, 1, 3, 2, 1, 3, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 0, 0, 3, 2, 3, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 44 and the episode is 2730 and the total_steps are 141461\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 0, 0, 2, 3, 2, 3, 3, 2, 0, 2, 2, 2, 2, 2, 3, 0, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 24 and the episode is 2731 and the total_steps are 141485\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 1, 1, 1, 2, 2, 2, 0, 2, 1, 2, 3, 3, 0, 3, 0, 3, 2, 2, 0, 2, 0, 2, 1, 3, 2, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 2732 and the total_steps are 141518\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2732     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4512     |\n",
      "|    total_timesteps  | 141518   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.64     |\n",
      "|    n_updates        | 22879    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 3, 0, 2, 1, 2, 0, 1, 0, 1, 1, 3, 1, 2, 0, 2, 2, 1, 2, 1, 0, 1, 3, 0, 0, 3, 0, 1, 2, 2, 1, 1, 3, 2, 0, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 42 and the episode is 2733 and the total_steps are 141560\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 2, 3, 3, 0, 0, 0, 3, 0, 2, 0, 2, 0, 3, 2, 0, 2, 3, 1, 2, 1, 2, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 2734 and the total_steps are 141589\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 0, 3, 3, 3, 3, 1, 0, 3, 3, 2, 2, 2, 1, 2, 0, 2, 2, 3, 0, 3, 2, 2, 0, 1, 0, 0, 2, 3, 2, 1, 1, 2, 3, 1, 2, 0, 0, 0, 0, 0, 2, 3, 2, 2, 2, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 53 and the episode is 2735 and the total_steps are 141642\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 1, 0, 0, 1, 0, 3, 2, 0, 0, 3, 1, 0, 1, 3, 3, 3, 2, 3, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 2736 and the total_steps are 141668\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2736     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4518     |\n",
      "|    total_timesteps  | 141668   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 22916    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 3, 3, 2, 1, 3, 3, 0, 0, 1, 0, 3, 0, 3, 2, 3, 3, 2, 2, 2, 3, 3, 2, 3, 2, 2, 3, 3, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was 1032. And steps were 33 and the episode is 2737 and the total_steps are 141701\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 3, 0, 1, 3, 2, 2, 3, 3, 3, 3, 3, 2, 1, 2, 1, 0, 0, 3, 2, 2, 3, 2, 1, 2, 2, 0, 0, 2, 0, 0, 2, 1, 0, 1, 1, 2, 1, 0, 3, 0, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 2738 and the total_steps are 141749\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 2, 1, 1, 0, 3, 3, 1, 3, 0, 1, 3, 2, 1, 2, 3, 3, 0, 3, 1, 0, 0, 2, 3, 0, 3, 0, 0, 2, 1, 3, 2, 1, 1, 2, 1, 1, 2, 3, 3, 3, 0, 0, 2, 2, 2, 0, 2, 2, 3, 2, 2, 1, 3, 3, 3, 2, 1, 1, 0, 0, 3, 3, 2, 0, 2, 3, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 3, 0, 1, 1, 2, 1, 2, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 92 and the episode is 2739 and the total_steps are 141841\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 2, 3, 3, 3, 1, 0, 0, 2, 2, 3, 0, 3, 0, 3, 3, 1, 0, 2, 1, 1, 0, 1, 2, 0, 1, 3, 0, 0, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 2740 and the total_steps are 141877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2740     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4527     |\n",
      "|    total_timesteps  | 141877   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 94.7     |\n",
      "|    n_updates        | 22969    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 1, 2, 0, 3, 2, 2, 0, 0, 1, 3, 3, 0, 1, 3, 2, 1, 0, 2, 0, 2, 1, 0, 0, 2, 2, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 2741 and the total_steps are 141910\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 0, 1, 1, 3, 0, 3, 3, 2, 1, 2, 1, 2, 0, 1, 0, 2, 1, 3, 0, 2, 1, 3, 0, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 31 and the episode is 2742 and the total_steps are 141941\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 0, 2, 1, 0, 3, 3, 2, 0, 2, 3, 3, 3, 0, 0, 0, 0, 3, 2, 2, 3, 2, 2, 2, 1, 2, 3, 3, 3, 0, 2, 2, 1, 0, 2, 1, 1, 0, 3, 0, 3, 1, 1, 2, 3, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 52 and the episode is 2743 and the total_steps are 141993\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 0, 1, 3, 2, 2, 1, 2, 0, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 16 and the episode is 2744 and the total_steps are 142009\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2744     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4533     |\n",
      "|    total_timesteps  | 142009   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 23002    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 3, 0, 0, 3, 3, 3, 2, 0, 3, 2, 3, 1, 2, 2, 1, 2, 2, 3, 2, 0, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2745 and the total_steps are 142037\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 1, 1, 1, 3, 3, 0, 1, 3, 3, 3, 0, 1, 0, 0, 2, 1, 0, 3, 3, 2, 2, 3, 3, 3, 3, 0, 2, 3, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 36 and the episode is 2746 and the total_steps are 142073\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 0, 1, 2, 3, 1, 2, 1, 3, 0, 1, 3, 1, 2, 2, 0, 0, 0, 2, 3, 1, 1, 2, 2, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2747 and the total_steps are 142104\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 2, 2, 0, 2, 3, 3, 0, 3, 1, 3, 1, 2, 2, 0, 0, 2, 2, 2, 0, 1, 0, 1, 1, 2, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2748 and the total_steps are 142136\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2748     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4538     |\n",
      "|    total_timesteps  | 142136   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.6     |\n",
      "|    n_updates        | 23033    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 2, 0, 2, 0, 3, 2, 0, 1, 0, 3, 3, 1, 2, 3, 0, 0, 3, 2, 2, 3, 3, 1, 0, 2, 2, 2, 2, 3, 3, 0, 1, 3, 2, 0, 1, 1, 0, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 45 and the episode is 2749 and the total_steps are 142181\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 3, 1, 3, 0, 0, 0, 2, 2, 3, 1, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 18 and the episode is 2750 and the total_steps are 142199\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 2, 2, 1, 2, 0, 2, 2, 0, 2, 0, 3, 1, 2, 0, 1, 0, 0, 3, 2, 0, 0, 1, 1, 0, 0, 3, 3, 0, 3, 3, 2, 1, 1, 0, 0, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1041. And steps were 43 and the episode is 2751 and the total_steps are 142242\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 0, 2, 0, 0, 3, 3, 0, 3, 2, 3, 3, 3, 1, 0, 1, 1, 1, 3, 3, 3, 2, 3, 1, 0, 2, 0, 1, 3, 2, 3, 0, 1, 0, 2, 2, 2, 3, 1, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 46 and the episode is 2752 and the total_steps are 142288\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2752     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4544     |\n",
      "|    total_timesteps  | 142288   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.2     |\n",
      "|    n_updates        | 23071    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 3, 0, 1, 0, 0, 1, 3, 3, 1, 2, 2, 1, 0, 2, 2, 0, 1, 3, 2, 2, 3, 3, 0, 0, 3, 1, 3, 3, 1, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 37 and the episode is 2753 and the total_steps are 142325\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 3, 0, 2, 3, 3, 3, 1, 1, 1, 0, 0, 2, 2, 3, 0, 2, 3, 1, 3, 0, 3, 0, 1, 3, 0, 1, 0, 3, 1, 3, 1, 1, 0, 1, 0, 1, 3, 1, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 46 and the episode is 2754 and the total_steps are 142371\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 0, 2, 1, 1, 2, 0, 2, 3, 2, 2, 3, 1, 3, 0, 2, 0, 3, 0, 0, 0, 0, 1, 3, 1, 3, 1, 1, 0, 0, 3, 1, 1, 3, 1, 1, 3, 0, 2, 2, 3, 2, 1, 2, 0, 1, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 53 and the episode is 2755 and the total_steps are 142424\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 3, 0, 1, 0, 1, 0, 0, 0, 1, 2, 3, 3, 2, 2, 0, 1, 2, 1, 0, 2, 1, 0, 2, 2, 2, 2, 2, 2, 0, 1, 3, 3, 0, 0, 0, 0, 0, 2, 1, 3, 0, 3, 2, 3, 3, 2, 0, 3, 0, 0, 3, 2, 2, 3, 3, 0, 0, 3, 2, 0, 2, 1, 2, 3, 3, 0, 1, 1, 3, 3, 0, 0, 3, 2, 1, 2, 0, 1, 1, 1, 3, 1, 3, 1, 0, 3, 2, 0, 2, 3, 0, 3, 2, 2, 3, 2, 3, 2, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 106 and the episode is 2756 and the total_steps are 142530\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2756     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4554     |\n",
      "|    total_timesteps  | 142530   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 23132    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 2, 0, 3, 0, 1, 1, 0, 1, 0, 2, 3, 2, 1, 0, 0, 0, 3, 1, 2, 0, 1, 2, 1, 3, 0, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 33 and the episode is 2757 and the total_steps are 142563\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 0, 2, 3, 3, 3, 0, 1, 3, 1, 3, 1, 3, 3, 2, 3, 3, 1, 3, 0, 2, 2, 2, 1, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 31 and the episode is 2758 and the total_steps are 142594\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 3, 3, 0, 1, 0, 3, 1, 1, 0, 1, 2, 0, 0, 2, 1, 2, 1, 0, 3, 1, 2, 3, 0, 0, 0, 1, 1, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 35 and the episode is 2759 and the total_steps are 142629\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 3, 2, 3, 1, 1, 1, 3, 2, 1, 1, 0, 1, 3, 3, 0, 2, 2, 3, 0, 3, 2, 3, 2, 1, 1, 1, 0, 2, 2, 1, 3, 1, 0, 3, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 42 and the episode is 2760 and the total_steps are 142671\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2760     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4560     |\n",
      "|    total_timesteps  | 142671   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.909    |\n",
      "|    n_updates        | 23167    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 2, 0, 1, 0, 0, 1, 0, 1, 1, 1, 3, 1, 2, 0, 3, 0, 3, 0, 3, 2, 1, 1, 0, 1, 0, 0, 1, 2, 0, 0, 1, 0, 1, 0, 0, 2, 3, 3, 3, 3, 2, 1, 2, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 51 and the episode is 2761 and the total_steps are 142722\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 0, 2, 2, 2, 2, 3, 3, 2, 3, 1, 1, 1, 0, 0, 0, 2, 0, 1, 1, 2, 2, 3, 2, 3, 3, 3, 0, 1, 0, 2, 0, 2, 3, 2, 3, 3, 0, 3, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 46 and the episode is 2762 and the total_steps are 142768\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 3, 0, 0, 0, 1, 1, 2, 1, 1, 2, 3, 0, 1, 3, 2, 1, 1, 2, 1, 1, 2, 3, 3, 1, 0, 2, 2, 0, 2, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 37 and the episode is 2763 and the total_steps are 142805\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 0, 0, 3, 0, 0, 3, 0, 0, 2, 2, 3, 1, 2, 1, 2, 1, 1, 0, 1, 2, 2, 3, 3, 2, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 32 and the episode is 2764 and the total_steps are 142837\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2764     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4567     |\n",
      "|    total_timesteps  | 142837   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.66     |\n",
      "|    n_updates        | 23209    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 3, 2, 3, 3, 0, 0, 1, 0, 3, 1, 2, 3, 3, 0, 2, 1, 0, 3, 3, 1, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 2765 and the total_steps are 142865\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 3, 2, 0, 2, 2, 3, 2, 1, 0, 0, 0, 2, 1, 2, 0, 0, 1, 2, 2, 1, 0, 2, 2, 2, 3, 0, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 42 and the episode is 2766 and the total_steps are 142907\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 1, 1, 2, 0, 1, 1, 1, 2, 2, 2, 3, 1, 3, 3, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 22 and the episode is 2767 and the total_steps are 142929\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 2, 0, 2, 2, 0, 2, 3, 2, 3, 2, 3, 3, 3, 2, 3, 1, 2, 3, 2, 3, 3, 0, 2, 0, 2, 1, 2, 0, 2, 3, 3, 3, 0, 3, 3, 2, 1, 2, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 46 and the episode is 2768 and the total_steps are 142975\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2768     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4573     |\n",
      "|    total_timesteps  | 142975   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 23243    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 3, 3, 3, 2, 1, 2, 3, 2, 3, 1, 3, 3, 1, 1, 3, 0, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 22 and the episode is 2769 and the total_steps are 142997\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 3, 3, 3, 0, 2, 1, 3, 1, 2, 0, 1, 3, 1, 2, 1, 3, 2, 1, 2, 3, 0, 2, 2, 0, 1, 0, 3, 0, 2, 2, 0, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 39 and the episode is 2770 and the total_steps are 143036\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 0, 2, 2, 3, 1, 3, 3, 0, 1, 1, 1, 0, 1, 2, 1, 2, 1, 0, 2, 3, 2, 1, 2, 3, 3, 3, 1, 0, 2, 1, 0, 2, 1, 3, 2, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 43 and the episode is 2771 and the total_steps are 143079\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 3, 0, 2, 0, 2, 1, 3, 3, 2, 2, 2, 2, 3, 3, 1, 0, 3, 3, 2, 2, 1, 2, 0, 1, 0, 0, 2, 1, 1, 3, 3, 0, 2, 3, 0, 1, 1, 0, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 46 and the episode is 2772 and the total_steps are 143125\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2772     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4579     |\n",
      "|    total_timesteps  | 143125   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.971    |\n",
      "|    n_updates        | 23281    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 1, 0, 2, 1, 1, 1, 3, 1, 3, 1, 3, 2, 3, 1, 1, 3, 1, 1, 2, 3, 2, 0, 1, 2, 0, 2, 0, 0, 2, 3, 0, 0, 3, 3, 3, 2, 2, 1, 2, 0, 2, 1, 2, 0, 0, 2, 1, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -953. And steps were 55 and the episode is 2773 and the total_steps are 143180\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 2, 2, 0, 3, 0, 3, 1, 3, 2, 3, 1, 2, 2, 3, 3, 1, 2, 3, 3, 3, 3, 1, 1, 1, 3, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 33 and the episode is 2774 and the total_steps are 143213\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 3, 1, 2, 3, 3, 2, 3, 1, 0, 3, 1, 0, 2, 1, 0, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 2775 and the total_steps are 143234\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 3, 3, 0, 3, 3, 1, 1, 3, 2, 2, 2, 1, 2, 2, 3, 0, 1, 2, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 26 and the episode is 2776 and the total_steps are 143260\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2776     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4584     |\n",
      "|    total_timesteps  | 143260   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 23314    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 3, 0, 1, 0, 0, 1, 3, 0, 3, 2, 0, 3, 3, 2, 2, 2, 3, 0, 1, 1, 3, 2, 1, 2, 0, 3, 1, 3, 0, 2, 1, 0, 0, 3, 1, 1, 1, 2, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 3, 1, 1, 0, 3, 3, 0, 1, 1, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 65 and the episode is 2777 and the total_steps are 143325\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 0, 1, 2, 2, 0, 1, 1, 1, 2, 0, 2, 0, 0, 2, 1, 0, 2, 0, 0, 1, 2, 2, 1, 2, 0, 3, 0, 2, 1, 3, 3, 0, 0, 0, 3, 0, 1, 2, 1, 3, 1, 3, 1, 3, 3, 3, 3, 2, 0, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 57 and the episode is 2778 and the total_steps are 143382\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 3, 1, 3, 3, 0, 0, 2, 2, 1, 2, 1, 0, 2, 1, 2, 0, 2, 2, 0, 3, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 28 and the episode is 2779 and the total_steps are 143410\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 3, 2, 3, 2, 1, 0, 0, 3, 2, 0, 1, 3, 1, 2, 0, 2, 1, 1, 0, 1, 1, 3, 0, 2, 1, 0, 1, 1, 1, 3, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 39 and the episode is 2780 and the total_steps are 143449\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -894     |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2780     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4593     |\n",
      "|    total_timesteps  | 143449   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 23362    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 3, 1, 0, 0, 1, 3, 0, 2, 1, 2, 3, 3, 1, 3, 2, 2, 1, 3, 0, 0, 3, 0, 2, 1, 0, 2, 3, 2, 1, 1, 0, 2, 1, 3, 3, 3, 1, 1, 1, 0, 1, 3, 1, 0, 2, 3, 1, 0, 3, 3, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 1, 0, 3, 2, 2, 2, 1, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -950. And steps were 76 and the episode is 2781 and the total_steps are 143525\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 1, 3, 3, 1, 0, 0, 1, 1, 3, 1, 0, 1, 0, 2, 1, 2, 0, 2, 3, 3, 0, 1, 0, 3, 1, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 33 and the episode is 2782 and the total_steps are 143558\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 0, 3, 1, 1, 0, 2, 1, 0, 3, 0, 1, 1, 2, 0, 3, 3, 1, 2, 1, 3, 2, 2, 0, 2, 3, 2, 0, 1, 2, 1, 0, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 39 and the episode is 2783 and the total_steps are 143597\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 2, 1, 2, 3, 0, 1, 2, 2, 0, 3, 2, 3, 2, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 21 and the episode is 2784 and the total_steps are 143618\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -893     |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2784     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4599     |\n",
      "|    total_timesteps  | 143618   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.1     |\n",
      "|    n_updates        | 23404    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 0, 2, 2, 1, 3, 3, 1, 1, 2, 3, 2, 2, 1, 1, 2, 1, 2, 0, 0, 3, 1, 1, 0, 2, 3, 2, 2, 0, 1, 3, 3, 2, 3, 0, 3, 3, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 44 and the episode is 2785 and the total_steps are 143662\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 1, 2, 2, 0, 2, 3, 0, 2, 1, 1, 1, 1, 2, 0, 3, 1, 2, 1, 2, 1, 2, 1, 3, 2, 1, 2, 1, 1, 2, 1, 2, 1, 0, 0, 3, 0, 2, 3, 2, 2, 3, 2, 1, 0, 2, 3, 3, 2, 1, 2, 0, 1, 0, 3, 1, 1, 2, 3, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 66 and the episode is 2786 and the total_steps are 143728\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 1, 0, 3, 3, 0, 1, 2, 1, 3, 0, 2, 1, 2, 0, 0, 2, 2, 2, 3, 0, 3, 0, 2, 3, 1, 3, 2, 1, 3, 3, 0, 3, 0, 3, 0, 3, 0, 1, 1, 2, 0, 0, 1, 0, 1, 0, 1, 3, 2, 2, 3, 2, 0, 1, 1, 1, 1, 1, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 66 and the episode is 2787 and the total_steps are 143794\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 3, 1, 0, 2, 3, 0, 0, 2, 3, 3, 0, 3, 0, 1, 3, 0, 1, 1, 2, 3, 0, 1, 1, 3, 0, 1, 0, 1, 1, 1, 3, 1, 1, 3, 2, 0, 2, 3, 3, 1, 1, 3, 0, 2, 2, 3, 2, 3, 0, 3, 3, 0, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 60 and the episode is 2788 and the total_steps are 143854\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -913     |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2788     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4609     |\n",
      "|    total_timesteps  | 143854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 23463    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 2, 2, 3, 3, 1, 0, 2, 2, 3, 1, 3, 3, 3, 0, 0, 2, 3, 1, 3, 0, 1, 3, 1, 2, 2, 0, 1, 0, 0, 0, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 38 and the episode is 2789 and the total_steps are 143892\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 3, 2, 3, 0, 3, 0, 2, 3, 3, 3, 1, 0, 3, 1, 3, 0, 2, 1, 2, 3, 0, 3, 1, 0, 3, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 33 and the episode is 2790 and the total_steps are 143925\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 3, 0, 1, 3, 2, 0, 0, 3, 3, 0, 3, 1, 1, 3, 1, 0, 3, 1, 1, 2, 0, 3, 2, 2, 2, 0, 1, 3, 3, 2, 1, 1, 3, 0, 1, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 44 and the episode is 2791 and the total_steps are 143969\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 0, 1, 1, 1, 1, 2, 2, 1, 1, 0, 2, 2, 0, 1, 3, 3, 0, 2, 1, 3, 3, 3, 2, 2, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 32 and the episode is 2792 and the total_steps are 144001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -912     |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2792     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4615     |\n",
      "|    total_timesteps  | 144001   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 23500    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 1, 0, 2, 2, 1, 0, 0, 0, 3, 3, 3, 2, 3, 1, 2, 1, 3, 3, 2, 2, 2, 3, 2, 0, 2, 0, 2, 3, 3, 1, 3, 0, 1, 2, 1, 3, 0, 1, 3, 1, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 48 and the episode is 2793 and the total_steps are 144049\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 1, 2, 1, 2, 3, 2, 2, 2, 2, 2, 1, 3, 3, 3, 2, 0, 1, 2, 0, 3, 2, 2, 0, 0, 1, 2, 1, 0, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 36 and the episode is 2794 and the total_steps are 144085\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 0, 2, 1, 2, 1, 3, 3, 1, 0, 3, 1, 0, 2, 2, 0, 1, 3, 3, 2, 0, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 35 and the episode is 2795 and the total_steps are 144120\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 2, 0, 3, 3, 0, 0, 1, 0, 1, 2, 2, 3, 2, 3, 3, 2, 3, 2, 0, 0, 3, 1, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 30 and the episode is 2796 and the total_steps are 144150\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -912     |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2796     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4621     |\n",
      "|    total_timesteps  | 144150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 23537    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 3, 1, 0, 2, 1, 0, 2, 3, 0, 2, 1, 3, 3, 3, 1, 3, 0, 0, 3, 3, 1, 2, 1, 2, 2, 2, 2, 2, 2, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1035. And steps were 37 and the episode is 2797 and the total_steps are 144187\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 0, 2, 2, 0, 2, 2, 0, 2, 1, 0, 3, 2, 0, 3, 3, 1, 1, 2, 3, 1, 1, 0, 2, 1, 0, 1, 1, 1, 2, 3, 1, 2, 1, 0, 1, 0, 0, 3, 2, 0, 3, 2, 1, 2, 1, 3, 3, 3, 2, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 57 and the episode is 2798 and the total_steps are 144244\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 1, 3, 2, 0, 1, 3, 3, 3, 1, 0, 3, 0, 3, 2, 2, 2, 3, 3, 2, 3, 0, 0, 1, 0, 3, 1, 3, 1, 1, 2, 3, 0, 2, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 41 and the episode is 2799 and the total_steps are 144285\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 2, 3, 1, 3, 1, 2, 3, 2, 1, 3, 3, 2, 0, 0, 3, 0, 2, 1, 0, 3, 2, 0, 1, 0, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 2800 and the total_steps are 144317\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -932     |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2800     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4628     |\n",
      "|    total_timesteps  | 144317   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.77     |\n",
      "|    n_updates        | 23579    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 3, 1, 3, 1, 1, 1, 3, 1, 3, 1, 0, 3, 3, 3, 2, 2, 3, 3, 2, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 2801 and the total_steps are 144342\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 3, 1, 0, 0, 3, 1, 3, 3, 0, 1, 3, 2, 0, 2, 0, 3, 3, 1, 1, 0, 0, 2, 1, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 31 and the episode is 2802 and the total_steps are 144373\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 1, 2, 1, 3, 1, 2, 1, 0, 3, 2, 2, 1, 2, 3, 1, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 2803 and the total_steps are 144403\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 3, 1, 2, 3, 3, 0, 3, 2, 2, 2, 1, 3, 1, 0, 1, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 23 and the episode is 2804 and the total_steps are 144426\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -913     |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2804     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4633     |\n",
      "|    total_timesteps  | 144426   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.06     |\n",
      "|    n_updates        | 23606    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 3, 1, 1, 2, 1, 1, 1, 0, 3, 0, 3, 0, 1, 2, 3, 1, 1, 0, 3, 3, 3, 0, 2, 3, 2, 2, 0, 3, 3, 2, 1, 3, 2, 0, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 42 and the episode is 2805 and the total_steps are 144468\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 1, 1, 1, 0, 2, 1, 1, 3, 1, 0, 2, 1, 0, 2, 3, 3, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 2806 and the total_steps are 144492\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 2, 1, 3, 3, 1, 0, 2, 1, 1, 1, 0, 3, 2, 0, 3, 1, 0, 1, 2, 0, 2, 3, 3, 3, 2, 3, 2, 2, 3, 0, 3, 0, 3, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 41 and the episode is 2807 and the total_steps are 144533\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 0, 0, 0, 1, 2, 2, 0, 0, 2, 1, 0, 0, 2, 0, 2, 1, 0, 1, 2, 3, 0, 2, 1, 0, 1, 0, 1, 0, 3, 2, 1, 3, 0, 1, 3, 2, 3, 2, 3, 0, 0, 0, 1, 0, 3, 0, 0, 2, 1, 2, 2, 3, 2, 3, 0, 3, 0, 3, 3, 2, 3, 3, 0, 2, 3, 0, 3, 1, 1, 0, 0, 0, 0, 1, 3, 3, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 84 and the episode is 2808 and the total_steps are 144617\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -912     |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2808     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4641     |\n",
      "|    total_timesteps  | 144617   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.9      |\n",
      "|    n_updates        | 23654    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 3, 2, 0, 3, 0, 3, 1, 0, 1, 3, 1, 0, 0, 1, 2, 1, 3, 1, 0, 1, 3, 3, 3, 2, 3, 2, 0, 1, 2, 0, 3, 1, 3, 2, 1, 3, 3, 3, 2, 3, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 48 and the episode is 2809 and the total_steps are 144665\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 1, 1, 2, 3, 3, 3, 2, 2, 2, 2, 0, 3, 2, 1, 0, 3, 0, 0, 0, 1, 2, 3, 2, 3, 1, 1, 0, 3, 0, 0, 2, 3, 0, 0, 2, 1, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 44 and the episode is 2810 and the total_steps are 144709\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 2, 3, 0, 3, 1, 1, 0, 1, 2, 2, 2, 2, 2, 0, 1, 2, 1, 3, 3, 2, 1, 3, 3, 0, 0, 1, 0, 2, 3, 0, 0, 3, 1, 3, 1, 3, 2, 1, 2, 0, 3, 3, 1, 0, 2, 0, 2, 2, 2, 1, 3, 2, 2, 0, 3, 2, 1, 1, 2, 3, 2, 0, 3, 3, 2, 2, 3, 2, 3, 3, 1, 1, 2, 2, 1, 1, 2, 1, 1, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -923. And steps were 87 and the episode is 2811 and the total_steps are 144796\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 3, 3, 1, 2, 2, 2, 0, 1, 3, 1, 0, 2, 1, 2, 3, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 33 and the episode is 2812 and the total_steps are 144829\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -912     |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2812     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4649     |\n",
      "|    total_timesteps  | 144829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 23707    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 0, 0, 0, 0, 2, 2, 2, 1, 3, 2, 1, 2, 0, 1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 0, 2, 2, 3, 0, 3, 0, 3, 0, 0, 0, 2, 0, 1, 0, 2, 0, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 48 and the episode is 2813 and the total_steps are 144877\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 3, 1, 1, 3, 3, 2, 3, 3, 0, 2, 3, 1, 3, 3, 2, 1, 1, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 25 and the episode is 2814 and the total_steps are 144902\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 3, 3, 2, 1, 3, 1, 2, 0, 3, 0, 1, 2, 3, 3, 1, 0, 2, 1, 2, 1, 0, 0, 2, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2815 and the total_steps are 144933\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 3, 1, 2, 2, 3, 0, 0, 1, 0, 1, 0, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 1, 2, 2, 3, 3, 0, 3, 2, 0, 2, 2, 1, 0, 0, 1, 0, 3, 1, 1, 3, 2, 3, 0, 0, 1, 3, 1, 1, 1, 3, 3, 1, 0, 3, 1, 0, 2, 1, 2, 0, 2, 3, 1, 0, 1, 1, 3, 1, 3, 3, 1, 2, 2, 0, 3, 1, 0, 0, 1, 2, 3, 2, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1056. And steps were 92 and the episode is 2816 and the total_steps are 145025\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -913     |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2816     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4657     |\n",
      "|    total_timesteps  | 145025   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 23756    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 2, 3, 3, 3, 3, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2817 and the total_steps are 145053\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 2, 3, 1, 0, 0, 3, 2, 2, 3, 3, 0, 0, 0, 3, 2, 2, 0, 0, 1, 3, 0, 1, 0, 2, 2, 1, 1, 1, 0, 2, 3, 0, 0, 2, 1, 1, 0, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 45 and the episode is 2818 and the total_steps are 145098\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 3, 3, 1, 0, 0, 3, 1, 1, 1, 3, 2, 3, 1, 2, 2, 0, 3, 2, 3, 1, 3, 2, 0, 3, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 32 and the episode is 2819 and the total_steps are 145130\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 0, 3, 1, 0, 0, 2, 3, 0, 2, 0, 1, 1, 1, 3, 1, 0, 0, 3, 1, 3, 3, 2, 2, 1, 0, 3, 3, 2, 3, 1, 1, 0, 3, 3, 2, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 43 and the episode is 2820 and the total_steps are 145173\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -913     |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2820     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4664     |\n",
      "|    total_timesteps  | 145173   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.9     |\n",
      "|    n_updates        | 23793    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 0, 3, 3, 2, 0, 2, 0, 2, 0, 0, 3, 0, 2, 1, 2, 2, 1, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 46 and the episode is 2821 and the total_steps are 145219\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 3, 2, 0, 3, 3, 0, 1, 2, 3, 3, 3, 2, 3, 1, 0, 1, 2, 2, 0, 2, 2, 3, 1, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 31 and the episode is 2822 and the total_steps are 145250\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 1, 3, 2, 3, 1, 1, 0, 3, 1, 2, 2, 2, 0, 1, 3, 0, 1, 0, 0, 1, 0, 3, 1, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 31 and the episode is 2823 and the total_steps are 145281\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 0, 1, 1, 2, 0, 2, 1, 0, 2, 3, 3, 0, 0, 1, 1, 1, 0, 1, 3, 3, 0, 0, 1, 2, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 2824 and the total_steps are 145313\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -913     |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2824     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4670     |\n",
      "|    total_timesteps  | 145313   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.23     |\n",
      "|    n_updates        | 23828    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 3, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 2, 2, 0, 3, 1, 3, 3, 3, 3, 2, 1, 1, 2, 0, 0, 1, 2, 2, 0, 0, 1, 0, 0, 2, 1, 0, 1, 1, 3, 2, 2, 0, 1, 0, 0, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 56 and the episode is 2825 and the total_steps are 145369\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 3, 2, 2, 3, 3, 1, 0, 3, 0, 1, 3, 3, 0, 0, 3, 0, 1, 0, 2, 3, 0, 1, 1, 1, 3, 3, 2, 1, 1, 3, 1, 3, 3, 1, 3, 2, 2, 2, 0, 0, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 48 and the episode is 2826 and the total_steps are 145417\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 3, 3, 1, 2, 1, 1, 1, 3, 2, 1, 2, 0, 0, 0, 0, 0, 2, 2, 3, 0, 0, 0, 1, 1, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 2827 and the total_steps are 145449\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 1, 2, 3, 1, 0, 2, 0, 0, 0, 0, 3, 0, 3, 2, 3, 1, 2, 0, 3, 2, 3, 1, 3, 2, 0, 3, 3, 1, 3, 2, 2, 2, 1, 0, 0, 2, 2, 3, 0, 1, 1, 3, 1, 2, 2, 1, 1, 0, 0, 0, 0, 3, 0, 2, 0, 1, 3, 1, 3, 2, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 68 and the episode is 2828 and the total_steps are 145517\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -915     |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2828     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4679     |\n",
      "|    total_timesteps  | 145517   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 23879    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 0, 2, 3, 3, 0, 1, 0, 2, 2, 0, 3, 0, 1, 2, 3, 3, 2, 1, 0, 2, 3, 1, 3, 3, 0, 1, 3, 2, 3, 3, 2, 0, 3, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 41 and the episode is 2829 and the total_steps are 145558\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 1, 0, 2, 0, 1, 2, 2, 3, 3, 1, 3, 0, 0, 2, 1, 0, 3, 1, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 27 and the episode is 2830 and the total_steps are 145585\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 0, 2, 2, 0, 0, 1, 2, 2, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 16 and the episode is 2831 and the total_steps are 145601\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 0, 3, 2, 0, 3, 1, 3, 1, 1, 2, 3, 3, 0, 1, 3, 0, 3, 1, 0, 3, 2, 1, 0, 0, 3, 1, 0, 1, 1, 2, 3, 1, 2, 0, 2, 0, 3, 2, 3, 2, 0, 0, 2, 2, 3, 0, 3, 1, 2, 3, 2, 1, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1058. And steps were 60 and the episode is 2832 and the total_steps are 145661\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -914     |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2832     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4685     |\n",
      "|    total_timesteps  | 145661   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2        |\n",
      "|    n_updates        | 23915    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 0, 2, 3, 0, 0, 3, 3, 0, 2, 1, 1, 1, 1, 2, 2, 2, 0, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 25 and the episode is 2833 and the total_steps are 145686\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 2, 3, 1, 0, 2, 3, 0, 1, 3, 1, 3, 0, 0, 2, 0, 2, 0, 1, 1, 3, 3, 3, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 30 and the episode is 2834 and the total_steps are 145716\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 3, 3, 2, 2, 2, 1, 2, 0, 2, 1, 1, 0, 3, 3, 2, 0, 2, 0, 2, 2, 0, 0, 3, 2, 2, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 33 and the episode is 2835 and the total_steps are 145749\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 3, 0, 3, 1, 3, 3, 3, 3, 1, 3, 3, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 3, 3, 2, 0, 3, 3, 1, 0, 2, 0, 0, 2, 2, 0, 3, 1, 3, 2, 0, 2, 2, 3, 0, 3, 2, 2, 3, 2, 3, 3, 2, 2, 3, 1, 1, 0, 2, 3, 0, 0, 3, 1, 3, 0, 2, 2, 1, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 76 and the episode is 2836 and the total_steps are 145825\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -914     |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2836     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4692     |\n",
      "|    total_timesteps  | 145825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 23956    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 3, 2, 3, 2, 0, 1, 3, 3, 3, 1, 2, 2, 3, 0, 0, 3, 0, 3, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 2837 and the total_steps are 145849\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 3, 1, 0, 0, 3, 3, 0, 3, 3, 2, 3, 3, 2, 1, 3, 0, 3, 3, 2, 1, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 2838 and the total_steps are 145875\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 0, 3, 0, 0, 0, 3, 3, 1, 1, 3, 1, 2, 1, 2, 3, 2, 0, 2, 3, 3, 2, 3, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 30 and the episode is 2839 and the total_steps are 145905\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 1, 1, 3, 2, 3, 3, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 3, 2, 0, 2, 0, 3, 3, 0, 3, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 2840 and the total_steps are 145938\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -894     |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2840     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4697     |\n",
      "|    total_timesteps  | 145938   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.63     |\n",
      "|    n_updates        | 23984    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 1, 1, 3, 3, 3, 1, 2, 0, 2, 2, 1, 3, 0, 1, 2, 1, 2, 0, 0, 0, 3, 1, 0, 2, 1, 0, 2, 3, 2, 0, 0, 0, 2, 2, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 43 and the episode is 2841 and the total_steps are 145981\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 2, 1, 3, 3, 3, 3, 3, 2, 2, 3, 1, 0, 1, 1, 1, 0, 3, 1, 1, 1, 2, 0, 2, 3, 1, 0, 3, 0, 1, 1, 2, 0, 0, 3, 1, 3, 0, 2, 2, 2, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 48 and the episode is 2842 and the total_steps are 146029\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 1, 1, 2, 2, 3, 0, 1, 3, 3, 2, 1, 3, 3, 1, 0, 3, 3, 0, 3, 3, 0, 0, 0, 1, 1, 1, 0, 1, 1, 3, 1, 2, 3, 3, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 42 and the episode is 2843 and the total_steps are 146071\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 1, 3, 2, 1, 3, 1, 3, 0, 3, 0, 1, 3, 0, 2, 3, 0, 0, 3, 3, 2, 0, 0, 3, 2, 0, 3, 3, 3, 1, 2, 0, 0, 1, 2, 1, 2, 3, 3, 1, 0, 1, 3, 1, 1, 1, 0, 2, 3, 0, 0, 0, 3, 3, 1, 3, 0, 0, 1, 0, 0, 3, 0, 3, 2, 3, 3, 3, 2, 3, 1, 0, 1, 3, 3, 1, 1, 3, 3, 0, 0, 1, 3, 3, 0, 0, 2, 3, 2, 1, 2, 1, 0, 3, 1, 3, 3, 2, 3, 0, 3, 2, 0, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1062. And steps were 110 and the episode is 2844 and the total_steps are 146181\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -893     |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2844     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4707     |\n",
      "|    total_timesteps  | 146181   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.38     |\n",
      "|    n_updates        | 24045    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 3, 0, 1, 0, 2, 0, 0, 1, 3, 2, 2, 3, 2, 0, 2, 3, 3, 2, 2, 2, 2, 3, 2, 2, 1, 0, 3, 1, 3, 1, 3, 1, 3, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 40 and the episode is 2845 and the total_steps are 146221\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 0, 2, 0, 0, 3, 0, 1, 0, 2, 2, 3, 0, 1, 2, 0, 3, 1, 0, 1, 2, 0, 3, 2, 2, 0, 0, 1, 3, 1, 1, 3, 3, 1, 3, 1, 1, 3, 2, 0, 1, 2, 3, 3, 3, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 52 and the episode is 2846 and the total_steps are 146273\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 0, 3, 3, 2, 2, 1, 0, 2, 1, 3, 2, 2, 1, 1, 1, 0, 2, 0, 3, 0, 1, 3, 3, 3, 3, 1, 2, 1, 1, 1, 3, 2, 0, 3, 0, 3, 0, 1, 2, 1, 2, 2, 0, 2, 1, 2, 1, 3, 3, 1, 3, 0, 1, 0, 0, 1, 0, 2, 2, 1, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 0, 1, 0, 3, 2, 2, 2, 3, 1, 2, 0, 3, 3, 2, 0, 1, 0, 0, 3, 2, 1, 3, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 3, 2, 0, 1, 3, 1, 1, 2, 3, 3, 2, 0, 3, 2, 2, 1, 2, 2, 2, 1, 3, 0, 0, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -890. And steps were 134 and the episode is 2847 and the total_steps are 146407\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 1, 0, 1, 1, 3, 3, 2, 0, 2, 3, 0, 2, 2, 2, 0, 2, 0, 2, 0, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 27 and the episode is 2848 and the total_steps are 146434\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43       |\n",
      "|    ep_rew_mean      | -891     |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2848     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4717     |\n",
      "|    total_timesteps  | 146434   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 94.8     |\n",
      "|    n_updates        | 24108    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 3, 2, 2, 3, 1, 3, 1, 1, 2, 2, 0, 1, 2, 0, 3, 2, 3, 3, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 26 and the episode is 2849 and the total_steps are 146460\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 2, 1, 1, 2, 3, 2, 1, 3, 1, 1, 3, 2, 2, 1, 0, 2, 2, 3, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 2850 and the total_steps are 146486\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 3, 0, 1, 2, 2, 1, 0, 1, 2, 1, 1, 1, 2, 1, 2, 0, 1, 3, 2, 0, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2851 and the total_steps are 146514\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 1, 0, 0, 2, 0, 1, 0, 3, 0, 0, 3, 2, 0, 0, 3, 0, 0, 0, 2, 1, 2, 2, 0, 2, 1, 1, 2, 1, 3, 2, 3, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 39 and the episode is 2852 and the total_steps are 146553\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.6     |\n",
      "|    ep_rew_mean      | -891     |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2852     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4722     |\n",
      "|    total_timesteps  | 146553   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.7     |\n",
      "|    n_updates        | 24138    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 2, 2, 2, 3, 0, 1, 0, 1, 0, 1, 2, 2, 2, 1, 0, 1, 0, 3, 1, 1, 1, 2, 1, 1, 3, 3, 0, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 35 and the episode is 2853 and the total_steps are 146588\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 0, 1, 1, 2, 3, 0, 0, 1, 0, 1, 3, 0, 0, 3, 0, 3, 2, 1, 2, 0, 2, 2, 0, 3, 0, 3, 0, 1, 1, 0, 3, 0, 3, 2, 3, 2, 2, 3, 3, 2, 1, 0, 0, 3, 3, 1, 0, 3, 2, 3, 3, 1, 3, 0, 0, 0, 1, 0, 0, 3, 0, 2, 1, 1, 0, 0, 2, 2, 2, 1, 2, 3, 2, 1, 0, 2, 0, 0, 3, 0, 3, 3, 1, 0, 3, 1, 3, 2, 3, 2, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1078. And steps were 98 and the episode is 2854 and the total_steps are 146686\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 0, 2, 1, 1, 0, 3, 0, 3, 2, 1, 3, 0, 2, 2, 0, 2, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 24 and the episode is 2855 and the total_steps are 146710\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 3, 0, 2, 2, 1, 2, 3, 1, 3, 3, 1, 2, 2, 0, 1, 1, 0, 0, 1, 2, 1, 1, 1, 1, 1, 3, 2, 3, 3, 1, 1, 0, 0, 2, 2, 3, 0, 0, 2, 1, 3, 2, 0, 3, 2, 0, 1, 2, 2, 3, 2, 0, 2, 0, 3, 2, 2, 1, 0, 2, 3, 1, 0, 0, 1, 0, 3, 1, 2, 3, 0, 3, 3, 3, 3, 0, 3, 2, 2, 2, 3, 3, 2, 3, 2, 1, 3, 3, 0, 3, 1, 2, 3, 2, 2, 0, 0, 0, 2, 1, 3, 2, 2, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1067. And steps were 111 and the episode is 2856 and the total_steps are 146821\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.9     |\n",
      "|    ep_rew_mean      | -893     |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2856     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4733     |\n",
      "|    total_timesteps  | 146821   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.33     |\n",
      "|    n_updates        | 24205    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 1, 0, 3, 3, 1, 0, 2, 0, 2, 1, 0, 3, 2, 1, 0, 1, 0, 0, 0, 2, 0, 2, 3, 2, 2, 3, 1, 1, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 36 and the episode is 2857 and the total_steps are 146857\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 0, 2, 2, 2, 3, 0, 3, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 15 and the episode is 2858 and the total_steps are 146872\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 2, 0, 0, 1, 3, 1, 0, 1, 1, 3, 3, 2, 3, 1, 0, 1, 1, 1, 2, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 27 and the episode is 2859 and the total_steps are 146899\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 2, 2, 0, 0, 3, 2, 0, 0, 0, 0, 3, 0, 1, 3, 2, 1, 1, 0, 2, 3, 0, 1, 2, 1, 2, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was 972. And steps were 31 and the episode is 2860 and the total_steps are 146930\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.6     |\n",
      "|    ep_rew_mean      | -874     |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2860     |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 4738     |\n",
      "|    total_timesteps  | 146930   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 24232    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 1, 3, 1, 3, 3, 0, 0, 0, 2, 3, 2, 0, 0, 0, 3, 2, 2, 0, 0, 1, 1, 2, 2, 3, 0, 1, 3, 2, 2, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 38 and the episode is 2861 and the total_steps are 146968\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 1, 3, 1, 0, 0, 0, 2, 1, 1, 1, 2, 0, 3, 3, 0, 2, 1, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 25 and the episode is 2862 and the total_steps are 146993\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 1, 0, 1, 0, 2, 3, 2, 0, 3, 3, 0, 3, 2, 0, 0, 2, 1, 3, 2, 2, 2, 3, 0, 3, 3, 3, 2, 1, 2, 3, 2, 1, 1, 1, 3, 3, 2, 0, 2, 2, 0, 0, 2, 3, 0, 2, 3, 3, 1, 2, 1, 2, 0, 3, 1, 3, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 64 and the episode is 2863 and the total_steps are 147057\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 2, 2, 1, 0, 2, 1, 0, 0, 1, 0, 3, 3, 2, 3, 2, 2, 0, 0, 2, 2, 0, 1, 3, 2, 1, 1, 0, 0, 2, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 37 and the episode is 2864 and the total_steps are 147094\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.6     |\n",
      "|    ep_rew_mean      | -874     |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2864     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4745     |\n",
      "|    total_timesteps  | 147094   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.43     |\n",
      "|    n_updates        | 24273    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 3, 0, 0, 3, 2, 1, 2, 2, 1, 3, 1, 2, 2, 1, 3, 0, 0, 0, 3, 0, 1, 3, 2, 2, 0, 2, 0, 2, 3, 1, 0, 1, 1, 0, 3, 0, 0, 1, 0, 1, 3, 0, 3, 2, 1, 1, 0, 3, 1, 3, 2, 3, 2, 0, 3, 1, 2, 1, 2, 2, 3, 1, 1, 1, 0, 0, 2, 0, 3, 3, 0, 3, 1, 2, 3, 0, 0, 0, 1, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -931. And steps were 87 and the episode is 2865 and the total_steps are 147181\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 2, 3, 3, 3, 2, 0, 0, 3, 2, 0, 2, 0, 1, 2, 2, 0, 2, 3, 3, 2, 3, 1, 2, 1, 0, 0, 0, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 35 and the episode is 2866 and the total_steps are 147216\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 0, 3, 1, 1, 3, 1, 3, 3, 2, 2, 2, 1, 3, 1, 2, 0, 1, 1, 3, 0, 2, 0, 1, 1, 0, 0, 2, 1, 3, 2, 3, 2, 3, 3, 1, 2, 2, 1, 3, 0, 0, 0, 0, 1, 3, 3, 1, 1, 0, 3, 2, 0, 1, 1, 0, 2, 3, 2, 2, 0, 1, 2, 1, 3, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 72 and the episode is 2867 and the total_steps are 147288\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 0, 0, 3, 3, 1, 3, 3, 2, 3, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 17 and the episode is 2868 and the total_steps are 147305\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.3     |\n",
      "|    ep_rew_mean      | -874     |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2868     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4754     |\n",
      "|    total_timesteps  | 147305   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31       |\n",
      "|    n_updates        | 24326    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 3, 2, 3, 0, 1, 0, 3, 1, 0, 0, 3, 1, 2, 3, 3, 1, 2, 1, 0, 1, 0, 1, 2, 3, 1, 3, 1, 0, 3, 2, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 0, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 49 and the episode is 2869 and the total_steps are 147354\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 3, 3, 3, 1, 1, 0, 0, 0, 2, 3, 3, 3, 2, 2, 3, 2, 3, 3, 3, 1, 0, 2, 0, 1, 0, 0, 0, 3, 2, 3, 3, 2, 2, 1, 1, 0, 0, 3, 2, 1, 0, 2, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 50 and the episode is 2870 and the total_steps are 147404\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 0, 2, 1, 1, 2, 2, 3, 2, 3, 1, 3, 0, 0, 3, 3, 2, 3, 0, 0, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 27 and the episode is 2871 and the total_steps are 147431\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 1, 1, 2, 2, 3, 2, 3, 3, 0, 3, 0, 1, 2, 0, 2, 2, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 2872 and the total_steps are 147455\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.3     |\n",
      "|    ep_rew_mean      | -894     |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2872     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4760     |\n",
      "|    total_timesteps  | 147455   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.454    |\n",
      "|    n_updates        | 24363    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 2, 0, 1, 3, 2, 0, 1, 0, 2, 1, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 18 and the episode is 2873 and the total_steps are 147473\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 2, 2, 3, 2, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 25 and the episode is 2874 and the total_steps are 147498\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 3, 0, 3, 1, 3, 1, 2, 2, 2, 0, 3, 0, 2, 2, 1, 2, 2, 1, 2, 3, 2, 3, 1, 1, 2, 3, 1, 1, 1, 1, 2, 3, 3, 3, 2, 3, 2, 0, 3, 1, 2, 3, 1, 0, 2, 1, 1, 2, 3, 3, 0, 3, 1, 2, 2, 3, 0, 0, 2, 2, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1066. And steps were 68 and the episode is 2875 and the total_steps are 147566\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 1, 0, 2, 0, 2, 0, 1, 2, 3, 0, 0, 0, 2, 3, 2, 2, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 3, 1, 0, 2, 3, 1, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 40 and the episode is 2876 and the total_steps are 147606\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.5     |\n",
      "|    ep_rew_mean      | -915     |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2876     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4766     |\n",
      "|    total_timesteps  | 147606   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 24401    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 1, 1, 0, 0, 0, 1, 0, 3, 2, 3, 3, 3, 0, 3, 1, 0, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 22 and the episode is 2877 and the total_steps are 147628\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 2, 0, 0, 1, 2, 2, 2, 3, 0, 2, 3, 1, 1, 3, 0, 3, 3, 1, 2, 0, 2, 0, 2, 3, 1, 3, 2, 3, 0, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 37 and the episode is 2878 and the total_steps are 147665\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 3, 0, 2, 2, 1, 0, 1, 0, 0, 2, 2, 0, 3, 1, 2, 2, 3, 3, 2, 2, 1, 0, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 30 and the episode is 2879 and the total_steps are 147695\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 1, 0, 1, 2, 1, 3, 0, 0, 1, 2, 3, 0, 3, 1, 3, 1, 2, 2, 1, 0, 2, 2, 3, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 31 and the episode is 2880 and the total_steps are 147726\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.8     |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2880     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4771     |\n",
      "|    total_timesteps  | 147726   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 24431    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 1, 0, 3, 1, 3, 0, 0, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 0, 0, 2, 0, 2, 3, 2, 1, 3, 3, 3, 1, 1, 2, 2, 1, 1, 0, 0, 3, 2, 0, 0, 2, 0, 0, 1, 0, 3, 3, 3, 0, 2, 3, 1, 0, 2, 0, 3, 1, 3, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -950. And steps were 66 and the episode is 2881 and the total_steps are 147792\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 1, 2, 2, 2, 0, 1, 3, 2, 0, 3, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 17 and the episode is 2882 and the total_steps are 147809\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 1, 0, 2, 3, 2, 0, 2, 1, 2, 1, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 18 and the episode is 2883 and the total_steps are 147827\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 2, 2, 2, 0, 3, 3, 0, 2, 2, 1, 1, 1, 1, 1, 3, 0, 1, 2, 0, 0, 1, 2, 1, 3, 3, 2, 0, 1, 2, 2, 2, 0, 3, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 2884 and the total_steps are 147868\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2884     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4777     |\n",
      "|    total_timesteps  | 147868   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.93     |\n",
      "|    n_updates        | 24466    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 2, 0, 2, 3, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 1, 1, 3, 0, 0, 1, 0, 1, 0, 3, 3, 2, 1, 3, 0, 3, 0, 3, 3, 2, 1, 3, 0, 2, 0, 0, 0, 2, 3, 3, 1, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 57 and the episode is 2885 and the total_steps are 147925\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 2, 2, 1, 1, 0, 0, 0, 3, 2, 0, 0, 1, 0, 2, 1, 2, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 2886 and the total_steps are 147949\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 3, 1, 0, 0, 0, 1, 0, 2, 1, 1, 2, 0, 1, 2, 2, 2, 2, 1, 3, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 2887 and the total_steps are 147977\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 3, 3, 0, 2, 1, 0, 1, 1, 2, 2, 2, 2, 0, 1, 3, 1, 2, 0, 0, 0, 0, 0, 2, 3, 3, 3, 2, 1, 1, 2, 1, 1, 3, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 41 and the episode is 2888 and the total_steps are 148018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2888     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4784     |\n",
      "|    total_timesteps  | 148018   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 24504    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 1, 0, 1, 0, 2, 0, 3, 1, 0, 3, 0, 3, 3, 1, 3, 2, 2, 1, 3, 2, 3, 0, 0, 3, 1, 1, 2, 0, 1, 2, 1, 1, 2, 3, 3, 3, 3, 0, 0, 2, 2, 2, 0, 2, 3, 3, 1, 3, 0, 3, 2, 0, 2, 0, 1, 3, 0, 2, 1, 2, 2, 1, 3, 3, 0, 3, 3, 0, 2, 0, 0, 2, 0, 3, 2, 3, 2, 0, 3, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 87 and the episode is 2889 and the total_steps are 148105\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 1, 2, 3, 2, 2, 3, 2, 2, 3, 0, 3, 0, 0, 0, 3, 1, 2, 2, 3, 2, 1, 2, 3, 1, 1, 2, 2, 1, 0, 0, 2, 1, 3, 2, 3, 1, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 44 and the episode is 2890 and the total_steps are 148149\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 3, 2, 0, 2, 3, 3, 2, 1, 3, 0, 3, 1, 0, 3, 1, 1, 0, 3, 1, 2, 2, 3, 1, 0, 0, 3, 2, 1, 2, 1, 2, 2, 0, 3, 3, 0, 2, 2, 0, 1, 3, 0, 2, 0, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 2891 and the total_steps are 148201\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 2, 1, 3, 2, 3, 1, 0, 2, 0, 1, 1, 0, 2, 0, 3, 0, 3, 1, 1, 2, 2, 3, 1, 2, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2892 and the total_steps are 148233\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2892     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4793     |\n",
      "|    total_timesteps  | 148233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.624    |\n",
      "|    n_updates        | 24558    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 3, 3, 1, 3, 1, 2, 3, 0, 0, 2, 0, 3, 1, 2, 2, 1, 3, 2, 2, 1, 2, 0, 2, 1, 3, 0, 1, 1, 1, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 37 and the episode is 2893 and the total_steps are 148270\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 3, 1, 3, 1, 1, 0, 1, 0, 2, 3, 2, 3, 1, 0, 2, 2, 0, 2, 1, 2, 2, 2, 3, 0, 0, 1, 2, 2, 2, 1, 0, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 39 and the episode is 2894 and the total_steps are 148309\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 2, 1, 0, 0, 3, 0, 2, 0, 2, 3, 2, 3, 1, 0, 2, 2, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 24 and the episode is 2895 and the total_steps are 148333\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 1, 1, 3, 1, 1, 1, 0, 0, 1, 1, 0, 2, 0, 2, 2, 3, 2, 0, 1, 0, 1, 3, 3, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 3, 1, 3, 2, 3, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 46 and the episode is 2896 and the total_steps are 148379\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2896     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4798     |\n",
      "|    total_timesteps  | 148379   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.916    |\n",
      "|    n_updates        | 24594    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 2, 2, 3, 0, 0, 3, 3, 3, 3, 2, 1, 1, 3, 3, 2, 0, 1, 0, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 26 and the episode is 2897 and the total_steps are 148405\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 3, 1, 2, 2, 3, 0, 1, 0, 2, 1, 0, 0, 1, 3, 3, 3, 3, 0, 1, 3, 2, 0, 0, 2, 3, 2, 0, 1, 1, 3, 1, 1, 3, 3, 2, 2, 0, 3, 2, 0, 2, 0, 1, 2, 1, 3, 1, 1, 1, 2, 1, 3, 1, 3, 2, 2, 0, 1, 1, 3, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 68 and the episode is 2898 and the total_steps are 148473\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 3, 0, 3, 0, 0, 2, 2, 2, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 1, 3, 3, 0, 2, 1, 3, 2, 0, 1, 3, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 37 and the episode is 2899 and the total_steps are 148510\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 1, 2, 1, 0, 2, 0, 0, 0, 3, 2, 3, 1, 2, 3, 0, 0, 3, 2, 3, 3, 3, 3, 0, 2, 2, 1, 0, 3, 3, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 37 and the episode is 2900 and the total_steps are 148547\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2900     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4806     |\n",
      "|    total_timesteps  | 148547   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.8     |\n",
      "|    n_updates        | 24636    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 1, 3, 0, 2, 2, 0, 2, 3, 2, 1, 0, 3, 1, 0, 1, 1, 2, 3, 0, 3, 0, 3, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 30 and the episode is 2901 and the total_steps are 148577\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 3, 2, 2, 3, 2, 1, 2, 2, 2, 3, 3, 3, 0, 3, 2, 1, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 2902 and the total_steps are 148601\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 3, 1, 3, 2, 3, 3, 3, 3, 2, 2, 2, 0, 0, 0, 0, 2, 0, 3, 1, 3, 0, 0, 3, 1, 2, 3, 2, 2, 3, 3, 3, 1, 3, 3, 2, 3, 3, 0, 3, 3, 2, 3, 1, 3, 3, 1, 2, 0, 1, 0, 2, 1, 3, 3, 2, 3, 1, 2, 3, 1, 3, 2, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1048. And steps were 70 and the episode is 2903 and the total_steps are 148671\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 1, 2, 2, 3, 2, 0, 1, 2, 1, 3, 1, 2, 0, 0, 1, 3, 3, 0, 1, 3, 1, 2, 1, 2, 1, 0, 2, 1, 3, 0, 3, 2, 0, 0, 1, 1, 3, 1, 3, 0, 2, 2, 3, 2, 2, 1, 0, 1, 2, 2, 1, 3, 0, 2, 0, 2, 2, 1, 2, 3, 2, 3, 3, 3, 2, 0, 2, 1, 1, 2, 2, 0, 3, 0, 3, 1, 3, 0, 2, 0, 3, 1, 3, 1, 2, 1, 2, 3, 1, 1, 3, 1, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 100 and the episode is 2904 and the total_steps are 148771\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.5     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2904     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4815     |\n",
      "|    total_timesteps  | 148771   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 24692    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 3, 1, 3, 0, 2, 3, 0, 0, 1, 2, 1, 1, 1, 3, 1, 0, 1, 0, 0, 2, 2, 3, 1, 1, 2, 3, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 34 and the episode is 2905 and the total_steps are 148805\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 3, 0, 0, 2, 1, 0, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 2906 and the total_steps are 148829\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 1, 1, 0, 2, 3, 0, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 3, 1, 1, 1, 1, 2, 0, 3, 3, 1, 2, 2, 3, 3, 3, 2, 0, 0, 0, 3, 1, 0, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 50 and the episode is 2907 and the total_steps are 148879\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 3, 1, 0, 2, 1, 3, 3, 3, 0, 2, 3, 1, 0, 1, 1, 0, 0, 3, 3, 2, 2, 2, 2, 3, 1, 0, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 34 and the episode is 2908 and the total_steps are 148913\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43       |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2908     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4821     |\n",
      "|    total_timesteps  | 148913   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.2     |\n",
      "|    n_updates        | 24728    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 0, 3, 1, 0, 2, 3, 1, 2, 1, 1, 2, 0, 3, 2, 1, 2, 3, 1, 3, 2, 1, 0, 1, 3, 1, 3, 3, 1, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 36 and the episode is 2909 and the total_steps are 148949\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 2, 2, 2, 0, 1, 0, 1, 0, 0, 1, 2, 0, 2, 0, 3, 2, 3, 2, 2, 2, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 2910 and the total_steps are 148977\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 0, 1, 3, 2, 1, 0, 0, 3, 0, 3, 0, 2, 3, 1, 1, 1, 0, 3, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 2911 and the total_steps are 149003\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 0, 2, 3, 1, 1, 3, 2, 1, 0, 1, 2, 2, 1, 2, 3, 1, 3, 1, 1, 0, 1, 3, 2, 1, 2, 3, 2, 1, 2, 3, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 38 and the episode is 2912 and the total_steps are 149041\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2912     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4826     |\n",
      "|    total_timesteps  | 149041   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 24760    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 2, 1, 1, 0, 2, 2, 1, 0, 3, 1, 3, 3, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1017. And steps were 18 and the episode is 2913 and the total_steps are 149059\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 2, 1, 1, 3, 2, 2, 0, 1, 3, 3, 3, 0, 1, 0, 3, 3, 2, 3, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 2914 and the total_steps are 149085\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 2, 0, 2, 1, 1, 3, 1, 1, 0, 0, 3, 1, 1, 1, 2, 3, 0, 1, 1, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 27 and the episode is 2915 and the total_steps are 149112\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 3, 0, 0, 3, 3, 0, 3, 3, 3, 0, 1, 3, 3, 2, 2, 1, 1, 3, 3, 1, 2, 0, 0, 0, 3, 3, 0, 2, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 43 and the episode is 2916 and the total_steps are 149155\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2916     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4831     |\n",
      "|    total_timesteps  | 149155   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 24788    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 0, 3, 1, 3, 2, 2, 2, 3, 2, 3, 1, 3, 2, 2, 1, 3, 1, 2, 3, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 27 and the episode is 2917 and the total_steps are 149182\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 3, 2, 0, 0, 3, 3, 3, 2, 1, 2, 0, 2, 2, 0, 1, 3, 3, 0, 1, 1, 1, 3, 3, 0, 3, 3, 2, 2, 3, 0, 0, 3, 3, 0, 0, 1, 3, 2, 0, 1, 0, 1, 0, 2, 2, 0, 1, 3, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 56 and the episode is 2918 and the total_steps are 149238\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 3, 3, 0, 2, 1, 2, 0, 3, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 2919 and the total_steps are 149254\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 3, 1, 2, 1, 1, 2, 2, 3, 2, 2, 2, 3, 2, 0, 1, 3, 1, 1, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 2920 and the total_steps are 149280\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2920     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4837     |\n",
      "|    total_timesteps  | 149280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.2     |\n",
      "|    n_updates        | 24819    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 2, 1, 0, 3, 1, 1, 0, 2, 2, 3, 2, 2, 3, 2, 3, 2, 1, 2, 1, 1, 3, 0, 3, 1, 0, 2, 0, 1, 1, 2, 0, 3, 1, 3, 3, 1, 1, 1, 1, 3, 2, 2, 0, 1, 3, 3, 3, 0, 2, 2, 3, 1, 3, 0, 0, 3, 1, 3, 1, 0, 1, 2, 3, 0, 2, 0, 0, 2, 1, 0, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1047. And steps were 77 and the episode is 2921 and the total_steps are 149357\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 1, 3, 1, 0, 0, 1, 3, 0, 3, 3, 0, 0, 2, 0, 0, 1, 3, 3, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 2922 and the total_steps are 149381\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 2, 2, 3, 3, 2, 1, 1, 2, 0, 3, 1, 0, 0, 0, 2, 1, 1, 2, 0, 1, 0, 2, 3, 3, 2, 0, 0, 3, 1, 2, 3, 0, 1, 2, 1, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 43 and the episode is 2923 and the total_steps are 149424\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 2, 2, 0, 1, 0, 2, 3, 2, 0, 3, 2, 3, 0, 3, 0, 0, 0, 3, 2, 2, 2, 0, 3, 0, 0, 1, 1, 0, 1, 1, 3, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 39 and the episode is 2924 and the total_steps are 149463\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2924     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4844     |\n",
      "|    total_timesteps  | 149463   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 24865    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 0, 3, 2, 1, 1, 3, 3, 0, 1, 0, 1, 1, 2, 0, 0, 2, 1, 1, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 2925 and the total_steps are 149489\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 0, 0, 1, 1, 1, 1, 1, 0, 1, 3, 1, 3, 0, 2, 0, 0, 2, 1, 3, 0, 3, 3, 1, 0, 1, 3, 3, 1, 2, 3, 2, 1, 2, 3, 3, 1, 2, 3, 3, 0, 0, 2, 0, 0, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 52 and the episode is 2926 and the total_steps are 149541\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 1, 2, 0, 2, 1, 3, 0, 2, 2, 3, 2, 0, 2, 2, 3, 2, 2, 2, 0, 3, 1, 2, 2, 3, 1, 0, 3, 0, 3, 1, 3, 2, 0, 2, 1, 1, 1, 0, 1, 0, 1, 3, 1, 3, 2, 1, 1, 3, 2, 0, 0, 1, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 60 and the episode is 2927 and the total_steps are 149601\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 1, 3, 3, 2, 3, 2, 0, 3, 1, 2, 2, 3, 3, 3, 0, 2, 2, 2, 3, 3, 1, 0, 1, 0, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2928 and the total_steps are 149633\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2928     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4851     |\n",
      "|    total_timesteps  | 149633   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31       |\n",
      "|    n_updates        | 24908    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 0, 3, 1, 2, 3, 3, 2, 2, 1, 1, 3, 1, 0, 3, 3, 2, 2, 3, 1, 0, 0, 3, 1, 2, 1, 0, 3, 0, 3, 2, 1, 1, 2, 0, 3, 1, 1, 2, 0, 1, 3, 0, 1, 3, 0, 0, 1, 0, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 56 and the episode is 2929 and the total_steps are 149689\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 2, 0, 0, 1, 3, 2, 2, 1, 0, 3, 2, 2, 1, 1, 3, 1, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 2930 and the total_steps are 149713\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 2, 2, 3, 2, 0, 2, 1, 1, 2, 0, 3, 1, 3, 0, 1, 3, 2, 3, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 33 and the episode is 2931 and the total_steps are 149746\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 3, 3, 2, 1, 1, 1, 1, 1, 2, 0, 3, 3, 0, 3, 3, 0, 3, 2, 2, 0, 1, 3, 1, 2, 0, 0, 0, 0, 3, 3, 3, 1, 2, 2, 0, 0, 0, 3, 0, 0, 2, 0, 2, 2, 0, 2, 2, 3, 3, 3, 2, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 59 and the episode is 2932 and the total_steps are 149805\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2932     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4859     |\n",
      "|    total_timesteps  | 149805   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.6     |\n",
      "|    n_updates        | 24951    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 0, 2, 1, 1, 1, 2, 2, 1, 0, 2, 1, 2, 1, 3, 2, 1, 2, 0, 2, 1, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 2933 and the total_steps are 149833\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 0, 2, 0, 3, 3, 2, 2, 2, 1, 0, 0, 2, 1, 2, 2, 2, 0, 1, 3, 1, 1, 2, 0, 1, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2934 and the total_steps are 149865\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 2, 2, 2, 1, 0, 3, 3, 3, 1, 1, 2, 1, 1, 0, 3, 0, 2, 0, 0, 2, 0, 0, 3, 3, 2, 2, 3, 0, 0, 3, 3, 3, 0, 0, 1, 2, 0, 3, 1, 3, 0, 2, 2, 2, 1, 3, 0, 1, 3, 1, 1, 3, 0, 2, 3, 1, 1, 3, 1, 0, 1, 1, 0, 1, 3, 1, 3, 0, 2, 0, 0, 2, 3, 1, 2, 3, 0, 3, 0, 1, 3, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1064. And steps were 90 and the episode is 2935 and the total_steps are 149955\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 1, 0, 2, 3, 2, 0, 3, 3, 1, 2, 0, 1, 0, 0, 3, 0, 3, 2, 3, 3, 0, 0, 2, 1, 2, 1, 2, 0, 1, 3, 0, 2, 0, 2, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 42 and the episode is 2936 and the total_steps are 149997\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2936     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4867     |\n",
      "|    total_timesteps  | 149997   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.2     |\n",
      "|    n_updates        | 24999    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 3, 1, 3, 1, 3, 0, 0, 2, 2, 0, 2, 3, 0, 0, 3, 0, 1, 2, 3, 1, 1, 0, 2, 0, 2, 0, 0, 3, 1, 0, 0, 3, 1, 1, 1, 1, 3, 2, 0, 0, 3, 2, 0, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 60 and the episode is 2937 and the total_steps are 150057\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 1, 0, 3, 0, 2, 1, 1, 2, 2, 0, 3, 3, 0, 1, 3, 2, 3, 3, 2, 0, 3, 2, 2, 2, 0, 1, 3, 0, 3, 0, 2, 3, 1, 2, 0, 3, 0, 0, 1, 2, 3, 1, 2, 0, 3, 3, 2, 2, 3, 3, 1, 2, 1, 3, 1, 3, 1, 3, 2, 3, 3, 1, 3, 1, 0, 2, 0, 1, 1, 0, 1, 3, 2, 2, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was 1015. And steps were 80 and the episode is 2938 and the total_steps are 150137\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 2, 2, 3, 0, 2, 3, 3, 2, 0, 1, 2, 1, 2, 2, 0, 0, 3, 0, 1, 3, 2, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 2939 and the total_steps are 150177\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 3, 0, 2, 3, 1, 0, 3, 2, 3, 3, 1, 3, 1, 1, 1, 1, 2, 3, 3, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 2940 and the total_steps are 150202\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.6     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2940     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4875     |\n",
      "|    total_timesteps  | 150202   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.6     |\n",
      "|    n_updates        | 25050    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 3, 3, 2, 1, 1, 0, 1, 0, 3, 1, 1, 0, 2, 1, 0, 2, 3, 2, 0, 0, 1, 2, 2, 0, 1, 2, 3, 1, 2, 3, 2, 3, 0, 3, 3, 3, 2, 0, 3, 3, 2, 2, 2, 0, 3, 2, 3, 0, 3, 3, 3, 0, 3, 0, 3, 0, 2, 3, 0, 0, 1, 3, 1, 2, 0, 2, 1, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -945. And steps were 75 and the episode is 2941 and the total_steps are 150277\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 0, 1, 3, 3, 3, 2, 2, 0, 2, 3, 0, 3, 1, 1, 1, 3, 0, 1, 0, 1, 2, 3, 0, 1, 0, 1, 3, 1, 0, 0, 3, 0, 0, 3, 3, 3, 0, 3, 0, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 60 and the episode is 2942 and the total_steps are 150337\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 3, 1, 2, 3, 1, 1, 2, 1, 1, 3, 3, 2, 2, 2, 0, 3, 1, 0, 1, 0, 2, 0, 3, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 31 and the episode is 2943 and the total_steps are 150368\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 3, 2, 2, 3, 0, 3, 3, 2, 2, 1, 3, 0, 1, 2, 0, 0, 0, 1, 3, 1, 1, 0, 0, 1, 2, 2, 2, 3, 3, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 37 and the episode is 2944 and the total_steps are 150405\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2944     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4884     |\n",
      "|    total_timesteps  | 150405   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 25101    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 3, 1, 3, 3, 0, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 0, 2, 3, 1, 0, 3, 3, 3, 3, 2, 3, 2, 1, 1, 0, 2, 2, 2, 2, 0, 3, 3, 3, 2, 0, 2, 1, 2, 1, 1, 0, 3, 2, 3, 2, 3, 1, 1, 2, 3, 1, 1, 2, 1, 2, 3, 2, 1, 0, 2, 2, 3, 3, 0, 0, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 78 and the episode is 2945 and the total_steps are 150483\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 2, 1, 3, 3, 2, 0, 2, 2, 2, 0, 0, 1, 1, 2, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 22 and the episode is 2946 and the total_steps are 150505\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 3, 3, 2, 3, 1, 3, 1, 1, 3, 1, 3, 3, 3, 3, 2, 0, 1, 0, 3, 1, 2, 0, 1, 2, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 32 and the episode is 2947 and the total_steps are 150537\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 3, 1, 3, 1, 0, 0, 2, 0, 1, 3, 0, 0, 3, 3, 0, 1, 3, 3, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 3, 2, 3, 1, 1, 1, 2, 1, 1, 2, 3, 2, 3, 2, 1, 0, 1, 0, 2, 2, 2, 3, 2, 0, 1, 3, 1, 3, 1, 2, 3, 0, 0, 3, 2, 0, 3, 2, 2, 1, 0, 0, 2, 3, 3, 3, 3, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 84 and the episode is 2948 and the total_steps are 150621\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2948     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4893     |\n",
      "|    total_timesteps  | 150621   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 25155    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 3, 2, 2, 1, 1, 3, 1, 0, 0, 0, 3, 1, 3, 2, 3, 2, 0, 2, 0, 1, 0, 0, 3, 1, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 32 and the episode is 2949 and the total_steps are 150653\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 3, 2, 2, 0, 0, 3, 0, 2, 2, 1, 1, 0, 1, 2, 1, 3, 3, 1, 3, 3, 3, 1, 0, 0, 3, 2, 1, 1, 0, 2, 2, 2, 0, 0, 2, 0, 0, 3, 0, 1, 1, 2, 1, 1, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 52 and the episode is 2950 and the total_steps are 150705\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 2, 2, 0, 0, 1, 0, 3, 3, 2, 3, 1, 2, 2, 3, 3, 1, 0, 0, 1, 2, 1, 2, 1, 3, 3, 3, 0, 1, 2, 2, 0, 1, 3, 0, 1, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1041. And steps were 43 and the episode is 2951 and the total_steps are 150748\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 0, 1, 2, 2, 1, 0, 3, 2, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 2952 and the total_steps are 150764\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2952     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4899     |\n",
      "|    total_timesteps  | 150764   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.68     |\n",
      "|    n_updates        | 25190    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 3, 3, 2, 1, 0, 1, 0, 0, 1, 2, 1, 2, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 3, 3, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 33 and the episode is 2953 and the total_steps are 150797\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 2, 3, 0, 1, 1, 1, 2, 2, 0, 0, 0, 3, 0, 2, 3, 0, 3, 2, 1, 3, 3, 2, 0, 2, 3, 1, 3, 1, 3, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 37 and the episode is 2954 and the total_steps are 150834\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 2, 0, 0, 1, 1, 0, 3, 0, 3, 0, 0, 3, 1, 3, 2, 3, 2, 2, 0, 3, 3, 3, 3, 0, 1, 2, 2, 0, 3, 2, 1, 2, 3, 1, 0, 2, 0, 0, 3, 2, 0, 0, 0, 2, 3, 3, 2, 1, 3, 3, 0, 2, 2, 0, 3, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 63 and the episode is 2955 and the total_steps are 150897\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 0, 1, 3, 1, 3, 1, 3, 0, 2, 3, 1, 1, 3, 1, 1, 1, 1, 0, 0, 1, 2, 0, 0, 0, 3, 1, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 40 and the episode is 2956 and the total_steps are 150937\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2956     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4906     |\n",
      "|    total_timesteps  | 150937   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.645    |\n",
      "|    n_updates        | 25234    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 2, 2, 0, 0, 1, 2, 2, 1, 0, 2, 2, 1, 3, 1, 3, 2, 2, 1, 3, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 27 and the episode is 2957 and the total_steps are 150964\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 0, 2, 1, 2, 3, 2, 1, 2, 1, 3, 3, 0, 2, 1, 3, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 2958 and the total_steps are 150985\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 0, 3, 2, 2, 3, 0, 2, 2, 1, 0, 1, 3, 3, 1, 3, 2, 1, 3, 2, 1, 0, 2, 0, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2959 and the total_steps are 151016\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 1, 0, 3, 1, 2, 3, 3, 0, 3, 2, 3, 1, 0, 3, 3, 1, 3, 0, 0, 2, 3, 1, 0, 1, 1, 2, 0, 2, 1, 0, 1, 2, 2, 2, 1, 3, 2, 0, 1, 1, 0, 2, 1, 1, 0, 0, 0, 2, 0, 1, 0, 3, 0, 3, 0, 3, 2, 1, 0, 2, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 68 and the episode is 2960 and the total_steps are 151084\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2960     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4912     |\n",
      "|    total_timesteps  | 151084   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 25270    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 1, 3, 1, 1, 1, 1, 3, 3, 2, 3, 0, 0, 1, 0, 0, 0, 0, 1, 2, 3, 1, 0, 0, 3, 3, 0, 3, 3, 2, 3, 0, 0, 0, 0, 2, 1, 1, 0, 2, 3, 0, 2, 3, 3, 3, 2, 0, 0, 1, 3, 0, 2, 2, 0, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 62 and the episode is 2961 and the total_steps are 151146\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 2, 0, 0, 3, 0, 0, 1, 0, 1, 1, 3, 2, 3, 0, 1, 1, 0, 2, 3, 3, 2, 3, 3, 0, 1, 0, 1, 1, 0, 3, 2, 1, 2, 0, 3, 1, 2, 1, 1, 0, 1, 3, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 50 and the episode is 2962 and the total_steps are 151196\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 0, 3, 0, 0, 2, 3, 3, 1, 1, 2, 3, 1, 1, 1, 2, 0, 2, 2, 2, 1, 1, 0, 0, 2, 2, 2, 2, 1, 3, 3, 0, 1, 2, 1, 1, 1, 3, 3, 1, 1, 1, 3, 3, 2, 1, 3, 1, 1, 2, 3, 1, 1, 3, 0, 1, 2, 2, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1063. And steps were 65 and the episode is 2963 and the total_steps are 151261\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 1, 3, 3, 0, 0, 3, 0, 0, 0, 3, 0, 2, 3, 3, 1, 3, 3, 1, 0, 3, 2, 0, 3, 3, 0, 1, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 43 and the episode is 2964 and the total_steps are 151304\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2964     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4921     |\n",
      "|    total_timesteps  | 151304   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 94.4     |\n",
      "|    n_updates        | 25325    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 2, 3, 0, 0, 1, 2, 1, 1, 2, 2, 3, 3, 3, 3, 0, 1, 0, 0, 2, 3, 2, 2, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 30 and the episode is 2965 and the total_steps are 151334\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 3, 1, 0, 1, 3, 3, 0, 1, 1, 2, 2, 3, 3, 1, 1, 3, 3, 3, 3, 1, 1, 1, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 30 and the episode is 2966 and the total_steps are 151364\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 0, 3, 0, 3, 0, 2, 3, 2, 3, 1, 0, 1, 2, 0, 1, 1, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 24 and the episode is 2967 and the total_steps are 151388\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 1, 3, 3, 3, 0, 3, 0, 0, 2, 0, 0, 2, 1, 1, 1, 0, 3, 3, 1, 2, 1, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 29 and the episode is 2968 and the total_steps are 151417\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2968     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4926     |\n",
      "|    total_timesteps  | 151417   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 25354    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 2, 1, 2, 1, 0, 2, 2, 1, 1, 1, 0, 0, 3, 1, 2, 0, 2, 2, 0, 0, 2, 3, 2, 0, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 2969 and the total_steps are 151449\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 0, 2, 2, 3, 3, 2, 2, 2, 1, 1, 0, 2, 3, 2, 2, 2, 2, 0, 3, 2, 1, 3, 3, 0, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 2970 and the total_steps are 151481\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 1, 0, 1, 3, 0, 0, 0, 0, 3, 0, 3, 0, 1, 1, 3, 0, 0, 2, 2, 0, 3, 2, 0, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 2971 and the total_steps are 151512\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 2, 0, 2, 0, 0, 2, 3, 2, 1, 2, 0, 1, 1, 2, 2, 3, 3, 3, 3, 2, 2, 3, 3, 3, 1, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 33 and the episode is 2972 and the total_steps are 151545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2972     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4931     |\n",
      "|    total_timesteps  | 151545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 25386    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 3, 0, 1, 1, 1, 0, 2, 3, 3, 3, 3, 1, 3, 1, 2, 1, 2, 3, 2, 1, 0, 2, 3, 0, 1, 1, 1, 0, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 36 and the episode is 2973 and the total_steps are 151581\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 2, 1, 0, 0, 2, 0, 0, 3, 1, 2, 1, 2, 2, 3, 2, 2, 2, 0, 3, 3, 0, 3, 1, 3, 3, 0, 1, 0, 0, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 37 and the episode is 2974 and the total_steps are 151618\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 3, 3, 0, 0, 2, 0, 1, 0, 2, 0, 2, 3, 0, 1, 2, 3, 0, 2, 1, 1, 0, 1, 1, 2, 2, 3, 2, 2, 0, 0, 0, 2, 0, 3, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 2975 and the total_steps are 151660\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 2, 0, 3, 2, 2, 3, 3, 2, 2, 0, 1, 3, 2, 1, 1, 2, 2, 0, 2, 0, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 2976 and the total_steps are 151688\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2976     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4938     |\n",
      "|    total_timesteps  | 151688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.64     |\n",
      "|    n_updates        | 25421    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 2, 2, 3, 1, 2, 2, 1, 0, 0, 0, 3, 1, 3, 2, 1, 1, 2, 0, 1, 3, 0, 2, 3, 1, 3, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 33 and the episode is 2977 and the total_steps are 151721\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 3, 0, 1, 3, 0, 3, 3, 1, 2, 0, 2, 0, 1, 0, 0, 3, 0, 2, 2, 2, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 28 and the episode is 2978 and the total_steps are 151749\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 2, 1, 2, 3, 1, 0, 0, 2, 2, 2, 3, 0, 0, 2, 2, 0, 3, 1, 1, 1, 1, 2, 3, 3, 3, 2, 2, 0, 3, 1, 1, 0, 1, 3, 0, 0, 2, 3, 2, 1, 2, 3, 2, 0, 1, 1, 1, 1, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 56 and the episode is 2979 and the total_steps are 151805\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 0, 0, 3, 1, 0, 2, 1, 1, 0, 2, 3, 0, 2, 1, 1, 2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 3, 3, 1, 1, 2, 3, 3, 0, 3, 1, 0, 3, 3, 0, 1, 1, 2, 3, 2, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 52 and the episode is 2980 and the total_steps are 151857\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2980     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4944     |\n",
      "|    total_timesteps  | 151857   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 25464    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 3, 0, 3, 3, 3, 2, 1, 3, 3, 1, 2, 3, 2, 2, 3, 2, 1, 2, 1, 2, 3, 3, 3, 1, 0, 2, 1, 0, 1, 2, 1, 0, 1, 1, 3, 1, 3, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 0, 3, 3, 3, 2, 2, 3, 3, 0, 2, 0, 1, 2, 2, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 76 and the episode is 2981 and the total_steps are 151933\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 0, 2, 1, 3, 1, 2, 0, 0, 1, 0, 2, 2, 2, 2, 1, 0, 2, 0, 3, 2, 0, 3, 1, 0, 3, 2, 3, 2, 3, 3, 2, 0, 0, 3, 3, 2, 0, 0, 3, 2, 3, 2, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 50 and the episode is 2982 and the total_steps are 151983\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 1, 2, 3, 2, 1, 3, 1, 3, 3, 0, 2, 3, 3, 1, 2, 0, 3, 0, 3, 2, 0, 3, 3, 0, 1, 2, 0, 3, 3, 3, 2, 2, 0, 1, 2, 3, 3, 1, 3, 2, 2, 3, 3, 1, 0, 2, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 54 and the episode is 2983 and the total_steps are 152037\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 0, 0, 1, 0, 2, 2, 1, 0, 1, 3, 1, 1, 2, 3, 0, 0, 0, 1, 1, 1, 0, 2, 1, 0, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 2984 and the total_steps are 152069\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2984     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4953     |\n",
      "|    total_timesteps  | 152069   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.19     |\n",
      "|    n_updates        | 25517    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 2, 3, 2, 0, 3, 3, 2, 0, 2, 2, 3, 2, 2, 3, 0, 1, 3, 3, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 26 and the episode is 2985 and the total_steps are 152095\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 1, 1, 3, 0, 0, 1, 1, 1, 3, 0, 1, 2, 1, 3, 3, 0, 2, 2, 3, 0, 1, 2, 3, 3, 0, 3, 1, 0, 0, 1, 0, 1, 0, 2, 1, 3, 2, 2, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 46 and the episode is 2986 and the total_steps are 152141\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 0, 3, 0, 0, 3, 0, 3, 3, 2, 2, 1, 1, 3, 0, 2, 0, 0, 1, 2, 3, 1, 3, 0, 0, 1, 1, 2, 2, 3, 0, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 2987 and the total_steps are 152179\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 3, 2, 0, 1, 2, 2, 1, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 3, 2, 0, 0, 0, 2, 0, 2, 1, 0, 0, 2, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 38 and the episode is 2988 and the total_steps are 152217\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2988     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4959     |\n",
      "|    total_timesteps  | 152217   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.61     |\n",
      "|    n_updates        | 25554    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 0, 2, 3, 3, 2, 0, 1, 2, 1, 0, 0, 3, 0, 3, 1, 1, 3, 2, 3, 1, 1, 2, 3, 3, 0, 1, 0, 1, 2, 3, 2, 1, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 40 and the episode is 2989 and the total_steps are 152257\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 1, 0, 1, 1, 2, 1, 1, 0, 2, 2, 1, 3, 2, 1, 2, 0, 3, 3, 0, 1, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 2990 and the total_steps are 152285\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 2, 0, 3, 3, 3, 3, 1, 3, 1, 0, 1, 1, 0, 0, 0, 1, 3, 0, 2, 1, 1, 0, 2, 2, 0, 0, 0, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 34 and the episode is 2991 and the total_steps are 152319\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 0, 1, 1, 2, 0, 3, 2, 1, 2, 2, 1, 2, 3, 3, 2, 1, 0, 0, 1, 1, 2, 3, 2, 3, 1, 3, 0, 2, 3, 2, 3, 0, 1, 0, 2, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 43 and the episode is 2992 and the total_steps are 152362\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2992     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4965     |\n",
      "|    total_timesteps  | 152362   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.03     |\n",
      "|    n_updates        | 25590    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 3, 0, 1, 1, 3, 1, 0, 1, 3, 1, 3, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 3, 3, 3, 3, 2, 3, 3, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 36 and the episode is 2993 and the total_steps are 152398\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 0, 2, 0, 2, 0, 1, 3, 1, 0, 3, 3, 1, 1, 0, 2, 2, 3, 2, 2, 2, 2, 0, 3, 2, 2, 3, 1, 0, 2, 0, 1, 0, 1, 3, 2, 2, 0, 3, 1, 0, 2, 1, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 50 and the episode is 2994 and the total_steps are 152448\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 3, 2, 0, 3, 0, 0, 1, 0, 0, 3, 1, 3, 3, 3, 1, 1, 2, 1, 0, 2, 3, 2, 0, 1, 1, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 33 and the episode is 2995 and the total_steps are 152481\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 0, 1, 2, 0, 3, 1, 1, 2, 0, 3, 3, 0, 2, 0, 1, 2, 0, 1, 0, 0, 3, 0, 1, 3, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 32 and the episode is 2996 and the total_steps are 152513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2996     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4972     |\n",
      "|    total_timesteps  | 152513   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 25628    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 1, 2, 1, 1, 2, 0, 0, 2, 2, 2, 1, 0, 1, 3, 0, 1, 2, 3, 0, 2, 0, 0, 1, 3, 3, 3, 0, 3, 3, 2, 1, 1, 3, 1, 2, 0, 3, 1, 1, 2, 1, 2, 0, 2, 0, 3, 0, 2, 2, 0, 2, 0, 1, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 61 and the episode is 2997 and the total_steps are 152574\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 1, 2, 2, 3, 1, 1, 1, 3, 1, 3, 3, 1, 3, 1, 1, 1, 1, 3, 2, 1, 0, 0, 3, 1, 0, 1, 0, 1, 1, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 43 and the episode is 2998 and the total_steps are 152617\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 1, 0, 0, 2, 2, 0, 3, 1, 0, 1, 0, 3, 2, 2, 1, 0, 0, 2, 2, 1, 1, 0, 0, 1, 1, 1, 2, 1, 2, 3, 1, 2, 0, 1, 0, 1, 1, 2, 3, 0, 0, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 49 and the episode is 2999 and the total_steps are 152666\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 2, 1, 2, 3, 3, 3, 1, 2, 0, 2, 1, 3, 2, 2, 1, 0, 2, 0, 3, 0, 3, 1, 2, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 31 and the episode is 3000 and the total_steps are 152697\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3000     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4980     |\n",
      "|    total_timesteps  | 152697   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.89     |\n",
      "|    n_updates        | 25674    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 3, 0, 2, 0, 1, 3, 3, 2, 1, 3, 2, 0, 1, 1, 1, 2, 1, 2, 2, 3, 3, 0, 0, 1, 1, 3, 3, 3, 0, 2, 1, 2, 1, 3, 3, 1, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 44 and the episode is 3001 and the total_steps are 152741\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 2, 1, 1, 2, 1, 1, 3, 0, 0, 0, 2, 1, 3, 1, 2, 3, 3, 3, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 33 and the episode is 3002 and the total_steps are 152774\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 2, 1, 2, 3, 2, 0, 2, 1, 0, 0, 2, 2, 2, 3, 1, 1, 0, 0, 2, 3, 3, 3, 3, 1, 0, 1, 3, 0, 1, 1, 1, 1, 1, 0, 0, 1, 3, 0, 2, 0, 0, 2, 3, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 51 and the episode is 3003 and the total_steps are 152825\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 2, 0, 2, 2, 1, 3, 0, 2, 1, 1, 2, 3, 3, 2, 2, 3, 0, 2, 1, 1, 3, 0, 2, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 31 and the episode is 3004 and the total_steps are 152856\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3004     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4986     |\n",
      "|    total_timesteps  | 152856   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 25713    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 3, 3, 2, 0, 3, 0, 2, 3, 2, 2, 0, 0, 1, 1, 2, 2, 2, 3, 0, 2, 2, 2, 1, 1, 0, 0, 0, 0, 1, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 37 and the episode is 3005 and the total_steps are 152893\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 2, 0, 2, 3, 2, 1, 3, 1, 0, 3, 0, 0, 3, 3, 2, 1, 3, 0, 1, 2, 0, 2, 3, 3, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3006 and the total_steps are 152925\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 3, 1, 2, 1, 1, 3, 2, 3, 2, 0, 2, 0, 2, 3, 3, 1, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 3007 and the total_steps are 152949\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 2, 3, 1, 0, 3, 3, 0, 2, 1, 3, 0, 1, 1, 1, 1, 2, 1, 3, 3, 1, 3, 0, 2, 0, 0, 1, 1, 1, 2, 0, 1, 1, 3, 3, 0, 1, 0, 2, 3, 1, 0, 3, 0, 2, 1, 0, 0, 2, 0, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 57 and the episode is 3008 and the total_steps are 153006\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3008     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4992     |\n",
      "|    total_timesteps  | 153006   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.437    |\n",
      "|    n_updates        | 25751    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 2, 2, 0, 1, 2, 1, 3, 1, 2, 2, 3, 0, 3, 3, 1, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 23 and the episode is 3009 and the total_steps are 153029\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 2, 3, 2, 2, 2, 3, 1, 2, 3, 3, 0, 3, 2, 3, 1, 1, 1, 0, 0, 0, 2, 0, 3, 3, 3, 0, 3, 1, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 36 and the episode is 3010 and the total_steps are 153065\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 3, 3, 2, 0, 1, 1, 0, 0, 3, 3, 1, 2, 0, 0, 3, 2, 2, 1, 1, 2, 1, 2, 3, 0, 2, 0, 0, 0, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 36 and the episode is 3011 and the total_steps are 153101\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 2, 2, 0, 1, 3, 1, 2, 3, 1, 1, 1, 3, 1, 2, 3, 3, 2, 1, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 3012 and the total_steps are 153125\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.8     |\n",
      "|    ep_rew_mean      | -882     |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3012     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 4998     |\n",
      "|    total_timesteps  | 153125   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.25     |\n",
      "|    n_updates        | 25781    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 0, 2, 2, 0, 3, 0, 2, 1, 2, 2, 2, 0, 2, 2, 1, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was 982. And steps were 21 and the episode is 3013 and the total_steps are 153146\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 1, 0, 3, 3, 3, 1, 1, 2, 3, 3, 1, 1, 2, 3, 1, 0, 2, 0, 0, 1, 1, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was 1026. And steps were 27 and the episode is 3014 and the total_steps are 153173\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 3, 1, 0, 3, 2, 2, 0, 2, 0, 3, 0, 2, 0, 2, 2, 2, 1, 3, 2, 0, 1, 1, 1, 0, 2, 1, 2, 2, 0, 2, 0, 1, 1, 0, 0, 2, 2, 2, 1, 3, 2, 2, 0, 0, 3, 2, 1, 0, 3, 3, 0, 1, 1, 1, 2, 0, 0, 0, 0, 1, 3, 2, 0, 1, 2, 3, 3, 1, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 76 and the episode is 3015 and the total_steps are 153249\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 3, 2, 2, 0, 0, 1, 1, 3, 1, 1, 3, 0, 2, 2, 1, 2, 3, 1, 0, 3, 2, 2, 1, 2, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 3016 and the total_steps are 153281\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -862     |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3016     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5004     |\n",
      "|    total_timesteps  | 153281   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 125      |\n",
      "|    n_updates        | 25820    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 1, 3, 0, 1, 1, 0, 1, 0, 1, 1, 3, 3, 3, 0, 3, 1, 3, 0, 1, 3, 2, 0, 2, 2, 3, 1, 0, 2, 0, 3, 1, 0, 0, 1, 0, 0, 3, 3, 3, 1, 0, 1, 0, 1, 0, 0, 0, 2, 2, 1, 1, 1, 0, 1, 0, 0, 1, 3, 3, 2, 1, 2, 1, 2, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -932. And steps were 72 and the episode is 3017 and the total_steps are 153353\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 3, 1, 0, 3, 3, 1, 0, 2, 3, 0, 1, 1, 0, 3, 0, 1, 3, 1, 2, 1, 1, 2, 2, 1, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 3018 and the total_steps are 153385\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 2, 3, 0, 2, 0, 2, 1, 3, 0, 2, 2, 1, 2, 0, 2, 2, 3, 0, 3, 3, 3, 2, 1, 3, 2, 2, 3, 1, 1, 2, 3, 1, 0, 1, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 50 and the episode is 3019 and the total_steps are 153435\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 2, 1, 2, 2, 0, 0, 0, 0, 3, 3, 2, 3, 2, 1, 3, 1, 1, 1, 3, 2, 3, 0, 1, 3, 0, 0, 2, 2, 0, 0, 2, 3, 0, 2, 3, 3, 1, 0, 3, 0, 1, 2, 2, 1, 2, 2, 3, 1, 1, 2, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1054. And steps were 58 and the episode is 3020 and the total_steps are 153493\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -861     |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3020     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5013     |\n",
      "|    total_timesteps  | 153493   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.97     |\n",
      "|    n_updates        | 25873    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 0, 3, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 1, 3, 1, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 3021 and the total_steps are 153517\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 3, 0, 3, 1, 2, 1, 2, 0, 3, 0, 2, 1, 1, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 0, 2, 0, 3, 3, 1, 3, 3, 2, 2, 3, 1, 2, 2, 2, 2, 3, 3, 2, 3, 0, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 52 and the episode is 3022 and the total_steps are 153569\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 0, 3, 0, 3, 2, 2, 0, 2, 0, 3, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 24 and the episode is 3023 and the total_steps are 153593\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 3, 0, 3, 3, 0, 0, 1, 2, 3, 0, 3, 1, 3, 2, 1, 1, 3, 0, 2, 0, 3, 0, 2, 0, 0, 2, 2, 3, 3, 3, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 44 and the episode is 3024 and the total_steps are 153637\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -881     |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3024     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5019     |\n",
      "|    total_timesteps  | 153637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 25909    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 1, 3, 3, 2, 0, 1, 2, 0, 3, 2, 2, 1, 1, 1, 1, 2, 0, 2, 1, 2, 0, 0, 3, 0, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 3025 and the total_steps are 153669\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 1, 3, 0, 2, 0, 3, 3, 2, 0, 1, 1, 1, 2, 2, 2, 2, 1, 2, 0, 0, 1, 2, 0, 2, 3, 1, 3, 3, 3, 2, 1, 0, 3, 0, 3, 0, 3, 2, 2, 1, 1, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 49 and the episode is 3026 and the total_steps are 153718\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 3, 0, 3, 0, 0, 1, 0, 2, 2, 2, 3, 0, 3, 0, 0, 1, 3, 2, 0, 1, 1, 3, 3, 2, 3, 0, 0, 1, 3, 0, 2, 3, 0, 3, 1, 2, 1, 0, 3, 2, 3, 0, 3, 1, 1, 0, 0, 0, 1, 2, 0, 1, 0, 2, 3, 1, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -950. And steps were 64 and the episode is 3027 and the total_steps are 153782\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 3, 0, 2, 1, 2, 3, 1, 1, 1, 0, 1, 3, 3, 2, 2, 0, 2, 3, 3, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 3028 and the total_steps are 153809\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3028     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5026     |\n",
      "|    total_timesteps  | 153809   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.65     |\n",
      "|    n_updates        | 25952    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 3, 3, 2, 2, 2, 2, 0, 3, 3, 0, 1, 0, 0, 3, 1, 3, 2, 1, 2, 1, 2, 1, 3, 0, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 32 and the episode is 3029 and the total_steps are 153841\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 0, 3, 3, 2, 0, 2, 0, 3, 3, 3, 0, 1, 3, 2, 2, 1, 0, 3, 3, 2, 0, 3, 3, 0, 3, 1, 3, 1, 2, 2, 0, 0, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 40 and the episode is 3030 and the total_steps are 153881\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 2, 3, 3, 1, 3, 2, 0, 0, 0, 2, 3, 1, 2, 1, 2, 2, 2, 2, 1, 0, 2, 3, 0, 2, 1, 1, 2, 0, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 36 and the episode is 3031 and the total_steps are 153917\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 0, 0, 1, 3, 0, 2, 0, 3, 2, 2, 2, 2, 1, 2, 1, 2, 3, 2, 1, 2, 3, 1, 0, 2, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3032 and the total_steps are 153949\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3032     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5032     |\n",
      "|    total_timesteps  | 153949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 25987    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 0, 2, 0, 3, 2, 0, 0, 0, 1, 0, 0, 3, 3, 1, 3, 3, 3, 3, 2, 2, 1, 2, 2, 1, 3, 3, 2, 2, 3, 3, 1, 2, 0, 1, 1, 0, 0, 3, 1, 1, 0, 2, 0, 3, 0, 3, 2, 3, 0, 1, 0, 0, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 61 and the episode is 3033 and the total_steps are 154010\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 3, 0, 1, 2, 1, 0, 1, 3, 3, 1, 0, 3, 3, 3, 0, 1, 0, 1, 2, 2, 1, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 2, 3, 1, 0, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 43 and the episode is 3034 and the total_steps are 154053\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 3, 0, 0, 2, 0, 0, 1, 1, 3, 0, 3, 1, 2, 0, 2, 2, 0, 2, 0, 2, 1, 0, 2, 3, 3, 3, 3, 0, 1, 3, 3, 1, 1, 1, 3, 2, 2, 0, 0, 1, 3, 2, 2, 0, 3, 1, 2, 3, 3, 3, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 57 and the episode is 3035 and the total_steps are 154110\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 1, 0, 0, 2, 1, 0, 2, 0, 0, 0, 3, 3, 3, 1, 3, 2, 0, 0, 2, 3, 2, 0, 3, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 3036 and the total_steps are 154141\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3036     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5040     |\n",
      "|    total_timesteps  | 154141   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 26035    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 3, 3, 2, 2, 0, 3, 3, 0, 1, 1, 0, 2, 3, 0, 0, 2, 3, 0, 2, 0, 2, 0, 3, 0, 3, 2, 1, 0, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 36 and the episode is 3037 and the total_steps are 154177\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 1, 3, 0, 0, 0, 2, 2, 0, 1, 2, 0, 1, 3, 0, 2, 1, 3, 1, 3, 1, 2, 3, 2, 0, 1, 2, 0, 0, 2, 3, 3, 1, 0, 1, 2, 0, 3, 0, 0, 2, 2, 0, 1, 3, 0, 1, 3, 0, 3, 0, 1, 3, 2, 2, 0, 2, 2, 3, 2, 1, 0, 1, 1, 3, 1, 3, 2, 2, 1, 3, 1, 2, 3, 2, 0, 1, 1, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 85 and the episode is 3038 and the total_steps are 154262\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 3, 0, 0, 0, 2, 2, 2, 3, 2, 2, 1, 1, 3, 3, 2, 2, 0, 0, 0, 3, 3, 3, 2, 3, 0, 2, 3, 2, 3, 2, 3, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 39 and the episode is 3039 and the total_steps are 154301\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 3, 3, 0, 1, 2, 1, 2, 1, 1, 3, 1, 3, 0, 2, 0, 0, 2, 3, 3, 3, 0, 2, 3, 1, 2, 2, 1, 2, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 3040 and the total_steps are 154337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3040     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5048     |\n",
      "|    total_timesteps  | 154337   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.8     |\n",
      "|    n_updates        | 26084    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 0, 3, 2, 0, 0, 2, 2, 1, 3, 2, 2, 0, 3, 1, 2, 0, 1, 3, 3, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3041 and the total_steps are 154365\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 0, 2, 3, 2, 3, 1, 0, 3, 3, 3, 3, 1, 0, 3, 2, 2, 2, 3, 0, 2, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 36 and the episode is 3042 and the total_steps are 154401\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 1, 3, 3, 3, 3, 0, 2, 0, 0, 0, 2, 3, 1, 0, 0, 0, 2, 3, 0, 1, 3, 2, 1, 3, 3, 3, 0, 3, 3, 0, 0, 2, 0, 3, 2, 0, 3, 1, 3, 3, 0, 1, 1, 1, 1, 3, 1, 0, 3, 0, 3, 2, 2, 3, 1, 3, 1, 3, 3, 2, 3, 2, 1, 3, 2, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 73 and the episode is 3043 and the total_steps are 154474\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 0, 1, 3, 3, 3, 1, 0, 0, 3, 1, 2, 1, 1, 1, 2, 1, 3, 0, 3, 1, 2, 1, 0, 3, 3, 2, 2, 2, 1, 1, 2, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 39 and the episode is 3044 and the total_steps are 154513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3044     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5055     |\n",
      "|    total_timesteps  | 154513   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 26128    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 2, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 2, 2, 3, 2, 1, 1, 0, 0, 1, 1, 2, 3, 1, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 32 and the episode is 3045 and the total_steps are 154545\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 3, 3, 0, 3, 3, 3, 2, 0, 2, 3, 0, 0, 3, 3, 3, 2, 1, 0, 3, 0, 3, 3, 1, 3, 1, 0, 2, 0, 2, 0, 1, 2, 1, 1, 3, 0, 2, 3, 0, 3, 1, 1, 0, 1, 3, 2, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 54 and the episode is 3046 and the total_steps are 154599\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 1, 0, 1, 1, 0, 3, 2, 3, 3, 0, 2, 1, 3, 0, 3, 1, 1, 3, 1, 0, 3, 3, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 30 and the episode is 3047 and the total_steps are 154629\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 3, 2, 0, 1, 1, 3, 1, 1, 2, 2, 1, 1, 2, 0, 0, 2, 1, 1, 3, 0, 3, 0, 2, 2, 3, 2, 0, 1, 0, 0, 0, 0, 2, 1, 1, 1, 2, 1, 0, 2, 2, 2, 0, 3, 0, 0, 3, 2, 0, 1, 0, 3, 2, 1, 1, 2, 0, 0, 2, 2, 2, 3, 3, 1, 3, 3, 1, 2, 1, 2, 3, 2, 3, 2, 0, 1, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -926. And steps were 84 and the episode is 3048 and the total_steps are 154713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3048     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5063     |\n",
      "|    total_timesteps  | 154713   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.1      |\n",
      "|    n_updates        | 26178    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 0, 1, 1, 1, 2, 3, 1, 3, 2, 3, 0, 0, 2, 0, 3, 0, 1, 1, 0, 3, 0, 0, 0, 2, 0, 3, 3, 0, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 3049 and the total_steps are 154749\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 2, 3, 1, 2, 3, 1, 3, 2, 1, 1, 3, 0, 2, 1, 0, 3, 3, 0, 2, 3, 1, 1, 1, 2, 1, 1, 3, 0, 0, 0, 1, 3, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 40 and the episode is 3050 and the total_steps are 154789\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 2, 1, 2, 2, 0, 0, 3, 2, 0, 1, 2, 3, 2, 0, 1, 2, 0, 1, 3, 1, 2, 2, 1, 3, 2, 0, 0, 3, 3, 1, 0, 2, 1, 3, 2, 0, 2, 1, 3, 0, 1, 3, 3, 3, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 52 and the episode is 3051 and the total_steps are 154841\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 3, 2, 0, 1, 1, 2, 0, 3, 1, 1, 2, 0, 3, 0, 1, 1, 3, 0, 3, 1, 3, 1, 0, 0, 0, 0, 1, 1, 0, 0, 2, 1, 3, 2, 1, 1, 3, 3, 3, 1, 3, 0, 0, 1, 2, 2, 1, 0, 1, 3, 3, 2, 3, 0, 3, 1, 3, 2, 3, 1, 3, 0, 3, 1, 1, 0, 1, 2, 2, 2, 0, 1, 3, 3, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1080. And steps were 82 and the episode is 3052 and the total_steps are 154923\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3052     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5071     |\n",
      "|    total_timesteps  | 154923   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.52     |\n",
      "|    n_updates        | 26230    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 2, 0, 0, 0, 1, 1, 0, 3, 3, 1, 1, 2, 1, 0, 0, 0, 1, 0, 1, 2, 1, 3, 0, 1, 3, 0, 1, 1, 0, 1, 2, 3, 3, 0, 0, 3, 1, 3, 1, 1, 0, 3, 1, 0, 0, 3, 1, 3, 1, 3, 3, 1, 0, 3, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 62 and the episode is 3053 and the total_steps are 154985\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 0, 2, 0, 1, 2, 3, 1, 3, 0, 3, 3, 3, 3, 3, 0, 1, 0, 2, 1, 2, 0, 0, 1, 2, 3, 3, 3, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 35 and the episode is 3054 and the total_steps are 155020\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 1, 1, 0, 1, 3, 0, 3, 3, 1, 3, 3, 0, 0, 1, 3, 0, 0, 2, 3, 0, 3, 3, 0, 2, 3, 1, 1, 1, 0, 0, 3, 3, 3, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 41 and the episode is 3055 and the total_steps are 155061\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 1, 0, 1, 3, 3, 3, 0, 0, 1, 0, 3, 3, 3, 2, 0, 1, 0, 2, 3, 2, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 3056 and the total_steps are 155089\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3056     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5078     |\n",
      "|    total_timesteps  | 155089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.7     |\n",
      "|    n_updates        | 26272    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 3, 2, 3, 2, 0, 0, 3, 2, 0, 0, 3, 3, 1, 1, 3, 3, 3, 1, 0, 3, 1, 3, 2, 2, 3, 3, 2, 2, 2, 2, 0, 2, 3, 0, 0, 3, 0, 3, 2, 0, 1, 2, 3, 3, 1, 0, 3, 3, 2, 3, 3, 3, 1, 0, 3, 3, 2, 2, 1, 3, 0, 2, 3, 2, 0, 1, 2, 3, 2, 2, 0, 2, 2, 1, 3, 1, 0, 1, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -936. And steps were 86 and the episode is 3057 and the total_steps are 155175\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 2, 0, 1, 1, 3, 0, 0, 0, 3, 3, 1, 3, 3, 0, 3, 1, 2, 0, 0, 1, 0, 0, 1, 1, 1, 3, 3, 0, 0, 2, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 38 and the episode is 3058 and the total_steps are 155213\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 1, 2, 3, 3, 0, 2, 1, 0, 1, 0, 2, 3, 0, 3, 0, 1, 3, 1, 2, 1, 3, 1, 1, 2, 1, 2, 3, 2, 0, 0, 0, 0, 0, 3, 2, 0, 2, 0, 0, 1, 3, 1, 1, 2, 1, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 53 and the episode is 3059 and the total_steps are 155266\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 2, 3, 1, 0, 3, 3, 0, 1, 0, 2, 3, 0, 1, 1, 0, 1, 0, 3, 2, 0, 0, 0, 3, 0, 2, 2, 2, 2, 1, 0, 0, 1, 0, 2, 0, 3, 3, 1, 2, 2, 3, 3, 1, 3, 3, 3, 3, 2, 2, 2, 0, 3, 1, 0, 3, 2, 2, 2, 0, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -943. And steps were 67 and the episode is 3060 and the total_steps are 155333\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3060     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5088     |\n",
      "|    total_timesteps  | 155333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 26333    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 0, 0, 2, 2, 1, 0, 3, 0, 2, 1, 1, 3, 2, 1, 0, 1, 2, 3, 2, 1, 3, 0, 3, 2, 3, 3, 1, 3, 0, 3, 0, 1, 3, 2, 2, 1, 1, 3, 3, 0, 2, 3, 0, 2, 3, 1, 2, 0, 0, 2, 3, 1, 3, 0, 1, 0, 1, 0, 1, 2, 2, 3, 3, 3, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 72 and the episode is 3061 and the total_steps are 155405\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 1, 1, 2, 2, 0, 3, 3, 3, 1, 1, 1, 0, 2, 3, 3, 2, 1, 1, 2, 0, 0, 1, 0, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 31 and the episode is 3062 and the total_steps are 155436\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 2, 2, 2, 1, 1, 3, 2, 3, 0, 2, 0, 1, 2, 2, 2, 0, 1, 0, 0, 2, 2, 2, 2, 1, 3, 3, 3, 2, 3, 0, 2, 0, 2, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 41 and the episode is 3063 and the total_steps are 155477\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 2, 1, 3, 0, 1, 2, 0, 1, 3, 2, 0, 3, 1, 2, 2, 0, 3, 1, 1, 2, 2, 2, 2, 0, 2, 2, 1, 3, 3, 2, 2, 3, 3, 2, 2, 1, 1, 0, 2, 1, 2, 3, 0, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 51 and the episode is 3064 and the total_steps are 155528\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3064     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5097     |\n",
      "|    total_timesteps  | 155528   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.1     |\n",
      "|    n_updates        | 26381    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 3, 3, 1, 0, 3, 3, 0, 2, 3, 3, 3, 1, 0, 3, 3, 3, 3, 1, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 26 and the episode is 3065 and the total_steps are 155554\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 1, 3, 3, 3, 3, 3, 0, 0, 0, 2, 0, 2, 3, 1, 1, 3, 1, 1, 1, 2, 2, 0, 3, 2, 1, 2, 2, 2, 3, 2, 3, 0, 2, 0, 3, 3, 0, 1, 3, 0, 1, 1, 0, 1, 2, 2, 2, 2, 2, 1, 0, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 59 and the episode is 3066 and the total_steps are 155613\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 0, 3, 3, 1, 3, 2, 1, 1, 3, 1, 1, 0, 3, 0, 0, 3, 3, 0, 1, 1, 1, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 3067 and the total_steps are 155642\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 1, 3, 0, 0, 1, 0, 1, 2, 3, 2, 0, 1, 3, 2, 1, 2, 0, 2, 2, 1, 3, 1, 1, 1, 3, 3, 1, 1, 3, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 47 and the episode is 3068 and the total_steps are 155689\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3068     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5103     |\n",
      "|    total_timesteps  | 155689   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 26422    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 3, 1, 0, 2, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 1, 0, 3, 3, 3, 0, 2, 2, 3, 1, 2, 0, 0, 2, 3, 3, 1, 1, 1, 1, 2, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 50 and the episode is 3069 and the total_steps are 155739\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 1, 2, 1, 2, 0, 3, 0, 0, 0, 1, 1, 0, 0, 1, 3, 1, 2, 2, 1, 2, 1, 0, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 30 and the episode is 3070 and the total_steps are 155769\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 3, 2, 2, 2, 1, 2, 2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 3, 3, 3, 0, 1, 2, 1, 2, 3, 3, 0, 1, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 3071 and the total_steps are 155805\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 3, 0, 3, 2, 2, 3, 2, 1, 0, 3, 2, 2, 3, 1, 3, 0, 3, 3, 0, 1, 3, 0, 2, 3, 3, 1, 1, 1, 1, 2, 2, 1, 2, 2, 3, 1, 1, 2, 2, 3, 3, 0, 0, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 64 and the episode is 3072 and the total_steps are 155869\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.2     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3072     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5111     |\n",
      "|    total_timesteps  | 155869   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 26467    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 0, 3, 3, 1, 0, 2, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 0, 0, 3, 1, 3, 1, 1, 1, 3, 1, 1, 3, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 36 and the episode is 3073 and the total_steps are 155905\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 1, 2, 0, 3, 2, 1, 2, 3, 1, 2, 2, 2, 2, 3, 1, 3, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 3074 and the total_steps are 155929\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 1, 0, 1, 1, 0, 3, 1, 2, 3, 2, 0, 2, 0, 2, 0, 1, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 22 and the episode is 3075 and the total_steps are 155951\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 1, 2, 0, 2, 0, 1, 2, 3, 1, 3, 1, 1, 2, 2, 2, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1019. And steps were 20 and the episode is 3076 and the total_steps are 155971\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.8     |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3076     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5116     |\n",
      "|    total_timesteps  | 155971   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.748    |\n",
      "|    n_updates        | 26492    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 1, 0, 3, 2, 1, 1, 3, 0, 1, 0, 2, 0, 0, 0, 1, 3, 1, 2, 0, 1, 0, 1, 0, 2, 3, 2, 0, 3, 2, 3, 3, 2, 2, 3, 1, 3, 1, 2, 1, 2, 2, 3, 0, 0, 0, 2, 3, 1, 1, 3, 3, 1, 0, 2, 1, 2, 2, 2, 0, 0, 1, 2, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 70 and the episode is 3077 and the total_steps are 156041\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 0, 2, 3, 1, 2, 0, 0, 2, 3, 0, 3, 0, 3, 1, 0, 1, 1, 1, 0, 2, 1, 1, 2, 3, 0, 1, 0, 2, 2, 3, 1, 2, 1, 3, 2, 1, 3, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1043. And steps were 45 and the episode is 3078 and the total_steps are 156086\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 0, 0, 0, 0, 0, 1, 2, 2, 0, 2, 3, 1, 0, 2, 1, 0, 1, 2, 1, 3, 0, 1, 0, 1, 3, 0, 1, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 3079 and the total_steps are 156121\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 0, 1, 0, 2, 0, 1, 0, 1, 2, 1, 3, 1, 3, 0, 3, 2, 3, 1, 1, 1, 1, 2, 2, 1, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3080 and the total_steps are 156153\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43       |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3080     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5123     |\n",
      "|    total_timesteps  | 156153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.01     |\n",
      "|    n_updates        | 26538    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 0, 1, 0, 3, 2, 2, 1, 0, 3, 0, 0, 3, 1, 1, 3, 2, 1, 2, 2, 3, 1, 2, 2, 0, 0, 0, 3, 3, 1, 0, 0, 0, 3, 1, 0, 0, 3, 2, 2, 1, 2, 1, 1, 2, 2, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 53 and the episode is 3081 and the total_steps are 156206\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 0, 3, 0, 0, 2, 1, 2, 0, 3, 2, 1, 1, 2, 1, 3, 1, 1, 3, 3, 0, 3, 0, 1, 1, 0, 2, 2, 3, 1, 2, 1, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 39 and the episode is 3082 and the total_steps are 156245\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 1, 1, 2, 2, 0, 0, 1, 2, 3, 0, 0, 3, 3, 3, 2, 0, 1, 0, 1, 3, 2, 0, 2, 0, 1, 0, 0, 2, 3, 0, 1, 1, 0, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 40 and the episode is 3083 and the total_steps are 156285\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 1, 2, 0, 1, 3, 2, 2, 3, 0, 3, 3, 0, 2, 3, 0, 2, 0, 1, 1, 0, 2, 1, 1, 0, 0, 1, 1, 3, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 36 and the episode is 3084 and the total_steps are 156321\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3084     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5130     |\n",
      "|    total_timesteps  | 156321   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.07     |\n",
      "|    n_updates        | 26580    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 0, 2, 2, 2, 0, 1, 0, 2, 0, 0, 0, 1, 3, 2, 0, 2, 3, 3, 1, 0, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 3085 and the total_steps are 156349\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 1, 0, 1, 2, 2, 3, 2, 1, 2, 0, 1, 1, 1, 2, 2, 3, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 3086 and the total_steps are 156373\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 3, 3, 0, 2, 3, 0, 1, 3, 2, 3, 2, 2, 3, 3, 1, 1, 2, 1, 0, 3, 2, 1, 1, 0, 1, 2, 0, 1, 3, 1, 1, 1, 1, 2, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 1, 1, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 64 and the episode is 3087 and the total_steps are 156437\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 3, 2, 2, 3, 1, 0, 1, 0, 2, 2, 0, 1, 2, 3, 2, 3, 3, 1, 0, 3, 3, 0, 0, 1, 1, 0, 1, 1, 1, 2, 0, 3, 0, 3, 2, 2, 2, 0, 0, 2, 0, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 49 and the episode is 3088 and the total_steps are 156486\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -894     |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3088     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5137     |\n",
      "|    total_timesteps  | 156486   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 154      |\n",
      "|    n_updates        | 26621    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 2, 3, 3, 2, 3, 2, 3, 1, 2, 3, 2, 0, 3, 0, 2, 1, 0, 2, 3, 1, 1, 0, 2, 0, 1, 2, 0, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 35 and the episode is 3089 and the total_steps are 156521\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 2, 2, 3, 0, 1, 3, 0, 3, 2, 3, 2, 2, 1, 3, 1, 3, 1, 3, 3, 3, 0, 0, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was 1027. And steps were 28 and the episode is 3090 and the total_steps are 156549\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 0, 0, 1, 0, 0, 1, 3, 3, 1, 0, 2, 3, 2, 1, 2, 3, 3, 0, 1, 1, 2, 3, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 30 and the episode is 3091 and the total_steps are 156579\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 1, 0, 0, 0, 1, 2, 1, 1, 1, 3, 1, 0, 1, 3, 0, 2, 0, 1, 0, 2, 0, 3, 2, 1, 0, 1, 0, 1, 2, 3, 1, 3, 1, 3, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 2, 1, 3, 1, 1, 0, 3, 0, 3, 1, 2, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 64 and the episode is 3092 and the total_steps are 156643\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.8     |\n",
      "|    ep_rew_mean      | -874     |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3092     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5144     |\n",
      "|    total_timesteps  | 156643   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.78     |\n",
      "|    n_updates        | 26660    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 1, 1, 2, 0, 2, 1, 0, 3, 3, 0, 0, 3, 2, 2, 3, 0, 0, 1, 2, 0, 3, 3, 2, 2, 3, 3, 3, 1, 2, 3, 1, 2, 1, 0, 3, 0, 2, 0, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 46 and the episode is 3093 and the total_steps are 156689\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 2, 1, 1, 1, 2, 0, 2, 2, 2, 1, 0, 3, 1, 0, 3, 3, 0, 0, 1, 2, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3094 and the total_steps are 156717\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 3, 2, 0, 2, 0, 0, 2, 3, 3, 0, 1, 3, 2, 3, 3, 2, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 24 and the episode is 3095 and the total_steps are 156741\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 0, 2, 2, 2, 1, 0, 3, 1, 1, 1, 0, 3, 2, 3, 1, 3, 3, 1, 1, 0, 3, 1, 0, 3, 1, 3, 1, 1, 2, 2, 1, 0, 0, 1, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 42 and the episode is 3096 and the total_steps are 156783\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3096     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5150     |\n",
      "|    total_timesteps  | 156783   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 66.8     |\n",
      "|    n_updates        | 26695    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 1, 3, 2, 0, 3, 1, 0, 0, 3, 2, 0, 0, 3, 3, 1, 1, 1, 2, 1, 2, 3, 1, 2, 0, 0, 2, 2, 1, 2, 3, 0, 0, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 40 and the episode is 3097 and the total_steps are 156823\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 1, 2, 3, 1, 3, 3, 3, 3, 1, 0, 0, 2, 0, 3, 3, 3, 3, 2, 3, 2, 3, 0, 3, 3, 0, 1, 0, 0, 1, 2, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 38 and the episode is 3098 and the total_steps are 156861\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 2, 0, 2, 0, 0, 2, 3, 1, 3, 3, 3, 2, 2, 3, 1, 3, 0, 2, 1, 1, 2, 0, 1, 2, 1, 2, 1, 0, 2, 1, 3, 2, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 40 and the episode is 3099 and the total_steps are 156901\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 3, 0, 1, 0, 1, 2, 3, 3, 3, 1, 0, 2, 2, 0, 3, 1, 0, 2, 2, 3, 2, 0, 0, 0, 2, 3, 2, 2, 0, 1, 0, 1, 3, 0, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 42 and the episode is 3100 and the total_steps are 156943\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | -874     |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3100     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5157     |\n",
      "|    total_timesteps  | 156943   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.07     |\n",
      "|    n_updates        | 26735    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 0, 3, 0, 2, 2, 1, 2, 2, 1, 3, 2, 0, 1, 1, 2, 0, 0, 1, 0, 3, 3, 0, 2, 1, 1, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 33 and the episode is 3101 and the total_steps are 156976\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 2, 0, 1, 3, 2, 0, 3, 2, 3, 3, 1, 0, 3, 2, 0, 2, 0, 3, 3, 3, 2, 3, 1, 1, 3, 0, 2, 1, 0, 0, 3, 1, 0, 3, 2, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 43 and the episode is 3102 and the total_steps are 157019\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 3, 1, 0, 1, 0, 3, 1, 3, 0, 3, 2, 0, 3, 3, 2, 0, 1, 2, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 3103 and the total_steps are 157045\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 2, 3, 1, 2, 3, 1, 1, 3, 1, 0, 2, 2, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 20 and the episode is 3104 and the total_steps are 157065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -873     |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3104     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5162     |\n",
      "|    total_timesteps  | 157065   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.38     |\n",
      "|    n_updates        | 26766    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 3, 3, 1, 0, 2, 3, 0, 1, 3, 2, 1, 1, 3, 2, 1, 1, 0, 1, 2, 0, 2, 3, 1, 1, 0, 1, 3, 3, 0, 2, 0, 0, 2, 2, 2, 3, 2, 3, 0, 1, 0, 2, 1, 0, 2, 2, 3, 0, 3, 2, 0, 1, 1, 3, 1, 3, 0, 0, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 66 and the episode is 3105 and the total_steps are 157131\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 3, 0, 2, 0, 0, 0, 1, 2, 0, 1, 1, 0, 3, 1, 0, 2, 1, 0, 0, 3, 0, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3106 and the total_steps are 157160\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 1, 2, 1, 1, 2, 0, 1, 0, 3, 0, 0, 0, 1, 0, 1, 3, 3, 0, 0, 1, 1, 3, 3, 0, 3, 1, 2, 3, 0, 0, 1, 0, 2, 1, 1, 1, 1, 3, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 46 and the episode is 3107 and the total_steps are 157206\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 2, 0, 0, 1, 2, 3, 0, 2, 2, 2, 3, 1, 3, 2, 2, 1, 2, 2, 3, 1, 0, 3, 3, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 31 and the episode is 3108 and the total_steps are 157237\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | -873     |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3108     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5169     |\n",
      "|    total_timesteps  | 157237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.33     |\n",
      "|    n_updates        | 26809    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 0, 2, 3, 2, 2, 0, 3, 3, 2, 2, 0, 2, 3, 2, 1, 0, 0, 2, 3, 3, 3, 3, 1, 1, 3, 0, 3, 3, 2, 2, 2, 3, 3, 1, 2, 3, 2, 2, 3, 3, 2, 0, 2, 2, 3, 0, 3, 2, 2, 0, 3, 2, 0, 2, 2, 1, 3, 0, 3, 0, 0, 0, 3, 3, 2, 3, 2, 2, 2, 1, 3, 3, 2, 3, 0, 3, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1082. And steps were 84 and the episode is 3109 and the total_steps are 157321\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 2, 1, 0, 0, 0, 3, 1, 0, 3, 3, 3, 0, 0, 3, 2, 1, 3, 3, 3, 1, 0, 0, 1, 1, 0, 3, 1, 3, 1, 0, 2, 0, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 50 and the episode is 3110 and the total_steps are 157371\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 0, 2, 2, 1, 0, 0, 0, 1, 2, 3, 0, 2, 2, 2, 1, 2, 3, 2, 2, 3, 0, 1, 3, 0, 2, 1, 1, 1, 2, 0, 2, 0, 1, 0, 2, 3, 2, 3, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 46 and the episode is 3111 and the total_steps are 157417\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 1, 1, 1, 1, 0, 1, 3, 3, 0, 1, 1, 1, 1, 0, 3, 1, 3, 2, 2, 0, 0, 1, 0, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 31 and the episode is 3112 and the total_steps are 157448\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.2     |\n",
      "|    ep_rew_mean      | -894     |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3112     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5177     |\n",
      "|    total_timesteps  | 157448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 26861    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 3, 1, 3, 2, 3, 3, 0, 2, 2, 0, 0, 3, 3, 2, 2, 2, 1, 0, 0, 1, 3, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3113 and the total_steps are 157477\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 3, 2, 3, 2, 2, 3, 1, 3, 3, 3, 0, 3, 0, 2, 1, 1, 2, 0, 3, 3, 1, 2, 3, 3, 1, 1, 3, 2, 3, 0, 0, 2, 0, 3, 3, 1, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 44 and the episode is 3114 and the total_steps are 157521\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 3, 2, 2, 2, 1, 1, 2, 0, 0, 2, 1, 1, 3, 2, 3, 0, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 24 and the episode is 3115 and the total_steps are 157545\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 2, 0, 3, 1, 0, 0, 0, 3, 1, 2, 2, 1, 3, 1, 1, 0, 3, 0, 1, 3, 0, 3, 3, 0, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 32 and the episode is 3116 and the total_steps are 157577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43       |\n",
      "|    ep_rew_mean      | -934     |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3116     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5183     |\n",
      "|    total_timesteps  | 157577   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.95     |\n",
      "|    n_updates        | 26894    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 0, 1, 2, 3, 3, 3, 3, 2, 0, 3, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 3, 1, 2, 1, 1, 3, 2, 1, 1, 1, 0, 3, 3, 0, 1, 2, 0, 1, 3, 2, 0, 3, 0, 1, 2, 1, 2, 2, 3, 3, 1, 1, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 63 and the episode is 3117 and the total_steps are 157640\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 3, 2, 0, 3, 1, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 21 and the episode is 3118 and the total_steps are 157661\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 2, 1, 1, 1, 3, 1, 0, 0, 1, 1, 3, 2, 3, 2, 2, 1, 3, 0, 1, 3, 1, 1, 3, 1, 2, 1, 1, 1, 2, 3, 3, 1, 1, 2, 3, 3, 2, 3, 1, 2, 3, 0, 0, 2, 1, 2, 1, 2, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 56 and the episode is 3119 and the total_steps are 157717\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 0, 1, 3, 1, 2, 0, 2, 1, 1, 0, 0, 0, 1, 2, 3, 1, 2, 2, 0, 0, 3, 3, 2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 1, 1, 3, 1, 2, 0, 3, 0, 1, 3, 0, 1, 0, 2, 3, 1, 0, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 61 and the episode is 3120 and the total_steps are 157778\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.9     |\n",
      "|    ep_rew_mean      | -934     |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3120     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5192     |\n",
      "|    total_timesteps  | 157778   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.571    |\n",
      "|    n_updates        | 26944    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 1, 0, 1, 3, 0, 0, 1, 0, 3, 2, 1, 0, 0, 1, 0, 3, 1, 1, 3, 3, 3, 2, 3, 2, 1, 1, 2, 2, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 36 and the episode is 3121 and the total_steps are 157814\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 1, 0, 0, 2, 2, 3, 0, 2, 0, 1, 3, 3, 3, 1, 1, 0, 2, 0, 1, 3, 0, 0, 0, 0, 2, 3, 1, 3, 0, 2, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 38 and the episode is 3122 and the total_steps are 157852\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1, 0, 2, 2, 2, 0, 1, 1, 2, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 25 and the episode is 3123 and the total_steps are 157877\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 1, 2, 3, 0, 0, 3, 1, 3, 3, 0, 3, 0, 2, 2, 2, 3, 1, 0, 3, 3, 1, 1, 1, 0, 2, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 33 and the episode is 3124 and the total_steps are 157910\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -934     |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3124     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5197     |\n",
      "|    total_timesteps  | 157910   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.97     |\n",
      "|    n_updates        | 26977    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 0, 1, 1, 2, 0, 3, 3, 3, 1, 0, 3, 3, 3, 1, 1, 2, 1, 2, 3, 0, 0, 1, 3, 1, 2, 2, 3, 0, 1, 3, 0, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 39 and the episode is 3125 and the total_steps are 157949\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 2, 2, 2, 0, 0, 1, 1, 2, 3, 3, 2, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 3126 and the total_steps are 157976\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 0, 3, 1, 1, 2, 2, 2, 2, 1, 1, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 18 and the episode is 3127 and the total_steps are 157994\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 1, 0, 1, 0, 0, 2, 2, 3, 2, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 24 and the episode is 3128 and the total_steps are 158018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -934     |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3128     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5202     |\n",
      "|    total_timesteps  | 158018   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 27004    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 3, 1, 3, 2, 3, 1, 2, 1, 1, 2, 2, 0, 0, 2, 0, 3, 1, 1, 2, 1, 0, 3, 3, 1, 2, 3, 0, 2, 3, 1, 3, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 39 and the episode is 3129 and the total_steps are 158057\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 2, 3, 2, 1, 2, 1, 0, 0, 2, 2, 1, 1, 2, 3, 1, 2, 1, 1, 3, 3, 2, 3, 3, 1, 3, 0, 1, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 35 and the episode is 3130 and the total_steps are 158092\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 3, 0, 1, 2, 1, 2, 2, 0, 0, 0, 2, 2, 1, 1, 3, 0, 3, 0, 1, 3, 3, 3, 0, 1, 3, 3, 1, 0, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 37 and the episode is 3131 and the total_steps are 158129\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 3, 3, 1, 2, 0, 3, 2, 1, 0, 3, 0, 0, 2, 0, 3, 2, 1, 3, 0, 2, 1, 3, 2, 1, 3, 2, 3, 1, 2, 2, 1, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 39 and the episode is 3132 and the total_steps are 158168\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -934     |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3132     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5208     |\n",
      "|    total_timesteps  | 158168   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 27041    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 1, 2, 2, 0, 1, 2, 0, 3, 2, 1, 0, 0, 1, 1, 3, 0, 1, 2, 1, 0, 3, 0, 0, 3, 1, 1, 1, 0, 3, 0, 3, 3, 0, 1, 0, 3, 2, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 45 and the episode is 3133 and the total_steps are 158213\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 3, 3, 0, 1, 1, 3, 3, 0, 1, 2, 0, 3, 3, 3, 2, 0, 1, 2, 3, 3, 3, 3, 1, 2, 1, 2, 1, 3, 2, 3, 1, 2, 3, 0, 2, 1, 3, 1, 3, 2, 1, 1, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 50 and the episode is 3134 and the total_steps are 158263\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 3, 0, 3, 1, 1, 2, 0, 3, 1, 2, 1, 0, 0, 3, 1, 2, 3, 3, 1, 3, 2, 2, 2, 0, 1, 1, 2, 0, 1, 2, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 38 and the episode is 3135 and the total_steps are 158301\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 0, 3, 2, 2, 3, 3, 1, 2, 0, 2, 2, 0, 1, 2, 2, 1, 1, 2, 2, 3, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 28 and the episode is 3136 and the total_steps are 158329\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -935     |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3136     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5215     |\n",
      "|    total_timesteps  | 158329   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 27082    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 0, 3, 1, 1, 3, 1, 0, 3, 2, 1, 2, 0, 3, 0, 0, 2, 0, 1, 0, 3, 1, 1, 3, 2, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 3137 and the total_steps are 158361\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 1, 1, 0, 3, 3, 1, 3, 3, 2, 1, 3, 2, 1, 1, 2, 3, 0, 0, 0, 3, 1, 0, 0, 0, 1, 2, 1, 3, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 36 and the episode is 3138 and the total_steps are 158397\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 1, 1, 1, 0, 3, 3, 2, 3, 1, 1, 3, 2, 1, 1, 1, 0, 0, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 25 and the episode is 3139 and the total_steps are 158422\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 2, 3, 3, 3, 2, 3, 0, 3, 2, 3, 0, 0, 2, 0, 0, 1, 3, 0, 1, 3, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 3140 and the total_steps are 158450\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -935     |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3140     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5220     |\n",
      "|    total_timesteps  | 158450   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.744    |\n",
      "|    n_updates        | 27112    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 2, 3, 3, 1, 2, 3, 3, 2, 1, 3, 3, 0, 3, 2, 2, 3, 3, 0, 0, 3, 3, 2, 1, 1, 3, 3, 1, 0, 2, 0, 0, 0, 0, 3, 3, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 43 and the episode is 3141 and the total_steps are 158493\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 2, 2, 2, 3, 0, 0, 2, 0, 2, 1, 2, 2, 3, 0, 1, 2, 0, 3, 2, 3, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 3142 and the total_steps are 158521\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 1, 2, 0, 1, 0, 1, 2, 0, 2, 0, 3, 2, 3, 0, 3, 0, 3, 3, 0, 0, 0, 1, 2, 3, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 3143 and the total_steps are 158553\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 1, 3, 2, 2, 2, 3, 1, 3, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 3144 and the total_steps are 158579\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -935     |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3144     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5226     |\n",
      "|    total_timesteps  | 158579   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 27144    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 1, 0, 2, 3, 0, 0, 3, 0, 2, 1, 3, 0, 3, 3, 3, 2, 1, 0, 3, 0, 0, 0, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 30 and the episode is 3145 and the total_steps are 158609\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 1, 0, 2, 1, 0, 3, 3, 1, 2, 1, 0, 3, 2, 3, 1, 3, 3, 2, 3, 3, 0, 2, 0, 1, 1, 1, 1, 1, 1, 2, 2, 0, 0, 1, 3, 3, 1, 2, 0, 3, 0, 1, 2, 1, 1, 2, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 60 and the episode is 3146 and the total_steps are 158669\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 2, 1, 3, 0, 3, 2, 1, 2, 1, 1, 1, 1, 1, 0, 2, 2, 0, 3, 2, 2, 0, 3, 0, 3, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 3147 and the total_steps are 158701\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 1, 0, 0, 1, 2, 3, 3, 1, 3, 3, 0, 0, 1, 2, 1, 1, 2, 2, 3, 2, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 3148 and the total_steps are 158729\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -935     |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3148     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5232     |\n",
      "|    total_timesteps  | 158729   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.44     |\n",
      "|    n_updates        | 27182    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 1, 2, 2, 3, 0, 3, 2, 1, 0, 1, 2, 0, 0, 3, 3, 3, 0, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 3149 and the total_steps are 158754\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 1, 2, 1, 2, 3, 1, 1, 2, 1, 2, 1, 2, 0, 1, 2, 1, 0, 2, 3, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 27 and the episode is 3150 and the total_steps are 158781\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 2, 0, 0, 1, 0, 3, 2, 2, 2, 1, 1, 2, 1, 0, 1, 3, 2, 3, 3, 1, 0, 0, 1, 2, 1, 2, 1, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 35 and the episode is 3151 and the total_steps are 158816\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 2, 3, 2, 0, 1, 3, 0, 3, 3, 0, 0, 3, 3, 3, 3, 2, 1, 0, 0, 2, 2, 0, 2, 3, 2, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 33 and the episode is 3152 and the total_steps are 158849\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | -935     |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3152     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5237     |\n",
      "|    total_timesteps  | 158849   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 27212    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 0, 1, 1, 1, 1, 3, 2, 2, 3, 3, 3, 0, 1, 1, 1, 0, 3, 2, 3, 0, 2, 2, 2, 0, 3, 3, 3, 3, 1, 0, 3, 3, 3, 3, 1, 0, 2, 0, 3, 2, 3, 3, 3, 3, 3, 1, 1, 3, 2, 1, 0, 1, 1, 3, 2, 0, 0, 1, 1, 0, 1, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 69 and the episode is 3153 and the total_steps are 158918\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 2, 0, 3, 2, 0, 3, 0, 0, 0, 0, 3, 0, 2, 1, 3, 2, 0, 0, 1, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 27 and the episode is 3154 and the total_steps are 158945\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 0, 1, 2, 3, 2, 2, 2, 1, 2, 1, 0, 1, 0, 3, 0, 0, 2, 0, 2, 1, 0, 0, 2, 3, 0, 3, 0, 0, 3, 1, 0, 0, 1, 2, 0, 2, 2, 2, 1, 3, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 48 and the episode is 3155 and the total_steps are 158993\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 3, 1, 1, 2, 2, 1, 2, 2, 1, 0, 1, 1, 2, 2, 1, 2, 0, 3, 0, 2, 3, 1, 1, 2, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 3156 and the total_steps are 159025\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -935     |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3156     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5245     |\n",
      "|    total_timesteps  | 159025   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 27256    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 1, 1, 0, 1, 0, 1, 2, 2, 2, 3, 1, 3, 0, 0, 3, 1, 3, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 25 and the episode is 3157 and the total_steps are 159050\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 0, 1, 1, 0, 0, 3, 1, 3, 0, 2, 2, 1, 0, 3, 1, 0, 2, 1, 2, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 27 and the episode is 3158 and the total_steps are 159077\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 2, 3, 2, 0, 1, 1, 0, 1, 1, 3, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1015. And steps were 16 and the episode is 3159 and the total_steps are 159093\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 0, 1, 0, 3, 2, 0, 2, 0, 2, 0, 3, 2, 3, 2, 2, 2, 3, 1, 0, 1, 0, 3, 3, 0, 3, 0, 1, 3, 2, 2, 1, 1, 3, 2, 0, 3, 3, 2, 1, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 47 and the episode is 3160 and the total_steps are 159140\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.1     |\n",
      "|    ep_rew_mean      | -915     |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3160     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5250     |\n",
      "|    total_timesteps  | 159140   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31       |\n",
      "|    n_updates        | 27284    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 3, 1, 3, 1, 2, 3, 2, 3, 0, 1, 2, 1, 2, 2, 2, 1, 2, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 25 and the episode is 3161 and the total_steps are 159165\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 3, 2, 0, 1, 3, 1, 0, 3, 3, 2, 1, 2, 3, 2, 0, 1, 0, 3, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 3162 and the total_steps are 159191\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 1, 1, 0, 1, 1, 1, 3, 1, 2, 2, 3, 2, 1, 2, 1, 3, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 24 and the episode is 3163 and the total_steps are 159215\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 3, 3, 2, 2, 1, 2, 3, 3, 3, 0, 2, 1, 1, 0, 2, 2, 2, 0, 0, 1, 3, 3, 2, 1, 0, 0, 0, 1, 3, 2, 1, 3, 2, 1, 2, 2, 2, 0, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 46 and the episode is 3164 and the total_steps are 159261\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3164     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5255     |\n",
      "|    total_timesteps  | 159261   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.09     |\n",
      "|    n_updates        | 27315    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 0, 1, 2, 3, 1, 2, 0, 2, 0, 1, 0, 3, 2, 1, 3, 3, 2, 3, 0, 3, 0, 3, 0, 0, 0, 2, 3, 2, 3, 3, 0, 3, 3, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 41 and the episode is 3165 and the total_steps are 159302\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 3, 3, 2, 2, 1, 2, 1, 3, 2, 2, 3, 2, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 3166 and the total_steps are 159322\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 2, 1, 2, 3, 1, 0, 3, 2, 0, 3, 3, 2, 3, 0, 0, 2, 2, 3, 2, 2, 2, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 29 and the episode is 3167 and the total_steps are 159351\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 1, 2, 3, 3, 0, 2, 2, 0, 1, 2, 2, 3, 3, 0, 0, 3, 0, 3, 1, 0, 3, 3, 0, 3, 2, 3, 1, 0, 2, 2, 3, 0, 3, 1, 1, 1, 0, 0, 3, 1, 0, 0, 3, 3, 3, 1, 0, 3, 1, 2, 3, 0, 1, 3, 2, 2, 0, 2, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 66 and the episode is 3168 and the total_steps are 159417\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3168     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5262     |\n",
      "|    total_timesteps  | 159417   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 27354    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 3, 2, 0, 1, 0, 3, 3, 1, 2, 3, 0, 0, 1, 0, 3, 3, 0, 2, 3, 1, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 28 and the episode is 3169 and the total_steps are 159445\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 0, 3, 3, 0, 1, 3, 1, 2, 3, 2, 3, 2, 3, 3, 2, 0, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 24 and the episode is 3170 and the total_steps are 159469\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 1, 1, 2, 0, 2, 1, 0, 3, 3, 0, 2, 1, 3, 3, 0, 0, 1, 2, 1, 0, 3, 1, 2, 1, 0, 0, 2, 0, 2, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 37 and the episode is 3171 and the total_steps are 159506\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 3, 3, 3, 3, 1, 3, 3, 1, 2, 2, 1, 0, 1, 2, 2, 0, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 24 and the episode is 3172 and the total_steps are 159530\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3172     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5267     |\n",
      "|    total_timesteps  | 159530   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.14     |\n",
      "|    n_updates        | 27382    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 1, 2, 3, 0, 2, 3, 3, 0, 1, 1, 3, 1, 3, 2, 0, 2, 2, 3, 2, 2, 3, 1, 1, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 0, 1, 3, 1, 2, 3, 3, 3, 0, 0, 3, 2, 1, 0, 3, 1, 0, 0, 3, 0, 1, 0, 2, 0, 1, 2, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 67 and the episode is 3173 and the total_steps are 159597\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 0, 3, 0, 0, 3, 3, 3, 2, 2, 0, 2, 3, 3, 1, 1, 0, 3, 1, 0, 0, 2, 3, 2, 3, 1, 0, 0, 1, 0, 0, 3, 3, 2, 2, 0, 3, 2, 3, 3, 2, 3, 0, 2, 1, 2, 1, 3, 1, 3, 3, 1, 1, 1, 2, 0, 1, 2, 2, 1, 2, 1, 0, 1, 1, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 72 and the episode is 3174 and the total_steps are 159669\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 1, 3, 1, 2, 2, 3, 0, 1, 2, 2, 3, 3, 0, 2, 2, 2, 1, 3, 0, 1, 0, 1, 2, 2, 3, 1, 0, 3, 2, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 37 and the episode is 3175 and the total_steps are 159706\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 2, 3, 0, 3, 1, 2, 3, 2, 1, 1, 0, 0, 3, 3, 2, 2, 2, 3, 3, 0, 3, 1, 0, 3, 1, 0, 2, 1, 3, 1, 1, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 39 and the episode is 3176 and the total_steps are 159745\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3176     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5275     |\n",
      "|    total_timesteps  | 159745   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 27436    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 2, 3, 2, 2, 3, 2, 3, 3, 2, 1, 3, 2, 1, 3, 2, 2, 2, 3, 1, 1, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 3177 and the total_steps are 159773\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 2, 2, 3, 0, 0, 3, 0, 0, 3, 2, 0, 1, 3, 2, 1, 2, 0, 2, 0, 1, 0, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3178 and the total_steps are 159802\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 2, 0, 3, 1, 0, 0, 3, 2, 1, 1, 2, 2, 3, 3, 3, 2, 2, 1, 3, 3, 2, 0, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 30 and the episode is 3179 and the total_steps are 159832\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 1, 0, 3, 0, 0, 0, 2, 0, 2, 2, 3, 0, 3, 1, 1, 3, 1, 0, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 3180 and the total_steps are 159858\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3180     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5280     |\n",
      "|    total_timesteps  | 159858   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.5     |\n",
      "|    n_updates        | 27464    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 1, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 1, 3, 3, 0, 3, 0, 3, 3, 0, 1, 2, 3, 2, 1, 2, 2, 2, 0, 2, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1011. And steps were 36 and the episode is 3181 and the total_steps are 159894\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 3, 2, 1, 2, 2, 3, 1, 1, 2, 3, 0, 0, 0, 3, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0, 1, 3, 1, 1, 1, 1, 2, 2, 0, 0, 2, 3, 1, 1, 0, 1, 3, 0, 2, 3, 3, 3, 2, 1, 2, 1, 3, 0, 2, 1, 1, 3, 1, 0, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 67 and the episode is 3182 and the total_steps are 159961\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 1, 0, 3, 2, 3, 0, 0, 0, 0, 0, 3, 0, 0, 2, 1, 0, 2, 2, 1, 3, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3183 and the total_steps are 159989\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 3, 0, 1, 1, 1, 3, 1, 3, 2, 1, 1, 2, 2, 1, 3, 0, 1, 2, 0, 0, 0, 3, 0, 0, 2, 2, 2, 1, 2, 0, 1, 1, 3, 0, 1, 2, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 44 and the episode is 3184 and the total_steps are 160033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.1     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3184     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5288     |\n",
      "|    total_timesteps  | 160033   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.9      |\n",
      "|    n_updates        | 27508    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 2, 1, 0, 0, 2, 3, 1, 2, 3, 3, 3, 2, 0, 2, 0, 0, 1, 0, 2, 2, 0, 0, 3, 1, 0, 1, 3, 2, 0, 1, 1, 2, 2, 2, 2, 3, 0, 1, 0, 3, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 3185 and the total_steps are 160081\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 3, 0, 0, 0, 3, 1, 0, 2, 2, 1, 3, 2, 2, 1, 2, 3, 0, 0, 0, 2, 2, 2, 0, 1, 0, 3, 0, 0, 0, 0, 1, 1, 1, 3, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 3186 and the total_steps are 160123\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 0, 3, 1, 0, 1, 3, 1, 1, 0, 3, 2, 3, 1, 3, 1, 3, 1, 1, 2, 3, 1, 1, 2, 0, 1, 0, 0, 0, 3, 2, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 38 and the episode is 3187 and the total_steps are 160161\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 0, 2, 2, 1, 3, 0, 1, 3, 2, 1, 0, 1, 1, 0, 2, 0, 2, 0, 2, 1, 3, 3, 1, 3, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 32 and the episode is 3188 and the total_steps are 160193\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.1     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3188     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5294     |\n",
      "|    total_timesteps  | 160193   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.6     |\n",
      "|    n_updates        | 27548    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 1, 2, 2, 1, 0, 3, 3, 2, 2, 1, 0, 2, 0, 2, 1, 3, 1, 0, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was 1022. And steps were 23 and the episode is 3189 and the total_steps are 160216\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 0, 3, 3, 0, 2, 2, 3, 2, 1, 1, 2, 0, 3, 0, 0, 0, 0, 0, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 2, 3, 2, 1, 0, 3, 3, 3, 0, 3, 0, 3, 1, 1, 2, 3, 2, 2, 0, 3, 1, 3, 3, 3, 1, 0, 3, 1, 0, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1063. And steps were 65 and the episode is 3190 and the total_steps are 160281\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 3, 2, 0, 0, 1, 2, 3, 0, 3, 3, 1, 3, 1, 3, 3, 3, 2, 3, 2, 1, 1, 3, 0, 2, 2, 0, 3, 1, 1, 0, 3, 1, 2, 3, 0, 0, 0, 1, 1, 1, 0, 0, 3, 2, 2, 1, 0, 2, 3, 3, 2, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 59 and the episode is 3191 and the total_steps are 160340\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 2, 2, 3, 2, 2, 1, 1, 3, 1, 2, 0, 0, 3, 0, 1, 0, 1, 1, 0, 3, 2, 3, 1, 1, 0, 1, 1, 3, 1, 1, 1, 0, 3, 1, 2, 0, 1, 3, 0, 2, 1, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 49 and the episode is 3192 and the total_steps are 160389\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3192     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5303     |\n",
      "|    total_timesteps  | 160389   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.11     |\n",
      "|    n_updates        | 27597    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 2, 2, 1, 3, 2, 1, 2, 2, 0, 0, 0, 1, 0, 0, 3, 1, 0, 2, 1, 2, 1, 1, 1, 1, 3, 1, 2, 3, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 36 and the episode is 3193 and the total_steps are 160425\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 3, 3, 1, 2, 1, 3, 3, 3, 2, 3, 3, 3, 0, 3, 2, 0, 1, 0, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 3194 and the total_steps are 160449\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 1, 3, 0, 2, 2, 2, 3, 2, 3, 2, 3, 0, 0, 1, 0, 0, 3, 0, 2, 0, 2, 1, 2, 1, 1, 1, 2, 2, 1, 0, 0, 3, 3, 2, 2, 0, 3, 2, 3, 0, 1, 1, 0, 1, 3, 0, 3, 0, 3, 0, 1, 2, 3, 3, 3, 3, 2, 0, 2, 2, 2, 0, 3, 1, 3, 2, 2, 0, 1, 3, 0, 2, 3, 0, 3, 3, 1, 0, 1, 1, 0, 2, 1, 2, 0, 1, 1, 3, 0, 0, 0, 3, 3, 1, 2, 0, 0, 1, 2, 1, 3, 0, 0, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -915. And steps were 117 and the episode is 3195 and the total_steps are 160566\n",
      "Done condition: collision\n",
      "[0, 0, 1, 2, 1, 3, 0, 1, 1, 0, 2, 2, 3, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 3, 0, 0, 3, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 31 and the episode is 3196 and the total_steps are 160597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.1     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3196     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5311     |\n",
      "|    total_timesteps  | 160597   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.3     |\n",
      "|    n_updates        | 27649    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 3, 3, 0, 3, 0, 3, 3, 0, 3, 0, 3, 1, 3, 0, 1, 2, 0, 3, 3, 1, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 3197 and the total_steps are 160633\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 0, 0, 3, 0, 0, 1, 0, 0, 3, 2, 0, 0, 2, 0, 2, 2, 2, 3, 0, 0, 2, 1, 2, 1, 3, 3, 2, 1, 0, 2, 3, 0, 3, 0, 3, 2, 3, 0, 3, 0, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 48 and the episode is 3198 and the total_steps are 160681\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 2, 2, 2, 1, 0, 0, 0, 3, 3, 0, 2, 0, 3, 3, 2, 3, 0, 0, 3, 1, 0, 0, 1, 0, 3, 3, 2, 2, 2, 1, 2, 3, 2, 0, 3, 1, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 44 and the episode is 3199 and the total_steps are 160725\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 1, 0, 0, 1, 1, 0, 2, 2, 2, 3, 0, 0, 1, 3, 2, 0, 2, 0, 2, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 27 and the episode is 3200 and the total_steps are 160752\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.1     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3200     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5317     |\n",
      "|    total_timesteps  | 160752   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 27687    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 2, 1, 2, 1, 3, 2, 3, 1, 2, 0, 2, 3, 3, 2, 1, 2, 3, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 25 and the episode is 3201 and the total_steps are 160777\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 3, 1, 0, 3, 1, 2, 0, 1, 0, 2, 3, 3, 3, 0, 2, 3, 1, 0, 3, 3, 3, 0, 3, 2, 1, 2, 2, 2, 1, 0, 1, 3, 2, 3, 1, 2, 1, 3, 0, 1, 2, 1, 3, 2, 2, 2, 1, 1, 2, 3, 0, 3, 3, 2, 2, 3, 1, 0, 0, 0, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -950. And steps were 68 and the episode is 3202 and the total_steps are 160845\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 0, 1, 1, 2, 2, 2, 1, 3, 2, 2, 3, 2, 1, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 2, 1, 1, 3, 0, 2, 3, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 38 and the episode is 3203 and the total_steps are 160883\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 2, 1, 2, 2, 2, 1, 3, 1, 0, 1, 1, 3, 1, 2, 1, 3, 2, 3, 2, 0, 2, 3, 1, 3, 0, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 3204 and the total_steps are 160916\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3204     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5324     |\n",
      "|    total_timesteps  | 160916   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 27728    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 1, 2, 3, 2, 0, 0, 3, 1, 3, 1, 1, 3, 3, 3, 1, 2, 1, 0, 3, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 27 and the episode is 3205 and the total_steps are 160943\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 1, 1, 3, 0, 2, 2, 3, 3, 2, 0, 1, 3, 1, 0, 0, 3, 0, 0, 3, 2, 1, 1, 2, 0, 2, 2, 0, 3, 3, 1, 3, 2, 3, 1, 2, 3, 2, 1, 3, 2, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 48 and the episode is 3206 and the total_steps are 160991\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 3, 3, 3, 3, 1, 1, 0, 0, 1, 1, 2, 1, 1, 2, 3, 1, 3, 2, 3, 2, 0, 1, 3, 0, 1, 3, 1, 3, 3, 1, 3, 3, 3, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 41 and the episode is 3207 and the total_steps are 161032\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 0, 2, 0, 0, 3, 2, 2, 3, 1, 1, 2, 2, 2, 3, 1, 2, 1, 3, 3, 2, 0, 1, 3, 0, 1, 3, 1, 1, 3, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 37 and the episode is 3208 and the total_steps are 161069\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3208     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5331     |\n",
      "|    total_timesteps  | 161069   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 27767    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 3, 1, 1, 3, 3, 2, 2, 2, 1, 3, 2, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 19 and the episode is 3209 and the total_steps are 161088\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 0, 2, 2, 2, 2, 2, 1, 2, 3, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 17 and the episode is 3210 and the total_steps are 161105\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 0, 3, 3, 3, 2, 0, 1, 0, 0, 0, 3, 1, 3, 3, 2, 3, 0, 3, 0, 0, 2, 0, 2, 1, 3, 0, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 34 and the episode is 3211 and the total_steps are 161139\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 0, 3, 0, 0, 3, 3, 3, 2, 1, 2, 3, 2, 0, 3, 2, 3, 1, 1, 3, 0, 3, 3, 3, 3, 0, 2, 0, 2, 0, 0, 3, 2, 3, 0, 0, 1, 3, 0, 0, 2, 1, 2, 0, 0, 0, 2, 3, 0, 2, 2, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 58 and the episode is 3212 and the total_steps are 161197\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -915     |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3212     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5336     |\n",
      "|    total_timesteps  | 161197   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 27799    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 3, 2, 2, 1, 0, 2, 1, 3, 2, 2, 1, 2, 1, 1, 3, 2, 0, 0, 0, 2, 2, 3, 1, 1, 2, 0, 3, 3, 3, 2, 3, 1, 3, 3, 1, 0, 2, 3, 0, 3, 2, 0, 2, 3, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 52 and the episode is 3213 and the total_steps are 161249\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 1, 1, 3, 1, 2, 3, 3, 3, 2, 0, 1, 2, 3, 0, 0, 0, 2, 2, 0, 2, 1, 0, 0, 2, 3, 3, 2, 1, 1, 2, 1, 3, 3, 0, 1, 2, 2, 1, 2, 1, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 3214 and the total_steps are 161297\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 1, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 0, 0, 0, 2, 0, 3, 0, 1, 2, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 3215 and the total_steps are 161325\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 2, 3, 3, 1, 0, 0, 3, 0, 0, 3, 2, 0, 2, 1, 1, 1, 3, 3, 2, 3, 2, 1, 1, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 3216 and the total_steps are 161356\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -915     |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3216     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5343     |\n",
      "|    total_timesteps  | 161356   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.2     |\n",
      "|    n_updates        | 27838    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 3, 3, 0, 2, 2, 3, 3, 2, 2, 1, 1, 3, 1, 2, 2, 1, 0, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 3217 and the total_steps are 161381\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 0, 0, 1, 3, 1, 1, 2, 1, 1, 0, 1, 3, 3, 1, 2, 1, 1, 2, 3, 0, 0, 1, 0, 3, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 3218 and the total_steps are 161413\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 0, 0, 0, 0, 1, 3, 3, 3, 0, 3, 1, 3, 3, 3, 2, 1, 3, 0, 2, 0, 2, 3, 1, 1, 2, 0, 0, 3, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 36 and the episode is 3219 and the total_steps are 161449\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 3, 1, 2, 2, 1, 0, 0, 0, 1, 2, 1, 0, 1, 1, 1, 2, 0, 1, 0, 0, 1, 0, 2, 1, 1, 0, 0, 0, 2, 3, 1, 3, 3, 1, 3, 3, 2, 0, 3, 2, 3, 1, 0, 1, 3, 1, 3, 3, 3, 2, 0, 3, 3, 3, 0, 1, 0, 3, 0, 2, 3, 1, 3, 2, 0, 1, 3, 3, 3, 3, 1, 0, 0, 3, 3, 2, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1060. And steps were 84 and the episode is 3220 and the total_steps are 161533\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3220     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5351     |\n",
      "|    total_timesteps  | 161533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 27883    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 3, 0, 0, 0, 3, 3, 1, 0, 1, 0, 0, 2, 2, 3, 3, 0, 1, 3, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 25 and the episode is 3221 and the total_steps are 161558\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 2, 0, 0, 3, 0, 2, 2, 2, 1, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 17 and the episode is 3222 and the total_steps are 161575\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 1, 3, 0, 0, 3, 1, 0, 0, 0, 0, 3, 3, 0, 3, 0, 2, 1, 1, 0, 0, 2, 2, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 30 and the episode is 3223 and the total_steps are 161605\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 0, 2, 2, 1, 2, 1, 0, 0, 2, 0, 2, 1, 2, 3, 1, 3, 0, 3, 2, 1, 3, 1, 3, 1, 2, 2, 3, 0, 2, 0, 1, 1, 0, 3, 1, 3, 3, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 45 and the episode is 3224 and the total_steps are 161650\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3224     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5356     |\n",
      "|    total_timesteps  | 161650   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.4     |\n",
      "|    n_updates        | 27912    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 0, 2, 0, 3, 0, 1, 0, 3, 1, 1, 3, 1, 1, 0, 2, 0, 3, 1, 3, 3, 0, 1, 1, 0, 2, 2, 2, 3, 2, 1, 2, 3, 1, 3, 3, 2, 1, 3, 3, 3, 3, 3, 3, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 51 and the episode is 3225 and the total_steps are 161701\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 2, 2, 2, 0, 1, 0, 3, 0, 3, 1, 2, 2, 3, 0, 3, 2, 1, 2, 1, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 27 and the episode is 3226 and the total_steps are 161728\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 3, 1, 1, 2, 2, 2, 3, 3, 3, 0, 3, 3, 2, 3, 0, 2, 0, 1, 0, 0, 0, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3227 and the total_steps are 161757\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 3, 1, 3, 1, 2, 3, 2, 2, 0, 3, 0, 2, 1, 1, 2, 3, 2, 0, 0, 2, 3, 2, 2, 3, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 3228 and the total_steps are 161789\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3228     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5362     |\n",
      "|    total_timesteps  | 161789   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.34     |\n",
      "|    n_updates        | 27947    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 1, 3, 2, 3, 2, 2, 2, 2, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 16 and the episode is 3229 and the total_steps are 161805\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 2, 2, 0, 1, 1, 3, 1, 3, 1, 3, 1, 0, 3, 2, 0, 3, 1, 3, 2, 0, 2, 3, 3, 3, 3, 0, 2, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 35 and the episode is 3230 and the total_steps are 161840\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 2, 2, 1, 1, 1, 3, 3, 3, 3, 2, 3, 2, 1, 3, 1, 1, 3, 1, 0, 0, 0, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 29 and the episode is 3231 and the total_steps are 161869\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 3, 2, 2, 1, 2, 2, 2, 0, 2, 2, 3, 2, 2, 2, 2, 2, 2, 0, 2, 3, 0, 1, 0, 1, 1, 2, 3, 2, 3, 3, 1, 0, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 40 and the episode is 3232 and the total_steps are 161909\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3232     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5367     |\n",
      "|    total_timesteps  | 161909   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 27977    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 3, 0, 1, 1, 3, 2, 0, 0, 3, 2, 2, 1, 2, 0, 1, 3, 2, 0, 3, 2, 2, 0, 0, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 3233 and the total_steps are 161940\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 1, 3, 0, 3, 0, 2, 2, 3, 0, 0, 1, 0, 2, 3, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 22 and the episode is 3234 and the total_steps are 161962\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 2, 0, 0, 1, 0, 0, 3, 3, 0, 2, 0, 3, 1, 2, 2, 0, 0, 0, 0, 0, 2, 3, 3, 0, 0, 1, 1, 3, 3, 1, 0, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 39 and the episode is 3235 and the total_steps are 162001\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 0, 3, 2, 3, 1, 1, 2, 2, 0, 0, 0, 1, 2, 3, 2, 0, 3, 2, 0, 3, 2, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 3236 and the total_steps are 162030\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3236     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5372     |\n",
      "|    total_timesteps  | 162030   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 28007    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 3, 1, 2, 2, 2, 1, 0, 2, 2, 2, 1, 1, 3, 3, 0, 2, 2, 2, 3, 2, 2, 3, 0, 0, 0, 3, 2, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 3237 and the total_steps are 162065\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 1, 2, 0, 1, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 1, 2, 2, 3, 3, 3, 3, 3, 0, 0, 3, 1, 2, 0, 1, 2, 2, 0, 3, 1, 1, 1, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 44 and the episode is 3238 and the total_steps are 162109\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 1, 2, 0, 2, 1, 2, 3, 1, 1, 0, 3, 0, 1, 0, 1, 3, 2, 0, 3, 0, 3, 3, 2, 2, 0, 0, 0, 0, 0, 2, 3, 2, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 40 and the episode is 3239 and the total_steps are 162149\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 2, 3, 0, 3, 3, 3, 2, 1, 1, 3, 2, 0, 3, 0, 2, 3, 0, 1, 0, 0, 3, 1, 0, 2, 2, 1, 1, 0, 2, 1, 3, 2, 1, 1, 1, 1, 3, 3, 3, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 52 and the episode is 3240 and the total_steps are 162201\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3240     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5380     |\n",
      "|    total_timesteps  | 162201   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.8     |\n",
      "|    n_updates        | 28050    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 2, 3, 3, 1, 0, 3, 0, 2, 2, 3, 2, 1, 0, 3, 0, 2, 0, 1, 2, 0, 3, 0, 1, 1, 3, 3, 3, 2, 0, 1, 0, 2, 3, 3, 0, 3, 1, 2, 3, 3, 3, 3, 1, 3, 1, 1, 2, 0, 2, 1, 2, 2, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -942. And steps were 60 and the episode is 3241 and the total_steps are 162261\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 0, 3, 1, 3, 3, 3, 1, 1, 3, 2, 3, 1, 2, 0, 0, 1, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 0, 3, 2, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 37 and the episode is 3242 and the total_steps are 162298\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 0, 1, 1, 0, 1, 0, 1, 0, 1, 2, 1, 3, 0, 2, 2, 3, 3, 2, 0, 0, 0, 0, 1, 0, 0, 1, 3, 1, 1, 1, 1, 1, 2, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 41 and the episode is 3243 and the total_steps are 162339\n",
      "Done condition: collision\n",
      "[3, 3, 3, 3, 1, 0, 1, 2, 2, 0, 0, 3, 1, 0, 2, 3, 1, 2, 1, 1, 0, 3, 1, 2, 3, 3, 3, 0, 2, 1, 2, 0, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 3, 1, 2, 0, 0, 1, 3, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 54 and the episode is 3244 and the total_steps are 162393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.1     |\n",
      "|    ep_rew_mean      | -914     |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3244     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5388     |\n",
      "|    total_timesteps  | 162393   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 28098    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 0, 3, 3, 1, 3, 2, 3, 0, 0, 2, 2, 3, 0, 2, 1, 0, 0, 3, 3, 3, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 3245 and the total_steps are 162421\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 0, 3, 0, 1, 1, 3, 1, 0, 1, 0, 1, 3, 0, 3, 0, 1, 2, 2, 3, 0, 1, 3, 3, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 40 and the episode is 3246 and the total_steps are 162461\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 2, 2, 1, 2, 3, 2, 0, 1, 3, 1, 2, 0, 1, 2, 2, 3, 3, 1, 1, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 35 and the episode is 3247 and the total_steps are 162496\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 0, 2, 2, 1, 3, 0, 2, 1, 3, 3, 0, 1, 0, 1, 0, 1, 0, 2, 0, 3, 1, 3, 2, 0, 1, 0, 2, 3, 3, 1, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 38 and the episode is 3248 and the total_steps are 162534\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -914     |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3248     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5394     |\n",
      "|    total_timesteps  | 162534   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.53     |\n",
      "|    n_updates        | 28133    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 2, 3, 2, 0, 3, 3, 0, 2, 0, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 2, 1, 1, 3, 3, 2, 3, 3, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 3249 and the total_steps are 162569\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 0, 2, 1, 1, 3, 0, 1, 2, 2, 2, 0, 2, 3, 0, 3, 3, 1, 0, 1, 2, 0, 1, 2, 3, 2, 2, 0, 2, 0, 3, 1, 2, 2, 1, 2, 2, 1, 0, 3, 0, 1, 0, 2, 3, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 52 and the episode is 3250 and the total_steps are 162621\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 1, 0, 2, 0, 3, 3, 0, 2, 0, 2, 1, 2, 0, 3, 1, 1, 1, 1, 1, 3, 2, 1, 3, 2, 3, 2, 3, 0, 1, 1, 3, 3, 1, 3, 3, 2, 2, 0, 3, 1, 2, 1, 1, 0, 2, 2, 0, 1, 1, 3, 1, 0, 3, 0, 0, 2, 3, 3, 1, 3, 2, 1, 3, 3, 2, 1, 0, 1, 1, 2, 2, 2, 0, 0, 0, 0, 1, 3, 2, 1, 2, 3, 0, 2, 1, 2, 1, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1063. And steps were 95 and the episode is 3251 and the total_steps are 162716\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 1, 1, 3, 3, 2, 3, 1, 3, 0, 2, 3, 3, 3, 3, 1, 1, 0, 3, 2, 1, 1, 0, 1, 2, 3, 1, 0, 1, 0, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 37 and the episode is 3252 and the total_steps are 162753\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -914     |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3252     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5403     |\n",
      "|    total_timesteps  | 162753   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 28188    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 2, 1, 3, 1, 3, 3, 2, 2, 1, 2, 2, 1, 0, 1, 0, 3, 1, 1, 2, 1, 1, 3, 2, 2, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 32 and the episode is 3253 and the total_steps are 162785\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 3, 3, 0, 1, 1, 3, 0, 1, 2, 2, 0, 1, 2, 3, 2, 0, 1, 3, 2, 3, 0, 0, 1, 3, 2, 3, 1, 1, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 3254 and the total_steps are 162821\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 0, 1, 2, 0, 1, 0, 2, 0, 2, 3, 3, 1, 1, 0, 0, 1, 0, 2, 2, 1, 0, 1, 3, 2, 1, 0, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 34 and the episode is 3255 and the total_steps are 162855\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 2, 1, 3, 3, 3, 1, 2, 2, 3, 2, 3, 2, 1, 0, 1, 1, 2, 1, 2, 1, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 3256 and the total_steps are 162883\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -915     |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3256     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5409     |\n",
      "|    total_timesteps  | 162883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 37.3     |\n",
      "|    n_updates        | 28220    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 1, 3, 3, 1, 1, 3, 3, 0, 2, 2, 1, 1, 1, 3, 1, 3, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 24 and the episode is 3257 and the total_steps are 162907\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 3, 3, 2, 3, 0, 3, 3, 3, 0, 2, 0, 0, 2, 0, 1, 3, 3, 1, 1, 1, 2, 3, 1, 1, 2, 3, 0, 2, 0, 1, 0, 3, 1, 1, 3, 1, 0, 3, 0, 3, 3, 0, 1, 0, 3, 2, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 54 and the episode is 3258 and the total_steps are 162961\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 0, 0, 1, 0, 1, 2, 2, 3, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 3259 and the total_steps are 162977\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 3, 0, 3, 0, 1, 1, 2, 3, 2, 0, 0, 1, 3, 3, 0, 2, 2, 2, 1, 3, 3, 1, 2, 0, 0, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 33 and the episode is 3260 and the total_steps are 163010\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -935     |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3260     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5414     |\n",
      "|    total_timesteps  | 163010   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.7     |\n",
      "|    n_updates        | 28252    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 3, 3, 3, 1, 0, 1, 1, 3, 1, 0, 2, 3, 3, 3, 0, 0, 0, 1, 2, 1, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 28 and the episode is 3261 and the total_steps are 163038\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 1, 3, 2, 3, 1, 1, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 26 and the episode is 3262 and the total_steps are 163064\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 3, 2, 0, 1, 2, 0, 3, 1, 3, 1, 1, 1, 1, 0, 0, 2, 0, 1, 2, 1, 3, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 29 and the episode is 3263 and the total_steps are 163093\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 2, 0, 0, 0, 3, 3, 2, 2, 0, 1, 0, 3, 1, 2, 3, 0, 3, 0, 1, 0, 1, 2, 0, 1, 3, 3, 3, 2, 3, 0, 0, 1, 1, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 3264 and the total_steps are 163134\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3264     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5419     |\n",
      "|    total_timesteps  | 163134   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 28283    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 1, 2, 1, 2, 1, 1, 0, 1, 3, 2, 2, 0, 1, 2, 0, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 23 and the episode is 3265 and the total_steps are 163157\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 2, 1, 1, 1, 0, 0, 0, 3, 2, 0, 3, 2, 1, 1, 0, 1, 0, 1, 0, 0, 3, 3, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 30 and the episode is 3266 and the total_steps are 163187\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 3, 3, 1, 0, 0, 2, 3, 2, 1, 0, 0, 0, 1, 3, 2, 1, 3, 0, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 3267 and the total_steps are 163213\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 1, 2, 1, 1, 2, 0, 0, 0, 3, 3, 2, 0, 2, 0, 0, 0, 0, 1, 2, 2, 0, 3, 3, 2, 2, 0, 0, 1, 2, 0, 2, 2, 0, 3, 1, 2, 0, 0, 1, 0, 2, 2, 1, 0, 3, 0, 2, 2, 1, 2, 0, 3, 2, 1, 3, 3, 1, 0, 0, 2, 0, 2, 0, 2, 3, 2, 3, 1, 2, 3, 0, 1, 2, 3, 1, 0, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1082. And steps were 84 and the episode is 3268 and the total_steps are 163297\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3268     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5426     |\n",
      "|    total_timesteps  | 163297   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 28324    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 3, 3, 2, 1, 1, 2, 0, 2, 1, 2, 3, 2, 0, 0, 2, 0, 1, 1, 0, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 34 and the episode is 3269 and the total_steps are 163331\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 0, 0, 2, 0, 2, 3, 0, 3, 3, 0, 3, 0, 0, 1, 0, 2, 3, 3, 3, 1, 0, 2, 0, 2, 0, 0, 3, 3, 0, 2, 3, 0, 1, 3, 2, 1, 2, 2, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 46 and the episode is 3270 and the total_steps are 163377\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 0, 0, 3, 1, 2, 1, 2, 0, 1, 3, 3, 0, 2, 3, 3, 2, 3, 1, 1, 0, 2, 0, 1, 0, 3, 0, 3, 1, 0, 3, 2, 2, 2, 3, 3, 2, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 44 and the episode is 3271 and the total_steps are 163421\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 2, 0, 2, 1, 3, 2, 3, 3, 2, 0, 1, 3, 3, 2, 3, 0, 3, 0, 1, 0, 2, 1, 2, 3, 0, 3, 2, 2, 0, 1, 3, 1, 0, 0, 3, 0, 0, 1, 3, 2, 1, 3, 2, 2, 0, 2, 2, 2, 3, 2, 1, 1, 0, 1, 1, 1, 1, 2, 3, 0, 1, 1, 2, 1, 0, 2, 0, 3, 2, 0, 0, 3, 0, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -932. And steps were 82 and the episode is 3272 and the total_steps are 163503\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3272     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5434     |\n",
      "|    total_timesteps  | 163503   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 28375    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 3, 0, 0, 0, 0, 3, 1, 2, 0, 0, 3, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 31 and the episode is 3273 and the total_steps are 163534\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 3, 3, 2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 2, 0, 0, 0, 3, 0, 3, 2, 3, 2, 0, 2, 3, 1, 3, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 0, 2, 0, 3, 1, 1, 0, 1, 1, 1, 1, 1, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 60 and the episode is 3274 and the total_steps are 163594\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 3, 2, 1, 3, 3, 0, 1, 1, 3, 0, 2, 1, 3, 3, 2, 0, 3, 2, 3, 0, 0, 0, 2, 1, 3, 0, 3, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 3275 and the total_steps are 163629\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 3, 3, 3, 3, 0, 1, 1, 1, 0, 3, 3, 0, 1, 1, 3, 3, 1, 2, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 26 and the episode is 3276 and the total_steps are 163655\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3276     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5441     |\n",
      "|    total_timesteps  | 163655   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.59     |\n",
      "|    n_updates        | 28413    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 0, 2, 3, 1, 1, 0, 3, 3, 3, 3, 2, 0, 3, 2, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 22 and the episode is 3277 and the total_steps are 163677\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 0, 3, 3, 2, 2, 3, 0, 0, 1, 1, 1, 3, 3, 2, 3, 1, 2, 1, 0, 3, 0, 0, 3, 1, 3, 3, 3, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 3278 and the total_steps are 163712\n",
      "Done condition: collision\n",
      "[3, 1, 3, 1, 0, 2, 2, 3, 1, 2, 2, 1, 3, 1, 0, 3, 3, 3, 1, 1, 0, 0, 1, 1, 3, 2, 3, 0, 2, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 33 and the episode is 3279 and the total_steps are 163745\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 2, 2, 1, 2, 3, 3, 0, 2, 3, 0, 0, 2, 3, 0, 1, 2, 2, 3, 3, 2, 0, 2, 0, 0, 3, 2, 1, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 35 and the episode is 3280 and the total_steps are 163780\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3280     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5446     |\n",
      "|    total_timesteps  | 163780   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.1     |\n",
      "|    n_updates        | 28444    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 0, 1, 3, 0, 1, 1, 1, 3, 3, 1, 0, 1, 2, 0, 0, 2, 3, 3, 3, 0, 3, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 29 and the episode is 3281 and the total_steps are 163809\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 0, 2, 0, 2, 1, 1, 0, 3, 0, 3, 0, 2, 3, 1, 3, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 23 and the episode is 3282 and the total_steps are 163832\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 2, 1, 2, 3, 2, 0, 1, 3, 2, 1, 0, 3, 3, 2, 3, 0, 1, 1, 1, 3, 1, 1, 2, 1, 2, 3, 0, 3, 0, 0, 0, 0, 2, 0, 1, 3, 1, 0, 2, 2, 2, 1, 3, 2, 3, 1, 2, 1, 3, 2, 0, 3, 1, 3, 1, 3, 2, 2, 1, 0, 1, 3, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -938. And steps were 70 and the episode is 3283 and the total_steps are 163902\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 2, 2, 1, 1, 0, 3, 1, 2, 2, 3, 1, 3, 0, 3, 1, 3, 2, 0, 2, 0, 3, 0, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 30 and the episode is 3284 and the total_steps are 163932\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3284     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5453     |\n",
      "|    total_timesteps  | 163932   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 28482    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 1, 3, 0, 0, 0, 3, 0, 2, 0, 1, 1, 1, 3, 2, 2, 0, 2, 1, 0, 2, 3, 3, 2, 3, 3, 1, 1, 2, 0, 3, 1, 3, 0, 3, 2, 2, 0, 2, 3, 2, 0, 0, 1, 2, 2, 0, 0, 1, 3, 3, 1, 1, 0, 1, 1, 0, 0, 3, 1, 2, 0, 3, 2, 3, 2, 1, 2, 3, 0, 0, 1, 0, 3, 0, 1, 2, 3, 0, 2, 2, 0, 3, 0, 0, 0, 2, 3, 3, 2, 2, 0, 0, 3, 1, 1, 1, 3, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1069. And steps were 105 and the episode is 3285 and the total_steps are 164037\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 3, 1, 1, 1, 3, 3, 0, 2, 3, 1, 2, 3, 0, 3, 3, 3, 3, 3, 2, 1, 1, 2, 0, 3, 2, 2, 3, 3, 3, 2, 2, 0, 2, 2, 3, 0, 3, 0, 1, 2, 3, 3, 1, 0, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 52 and the episode is 3286 and the total_steps are 164089\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 1, 2, 2, 3, 1, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 0, 1, 3, 1, 2, 3, 0, 2, 1, 3, 0, 2, 1, 1, 3, 3, 3, 2, 0, 1, 1, 2, 0, 1, 1, 0, 3, 0, 0, 0, 0, 3, 0, 2, 2, 0, 3, 1, 1, 1, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 68 and the episode is 3287 and the total_steps are 164157\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 1, 1, 0, 3, 1, 1, 2, 2, 0, 3, 0, 0, 2, 2, 2, 0, 1, 0, 3, 1, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 3288 and the total_steps are 164185\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -955     |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3288     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5463     |\n",
      "|    total_timesteps  | 164185   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.69     |\n",
      "|    n_updates        | 28546    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 2, 2, 2, 2, 3, 2, 3, 0, 0, 0, 1, 0, 1, 3, 3, 3, 3, 0, 0, 3, 2, 3, 2, 2, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 3289 and the total_steps are 164217\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 2, 1, 2, 2, 3, 0, 1, 0, 3, 3, 2, 0, 3, 2, 1, 3, 0, 2, 2, 3, 0, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3290 and the total_steps are 164246\n",
      "Done condition: collision\n",
      "[3, 0, 0, 1, 1, 3, 3, 2, 1, 1, 3, 3, 0, 1, 0, 2, 0, 3, 1, 2, 1, 3, 2, 3, 1, 0, 1, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 31 and the episode is 3291 and the total_steps are 164277\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 1, 2, 1, 0, 1, 0, 2, 0, 0, 0, 3, 2, 0, 1, 0, 3, 0, 3, 2, 2, 2, 0, 0, 3, 0, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 3292 and the total_steps are 164310\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -975     |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3292     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5468     |\n",
      "|    total_timesteps  | 164310   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 37.6     |\n",
      "|    n_updates        | 28577    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 3, 0, 3, 3, 3, 0, 2, 3, 0, 1, 0, 1, 0, 0, 2, 1, 0, 2, 3, 2, 3, 1, 0, 3, 0, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 33 and the episode is 3293 and the total_steps are 164343\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 3, 0, 2, 1, 2, 3, 1, 3, 2, 0, 3, 0, 1, 3, 3, 2, 3, 0, 0, 3, 3, 0, 3, 2, 1, 1, 2, 0, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 42 and the episode is 3294 and the total_steps are 164385\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 0, 3, 3, 0, 2, 3, 3, 2, 0, 3, 3, 3, 1, 3, 0, 3, 2, 1, 2, 1, 3, 1, 2, 1, 3, 1, 0, 2, 2, 1, 2, 0, 3, 3, 1, 1, 1, 2, 3, 3, 3, 0, 1, 0, 0, 1, 2, 1, 2, 1, 1, 0, 3, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 61 and the episode is 3295 and the total_steps are 164446\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 3, 1, 1, 0, 3, 2, 3, 3, 3, 1, 3, 0, 3, 0, 2, 0, 0, 0, 2, 1, 3, 0, 0, 0, 2, 1, 3, 0, 1, 1, 0, 0, 0, 0, 3, 1, 1, 2, 2, 3, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 48 and the episode is 3296 and the total_steps are 164494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -996     |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3296     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5476     |\n",
      "|    total_timesteps  | 164494   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.54     |\n",
      "|    n_updates        | 28623    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 3, 1, 0, 2, 2, 3, 3, 0, 1, 3, 1, 2, 3, 1, 0, 2, 2, 1, 1, 1, 0, 0, 0, 2, 0, 2, 3, 3, 2, 3, 1, 3, 2, 3, 2, 0, 1, 2, 0, 2, 2, 2, 1, 1, 2, 2, 0, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 55 and the episode is 3297 and the total_steps are 164549\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 3, 3, 2, 2, 3, 0, 3, 1, 2, 2, 2, 0, 2, 2, 0, 3, 0, 3, 2, 2, 0, 1, 2, 2, 3, 1, 1, 0, 0, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 37 and the episode is 3298 and the total_steps are 164586\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 2, 1, 0, 3, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 1, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 23 and the episode is 3299 and the total_steps are 164609\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 2, 3, 0, 0, 2, 3, 0, 1, 3, 0, 3, 2, 3, 1, 2, 0, 0, 3, 1, 3, 2, 0, 3, 2, 3, 3, 2, 0, 3, 3, 0, 2, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 40 and the episode is 3300 and the total_steps are 164649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -996     |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3300     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5483     |\n",
      "|    total_timesteps  | 164649   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.92     |\n",
      "|    n_updates        | 28662    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 3, 2, 1, 3, 2, 3, 3, 2, 3, 0, 2, 1, 2, 1, 2, 2, 0, 2, 2, 1, 1, 0, 0, 2, 3, 1, 3, 1, 0, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 48 and the episode is 3301 and the total_steps are 164697\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 1, 3, 0, 2, 2, 0, 3, 3, 1, 2, 0, 3, 1, 3, 3, 0, 2, 3, 1, 3, 0, 3, 3, 3, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 3302 and the total_steps are 164729\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 1, 2, 0, 1, 2, 0, 1, 2, 2, 1, 1, 1, 1, 3, 2, 2, 2, 0, 2, 1, 0, 1, 0, 1, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 3303 and the total_steps are 164761\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 2, 3, 1, 1, 3, 2, 2, 3, 0, 3, 3, 3, 0, 1, 3, 3, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 3304 and the total_steps are 164785\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -996     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3304     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5489     |\n",
      "|    total_timesteps  | 164785   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63       |\n",
      "|    n_updates        | 28696    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 0, 3, 2, 2, 0, 1, 2, 1, 2, 2, 0, 2, 2, 0, 0, 1, 1, 1, 2, 0, 2, 3, 0, 3, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 3, 0, 0, 2, 0, 1, 2, 2, 3, 3, 1, 3, 2, 3, 0, 0, 2, 1, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1058. And steps were 60 and the episode is 3305 and the total_steps are 164845\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 1, 1, 2, 1, 3, 1, 1, 2, 3, 0, 1, 1, 3, 3, 1, 0, 0, 2, 1, 1, 0, 0, 1, 0, 3, 3, 1, 1, 0, 1, 0, 2, 0, 3, 0, 3, 2, 3, 3, 3, 3, 2, 1, 1, 0, 1, 2, 2, 1, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 57 and the episode is 3306 and the total_steps are 164902\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 3, 1, 2, 3, 2, 0, 0, 1, 3, 2, 0, 1, 1, 1, 2, 3, 2, 0, 2, 1, 3, 3, 0, 2, 1, 2, 1, 2, 1, 1, 2, 3, 1, 2, 1, 3, 3, 1, 3, 0, 0, 3, 3, 2, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 52 and the episode is 3307 and the total_steps are 164954\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 0, 0, 0, 3, 3, 1, 2, 2, 1, 3, 2, 0, 1, 2, 0, 3, 2, 0, 2, 1, 1, 1, 1, 3, 0, 2, 2, 0, 1, 1, 1, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 39 and the episode is 3308 and the total_steps are 164993\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -997     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3308     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5497     |\n",
      "|    total_timesteps  | 164993   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31       |\n",
      "|    n_updates        | 28748    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 2, 1, 2, 1, 0, 2, 3, 1, 1, 2, 3, 3, 0, 3, 0, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 23 and the episode is 3309 and the total_steps are 165016\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 2, 3, 0, 0, 3, 3, 1, 3, 3, 0, 3, 2, 3, 0, 3, 3, 3, 3, 2, 2, 2, 3, 2, 2, 3, 0, 3, 2, 3, 0, 0, 3, 0, 2, 1, 3, 0, 3, 2, 1, 0, 0, 3, 3, 0, 2, 3, 0, 3, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 57 and the episode is 3310 and the total_steps are 165073\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 2, 1, 1, 3, 0, 0, 3, 1, 0, 1, 2, 0, 3, 3, 3, 2, 3, 3, 2, 1, 2, 3, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was 997. And steps were 28 and the episode is 3311 and the total_steps are 165101\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 3, 2, 0, 2, 3, 2, 2, 3, 3, 0, 1, 3, 2, 0, 2, 2, 2, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 25 and the episode is 3312 and the total_steps are 165126\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3312     |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 5503     |\n",
      "|    total_timesteps  | 165126   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 28781    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 1, 2, 3, 1, 3, 0, 3, 2, 3, 1, 3, 1, 1, 3, 1, 3, 1, 0, 2, 1, 0, 0, 2, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 31 and the episode is 3313 and the total_steps are 165157\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 3, 3, 2, 0, 0, 2, 3, 3, 3, 3, 2, 3, 0, 1, 0, 0, 1, 1, 1, 2, 3, 1, 0, 0, 1, 2, 0, 2, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 36 and the episode is 3314 and the total_steps are 165193\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1, 1, 2, 0, 1, 1, 3, 3, 0, 3, 0, 1, 0, 3, 2, 1, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 33 and the episode is 3315 and the total_steps are 165226\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 2, 3, 0, 0, 3, 0, 3, 1, 1, 2, 0, 3, 1, 0, 1, 2, 0, 0, 3, 2, 3, 3, 0, 2, 3, 0, 1, 2, 1, 3, 0, 0, 3, 3, 2, 1, 2, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1043. And steps were 45 and the episode is 3316 and the total_steps are 165271\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3316     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5509     |\n",
      "|    total_timesteps  | 165271   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 28817    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 2, 2, 3, 2, 3, 2, 3, 3, 0, 3, 1, 3, 1, 3, 3, 2, 3, 3, 2, 1, 1, 1, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 30 and the episode is 3317 and the total_steps are 165301\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 2, 2, 3, 0, 3, 3, 3, 3, 1, 1, 3, 3, 0, 1, 1, 1, 1, 0, 1, 0, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 3318 and the total_steps are 165329\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 0, 0, 3, 0, 0, 2, 1, 1, 2, 1, 0, 2, 3, 0, 0, 1, 3, 1, 0, 3, 0, 2, 3, 2, 3, 0, 2, 1, 3, 3, 2, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 2, 3, 3, 1, 2, 2, 3, 1, 2, 3, 0, 1, 0, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 64 and the episode is 3319 and the total_steps are 165393\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 2, 3, 3, 3, 3, 0, 0, 2, 2, 3, 2, 2, 0, 0, 1, 2, 2, 0, 0, 1, 2, 1, 0, 2, 1, 1, 1, 0, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 3320 and the total_steps are 165429\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3320     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5515     |\n",
      "|    total_timesteps  | 165429   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.2     |\n",
      "|    n_updates        | 28857    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 3, 3, 1, 1, 1, 2, 3, 2, 2, 0, 1, 3, 1, 0, 1, 3, 1, 3, 1, 3, 1, 0, 0, 1, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 3321 and the total_steps are 165461\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 3, 1, 0, 1, 2, 2, 1, 2, 3, 2, 3, 2, 3, 2, 0, 1, 2, 1, 2, 2, 0, 3, 0, 1, 2, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 33 and the episode is 3322 and the total_steps are 165494\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 3, 0, 2, 0, 3, 2, 1, 1, 1, 3, 0, 2, 1, 2, 3, 1, 1, 0, 0, 0, 2, 1, 1, 1, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1029. And steps were 30 and the episode is 3323 and the total_steps are 165524\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 2, 2, 0, 3, 3, 0, 3, 2, 0, 3, 2, 0, 2, 1, 2, 1, 3, 3, 1, 2, 1, 3, 2, 3, 0, 3, 1, 1, 3, 3, 3, 2, 2, 0, 3, 1, 0, 0, 2, 0, 1, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 49 and the episode is 3324 and the total_steps are 165573\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3324     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5521     |\n",
      "|    total_timesteps  | 165573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.66     |\n",
      "|    n_updates        | 28893    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 3, 1, 3, 0, 1, 1, 0, 1, 3, 2, 1, 0, 2, 1, 3, 0, 0, 1, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 3325 and the total_steps are 165599\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 3, 1, 0, 3, 1, 0, 3, 1, 3, 2, 2, 2, 0, 2, 3, 0, 1, 0, 3, 2, 3, 0, 0, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was 1004. And steps were 29 and the episode is 3326 and the total_steps are 165628\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 0, 3, 1, 3, 0, 1, 0, 2, 1, 3, 2, 2, 1, 1, 0, 1, 0, 0, 0, 1, 0, 3, 2, 2, 3, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 33 and the episode is 3327 and the total_steps are 165661\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 1, 3, 1, 3, 1, 3, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 3, 2, 3, 2, 1, 1, 3, 1, 3, 1, 0, 2, 1, 1, 2, 2, 2, 3, 3, 2, 2, 3, 2, 3, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 48 and the episode is 3328 and the total_steps are 165709\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3328     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5527     |\n",
      "|    total_timesteps  | 165709   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 28927    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 1, 2, 3, 3, 0, 3, 1, 1, 3, 1, 2, 2, 1, 3, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 22 and the episode is 3329 and the total_steps are 165731\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 1, 3, 2, 0, 2, 2, 2, 1, 0, 0, 1, 0, 3, 1, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0, 0, 3, 1, 1, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 3330 and the total_steps are 165767\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 3, 1, 3, 3, 0, 3, 1, 1, 0, 3, 0, 1, 1, 2, 0, 3, 0, 3, 0, 2, 1, 3, 3, 0, 2, 3, 0, 3, 2, 2, 2, 2, 3, 1, 2, 0, 0, 0, 2, 2, 0, 3, 2, 0, 3, 2, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 54 and the episode is 3331 and the total_steps are 165821\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 2, 1, 1, 1, 1, 3, 3, 2, 2, 3, 2, 3, 3, 3, 1, 0, 1, 1, 2, 2, 3, 2, 0, 2, 1, 0, 0, 1, 3, 3, 1, 1, 0, 2, 1, 2, 3, 1, 0, 0, 3, 3, 3, 3, 3, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1051. And steps were 53 and the episode is 3332 and the total_steps are 165874\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3332     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5534     |\n",
      "|    total_timesteps  | 165874   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.13     |\n",
      "|    n_updates        | 28968    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 1, 2, 1, 2, 3, 0, 3, 3, 0, 2, 3, 3, 2, 2, 0, 0, 2, 2, 3, 1, 1, 0, 2, 2, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 32 and the episode is 3333 and the total_steps are 165906\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 1, 1, 1, 0, 2, 3, 2, 2, 1, 1, 0, 1, 1, 1, 1, 2, 2, 0, 3, 2, 1, 1, 2, 2, 3, 1, 3, 3, 3, 3, 1, 0, 3, 3, 0, 1, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 44 and the episode is 3334 and the total_steps are 165950\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 3, 3, 3, 0, 0, 2, 2, 3, 2, 2, 1, 0, 2, 2, 1, 0, 2, 3, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 3335 and the total_steps are 165976\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 0, 2, 1, 3, 1, 1, 3, 0, 2, 2, 1, 0, 1, 3, 1, 2, 2, 3, 1, 3, 2, 2, 3, 3, 3, 3, 1, 1, 2, 2, 2, 3, 1, 0, 0, 0, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 44 and the episode is 3336 and the total_steps are 166020\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3336     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5540     |\n",
      "|    total_timesteps  | 166020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.4     |\n",
      "|    n_updates        | 29004    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 2, 3, 1, 1, 3, 1, 3, 2, 3, 1, 1, 1, 1, 2, 3, 2, 1, 1, 3, 3, 1, 3, 2, 3, 0, 0, 1, 2, 0, 0, 1, 3, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 39 and the episode is 3337 and the total_steps are 166059\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 2, 3, 1, 3, 3, 2, 0, 3, 2, 3, 2, 2, 1, 3, 2, 2, 1, 0, 3, 3, 3, 1, 0, 3, 1, 3, 1, 1, 2, 0, 2, 0, 3, 3, 0, 1, 1, 3, 1, 2, 3, 0, 0, 1, 3, 2, 0, 3, 3, 2, 1, 3, 2, 3, 2, 2, 0, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 66 and the episode is 3338 and the total_steps are 166125\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 1, 3, 0, 2, 0, 1, 0, 3, 2, 0, 2, 2, 0, 0, 3, 1, 2, 1, 3, 0, 1, 3, 2, 3, 2, 3, 3, 2, 3, 0, 1, 2, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 40 and the episode is 3339 and the total_steps are 166165\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 1, 1, 3, 1, 1, 0, 2, 2, 3, 1, 2, 3, 1, 3, 1, 0, 2, 3, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 26 and the episode is 3340 and the total_steps are 166191\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3340     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5547     |\n",
      "|    total_timesteps  | 166191   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 29047    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 1, 0, 2, 1, 1, 3, 2, 0, 2, 2, 1, 1, 1, 0, 3, 1, 2, 3, 0, 3, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 28 and the episode is 3341 and the total_steps are 166219\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 0, 3, 0, 0, 3, 3, 1, 0, 1, 3, 3, 2, 2, 2, 1, 0, 0, 0, 0, 2, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3342 and the total_steps are 166247\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 2, 3, 2, 0, 1, 0, 2, 1, 2, 1, 1, 0, 0, 0, 2, 2, 0, 0, 2, 3, 1, 0, 1, 0, 1, 2, 1, 3, 2, 2, 1, 1, 0, 2, 1, 2, 1, 0, 1, 2, 3, 0, 2, 1, 0, 3, 2, 2, 2, 1, 3, 1, 1, 0, 3, 2, 0, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 2, 1, 2, 3, 3, 1, 2, 2, 1, 2, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 86 and the episode is 3343 and the total_steps are 166333\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 2, 3, 2, 1, 3, 3, 2, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 27 and the episode is 3344 and the total_steps are 166360\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3344     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5554     |\n",
      "|    total_timesteps  | 166360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.23     |\n",
      "|    n_updates        | 29089    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 2, 1, 0, 0, 1, 3, 3, 2, 3, 1, 1, 3, 3, 2, 2, 2, 1, 3, 3, 1, 2, 1, 3, 1, 1, 1, 0, 1, 3, 3, 2, 2, 3, 0, 2, 2, 0, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 45 and the episode is 3345 and the total_steps are 166405\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 3, 3, 0, 1, 1, 2, 0, 0, 3, 3, 3, 3, 1, 1, 3, 0, 2, 1, 2, 2, 0, 3, 3, 2, 3, 2, 3, 2, 3, 3, 0, 0, 1, 3, 2, 0, 2, 0, 3, 1, 1, 2, 2, 2, 3, 0, 2, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 64 and the episode is 3346 and the total_steps are 166469\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 2, 1, 3, 0, 1, 1, 2, 3, 1, 1, 1, 3, 2, 3, 2, 0, 2, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 25 and the episode is 3347 and the total_steps are 166494\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 3, 3, 0, 0, 2, 1, 3, 3, 1, 1, 1, 2, 1, 2, 0, 1, 3, 0, 0, 3, 1, 0, 0, 0, 0, 0, 1, 1, 3, 3, 2, 1, 0, 1, 1, 0, 1, 2, 0, 2, 2, 3, 0, 1, 0, 0, 2, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 55 and the episode is 3348 and the total_steps are 166549\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3348     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5561     |\n",
      "|    total_timesteps  | 166549   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 29137    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 3, 3, 2, 0, 3, 0, 1, 2, 1, 2, 0, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 28 and the episode is 3349 and the total_steps are 166577\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 1, 3, 1, 3, 1, 1, 0, 2, 3, 2, 0, 1, 2, 2, 3, 3, 1, 2, 1, 2, 1, 1, 0, 3, 1, 0, 1, 1, 1, 3, 2, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 38 and the episode is 3350 and the total_steps are 166615\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 0, 3, 3, 2, 2, 1, 2, 1, 3, 1, 3, 0, 3, 1, 2, 0, 1, 0, 1, 0, 2, 2, 1, 1, 0, 1, 3, 1, 1, 0, 0, 3, 1, 3, 3, 2, 3, 3, 2, 0, 2, 0, 3, 0, 3, 0, 2, 2, 1, 0, 1, 1, 1, 3, 2, 0, 1, 2, 1, 2, 1, 0, 1, 0, 3, 0, 2, 0, 3, 0, 3, 0, 3, 0, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -942. And steps were 82 and the episode is 3351 and the total_steps are 166697\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 1, 2, 0, 3, 0, 3, 2, 0, 2, 2, 3, 3, 3, 2, 1, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 3352 and the total_steps are 166718\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3352     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5569     |\n",
      "|    total_timesteps  | 166718   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.23     |\n",
      "|    n_updates        | 29179    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 2, 3, 1, 2, 0, 2, 3, 2, 0, 2, 2, 3, 2, 0, 3, 0, 0, 0, 3, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 3353 and the total_steps are 166743\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 0, 2, 3, 0, 1, 2, 2, 2, 1, 3, 1, 3, 2, 2, 0, 1, 2, 1, 2, 0, 1, 2, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 30 and the episode is 3354 and the total_steps are 166773\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 0, 2, 2, 3, 0, 2, 2, 2, 1, 2, 3, 0, 1, 2, 2, 1, 0, 0, 0, 1, 0, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3355 and the total_steps are 166802\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 1, 1, 0, 1, 1, 3, 0, 3, 3, 1, 3, 2, 2, 3, 2, 3, 2, 3, 1, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 27 and the episode is 3356 and the total_steps are 166829\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3356     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5574     |\n",
      "|    total_timesteps  | 166829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.15     |\n",
      "|    n_updates        | 29207    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 0, 3, 0, 0, 2, 0, 0, 3, 3, 2, 3, 2, 0, 0, 2, 0, 0, 2, 2, 3, 3, 0, 1, 3, 2, 3, 0, 2, 2, 2, 3, 2, 0, 1, 3, 3, 2, 0, 2, 2, 2, 3, 3, 0, 0, 0, 1, 2, 0, 2, 1, 2, 0, 1, 2, 1, 2, 3, 0, 3, 0, 0, 2, 2, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1070. And steps were 72 and the episode is 3357 and the total_steps are 166901\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 3, 2, 0, 1, 2, 2, 2, 2, 3, 1, 1, 1, 2, 2, 2, 3, 3, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 25 and the episode is 3358 and the total_steps are 166926\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 3, 1, 0, 1, 1, 2, 1, 0, 0, 3, 1, 0, 2, 0, 1, 2, 1, 2, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 3359 and the total_steps are 166952\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 1, 2, 0, 1, 0, 3, 2, 0, 2, 3, 0, 0, 2, 1, 2, 1, 3, 0, 1, 0, 0, 2, 2, 2, 3, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 33 and the episode is 3360 and the total_steps are 166985\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3360     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5580     |\n",
      "|    total_timesteps  | 166985   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.8     |\n",
      "|    n_updates        | 29246    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 0, 2, 2, 2, 2, 0, 2, 3, 3, 1, 0, 0, 3, 2, 0, 1, 1, 3, 2, 3, 0, 1, 0, 0, 2, 2, 1, 0, 3, 1, 2, 1, 2, 0, 0, 1, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 44 and the episode is 3361 and the total_steps are 167029\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 0, 0, 2, 0, 2, 3, 3, 1, 2, 3, 1, 1, 1, 0, 3, 1, 2, 0, 1, 3, 3, 3, 1, 0, 2, 2, 2, 3, 3, 2, 0, 0, 2, 0, 2, 2, 0, 3, 1, 1, 1, 0, 1, 0, 0, 1, 1, 2, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 56 and the episode is 3362 and the total_steps are 167085\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 1, 0, 0, 2, 3, 1, 0, 0, 0, 0, 3, 3, 3, 3, 0, 3, 0, 0, 2, 1, 3, 2, 2, 3, 1, 1, 1, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 35 and the episode is 3363 and the total_steps are 167120\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 2, 3, 1, 0, 0, 3, 3, 3, 3, 2, 3, 3, 1, 1, 0, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 23 and the episode is 3364 and the total_steps are 167143\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3364     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5587     |\n",
      "|    total_timesteps  | 167143   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65.2     |\n",
      "|    n_updates        | 29285    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 0, 1, 3, 3, 0, 0, 1, 3, 2, 1, 3, 1, 0, 1, 0, 3, 2, 2, 0, 1, 3, 1, 3, 2, 2, 3, 0, 3, 1, 0, 0, 1, 3, 3, 2, 3, 0, 1, 2, 2, 2, 1, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 50 and the episode is 3365 and the total_steps are 167193\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 0, 0, 3, 2, 1, 3, 0, 1, 3, 0, 2, 3, 3, 1, 2, 3, 0, 0, 3, 3, 0, 0, 0, 3, 3, 2, 1, 0, 3, 1, 3, 0, 0, 3, 2, 3, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 44 and the episode is 3366 and the total_steps are 167237\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 2, 0, 1, 3, 0, 1, 0, 3, 1, 3, 1, 3, 3, 3, 1, 0, 1, 2, 1, 1, 2, 3, 0, 2, 0, 3, 3, 3, 0, 1, 0, 3, 2, 2, 1, 2, 3, 0, 2, 1, 3, 1, 2, 3, 2, 2, 1, 2, 0, 0, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 58 and the episode is 3367 and the total_steps are 167295\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 0, 0, 1, 1, 0, 2, 2, 2, 3, 1, 0, 0, 2, 3, 0, 1, 2, 2, 0, 1, 0, 3, 3, 2, 1, 3, 3, 1, 0, 0, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 38 and the episode is 3368 and the total_steps are 167333\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3368     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5595     |\n",
      "|    total_timesteps  | 167333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48     |\n",
      "|    n_updates        | 29333    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 0, 2, 3, 0, 0, 2, 2, 1, 3, 3, 0, 2, 0, 2, 0, 1, 3, 3, 2, 1, 2, 2, 0, 0, 1, 0, 1, 3, 0, 1, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 38 and the episode is 3369 and the total_steps are 167371\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 3, 1, 1, 0, 3, 1, 2, 2, 3, 2, 2, 3, 3, 0, 3, 3, 0, 2, 3, 1, 3, 2, 1, 3, 3, 0, 2, 0, 2, 2, 3, 1, 1, 2, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 42 and the episode is 3370 and the total_steps are 167413\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 3, 2, 3, 2, 0, 1, 3, 2, 1, 0, 1, 0, 0, 1, 3, 1, 2, 3, 0, 0, 0, 2, 2, 2, 2, 3, 0, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 35 and the episode is 3371 and the total_steps are 167448\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 2, 1, 3, 3, 1, 2, 3, 3, 3, 3, 0, 3, 2, 0, 3, 3, 3, 0, 0, 2, 2, 1, 2, 3, 3, 2, 3, 2, 1, 3, 1, 1, 1, 0, 3, 3, 3, 3, 2, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 47 and the episode is 3372 and the total_steps are 167495\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3372     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5602     |\n",
      "|    total_timesteps  | 167495   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 29373    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 2, 2, 1, 3, 0, 3, 3, 0, 3, 0, 1, 0, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 3373 and the total_steps are 167515\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 3, 3, 0, 3, 1, 1, 0, 0, 2, 2, 0, 0, 0, 3, 3, 3, 2, 3, 0, 1, 1, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 29 and the episode is 3374 and the total_steps are 167544\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 0, 0, 2, 3, 0, 0, 2, 1, 2, 1, 3, 3, 3, 1, 2, 2, 0, 2, 1, 0, 3, 0, 0, 1, 2, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 3375 and the total_steps are 167577\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 1, 3, 3, 2, 2, 0, 1, 1, 0, 3, 1, 0, 2, 3, 1, 2, 2, 1, 0, 1, 2, 2, 2, 0, 3, 2, 0, 3, 0, 3, 1, 2, 3, 1, 3, 2, 3, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 45 and the episode is 3376 and the total_steps are 167622\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3376     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5607     |\n",
      "|    total_timesteps  | 167622   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.18     |\n",
      "|    n_updates        | 29405    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 3, 1, 1, 0, 0, 2, 2, 0, 2, 0, 1, 2, 1, 0, 3, 1, 1, 2, 1, 3, 3, 3, 0, 0, 3, 3, 2, 3, 1, 0, 2, 3, 2, 2, 0, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 43 and the episode is 3377 and the total_steps are 167665\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 0, 0, 0, 0, 3, 1, 3, 3, 2, 1, 1, 0, 2, 2, 3, 2, 0, 3, 2, 1, 2, 3, 1, 2, 0, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 33 and the episode is 3378 and the total_steps are 167698\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 3, 2, 3, 0, 1, 1, 1, 0, 2, 1, 3, 1, 2, 2, 3, 2, 2, 2, 2, 1, 2, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 36 and the episode is 3379 and the total_steps are 167734\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 2, 1, 0, 1, 3, 0, 1, 1, 1, 1, 2, 2, 0, 2, 2, 0, 1, 0, 3, 3, 2, 0, 0, 1, 2, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3380 and the total_steps are 167766\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3380     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5613     |\n",
      "|    total_timesteps  | 167766   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.5     |\n",
      "|    n_updates        | 29441    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 0, 0, 3, 1, 0, 2, 0, 3, 1, 0, 0, 3, 0, 0, 1, 2, 1, 2, 3, 0, 3, 3, 3, 1, 1, 1, 3, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 35 and the episode is 3381 and the total_steps are 167801\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 2, 0, 1, 3, 0, 1, 0, 2, 2, 1, 0, 0, 2, 2, 1, 2, 3, 3, 1, 2, 0, 0, 3, 2, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 32 and the episode is 3382 and the total_steps are 167833\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 3, 3, 1, 2, 1, 0, 1, 1, 3, 0, 0, 1, 1, 3, 1, 2, 3, 1, 1, 0, 1, 1, 1, 2, 0, 2, 3, 1, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 3383 and the total_steps are 167869\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 2, 2, 0, 0, 3, 3, 2, 2, 1, 2, 3, 0, 1, 2, 2, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 3384 and the total_steps are 167894\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3384     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5619     |\n",
      "|    total_timesteps  | 167894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.39     |\n",
      "|    n_updates        | 29473    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 0, 2, 1, 1, 2, 1, 3, 2, 3, 1, 2, 2, 0, 1, 0, 3, 3, 3, 2, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 27 and the episode is 3385 and the total_steps are 167921\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 0, 2, 3, 0, 2, 2, 1, 1, 0, 2, 2, 3, 1, 3, 0, 0, 0, 0, 3, 3, 1, 2, 3, 3, 2, 0, 3, 2, 3, 0, 3, 3, 1, 1, 1, 3, 0, 3, 1, 0, 0, 3, 1, 0, 2, 3, 1, 1, 2, 2, 3, 3, 0, 1, 0, 0, 2, 0, 1, 0, 2, 2, 2, 3, 2, 1, 1, 2, 0, 2, 3, 0, 1, 3, 0, 0, 1, 1, 1, 1, 3, 0, 2, 0, 0, 2, 0, 2, 2, 0, 1, 1, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -918. And steps were 100 and the episode is 3386 and the total_steps are 168021\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 1, 0, 0, 3, 2, 3, 1, 3, 3, 0, 1, 3, 3, 2, 2, 2, 3, 1, 2, 2, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3387 and the total_steps are 168049\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 0, 1, 3, 3, 1, 1, 1, 3, 2, 2, 3, 1, 1, 3, 3, 0, 2, 3, 3, 0, 3, 0, 0, 0, 3, 1, 2, 1, 1, 3, 2, 2, 2, 0, 2, 3, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 44 and the episode is 3388 and the total_steps are 168093\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3388     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5627     |\n",
      "|    total_timesteps  | 168093   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.61     |\n",
      "|    n_updates        | 29523    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 2, 1, 3, 2, 0, 2, 3, 0, 2, 1, 3, 2, 0, 1, 2, 3, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 24 and the episode is 3389 and the total_steps are 168117\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 1, 1, 1, 0, 0, 2, 1, 2, 0, 0, 2, 3, 2, 0, 2, 0, 0, 1, 0, 1, 0, 3, 2, 1, 3, 1, 1, 1, 3, 2, 1, 3, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 3390 and the total_steps are 168157\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 3, 2, 1, 2, 3, 1, 3, 1, 2, 0, 1, 1, 3, 2, 1, 0, 3, 2, 2, 0, 3, 3, 2, 1, 2, 0, 3, 0, 0, 2, 0, 0, 0, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 41 and the episode is 3391 and the total_steps are 168198\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 0, 1, 2, 2, 2, 2, 0, 1, 1, 2, 0, 0, 0, 0, 3, 0, 0, 0, 2, 1, 2, 0, 3, 1, 2, 2, 2, 3, 0, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 3, 2, 3, 0, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -951. And steps were 51 and the episode is 3392 and the total_steps are 168249\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3392     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5633     |\n",
      "|    total_timesteps  | 168249   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.09     |\n",
      "|    n_updates        | 29562    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 1, 1, 0, 1, 0, 0, 2, 3, 3, 3, 0, 2, 2, 1, 1, 1, 1, 2, 2, 0, 2, 1, 1, 2, 1, 1, 0, 0, 3, 3, 2, 2, 0, 0, 0, 0, 2, 1, 3, 0, 1, 0, 0, 0, 2, 3, 0, 3, 3, 2, 0, 0, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 60 and the episode is 3393 and the total_steps are 168309\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 3, 1, 3, 2, 0, 3, 1, 2, 0, 2, 1, 1, 0, 2, 1, 2, 2, 3, 1, 0, 3, 2, 3, 2, 0, 2, 1, 0, 2, 1, 2, 3, 2, 3, 2, 0, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 44 and the episode is 3394 and the total_steps are 168353\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 0, 1, 2, 3, 2, 2, 3, 2, 0, 2, 0, 0, 2, 2, 2, 1, 1, 0, 2, 3, 0, 2, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 30 and the episode is 3395 and the total_steps are 168383\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 2, 1, 3, 2, 0, 0, 3, 1, 0, 1, 3, 0, 0, 0, 0, 3, 1, 3, 1, 0, 1, 2, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 30 and the episode is 3396 and the total_steps are 168413\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3396     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5640     |\n",
      "|    total_timesteps  | 168413   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.9     |\n",
      "|    n_updates        | 29603    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 2, 3, 0, 3, 2, 3, 0, 0, 1, 3, 0, 0, 2, 3, 2, 0, 1, 0, 3, 1, 1, 3, 3, 2, 0, 1, 3, 3, 3, 0, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 37 and the episode is 3397 and the total_steps are 168450\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 3, 1, 0, 1, 2, 2, 2, 1, 1, 2, 0, 2, 2, 0, 1, 0, 1, 0, 2, 3, 3, 1, 1, 2, 3, 3, 3, 1, 1, 3, 3, 3, 0, 1, 2, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 43 and the episode is 3398 and the total_steps are 168493\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 2, 2, 1, 1, 1, 0, 2, 0, 2, 0, 3, 1, 1, 0, 2, 2, 3, 3, 1, 2, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 3399 and the total_steps are 168521\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 3, 0, 2, 2, 2, 0, 1, 3, 1, 3, 1, 1, 2, 1, 1, 0, 0, 3, 3, 1, 0, 3, 1, 0, 0, 1, 2, 0, 1, 3, 3, 2, 3, 1, 0, 0, 1, 3, 3, 3, 1, 2, 0, 2, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 52 and the episode is 3400 and the total_steps are 168573\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3400     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5646     |\n",
      "|    total_timesteps  | 168573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 66       |\n",
      "|    n_updates        | 29643    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 1, 1, 3, 1, 1, 3, 2, 1, 3, 3, 0, 1, 2, 2, 1, 1, 2, 1, 0, 3, 2, 2, 1, 2, 3, 2, 3, 2, 0, 2, 1, 3, 2, 2, 2, 0, 1, 3, 1, 3, 2, 0, 3, 1, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 52 and the episode is 3401 and the total_steps are 168625\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 3, 1, 3, 2, 1, 3, 2, 1, 1, 1, 0, 1, 2, 2, 3, 1, 2, 2, 0, 2, 1, 3, 0, 1, 2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 1, 2, 2, 2, 0, 1, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 49 and the episode is 3402 and the total_steps are 168674\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 2, 1, 1, 3, 3, 1, 0, 1, 1, 1, 0, 0, 2, 2, 2, 3, 2, 2, 2, 3, 0, 0, 0, 2, 1, 0, 0, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 35 and the episode is 3403 and the total_steps are 168709\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 1, 2, 2, 0, 3, 0, 0, 2, 2, 2, 3, 1, 2, 1, 3, 2, 1, 0, 1, 2, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 3404 and the total_steps are 168734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -856     |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3404     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5653     |\n",
      "|    total_timesteps  | 168734   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 60.1     |\n",
      "|    n_updates        | 29683    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 3, 1, 2, 1, 2, 0, 2, 0, 3, 3, 2, 1, 2, 2, 2, 1, 2, 3, 3, 1, 0, 0, 2, 2, 0, 1, 0, 0, 1, 2, 2, 0, 3, 2, 2, 0, 2, 3, 1, 1, 0, 2, 0, 3, 0, 3, 2, 1, 0, 1, 1, 1, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 60 and the episode is 3405 and the total_steps are 168794\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 1, 1, 1, 1, 3, 3, 2, 1, 3, 3, 2, 3, 0, 3, 2, 0, 0, 0, 1, 2, 3, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 29 and the episode is 3406 and the total_steps are 168823\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 3, 3, 0, 2, 2, 1, 1, 0, 0, 3, 3, 0, 0, 2, 1, 1, 1, 3, 3, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 3, 0, 0, 2, 0, 2, 0, 3, 3, 3, 1, 2, 0, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1049. And steps were 51 and the episode is 3407 and the total_steps are 168874\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 3, 1, 3, 3, 2, 3, 2, 3, 2, 3, 3, 0, 3, 3, 1, 0, 3, 0, 2, 1, 1, 3, 2, 2, 2, 3, 1, 2, 2, 1, 1, 0, 1, 3, 0, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 43 and the episode is 3408 and the total_steps are 168917\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -855     |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3408     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5661     |\n",
      "|    total_timesteps  | 168917   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 29729    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 2, 2, 2, 2, 1, 3, 1, 2, 1, 3, 2, 0, 2, 3, 3, 3, 0, 3, 1, 1, 3, 0, 2, 0, 0, 0, 3, 1, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 36 and the episode is 3409 and the total_steps are 168953\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 2, 1, 0, 2, 2, 3, 0, 2, 0, 2, 0, 2, 3, 1, 3, 3, 1, 1, 2, 2, 2, 2, 0, 1, 2, 2, 1, 3, 1, 2, 1, 1, 2, 1, 1, 2, 2, 3, 1, 1, 1, 0, 0, 1, 2, 1, 3, 3, 1, 3, 1, 1, 2, 2, 3, 1, 1, 1, 2, 2, 2, 0, 1, 0, 3, 2, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -942. And steps were 74 and the episode is 3410 and the total_steps are 169027\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 1, 3, 0, 0, 1, 2, 0, 1, 0, 0, 0, 1, 0, 0, 3, 1, 2, 0, 0, 3, 1, 2, 0, 0, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 3411 and the total_steps are 169059\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 0, 0, 0, 1, 1, 2, 2, 2, 3, 0, 1, 3, 3, 3, 0, 2, 1, 3, 0, 1, 1, 2, 0, 2, 1, 0, 2, 0, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 3412 and the total_steps are 169101\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3412     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5669     |\n",
      "|    total_timesteps  | 169101   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.54     |\n",
      "|    n_updates        | 29775    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 3, 3, 3, 0, 1, 1, 2, 2, 3, 2, 0, 2, 1, 3, 3, 0, 3, 1, 1, 1, 1, 0, 1, 2, 3, 2, 3, 0, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 36 and the episode is 3413 and the total_steps are 169137\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 0, 3, 2, 0, 2, 0, 0, 2, 1, 0, 3, 0, 1, 1, 2, 0, 2, 2, 2, 1, 3, 2, 0, 1, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 32 and the episode is 3414 and the total_steps are 169169\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 3, 1, 0, 2, 3, 3, 1, 2, 2, 0, 1, 3, 0, 0, 2, 2, 1, 0, 0, 3, 1, 1, 0, 3, 1, 3, 1, 3, 3, 3, 0, 0, 0, 3, 1, 0, 2, 0, 0, 1, 0, 3, 1, 2, 1, 2, 2, 0, 1, 0, 2, 1, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1058. And steps were 60 and the episode is 3415 and the total_steps are 169229\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 1, 3, 3, 3, 3, 0, 3, 3, 2, 3, 0, 0, 3, 1, 2, 2, 1, 2, 1, 0, 0, 2, 1, 3, 0, 0, 0, 3, 0, 0, 1, 2, 3, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1049. And steps were 55 and the episode is 3416 and the total_steps are 169284\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3416     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5676     |\n",
      "|    total_timesteps  | 169284   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 29820    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 3, 2, 3, 0, 0, 0, 3, 1, 1, 3, 3, 0, 3, 2, 3, 3, 1, 0, 2, 0, 0, 3, 1, 2, 1, 3, 0, 2, 3, 3, 2, 1, 3, 3, 3, 2, 3, 1, 1, 0, 3, 1, 1, 1, 2, 0, 0, 1, 2, 3, 0, 2, 1, 2, 3, 2, 0, 2, 2, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 66 and the episode is 3417 and the total_steps are 169350\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 3, 2, 1, 3, 3, 3, 0, 3, 0, 3, 3, 3, 2, 1, 3, 2, 3, 2, 1, 3, 1, 1, 0, 0, 1, 1, 2, 0, 3, 2, 1, 0, 2, 0, 0, 3, 0, 1, 3, 3, 2, 1, 3, 3, 1, 2, 3, 0, 2, 1, 3, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 1, 2, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -941. And steps were 73 and the episode is 3418 and the total_steps are 169423\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 1, 3, 2, 2, 3, 1, 3, 1, 2, 2, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 18 and the episode is 3419 and the total_steps are 169441\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 3, 3, 0, 1, 1, 0, 3, 0, 3, 3, 1, 2, 2, 1, 2, 3, 3, 0, 0, 0, 0, 1, 3, 3, 0, 2, 2, 0, 0, 1, 2, 2, 2, 0, 3, 3, 3, 0, 2, 0, 1, 2, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 50 and the episode is 3420 and the total_steps are 169491\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -874     |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3420     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5685     |\n",
      "|    total_timesteps  | 169491   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.83     |\n",
      "|    n_updates        | 29872    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 2, 2, 0, 3, 0, 1, 0, 1, 1, 3, 3, 0, 1, 3, 3, 0, 1, 0, 1, 3, 2, 3, 2, 2, 3, 2, 0, 0, 2, 2, 2, 1, 3, 1, 2, 0, 3, 2, 0, 0, 3, 0, 1, 1, 0, 1, 2, 2, 1, 0, 0, 1, 0, 1, 1, 3, 0, 1, 3, 2, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 68 and the episode is 3421 and the total_steps are 169559\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 2, 1, 0, 0, 0, 3, 3, 0, 0, 1, 0, 3, 0, 0, 0, 3, 1, 2, 2, 3, 1, 0, 1, 0, 2, 0, 3, 1, 3, 2, 1, 0, 1, 2, 0, 1, 0, 3, 2, 3, 1, 1, 2, 0, 2, 3, 2, 0, 1, 1, 3, 2, 1, 3, 3, 3, 1, 3, 0, 0, 3, 0, 1, 2, 2, 2, 1, 3, 1, 2, 3, 2, 2, 2, 2, 0, 1, 2, 3, 3, 3, 3, 2, 2, 3, 2, 1, 1, 2, 1, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1078. And steps were 98 and the episode is 3422 and the total_steps are 169657\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 2, 0, 3, 2, 2, 1, 0, 1, 3, 2, 1, 2, 0, 2, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 30 and the episode is 3423 and the total_steps are 169687\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 2, 2, 1, 3, 3, 2, 3, 0, 1, 3, 3, 3, 3, 0, 3, 2, 3, 0, 2, 3, 3, 1, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 3424 and the total_steps are 169717\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3424     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5694     |\n",
      "|    total_timesteps  | 169717   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 29929    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 3, 3, 2, 1, 3, 3, 2, 2, 3, 1, 1, 3, 0, 1, 2, 3, 2, 2, 3, 1, 2, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was 1026. And steps were 27 and the episode is 3425 and the total_steps are 169744\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 1, 0, 1, 0, 0, 1, 3, 2, 2, 2, 0, 0, 3, 2, 3, 0, 3, 2, 1, 1, 3, 0, 2, 3, 2, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 3426 and the total_steps are 169777\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 1, 1, 2, 0, 2, 3, 3, 0, 1, 2, 1, 3, 2, 1, 2, 3, 0, 1, 0, 3, 1, 2, 2, 0, 1, 2, 0, 2, 1, 0, 3, 1, 1, 3, 3, 0, 0, 1, 3, 3, 3, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 49 and the episode is 3427 and the total_steps are 169826\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 1, 0, 3, 1, 2, 1, 1, 0, 3, 0, 3, 1, 1, 0, 3, 3, 1, 1, 0, 3, 3, 2, 3, 1, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 32 and the episode is 3428 and the total_steps are 169858\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -894     |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3428     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5700     |\n",
      "|    total_timesteps  | 169858   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.6     |\n",
      "|    n_updates        | 29964    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 0, 2, 0, 2, 1, 0, 0, 1, 1, 1, 2, 0, 2, 0, 1, 0, 1, 0, 0, 2, 2, 3, 2, 3, 1, 3, 0, 0, 3, 3, 2, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 39 and the episode is 3429 and the total_steps are 169897\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 2, 2, 0, 2, 1, 2, 2, 2, 3, 1, 1, 2, 2, 3, 2, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 29 and the episode is 3430 and the total_steps are 169926\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 2, 3, 1, 2, 3, 0, 3, 2, 2, 0, 0, 2, 0, 2, 3, 2, 1, 2, 2, 3, 3, 0, 0, 1, 3, 2, 3, 1, 0, 1, 1, 1, 3, 2, 1, 0, 1, 2, 3, 1, 1, 2, 2, 1, 1, 1, 1, 0, 0, 3, 2, 2, 3, 1, 1, 3, 0, 2, 2, 1, 1, 1, 1, 2, 3, 1, 0, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -953. And steps were 75 and the episode is 3431 and the total_steps are 170001\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 0, 2, 1, 3, 3, 0, 0, 1, 1, 1, 0, 2, 1, 2, 3, 0, 0, 3, 1, 1, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 3432 and the total_steps are 170027\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -872     |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3432     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5707     |\n",
      "|    total_timesteps  | 170027   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 30006    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 1, 0, 0, 2, 0, 2, 1, 3, 0, 0, 0, 1, 2, 3, 2, 2, 2, 1, 3, 2, 1, 0, 3, 2, 0, 2, 2, 1, 1, 0, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 3433 and the total_steps are 170065\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 0, 3, 2, 3, 3, 0, 3, 0, 0, 0, 2, 2, 2, 0, 1, 3, 1, 2, 1, 2, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 28 and the episode is 3434 and the total_steps are 170093\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 1, 2, 2, 1, 1, 0, 3, 3, 1, 3, 3, 2, 2, 3, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 28 and the episode is 3435 and the total_steps are 170121\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 3, 2, 0, 3, 3, 0, 2, 1, 1, 1, 3, 2, 1, 2, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 22 and the episode is 3436 and the total_steps are 170143\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.2     |\n",
      "|    ep_rew_mean      | -872     |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3436     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5712     |\n",
      "|    total_timesteps  | 170143   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 30035    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 3, 3, 3, 1, 0, 3, 2, 0, 1, 1, 0, 3, 2, 1, 3, 3, 1, 3, 1, 3, 3, 1, 0, 2, 0, 1, 1, 1, 1, 3, 3, 0, 3, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 3, 2, 2, 2, 3, 3, 1, 2, 2, 3, 0, 2, 2, 0, 1, 2, 3, 1, 2, 0, 2, 3, 0, 0, 0, 2, 0, 2, 3, 3, 1, 0, 2, 0, 0, 3, 2, 2, 2, 2, 2, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 94 and the episode is 3437 and the total_steps are 170237\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 2, 2, 2, 3, 1, 2, 0, 1, 3, 1, 0, 3, 1, 0, 1, 3, 3, 0, 3, 0, 0, 3, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 30 and the episode is 3438 and the total_steps are 170267\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 0, 1, 2, 1, 0, 1, 0, 3, 0, 2, 3, 1, 2, 2, 0, 3, 1, 1, 3, 0, 1, 2, 1, 3, 2, 1, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 34 and the episode is 3439 and the total_steps are 170301\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 1, 1, 1, 1, 2, 2, 3, 2, 0, 3, 0, 1, 2, 0, 1, 0, 3, 1, 0, 2, 0, 2, 0, 0, 3, 2, 1, 0, 2, 1, 0, 2, 0, 3, 3, 1, 3, 0, 1, 1, 1, 0, 1, 2, 0, 2, 0, 1, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 56 and the episode is 3440 and the total_steps are 170357\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -872     |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3440     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5721     |\n",
      "|    total_timesteps  | 170357   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.8      |\n",
      "|    n_updates        | 30089    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 1, 1, 2, 3, 2, 1, 0, 0, 3, 3, 1, 2, 3, 2, 3, 1, 3, 1, 1, 2, 2, 2, 2, 3, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 32 and the episode is 3441 and the total_steps are 170389\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 2, 0, 1, 2, 2, 1, 2, 3, 0, 1, 3, 3, 2, 2, 0, 0, 3, 3, 1, 1, 2, 2, 2, 3, 1, 3, 2, 0, 2, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 37 and the episode is 3442 and the total_steps are 170426\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 0, 0, 0, 3, 0, 2, 1, 2, 1, 0, 2, 3, 0, 3, 3, 3, 0, 0, 1, 0, 3, 3, 2, 3, 1, 2, 3, 1, 0, 2, 3, 1, 0, 2, 3, 1, 0, 2, 3, 1, 0, 1, 2, 1, 0, 0, 2, 2, 1, 3, 2, 3, 2, 2, 1, 2, 0, 3, 1, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 67 and the episode is 3443 and the total_steps are 170493\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 1, 2, 3, 0, 1, 1, 0, 3, 2, 0, 3, 0, 1, 1, 3, 0, 2, 3, 1, 2, 2, 1, 3, 0, 3, 0, 2, 3, 2, 2, 1, 1, 2, 1, 2, 2, 2, 3, 2, 1, 0, 0, 1, 0, 3, 0, 3, 1, 1, 1, 2, 0, 2, 3, 1, 0, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 64 and the episode is 3444 and the total_steps are 170557\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | -871     |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3444     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5729     |\n",
      "|    total_timesteps  | 170557   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 30139    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 2, 0, 0, 0, 0, 2, 3, 0, 2, 0, 0, 0, 2, 0, 3, 0, 1, 2, 2, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 27 and the episode is 3445 and the total_steps are 170584\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 0, 2, 1, 3, 0, 2, 3, 2, 3, 1, 0, 2, 1, 0, 0, 3, 3, 3, 2, 2, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 28 and the episode is 3446 and the total_steps are 170612\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 3, 2, 1, 2, 0, 1, 0, 3, 1, 0, 3, 2, 3, 0, 2, 0, 2, 0, 3, 3, 2, 2, 3, 2, 3, 0, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 34 and the episode is 3447 and the total_steps are 170646\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 0, 2, 2, 3, 3, 1, 1, 2, 0, 1, 2, 2, 1, 2, 0, 3, 3, 3, 2, 3, 0, 0, 0, 3, 0, 0, 2, 1, 3, 1, 1, 2, 3, 3, 0, 0, 3, 2, 0, 3, 3, 3, 3, 2, 3, 3, 0, 3, 0, 0, 0, 2, 2, 3, 1, 0, 0, 2, 1, 1, 2, 2, 3, 0, 3, 3, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -936. And steps were 84 and the episode is 3448 and the total_steps are 170730\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | -871     |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3448     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5736     |\n",
      "|    total_timesteps  | 170730   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 30182    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 1, 3, 1, 3, 3, 3, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 3, 1, 0, 0, 2, 0, 3, 1, 1, 2, 3, 2, 3, 1, 2, 2, 3, 1, 0, 1, 3, 2, 1, 2, 1, 0, 1, 3, 3, 0, 1, 0, 0, 0, 1, 1, 3, 3, 0, 1, 2, 3, 3, 2, 0, 1, 1, 2, 3, 1, 0, 3, 3, 2, 3, 0, 3, 1, 1, 3, 3, 1, 0, 1, 0, 2, 3, 3, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -926. And steps were 92 and the episode is 3449 and the total_steps are 170822\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 1, 2, 2, 3, 2, 1, 0, 1, 2, 1, 2, 0, 1, 0, 2, 3, 3, 3, 0, 0, 2, 2, 3, 0, 0, 2, 2, 3, 2, 1, 2, 1, 0, 3, 2, 1, 3, 3, 2, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 47 and the episode is 3450 and the total_steps are 170869\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 0, 3, 1, 2, 2, 0, 1, 0, 3, 1, 1, 3, 0, 2, 0, 2, 0, 2, 0, 1, 2, 1, 1, 2, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3451 and the total_steps are 170901\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 1, 1, 2, 0, 0, 0, 0, 2, 1, 1, 3, 2, 3, 0, 2, 2, 3, 1, 0, 0, 0, 1, 3, 0, 1, 2, 0, 1, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 36 and the episode is 3452 and the total_steps are 170937\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -891     |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3452     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5744     |\n",
      "|    total_timesteps  | 170937   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.68     |\n",
      "|    n_updates        | 30234    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 1, 1, 1, 3, 3, 2, 0, 2, 0, 0, 2, 3, 1, 0, 2, 0, 0, 1, 2, 0, 2, 2, 1, 2, 1, 2, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 34 and the episode is 3453 and the total_steps are 170971\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 1, 1, 1, 0, 1, 3, 0, 1, 3, 2, 0, 3, 1, 1, 1, 0, 0, 1, 0, 1, 1, 2, 0, 2, 3, 3, 1, 1, 0, 1, 2, 0, 0, 1, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 42 and the episode is 3454 and the total_steps are 171013\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 3, 2, 2, 1, 3, 0, 1, 0, 2, 2, 0, 0, 2, 2, 0, 3, 3, 1, 3, 2, 3, 3, 1, 3, 0, 0, 1, 0, 2, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 44 and the episode is 3455 and the total_steps are 171057\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 2, 2, 2, 1, 3, 3, 1, 1, 3, 1, 2, 0, 0, 1, 3, 2, 3, 2, 0, 3, 2, 0, 1, 2, 1, 0, 0, 2, 3, 3, 2, 0, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 3456 and the total_steps are 171097\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -911     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3456     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5751     |\n",
      "|    total_timesteps  | 171097   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.24     |\n",
      "|    n_updates        | 30274    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 1, 1, 0, 2, 3, 0, 3, 1, 0, 1, 2, 1, 3, 1, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 1, 0, 1, 0, 3, 3, 3, 0, 1, 0, 1, 3, 1, 3, 3, 1, 0, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 49 and the episode is 3457 and the total_steps are 171146\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 0, 1, 3, 2, 2, 3, 3, 1, 1, 1, 3, 2, 1, 1, 3, 1, 2, 1, 0, 2, 1, 3, 2, 0, 1, 1, 3, 1, 1, 0, 3, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 39 and the episode is 3458 and the total_steps are 171185\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 3, 3, 0, 2, 0, 0, 1, 0, 3, 1, 0, 1, 3, 1, 3, 0, 3, 3, 2, 2, 1, 0, 2, 2, 0, 2, 1, 3, 1, 3, 3, 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 3, 3, 3, 1, 0, 2, 2, 3, 2, 2, 0, 0, 3, 2, 3, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 64 and the episode is 3459 and the total_steps are 171249\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 2, 2, 0, 0, 2, 1, 3, 0, 3, 0, 0, 2, 1, 1, 1, 2, 2, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was 980. And steps were 23 and the episode is 3460 and the total_steps are 171272\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.9     |\n",
      "|    ep_rew_mean      | -890     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3460     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5758     |\n",
      "|    total_timesteps  | 171272   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 30317    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 3, 3, 2, 3, 3, 0, 0, 3, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 3, 3, 2, 0, 0, 1, 1, 0, 3, 3, 0, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 37 and the episode is 3461 and the total_steps are 171309\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 1, 1, 2, 1, 1, 3, 2, 1, 3, 1, 3, 2, 0, 2, 0, 1, 2, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 25 and the episode is 3462 and the total_steps are 171334\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 1, 0, 2, 1, 1, 3, 2, 2, 1, 1, 0, 1, 1, 0, 3, 1, 3, 0, 1, 0, 3, 2, 3, 0, 3, 3, 1, 3, 2, 3, 0, 3, 2, 2, 1, 2, 3, 0, 0, 2, 2, 2, 1, 2, 0, 0, 2, 0, 0, 2, 3, 3, 2, 0, 1, 3, 3, 3, 0, 0, 2, 1, 1, 0, 3, 0, 0, 1, 0, 3, 1, 3, 1, 1, 0, 3, 0, 2, 3, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1065. And steps were 87 and the episode is 3463 and the total_steps are 171421\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 0, 3, 2, 3, 1, 3, 0, 2, 0, 0, 1, 3, 3, 1, 0, 1, 1, 1, 0, 1, 3, 0, 1, 3, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 3464 and the total_steps are 171453\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.1     |\n",
      "|    ep_rew_mean      | -891     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3464     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5766     |\n",
      "|    total_timesteps  | 171453   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 30363    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 3, 0, 2, 3, 2, 2, 0, 0, 3, 3, 0, 1, 2, 3, 3, 1, 3, 0, 2, 3, 3, 3, 2, 3, 1, 2, 2, 0, 0, 2, 2, 2, 2, 0, 3, 1, 3, 0, 3, 0, 1, 2, 3, 2, 0, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 52 and the episode is 3465 and the total_steps are 171505\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 3, 1, 1, 1, 2, 1, 2, 1, 1, 0, 2, 2, 3, 3, 3, 2, 1, 3, 1, 3, 1, 0, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 30 and the episode is 3466 and the total_steps are 171535\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 3, 1, 2, 2, 2, 1, 3, 3, 0, 3, 2, 0, 1, 1, 0, 2, 0, 2, 3, 3, 3, 2, 0, 0, 2, 2, 3, 3, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 36 and the episode is 3467 and the total_steps are 171571\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 2, 1, 3, 2, 0, 1, 3, 2, 3, 0, 2, 1, 1, 3, 0, 3, 1, 0, 0, 2, 3, 2, 2, 2, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 32 and the episode is 3468 and the total_steps are 171603\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | -892     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3468     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5773     |\n",
      "|    total_timesteps  | 171603   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65.3     |\n",
      "|    n_updates        | 30400    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 1, 0, 1, 3, 1, 0, 2, 2, 2, 1, 2, 2, 0, 0, 1, 3, 2, 3, 2, 0, 0, 2, 2, 3, 3, 3, 1, 0, 0, 0, 0, 1, 0, 1, 0, 3, 0, 1, 1, 2, 0, 1, 0, 3, 1, 0, 1, 3, 2, 0, 2, 0, 2, 3, 3, 1, 2, 1, 3, 3, 2, 2, 0, 1, 3, 3, 1, 0, 2, 3, 1, 2, 1, 1, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 82 and the episode is 3469 and the total_steps are 171685\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 1, 3, 2, 1, 2, 0, 1, 0, 2, 3, 2, 1, 3, 0, 3, 1, 1, 0, 1, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 3470 and the total_steps are 171712\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 2, 0, 1, 1, 0, 1, 2, 0, 3, 3, 2, 2, 0, 2, 3, 1, 2, 1, 3, 0, 1, 2, 3, 1, 1, 1, 0, 3, 2, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 37 and the episode is 3471 and the total_steps are 171749\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 1, 1, 1, 0, 3, 0, 2, 1, 3, 2, 3, 3, 3, 0, 2, 2, 1, 2, 0, 3, 2, 1, 2, 1, 0, 3, 0, 0, 1, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1035. And steps were 37 and the episode is 3472 and the total_steps are 171786\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.9     |\n",
      "|    ep_rew_mean      | -893     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3472     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5780     |\n",
      "|    total_timesteps  | 171786   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.12     |\n",
      "|    n_updates        | 30446    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 2, 1, 2, 2, 0, 1, 2, 1, 1, 0, 3, 0, 2, 1, 2, 1, 0, 3, 2, 3, 0, 2, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 3, 3, 1, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 43 and the episode is 3473 and the total_steps are 171829\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 3, 1, 0, 1, 2, 3, 1, 2, 3, 3, 3, 1, 3, 2, 1, 3, 3, 3, 3, 3, 3, 2, 1, 3, 1, 0, 2, 0, 2, 2, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 38 and the episode is 3474 and the total_steps are 171867\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 2, 1, 2, 0, 1, 3, 1, 2, 1, 3, 0, 3, 0, 2, 1, 3, 0, 2, 0, 1, 0, 0, 3, 3, 3, 1, 2, 1, 0, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 37 and the episode is 3475 and the total_steps are 171904\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 1, 2, 2, 1, 1, 0, 3, 3, 3, 3, 0, 1, 0, 2, 1, 0, 2, 0, 1, 1, 2, 3, 1, 2, 0, 2, 0, 2, 0, 3, 3, 3, 2, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 41 and the episode is 3476 and the total_steps are 171945\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.2     |\n",
      "|    ep_rew_mean      | -893     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3476     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5787     |\n",
      "|    total_timesteps  | 171945   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.3     |\n",
      "|    n_updates        | 30486    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 2, 2, 0, 3, 3, 3, 3, 0, 2, 2, 0, 1, 1, 0, 1, 1, 3, 3, 1, 3, 2, 0, 1, 3, 0, 1, 3, 1, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 36 and the episode is 3477 and the total_steps are 171981\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 1, 1, 1, 2, 3, 1, 1, 3, 0, 1, 3, 0, 1, 1, 2, 3, 2, 3, 3, 1, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3478 and the total_steps are 172009\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 0, 0, 1, 0, 2, 1, 2, 0, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 16 and the episode is 3479 and the total_steps are 172025\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 2, 1, 0, 0, 0, 0, 3, 1, 3, 3, 3, 3, 3, 2, 2, 2, 3, 1, 3, 0, 0, 1, 1, 2, 2, 1, 2, 1, 0, 2, 1, 3, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 40 and the episode is 3480 and the total_steps are 172065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43       |\n",
      "|    ep_rew_mean      | -893     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3480     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5793     |\n",
      "|    total_timesteps  | 172065   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 30516    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 3, 2, 0, 0, 0, 1, 1, 1, 0, 1, 3, 1, 0, 1, 1, 2, 2, 1, 2, 3, 2, 2, 1, 3, 3, 2, 1, 0, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 3481 and the total_steps are 172101\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 0, 0, 2, 2, 2, 1, 1, 0, 3, 3, 1, 0, 3, 3, 0, 2, 2, 3, 2, 0, 0, 1, 0, 3, 0, 2, 0, 1, 2, 0, 3, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 39 and the episode is 3482 and the total_steps are 172140\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 2, 1, 2, 3, 1, 2, 2, 3, 1, 2, 0, 0, 1, 1, 2, 0, 2, 0, 0, 1, 3, 2, 1, 2, 0, 2, 2, 3, 3, 1, 2, 1, 1, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 41 and the episode is 3483 and the total_steps are 172181\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 0, 2, 3, 2, 2, 3, 3, 3, 3, 2, 1, 3, 3, 3, 1, 3, 0, 0, 3, 2, 3, 0, 1, 3, 2, 2, 2, 1, 3, 2, 0, 2, 1, 1, 3, 2, 2, 3, 1, 0, 3, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 49 and the episode is 3484 and the total_steps are 172230\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.4     |\n",
      "|    ep_rew_mean      | -913     |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3484     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5800     |\n",
      "|    total_timesteps  | 172230   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 30557    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 2, 3, 1, 2, 0, 2, 3, 3, 3, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 17 and the episode is 3485 and the total_steps are 172247\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 3, 1, 2, 0, 0, 1, 1, 0, 2, 2, 3, 3, 0, 2, 2, 0, 1, 0, 3, 0, 3, 3, 1, 3, 0, 2, 0, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 35 and the episode is 3486 and the total_steps are 172282\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 0, 0, 0, 2, 1, 2, 3, 0, 0, 1, 1, 0, 0, 0, 1, 3, 1, 2, 0, 1, 0, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3487 and the total_steps are 172311\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 1, 3, 3, 1, 2, 0, 2, 0, 2, 3, 3, 0, 1, 3, 1, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 3488 and the total_steps are 172332\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | -894     |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3488     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5804     |\n",
      "|    total_timesteps  | 172332   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.8     |\n",
      "|    n_updates        | 30582    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 0, 2, 3, 0, 2, 0, 0, 3, 3, 2, 2, 1, 3, 0, 0, 0, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 33 and the episode is 3489 and the total_steps are 172365\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 0, 0, 3, 2, 1, 0, 3, 1, 1, 0, 3, 2, 2, 3, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 3490 and the total_steps are 172406\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 1, 0, 0, 3, 0, 2, 0, 3, 1, 0, 1, 3, 0, 3, 1, 2, 3, 0, 1, 1, 2, 1, 3, 0, 0, 1, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 34 and the episode is 3491 and the total_steps are 172440\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 0, 3, 2, 3, 0, 3, 1, 1, 3, 3, 1, 3, 3, 0, 3, 1, 1, 1, 0, 1, 0, 1, 0, 3, 3, 3, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 34 and the episode is 3492 and the total_steps are 172474\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3492     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5810     |\n",
      "|    total_timesteps  | 172474   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 30618    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 0, 1, 0, 0, 2, 2, 2, 3, 3, 3, 2, 3, 1, 1, 3, 2, 3, 2, 3, 0, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 3493 and the total_steps are 172502\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 1, 0, 2, 3, 0, 2, 2, 0, 3, 1, 3, 2, 0, 0, 3, 1, 2, 2, 0, 2, 3, 0, 3, 3, 0, 2, 3, 2, 3, 3, 3, 0, 0, 2, 3, 3, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 44 and the episode is 3494 and the total_steps are 172546\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 3, 1, 0, 0, 2, 0, 2, 0, 3, 0, 1, 2, 2, 3, 1, 1, 0, 1, 3, 0, 3, 1, 0, 1, 2, 2, 2, 0, 1, 2, 2, 0, 2, 3, 1, 3, 0, 2, 2, 0, 2, 3, 3, 2, 3, 0, 0, 2, 0, 1, 2, 3, 0, 3, 0, 0, 3, 3, 3, 0, 3, 2, 3, 0, 1, 1, 0, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1051. And steps were 75 and the episode is 3495 and the total_steps are 172621\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 2, 2, 3, 1, 1, 1, 1, 2, 3, 3, 0, 1, 3, 0, 1, 3, 0, 1, 1, 2, 3, 2, 3, 3, 0, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 3496 and the total_steps are 172653\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3496     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5817     |\n",
      "|    total_timesteps  | 172653   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 30663    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 0, 0, 2, 3, 3, 3, 0, 0, 1, 0, 2, 2, 0, 3, 1, 2, 3, 3, 0, 1, 2, 3, 2, 2, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3497 and the total_steps are 172685\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 2, 1, 0, 3, 0, 0, 1, 3, 1, 3, 2, 0, 2, 3, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 22 and the episode is 3498 and the total_steps are 172707\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 0, 1, 1, 1, 2, 2, 2, 3, 2, 3, 3, 2, 1, 1, 3, 3, 3, 1, 2, 0, 1, 2, 1, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 31 and the episode is 3499 and the total_steps are 172738\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 3, 3, 2, 1, 0, 2, 2, 1, 2, 1, 2, 1, 3, 2, 2, 2, 2, 2, 3, 1, 2, 3, 2, 1, 2, 2, 3, 2, 3, 1, 0, 3, 1, 1, 0, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 43 and the episode is 3500 and the total_steps are 172781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3500     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5823     |\n",
      "|    total_timesteps  | 172781   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.31     |\n",
      "|    n_updates        | 30695    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 2, 2, 1, 1, 3, 0, 3, 3, 2, 3, 0, 0, 2, 2, 3, 0, 1, 1, 0, 2, 1, 3, 2, 2, 3, 3, 1, 0, 2, 2, 0, 1, 2, 2, 2, 1, 1, 0, 1, 1, 0, 0, 2, 2, 3, 1, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 54 and the episode is 3501 and the total_steps are 172835\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 3, 1, 2, 0, 1, 3, 2, 3, 1, 0, 0, 0, 2, 3, 3, 0, 2, 2, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 26 and the episode is 3502 and the total_steps are 172861\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 3, 2, 1, 1, 3, 2, 3, 1, 0, 1, 0, 3, 0, 3, 3, 2, 1, 1, 3, 2, 2, 2, 2, 2, 2, 1, 2, 1, 0, 0, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 0, 2, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 51 and the episode is 3503 and the total_steps are 172912\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 2, 1, 2, 1, 1, 2, 3, 2, 2, 0, 2, 1, 2, 1, 1, 3, 2, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 3504 and the total_steps are 172937\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3504     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5830     |\n",
      "|    total_timesteps  | 172937   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 37.4     |\n",
      "|    n_updates        | 30734    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 3, 3, 0, 3, 2, 2, 0, 2, 2, 1, 1, 2, 2, 3, 1, 0, 3, 0, 2, 0, 0, 3, 0, 3, 3, 2, 0, 2, 1, 2, 3, 0, 2, 0, 0, 3, 1, 1, 0, 1, 3, 1, 2, 2, 2, 0, 2, 3, 2, 2, 3, 0, 2, 2, 3, 2, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 64 and the episode is 3505 and the total_steps are 173001\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 0, 1, 3, 2, 3, 0, 3, 2, 0, 1, 3, 1, 3, 0, 2, 0, 2, 2, 1, 0, 0, 3, 3, 1, 3, 2, 2, 2, 3, 2, 2, 0, 2, 0, 1, 1, 3, 3, 3, 2, 1, 0, 0, 0, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 52 and the episode is 3506 and the total_steps are 173053\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 1, 1, 3, 2, 1, 3, 2, 3, 3, 3, 2, 0, 0, 2, 1, 0, 0, 2, 0, 0, 1, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 29 and the episode is 3507 and the total_steps are 173082\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 2, 3, 3, 3, 0, 2, 3, 2, 1, 0, 0, 2, 0, 1, 3, 3, 3, 3, 2, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 27 and the episode is 3508 and the total_steps are 173109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3508     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5837     |\n",
      "|    total_timesteps  | 173109   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 30777    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 1, 1, 0, 2, 2, 2, 1, 2, 1, 0, 1, 3, 2, 1, 1, 3, 1, 1, 3, 1, 0, 3, 1, 1, 1, 1, 1, 2, 0, 1, 3, 0, 1, 3, 2, 1, 2, 2, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 46 and the episode is 3509 and the total_steps are 173155\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 2, 3, 0, 0, 3, 2, 1, 2, 3, 1, 0, 1, 1, 3, 3, 3, 2, 1, 2, 1, 3, 2, 3, 1, 0, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 33 and the episode is 3510 and the total_steps are 173188\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 1, 2, 0, 1, 2, 3, 0, 0, 2, 1, 2, 1, 3, 3, 3, 2, 1, 0, 2, 1, 2, 1, 1, 0, 0, 0, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 34 and the episode is 3511 and the total_steps are 173222\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 3, 3, 0, 3, 3, 1, 3, 3, 1, 3, 3, 0, 3, 2, 1, 0, 2, 0, 2, 2, 2, 3, 1, 0, 1, 1, 2, 3, 2, 0, 0, 1, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 47 and the episode is 3512 and the total_steps are 173269\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3512     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5843     |\n",
      "|    total_timesteps  | 173269   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.79     |\n",
      "|    n_updates        | 30817    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 2, 0, 1, 0, 1, 0, 3, 0, 0, 0, 0, 2, 3, 2, 2, 2, 1, 3, 2, 3, 3, 3, 2, 0, 3, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 32 and the episode is 3513 and the total_steps are 173301\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 2, 2, 3, 0, 3, 2, 0, 1, 3, 3, 0, 0, 0, 2, 0, 3, 3, 3, 0, 1, 3, 0, 3, 3, 1, 1, 3, 2, 0, 1, 3, 2, 3, 2, 0, 1, 3, 3, 0, 0, 1, 1, 3, 0, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 3, 3, 2, 0, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 66 and the episode is 3514 and the total_steps are 173367\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 2, 1, 2, 2, 2, 0, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 14 and the episode is 3515 and the total_steps are 173381\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 2, 2, 0, 3, 0, 2, 3, 3, 1, 1, 0, 0, 3, 3, 3, 3, 2, 2, 1, 0, 2, 2, 1, 2, 2, 3, 3, 1, 0, 0, 0, 2, 1, 0, 3, 0, 3, 2, 0, 2, 2, 3, 2, 0, 2, 3, 3, 2, 1, 3, 0, 3, 1, 1, 2, 1, 2, 3, 3, 2, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -934. And steps were 68 and the episode is 3516 and the total_steps are 173449\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | -915     |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3516     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5851     |\n",
      "|    total_timesteps  | 173449   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.6     |\n",
      "|    n_updates        | 30862    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 2, 1, 1, 1, 3, 1, 2, 3, 1, 1, 1, 1, 2, 1, 2, 3, 2, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 3517 and the total_steps are 173474\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 1, 1, 3, 3, 1, 2, 1, 3, 3, 1, 1, 1, 3, 2, 0, 3, 0, 3, 0, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 3518 and the total_steps are 173501\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 3, 0, 1, 2, 3, 3, 3, 2, 3, 0, 1, 2, 2, 3, 0, 1, 0, 2, 1, 0, 2, 2, 2, 2, 3, 1, 2, 0, 0, 1, 2, 2, 1, 3, 2, 0, 2, 2, 0, 0, 3, 1, 0, 3, 2, 1, 1, 1, 3, 2, 2, 2, 3, 3, 2, 0, 1, 0, 0, 2, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 68 and the episode is 3519 and the total_steps are 173569\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 0, 2, 3, 2, 0, 3, 1, 2, 2, 1, 3, 0, 1, 3, 1, 3, 3, 3, 2, 1, 0, 0, 1, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 31 and the episode is 3520 and the total_steps are 173600\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3520     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5858     |\n",
      "|    total_timesteps  | 173600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.3     |\n",
      "|    n_updates        | 30899    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 2, 1, 2, 0, 1, 3, 1, 2, 1, 3, 2, 1, 3, 1, 3, 2, 2, 2, 1, 3, 0, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 3521 and the total_steps are 173629\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 2, 3, 0, 1, 2, 1, 1, 0, 3, 1, 0, 1, 2, 3, 2, 1, 0, 0, 3, 3, 2, 1, 2, 0, 3, 2, 1, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 35 and the episode is 3522 and the total_steps are 173664\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 2, 2, 1, 1, 0, 1, 0, 3, 3, 0, 2, 1, 3, 0, 2, 2, 1, 2, 2, 2, 1, 2, 0, 3, 0, 3, 0, 0, 0, 1, 1, 3, 1, 0, 1, 0, 2, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 45 and the episode is 3523 and the total_steps are 173709\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 3, 3, 3, 0, 1, 2, 0, 3, 2, 2, 3, 3, 1, 1, 2, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 34 and the episode is 3524 and the total_steps are 173743\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3524     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5864     |\n",
      "|    total_timesteps  | 173743   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.5     |\n",
      "|    n_updates        | 30935    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 2, 2, 3, 2, 3, 0, 2, 2, 0, 3, 2, 2, 2, 3, 2, 2, 3, 3, 1, 3, 2, 2, 2, 2, 0, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 33 and the episode is 3525 and the total_steps are 173776\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 3, 2, 2, 1, 3, 0, 0, 3, 2, 1, 2, 0, 3, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 1, 3, 1, 3, 3, 0, 1, 3, 0, 3, 3, 2, 0, 2, 2, 2, 1, 0, 3, 3, 3, 1, 2, 1, 0, 1, 3, 2, 1, 1, 1, 3, 2, 2, 1, 1, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 69 and the episode is 3526 and the total_steps are 173845\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 0, 3, 0, 2, 3, 0, 0, 0, 1, 3, 2, 0, 3, 1, 3, 1, 2, 1, 1, 3, 2, 2, 0, 3, 0, 3, 0, 0, 1, 0, 1, 1, 2, 2, 2, 2, 0, 0, 2, 1, 1, 0, 2, 3, 1, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 53 and the episode is 3527 and the total_steps are 173898\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 3, 3, 2, 3, 2, 0, 3, 2, 3, 3, 3, 2, 1, 1, 2, 0, 0, 2, 1, 2, 0, 1, 0, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 31 and the episode is 3528 and the total_steps are 173929\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3528     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5872     |\n",
      "|    total_timesteps  | 173929   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.14     |\n",
      "|    n_updates        | 30982    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 0, 2, 3, 2, 3, 2, 3, 2, 3, 3, 0, 0, 2, 3, 2, 0, 3, 1, 0, 3, 3, 3, 2, 0, 0, 0, 1, 2, 3, 0, 2, 3, 1, 2, 2, 2, 1, 1, 2, 3, 1, 3, 0, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 51 and the episode is 3529 and the total_steps are 173980\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 2, 1, 1, 1, 2, 3, 1, 3, 1, 0, 0, 1, 3, 1, 0, 0, 2, 3, 2, 0, 3, 1, 3, 1, 2, 1, 0, 0, 0, 3, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 38 and the episode is 3530 and the total_steps are 174018\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 0, 1, 0, 1, 1, 3, 1, 3, 2, 0, 0, 1, 3, 3, 2, 2, 1, 1, 1, 3, 3, 1, 1, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 31 and the episode is 3531 and the total_steps are 174049\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 2, 1, 3, 2, 0, 2, 0, 0, 1, 3, 1, 3, 1, 3, 3, 2, 2, 3, 0, 1, 2, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 29 and the episode is 3532 and the total_steps are 174078\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3532     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5878     |\n",
      "|    total_timesteps  | 174078   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.944    |\n",
      "|    n_updates        | 31019    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 2, 2, 0, 2, 2, 1, 3, 0, 0, 1, 1, 2, 3, 3, 2, 0, 1, 0, 1, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 27 and the episode is 3533 and the total_steps are 174105\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 3, 1, 3, 1, 2, 1, 1, 2, 3, 2, 1, 3, 3, 0, 3, 1, 1, 2, 1, 0, 1, 1, 3, 3, 2, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 3534 and the total_steps are 174138\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 2, 2, 0, 2, 2, 1, 3, 2, 3, 0, 1, 3, 0, 0, 3, 3, 0, 0, 3, 3, 0, 1, 0, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 31 and the episode is 3535 and the total_steps are 174169\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 1, 3, 1, 0, 0, 3, 0, 2, 3, 3, 1, 3, 2, 0, 3, 2, 0, 2, 3, 0, 3, 0, 1, 3, 3, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 33 and the episode is 3536 and the total_steps are 174202\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3536     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5884     |\n",
      "|    total_timesteps  | 174202   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.48     |\n",
      "|    n_updates        | 31050    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 2, 3, 0, 2, 0, 0, 3, 0, 3, 2, 0, 2, 3, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 3, 3, 0, 0, 2, 2, 2, 0, 3, 0, 3, 3, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 51 and the episode is 3537 and the total_steps are 174253\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 0, 1, 3, 1, 3, 2, 2, 1, 3, 0, 0, 2, 1, 0, 2, 2, 1, 2, 0, 1, 1, 2, 0, 1, 2, 0, 0, 3, 1, 1, 0, 3, 0, 3, 2, 3, 0, 0, 2, 0, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 48 and the episode is 3538 and the total_steps are 174301\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 1, 0, 0, 0, 0, 1, 2, 1, 1, 3, 1, 1, 0, 1, 2, 0, 0, 3, 1, 0, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 28 and the episode is 3539 and the total_steps are 174329\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 2, 2, 1, 0, 2, 1, 0, 2, 0, 0, 1, 2, 0, 2, 1, 0, 1, 3, 0, 0, 0, 3, 2, 0, 1, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 33 and the episode is 3540 and the total_steps are 174362\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3540     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5891     |\n",
      "|    total_timesteps  | 174362   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 31090    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 0, 1, 3, 1, 2, 2, 1, 1, 2, 3, 2, 0, 3, 1, 0, 1, 3, 3, 2, 2, 0, 2, 1, 2, 1, 3, 3, 3, 3, 0, 0, 2, 1, 3, 0, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1041. And steps were 43 and the episode is 3541 and the total_steps are 174405\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 0, 2, 3, 0, 3, 0, 3, 2, 3, 3, 3, 1, 0, 3, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was 1019. And steps were 20 and the episode is 3542 and the total_steps are 174425\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 2, 2, 3, 2, 2, 1, 1, 3, 3, 3, 1, 2, 0, 3, 3, 1, 0, 3, 0, 3, 3, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 1, 2, 1, 3, 0, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 44 and the episode is 3543 and the total_steps are 174469\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 2, 2, 2, 1, 3, 1, 2, 0, 2, 2, 2, 0, 2, 1, 2, 3, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 3544 and the total_steps are 174493\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3544     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5896     |\n",
      "|    total_timesteps  | 174493   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.14     |\n",
      "|    n_updates        | 31123    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 3, 2, 1, 3, 1, 0, 0, 3, 2, 3, 1, 2, 2, 3, 2, 0, 2, 3, 0, 1, 2, 0, 2, 3, 3, 1, 2, 2, 3, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 37 and the episode is 3545 and the total_steps are 174530\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 2, 2, 0, 0, 0, 0, 3, 1, 2, 0, 1, 3, 1, 0, 0, 2, 1, 1, 0, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 27 and the episode is 3546 and the total_steps are 174557\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 0, 3, 1, 0, 0, 1, 3, 1, 3, 2, 2, 1, 1, 1, 2, 0, 2, 1, 0, 2, 3, 2, 1, 1, 3, 0, 1, 3, 2, 2, 1, 1, 1, 1, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 42 and the episode is 3547 and the total_steps are 174599\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 2, 2, 3, 0, 2, 0, 2, 1, 1, 1, 3, 2, 1, 3, 2, 0, 1, 0, 2, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 27 and the episode is 3548 and the total_steps are 174626\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3548     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5902     |\n",
      "|    total_timesteps  | 174626   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.38     |\n",
      "|    n_updates        | 31156    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 0, 1, 1, 1, 1, 1, 0, 1, 0, 3, 2, 3, 2, 2, 0, 1, 1, 2, 3, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 3549 and the total_steps are 174653\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 2, 0, 0, 2, 1, 0, 0, 2, 1, 1, 2, 0, 3, 3, 1, 2, 2, 2, 2, 1, 0, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 29 and the episode is 3550 and the total_steps are 174682\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 1, 2, 3, 0, 1, 2, 2, 2, 3, 2, 1, 0, 0, 2, 0, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 23 and the episode is 3551 and the total_steps are 174705\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 1, 3, 1, 1, 3, 3, 3, 2, 2, 0, 0, 2, 0, 0, 2, 1, 3, 1, 3, 1, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 28 and the episode is 3552 and the total_steps are 174733\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3552     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5907     |\n",
      "|    total_timesteps  | 174733   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 31183    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 0, 1, 0, 0, 3, 1, 0, 2, 3, 1, 3, 3, 2, 2, 2, 2, 2, 2, 0, 3, 1, 1, 2, 0, 2, 3, 1, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 35 and the episode is 3553 and the total_steps are 174768\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 3, 0, 2, 2, 3, 0, 2, 0, 0, 1, 2, 1, 3, 0, 3, 2, 2, 0, 0, 1, 3, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 29 and the episode is 3554 and the total_steps are 174797\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 3, 3, 0, 2, 1, 0, 3, 2, 0, 0, 0, 3, 2, 2, 3, 3, 1, 2, 1, 2, 3, 2, 2, 1, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 32 and the episode is 3555 and the total_steps are 174829\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 0, 2, 1, 2, 1, 2, 2, 3, 3, 0, 0, 3, 1, 2, 1, 0, 2, 1, 0, 3, 3, 0, 1, 1, 3, 0, 3, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 35 and the episode is 3556 and the total_steps are 174864\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3556     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5913     |\n",
      "|    total_timesteps  | 174864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 31215    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 0, 2, 1, 0, 2, 1, 1, 2, 0, 2, 2, 0, 1, 3, 3, 1, 1, 3, 1, 3, 2, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3557 and the total_steps are 174893\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 0, 2, 0, 2, 0, 2, 2, 2, 3, 3, 2, 2, 3, 1, 2, 0, 3, 0, 3, 1, 2, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 29 and the episode is 3558 and the total_steps are 174922\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 2, 1, 1, 1, 0, 0, 1, 2, 2, 3, 2, 1, 0, 2, 2, 1, 0, 0, 0, 0, 3, 2, 1, 0, 3, 3, 0, 1, 1, 0, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 39 and the episode is 3559 and the total_steps are 174961\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 1, 3, 3, 1, 1, 2, 1, 2, 0, 1, 1, 2, 0, 2, 1, 1, 3, 1, 3, 2, 0, 2, 2, 1, 2, 0, 2, 3, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 36 and the episode is 3560 and the total_steps are 174997\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.2     |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3560     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5918     |\n",
      "|    total_timesteps  | 174997   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 31249    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 0, 0, 0, 1, 0, 0, 3, 0, 3, 2, 1, 1, 0, 3, 1, 1, 3, 0, 1, 2, 2, 0, 1, 2, 2, 2, 3, 2, 1, 1, 2, 3, 3, 3, 1, 2, 3, 2, 2, 3, 3, 1, 3, 0, 1, 0, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1051. And steps were 53 and the episode is 3561 and the total_steps are 175050\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 0, 3, 2, 0, 3, 2, 1, 1, 1, 3, 1, 0, 2, 2, 2, 0, 1, 2, 3, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 27 and the episode is 3562 and the total_steps are 175077\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 0, 1, 0, 3, 0, 0, 0, 1, 1, 3, 2, 2, 0, 3, 0, 0, 2, 0, 1, 0, 0, 2, 2, 1, 2, 1, 1, 0, 1, 1, 3, 1, 3, 2, 1, 2, 1, 0, 1, 2, 0, 0, 0, 0, 3, 0, 3, 2, 0, 2, 2, 2, 1, 2, 1, 1, 1, 3, 2, 3, 2, 0, 1, 1, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -946. And steps were 72 and the episode is 3563 and the total_steps are 175149\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 1, 2, 1, 1, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 0, 1, 3, 1, 2, 3, 0, 0, 2, 0, 2, 0, 0, 3, 1, 2, 1, 0, 2, 0, 1, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 1, 3, 3, 3, 3, 1, 0, 1, 0, 1, 2, 0, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 64 and the episode is 3564 and the total_steps are 175213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3564     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5927     |\n",
      "|    total_timesteps  | 175213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.87     |\n",
      "|    n_updates        | 31303    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 0, 3, 2, 0, 1, 2, 2, 1, 0, 3, 2, 1, 2, 2, 0, 0, 3, 1, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 3565 and the total_steps are 175239\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 3, 1, 1, 0, 1, 0, 3, 2, 0, 1, 0, 0, 1, 3, 3, 0, 0, 0, 2, 0, 2, 3, 3, 3, 0, 1, 0, 2, 0, 3, 1, 2, 2, 2, 0, 0, 1, 0, 0, 3, 1, 1, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 50 and the episode is 3566 and the total_steps are 175289\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 2, 0, 2, 3, 3, 0, 3, 0, 0, 1, 3, 2, 2, 2, 2, 1, 0, 3, 1, 3, 1, 2, 2, 0, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 38 and the episode is 3567 and the total_steps are 175327\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 3, 1, 0, 2, 1, 2, 3, 1, 0, 1, 2, 3, 1, 2, 0, 1, 1, 1, 1, 2, 1, 2, 3, 0, 2, 3, 0, 0, 0, 2, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 38 and the episode is 3568 and the total_steps are 175365\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3568     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5934     |\n",
      "|    total_timesteps  | 175365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.4     |\n",
      "|    n_updates        | 31341    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 3, 3, 3, 2, 1, 3, 0, 2, 1, 0, 1, 2, 3, 2, 2, 2, 3, 0, 0, 2, 0, 1, 1, 1, 2, 2, 0, 3, 3, 3, 0, 3, 0, 2, 0, 1, 1, 3, 3, 2, 0, 0, 2, 3, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 52 and the episode is 3569 and the total_steps are 175417\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 1, 1, 3, 0, 2, 0, 0, 1, 3, 2, 2, 0, 1, 1, 3, 2, 1, 3, 3, 1, 1, 3, 2, 1, 2, 3, 0, 0, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 36 and the episode is 3570 and the total_steps are 175453\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 1, 1, 3, 0, 1, 1, 0, 3, 2, 0, 0, 0, 3, 1, 2, 3, 2, 2, 3, 3, 2, 3, 1, 3, 0, 3, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 34 and the episode is 3571 and the total_steps are 175487\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 0, 3, 0, 2, 2, 1, 3, 1, 0, 1, 3, 2, 2, 0, 0, 0, 2, 0, 3, 3, 1, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3572 and the total_steps are 175516\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3572     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5940     |\n",
      "|    total_timesteps  | 175516   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.58     |\n",
      "|    n_updates        | 31378    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 0, 3, 3, 0, 0, 3, 1, 2, 3, 2, 0, 0, 1, 3, 2, 1, 3, 1, 3, 2, 0, 0, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 3573 and the total_steps are 175546\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 2, 0, 2, 2, 1, 1, 3, 2, 1, 3, 2, 1, 2, 1, 0, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 23 and the episode is 3574 and the total_steps are 175569\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 2, 1, 0, 3, 3, 2, 0, 2, 2, 2, 0, 1, 3, 1, 1, 2, 3, 2, 3, 3, 3, 1, 0, 3, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 3575 and the total_steps are 175601\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 3, 3, 2, 3, 1, 3, 0, 1, 2, 0, 1, 1, 0, 1, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1019. And steps were 20 and the episode is 3576 and the total_steps are 175621\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3576     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5945     |\n",
      "|    total_timesteps  | 175621   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 94.4     |\n",
      "|    n_updates        | 31405    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 0, 0, 3, 3, 0, 2, 0, 2, 0, 2, 2, 3, 1, 3, 2, 2, 0, 1, 0, 3, 2, 3, 3, 2, 2, 0, 0, 2, 0, 3, 3, 0, 0, 0, 3, 2, 3, 2, 1, 0, 0, 0, 2, 0, 1, 3, 0, 2, 0, 3, 2, 3, 3, 2, 0, 1, 2, 2, 3, 1, 1, 2, 3, 2, 0, 0, 1, 2, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 76 and the episode is 3577 and the total_steps are 175697\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 2, 3, 3, 1, 2, 3, 1, 0, 1, 1, 1, 3, 1, 2, 0, 1, 3, 1, 3, 0, 0, 0, 0, 2, 1, 1, 0, 0, 2, 1, 1, 0, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 40 and the episode is 3578 and the total_steps are 175737\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 1, 2, 0, 2, 3, 2, 2, 3, 2, 2, 1, 1, 1, 2, 1, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 23 and the episode is 3579 and the total_steps are 175760\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 3, 2, 0, 0, 3, 2, 1, 1, 2, 1, 3, 0, 3, 1, 0, 0, 3, 1, 1, 1, 3, 2, 0, 0, 1, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 33 and the episode is 3580 and the total_steps are 175793\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3580     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5952     |\n",
      "|    total_timesteps  | 175793   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 31448    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 2, 2, 2, 2, 1, 3, 2, 3, 3, 0, 0, 0, 0, 2, 1, 1, 1, 3, 0, 3, 1, 1, 1, 0, 3, 0, 1, 3, 2, 1, 3, 3, 3, 0, 3, 2, 3, 0, 2, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 3, 3, 0, 3, 2, 0, 3, 1, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 76 and the episode is 3581 and the total_steps are 175869\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 2, 1, 1, 3, 2, 3, 1, 3, 1, 0, 3, 2, 3, 0, 2, 0, 0, 1, 1, 2, 2, 1, 3, 3, 1, 0, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 33 and the episode is 3582 and the total_steps are 175902\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 3, 1, 2, 3, 0, 0, 1, 0, 3, 0, 2, 1, 2, 2, 3, 3, 2, 2, 0, 2, 1, 1, 2, 1, 1, 2, 3, 3, 2, 2, 0, 1, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 3583 and the total_steps are 175942\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 0, 2, 3, 3, 3, 3, 2, 1, 2, 2, 3, 0, 1, 2, 0, 1, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 3584 and the total_steps are 175966\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3584     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5959     |\n",
      "|    total_timesteps  | 175966   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.45     |\n",
      "|    n_updates        | 31491    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 1, 3, 3, 3, 2, 2, 3, 1, 3, 1, 3, 0, 2, 2, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was 1019. And steps were 20 and the episode is 3585 and the total_steps are 175986\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 1, 3, 1, 3, 1, 0, 2, 0, 1, 1, 3, 1, 2, 2, 0, 0, 3, 0, 2, 2, 2, 0, 0, 0, 1, 3, 3, 2, 0, 1, 3, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 39 and the episode is 3586 and the total_steps are 176025\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 1, 1, 0, 1, 3, 1, 0, 3, 1, 2, 0, 2, 1, 2, 0, 2, 1, 2, 3, 0, 1, 0, 1, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 3587 and the total_steps are 176056\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 0, 1, 0, 1, 1, 0, 0, 0, 3, 2, 2, 1, 3, 3, 3, 2, 2, 2, 2, 1, 3, 1, 3, 3, 3, 3, 3, 2, 1, 0, 0, 3, 1, 1, 1, 0, 0, 3, 2, 1, 0, 1, 0, 1, 0, 1, 0, 2, 1, 2, 0, 1, 3, 1, 1, 0, 1, 1, 2, 2, 3, 3, 2, 2, 1, 1, 2, 3, 3, 2, 3, 3, 1, 3, 2, 1, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1058. And steps were 84 and the episode is 3588 and the total_steps are 176140\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.1     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3588     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5966     |\n",
      "|    total_timesteps  | 176140   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.56     |\n",
      "|    n_updates        | 31534    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 2, 1, 3, 1, 3, 3, 1, 3, 0, 3, 2, 2, 0, 3, 3, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 3589 and the total_steps are 176161\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 1, 3, 3, 1, 0, 1, 2, 2, 0, 3, 0, 2, 2, 2, 0, 2, 2, 3, 1, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 3590 and the total_steps are 176186\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 3, 0, 3, 0, 3, 1, 0, 1, 2, 2, 2, 1, 2, 2, 3, 1, 2, 3, 3, 2, 2, 3, 1, 3, 1, 3, 2, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 35 and the episode is 3591 and the total_steps are 176221\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 1, 2, 3, 3, 0, 3, 1, 3, 0, 3, 1, 2, 2, 0, 3, 2, 2, 3, 3, 3, 3, 2, 3, 2, 0, 1, 3, 0, 3, 1, 3, 2, 3, 3, 3, 3, 3, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 1, 3, 3, 0, 3, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 60 and the episode is 3592 and the total_steps are 176281\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.1     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3592     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5972     |\n",
      "|    total_timesteps  | 176281   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.1      |\n",
      "|    n_updates        | 31570    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 3, 1, 2, 0, 3, 0, 3, 0, 2, 0, 2, 1, 1, 0, 1, 0, 1, 3, 1, 0, 1, 1, 0, 0, 1, 3, 3, 2, 0, 0, 2, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 39 and the episode is 3593 and the total_steps are 176320\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 0, 1, 2, 1, 3, 1, 1, 0, 1, 1, 1, 3, 2, 1, 3, 1, 1, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 25 and the episode is 3594 and the total_steps are 176345\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 3, 2, 3, 0, 2, 3, 3, 3, 3, 3, 3, 0, 1, 1, 0, 2, 3, 2, 0, 3, 0, 1, 2, 3, 2, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 3595 and the total_steps are 176378\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 3, 1, 1, 0, 2, 0, 2, 0, 2, 3, 1, 3, 1, 3, 0, 2, 0, 2, 2, 2, 2, 2, 2, 1, 3, 0, 2, 1, 2, 2, 3, 0, 2, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 3596 and the total_steps are 176419\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3596     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5978     |\n",
      "|    total_timesteps  | 176419   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.53     |\n",
      "|    n_updates        | 31604    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 1, 1, 0, 3, 2, 3, 2, 1, 2, 3, 2, 0, 3, 2, 2, 2, 3, 1, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 3597 and the total_steps are 176445\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 3, 0, 0, 3, 0, 1, 0, 3, 3, 1, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was 987. And steps were 16 and the episode is 3598 and the total_steps are 176461\n",
      "Done condition: collision\n",
      "[1, 1, 3, 0, 1, 1, 2, 0, 0, 3, 1, 0, 1, 2, 3, 3, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 0, 3, 0, 1, 1, 1, 1, 3, 3, 0, 1, 0, 1, 3, 3, 3, 1, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 48 and the episode is 3599 and the total_steps are 176509\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 0, 1, 3, 3, 3, 3, 3, 3, 2, 2, 3, 0, 1, 1, 1, 1, 2, 2, 2, 3, 1, 0, 1, 0, 0, 1, 0, 3, 2, 0, 3, 0, 2, 3, 1, 0, 1, 3, 2, 1, 0, 3, 1, 3, 0, 0, 2, 2, 1, 0, 3, 1, 1, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 61 and the episode is 3600 and the total_steps are 176570\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3600     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5984     |\n",
      "|    total_timesteps  | 176570   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 31642    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 2, 0, 1, 0, 0, 2, 1, 1, 2, 3, 0, 0, 0, 2, 0, 2, 1, 3, 1, 2, 0, 1, 0, 2, 1, 3, 3, 3, 3, 3, 2, 3, 1, 1, 3, 0, 1, 0, 2, 1, 3, 3, 1, 0, 3, 0, 0, 2, 0, 0, 3, 2, 0, 3, 2, 2, 1, 2, 3, 3, 0, 3, 3, 2, 1, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 73 and the episode is 3601 and the total_steps are 176643\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 1, 2, 1, 1, 3, 2, 1, 2, 3, 1, 3, 3, 3, 0, 0, 3, 0, 3, 0, 1, 2, 1, 1, 3, 1, 3, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 34 and the episode is 3602 and the total_steps are 176677\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 3, 3, 2, 2, 1, 3, 2, 0, 3, 3, 1, 2, 2, 1, 1, 3, 2, 3, 0, 0, 1, 2, 3, 1, 1, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 3603 and the total_steps are 176710\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 1, 0, 0, 1, 3, 0, 3, 3, 0, 3, 0, 1, 3, 3, 2, 0, 0, 2, 3, 3, 1, 0, 0, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 31 and the episode is 3604 and the total_steps are 176741\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3604     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5991     |\n",
      "|    total_timesteps  | 176741   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.4     |\n",
      "|    n_updates        | 31685    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 3, 3, 2, 2, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 3, 2, 0, 3, 2, 2, 2, 3, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 30 and the episode is 3605 and the total_steps are 176771\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 0, 2, 2, 1, 2, 3, 3, 2, 0, 2, 1, 1, 2, 3, 0, 1, 2, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 25 and the episode is 3606 and the total_steps are 176796\n",
      "Done condition: collision\n",
      "[3, 0, 0, 1, 1, 2, 1, 1, 1, 2, 1, 3, 3, 3, 2, 3, 3, 3, 3, 0, 1, 1, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 26 and the episode is 3607 and the total_steps are 176822\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 3, 3, 3, 2, 0, 2, 0, 1, 1, 1, 0, 3, 1, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1016. And steps were 19 and the episode is 3608 and the total_steps are 176841\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3608     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 5996     |\n",
      "|    total_timesteps  | 176841   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 31710    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 3, 2, 2, 1, 2, 2, 3, 2, 0, 2, 0, 2, 1, 2, 0, 3, 2, 2, 0, 2, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3609 and the total_steps are 176869\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 1, 0, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 2, 2, 0, 3, 0, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 25 and the episode is 3610 and the total_steps are 176894\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 1, 2, 0, 3, 1, 3, 1, 1, 0, 0, 1, 0, 1, 1, 2, 2, 3, 2, 3, 2, 1, 2, 1, 2, 2, 2, 0, 3, 1, 2, 0, 1, 0, 0, 3, 2, 0, 1, 3, 2, 1, 3, 3, 3, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 52 and the episode is 3611 and the total_steps are 176946\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 0, 1, 1, 0, 3, 1, 1, 1, 2, 3, 0, 2, 3, 3, 1, 1, 1, 0, 3, 0, 3, 0, 0, 1, 2, 3, 2, 2, 3, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 37 and the episode is 3612 and the total_steps are 176983\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.1     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3612     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6002     |\n",
      "|    total_timesteps  | 176983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 35       |\n",
      "|    n_updates        | 31745    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 2, 2, 1, 0, 3, 0, 1, 1, 2, 2, 2, 3, 3, 0, 0, 0, 3, 0, 2, 3, 1, 2, 0, 0, 3, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 3613 and the total_steps are 177016\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 1, 2, 1, 0, 1, 3, 2, 2, 3, 2, 2, 1, 0, 2, 2, 3, 2, 1, 2, 0, 1, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 3614 and the total_steps are 177045\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 0, 3, 0, 3, 1, 1, 2, 1, 2, 2, 0, 0, 0, 1, 3, 1, 0, 0, 3, 3, 0, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 2, 1, 3, 2, 2, 3, 0, 0, 0, 2, 0, 0, 1, 2, 1, 1, 0, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 56 and the episode is 3615 and the total_steps are 177101\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 2, 0, 2, 3, 3, 2, 3, 2, 2, 3, 0, 3, 3, 0, 3, 3, 2, 1, 2, 2, 0, 3, 0, 0, 1, 3, 0, 0, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 36 and the episode is 3616 and the total_steps are 177137\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.9     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3616     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6009     |\n",
      "|    total_timesteps  | 177137   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.32     |\n",
      "|    n_updates        | 31784    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 0, 3, 0, 1, 0, 0, 1, 0, 1, 1, 1, 3, 0, 3, 3, 1, 1, 3, 2, 1, 0, 3, 3, 3, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3617 and the total_steps are 177169\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 2, 1, 2, 3, 0, 1, 1, 2, 0, 0, 2, 3, 2, 0, 2, 3, 1, 0, 2, 3, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 3618 and the total_steps are 177197\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 2, 3, 3, 3, 0, 3, 0, 3, 0, 1, 0, 0, 1, 1, 2, 3, 3, 3, 1, 2, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3619 and the total_steps are 177225\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 2, 3, 0, 1, 3, 0, 2, 3, 2, 1, 3, 3, 1, 1, 0, 0, 3, 0, 1, 2, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 3620 and the total_steps are 177253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.5     |\n",
      "|    ep_rew_mean      | -859     |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3620     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6014     |\n",
      "|    total_timesteps  | 177253   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.921    |\n",
      "|    n_updates        | 31813    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 3, 1, 2, 0, 3, 2, 1, 2, 3, 0, 3, 0, 2, 1, 3, 2, 2, 1, 1, 1, 1, 0, 0, 2, 1, 2, 3, 3, 2, 3, 1, 3, 2, 0, 3, 2, 3, 3, 2, 0, 1, 2, 3, 2, 3, 3, 2, 1, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 56 and the episode is 3621 and the total_steps are 177309\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 1, 0, 1, 0, 2, 3, 1, 1, 2, 1, 1, 3, 2, 2, 3, 3, 3, 3, 2, 1, 2, 2, 3, 0, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 32 and the episode is 3622 and the total_steps are 177341\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 15 and the episode is 3623 and the total_steps are 177356\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 1, 3, 3, 2, 3, 3, 0, 3, 3, 3, 1, 3, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 3, 2, 2, 0, 1, 3, 3, 2, 1, 2, 2, 0, 3, 0, 0, 1, 0, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 49 and the episode is 3624 and the total_steps are 177405\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3624     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6020     |\n",
      "|    total_timesteps  | 177405   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.7     |\n",
      "|    n_updates        | 31851    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 3, 0, 2, 1, 1, 2, 1, 3, 3, 2, 3, 1, 2, 1, 2, 1, 3, 2, 3, 0, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 3625 and the total_steps are 177433\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 3, 1, 2, 2, 1, 1, 3, 0, 0, 0, 2, 0, 3, 3, 0, 1, 1, 2, 3, 2, 0, 3, 1, 3, 3, 3, 3, 1, 2, 3, 1, 1, 1, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 41 and the episode is 3626 and the total_steps are 177474\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 1, 3, 3, 0, 2, 2, 0, 0, 2, 3, 3, 2, 3, 1, 3, 1, 1, 1, 2, 2, 3, 0, 3, 1, 1, 3, 0, 0, 1, 2, 2, 0, 1, 2, 0, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 43 and the episode is 3627 and the total_steps are 177517\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 3, 3, 1, 2, 1, 3, 0, 1, 2, 0, 1, 1, 1, 0, 2, 0, 3, 3, 3, 1, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 3628 and the total_steps are 177545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3628     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6026     |\n",
      "|    total_timesteps  | 177545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.46     |\n",
      "|    n_updates        | 31886    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 2, 0, 3, 3, 3, 3, 3, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 3, 3, 2, 1, 3, 3, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 34 and the episode is 3629 and the total_steps are 177579\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 0, 1, 0, 2, 0, 1, 3, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 1, 0, 0, 3, 2, 2, 2, 0, 3, 2, 0, 1, 2, 0, 2, 1, 0, 1, 2, 0, 0, 2, 0, 1, 2, 3, 2, 2, 2, 0, 2, 0, 3, 1, 1, 3, 1, 0, 1, 0, 3, 0, 1, 0, 0, 1, 3, 0, 3, 3, 2, 3, 0, 2, 1, 3, 2, 3, 1, 3, 3, 1, 0, 2, 0, 2, 2, 1, 3, 2, 1, 1, 1, 2, 1, 1, 1, 3, 2, 2, 3, 2, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -933. And steps were 107 and the episode is 3630 and the total_steps are 177686\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 0, 3, 1, 0, 0, 1, 0, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 3, 3, 1, 2, 0, 3, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 3631 and the total_steps are 177717\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 2, 2, 1, 2, 3, 1, 3, 3, 1, 3, 3, 2, 0, 2, 3, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 23 and the episode is 3632 and the total_steps are 177740\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3632     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6034     |\n",
      "|    total_timesteps  | 177740   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.98     |\n",
      "|    n_updates        | 31934    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 1, 1, 3, 0, 2, 3, 2, 1, 1, 2, 1, 0, 0, 2, 2, 1, 1, 3, 2, 2, 1, 0, 2, 2, 1, 3, 3, 0, 2, 0, 0, 2, 1, 0, 0, 0, 1, 0, 1, 2, 2, 3, 1, 0, 2, 2, 3, 0, 2, 1, 0, 0, 0, 1, 1, 1, 3, 3, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 66 and the episode is 3633 and the total_steps are 177806\n",
      "Done condition: collision\n",
      "[1, 3, 2, 1, 1, 0, 0, 3, 1, 2, 2, 3, 3, 1, 0, 2, 0, 2, 2, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 23 and the episode is 3634 and the total_steps are 177829\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 0, 1, 2, 2, 3, 1, 1, 2, 3, 2, 3, 0, 3, 2, 2, 0, 1, 2, 1, 0, 0, 3, 1, 0, 0, 3, 2, 1, 1, 3, 1, 0, 1, 0, 1, 3, 1, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 45 and the episode is 3635 and the total_steps are 177874\n",
      "Done condition: collision\n",
      "[3, 3, 2, 3, 3, 1, 0, 1, 2, 2, 1, 2, 1, 0, 3, 1, 1, 0, 1, 1, 2, 0, 2, 0, 3, 0, 3, 1, 1, 0, 2, 1, 2, 2, 3, 0, 3, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 41 and the episode is 3636 and the total_steps are 177915\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.1     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3636     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6042     |\n",
      "|    total_timesteps  | 177915   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.65     |\n",
      "|    n_updates        | 31978    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 2, 2, 1, 1, 0, 2, 3, 2, 0, 0, 2, 2, 3, 1, 3, 2, 3, 0, 2, 1, 0, 1, 3, 3, 0, 3, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 34 and the episode is 3637 and the total_steps are 177949\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 0, 2, 2, 3, 1, 0, 3, 3, 0, 2, 2, 3, 1, 3, 2, 3, 3, 1, 1, 2, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 3638 and the total_steps are 177977\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 0, 2, 1, 3, 0, 1, 0, 1, 1, 3, 2, 3, 3, 2, 0, 1, 3, 0, 3, 0, 3, 3, 3, 3, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 32 and the episode is 3639 and the total_steps are 178009\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 2, 0, 3, 2, 2, 1, 2, 2, 0, 0, 2, 3, 2, 0, 0, 2, 1, 1, 3, 1, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 3640 and the total_steps are 178037\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3640     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6047     |\n",
      "|    total_timesteps  | 178037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 32009    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 0, 1, 1, 1, 0, 0, 3, 2, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 3641 and the total_steps are 178053\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 2, 0, 0, 3, 1, 2, 2, 1, 1, 2, 1, 2, 3, 0, 1, 2, 1, 1, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 26 and the episode is 3642 and the total_steps are 178079\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 3, 2, 3, 1, 0, 2, 2, 0, 2, 1, 3, 1, 3, 3, 0, 2, 3, 3, 2, 0, 2, 1, 2, 1, 2, 1, 2, 0, 0, 3, 3, 1, 1, 1, 3, 2, 2, 3, 1, 0, 3, 0, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1048. And steps were 50 and the episode is 3643 and the total_steps are 178129\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 1, 2, 2, 2, 0, 0, 1, 2, 0, 1, 1, 0, 3, 1, 0, 2, 0, 0, 0, 1, 3, 3, 3, 2, 2, 2, 1, 2, 3, 2, 1, 2, 3, 3, 0, 3, 3, 3, 0, 0, 1, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 49 and the episode is 3644 and the total_steps are 178178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.9     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3644     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6053     |\n",
      "|    total_timesteps  | 178178   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.62     |\n",
      "|    n_updates        | 32044    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 2, 1, 3, 3, 0, 2, 0, 0, 0, 2, 3, 1, 2, 2, 1, 2, 3, 2, 0, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 27 and the episode is 3645 and the total_steps are 178205\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 3, 0, 0, 2, 2, 2, 3, 1, 1, 3, 2, 1, 3, 0, 2, 1, 2, 3, 0, 2, 3, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3646 and the total_steps are 178234\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 2, 1, 2, 1, 2, 2, 2, 1, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 3647 and the total_steps are 178250\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 1, 3, 2, 3, 2, 3, 0, 3, 1, 0, 1, 1, 0, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1018. And steps were 19 and the episode is 3648 and the total_steps are 178269\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3648     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6057     |\n",
      "|    total_timesteps  | 178269   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63       |\n",
      "|    n_updates        | 32067    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 3, 1, 1, 3, 1, 0, 2, 3, 3, 0, 3, 1, 1, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 27 and the episode is 3649 and the total_steps are 178296\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 3, 0, 3, 1, 2, 3, 0, 0, 3, 1, 0, 0, 2, 3, 2, 3, 0, 1, 1, 1, 1, 3, 1, 2, 3, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 33 and the episode is 3650 and the total_steps are 178329\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 0, 2, 0, 1, 1, 0, 0, 0, 0, 3, 2, 2, 0, 0, 0, 2, 3, 3, 3, 1, 3, 0, 2, 1, 1, 2, 0, 3, 3, 2, 0, 0, 2, 0, 2, 3, 3, 0, 0, 3, 2, 0, 1, 3, 0, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 53 and the episode is 3651 and the total_steps are 178382\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 0, 1, 1, 2, 1, 3, 3, 2, 2, 1, 0, 3, 0, 1, 0, 2, 1, 2, 3, 0, 0, 1, 2, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 31 and the episode is 3652 and the total_steps are 178413\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3652     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6063     |\n",
      "|    total_timesteps  | 178413   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.92     |\n",
      "|    n_updates        | 32103    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 0, 2, 2, 2, 0, 2, 3, 1, 0, 0, 3, 1, 2, 2, 1, 1, 2, 3, 2, 3, 3, 3, 3, 3, 3, 0, 3, 0, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 36 and the episode is 3653 and the total_steps are 178449\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 3, 3, 2, 2, 0, 0, 1, 1, 2, 2, 3, 2, 0, 0, 3, 1, 1, 2, 2, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 27 and the episode is 3654 and the total_steps are 178476\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 2, 0, 0, 2, 2, 1, 3, 1, 2, 3, 2, 3, 2, 1, 3, 2, 3, 1, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 26 and the episode is 3655 and the total_steps are 178502\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 1, 1, 3, 2, 0, 3, 1, 0, 2, 1, 0, 0, 2, 1, 1, 2, 2, 1, 0, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 27 and the episode is 3656 and the total_steps are 178529\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -859     |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3656     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6069     |\n",
      "|    total_timesteps  | 178529   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 32132    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 1, 2, 1, 1, 1, 1, 3, 0, 1, 2, 1, 3, 1, 3, 3, 0, 3, 0, 3, 2, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 28 and the episode is 3657 and the total_steps are 178557\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 1, 3, 3, 2, 2, 0, 3, 1, 3, 1, 0, 2, 1, 1, 1, 1, 1, 3, 0, 0, 2, 3, 1, 0, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 3658 and the total_steps are 178589\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 2, 1, 0, 2, 0, 3, 3, 2, 1, 3, 1, 0, 3, 3, 0, 3, 3, 0, 1, 1, 0, 0, 2, 0, 1, 0, 3, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 35 and the episode is 3659 and the total_steps are 178624\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 2, 1, 3, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 0, 3, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 33 and the episode is 3660 and the total_steps are 178657\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3660     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6074     |\n",
      "|    total_timesteps  | 178657   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 32164    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 1, 1, 1, 0, 2, 2, 3, 1, 2, 3, 3, 2, 1, 2, 3, 3, 1, 3, 3, 3, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 3661 and the total_steps are 178685\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 2, 3, 0, 2, 2, 2, 2, 0, 2, 3, 3, 2, 3, 3, 3, 0, 0, 2, 0, 1, 2, 1, 2, 0, 3, 3, 3, 2, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 45 and the episode is 3662 and the total_steps are 178730\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 2, 0, 2, 1, 0, 3, 3, 1, 2, 0, 3, 0, 2, 2, 3, 2, 2, 3, 0, 1, 2, 2, 3, 0, 1, 3, 2, 0, 0, 1, 3, 3, 1, 1, 2, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 43 and the episode is 3663 and the total_steps are 178773\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 2, 2, 1, 2, 0, 2, 2, 1, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 16 and the episode is 3664 and the total_steps are 178789\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3664     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6079     |\n",
      "|    total_timesteps  | 178789   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 32197    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 0, 2, 3, 3, 0, 2, 3, 2, 0, 3, 2, 0, 0, 2, 2, 2, 0, 1, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 3665 and the total_steps are 178815\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 1, 3, 1, 3, 3, 0, 0, 3, 2, 0, 2, 1, 2, 3, 2, 1, 1, 1, 1, 2, 0, 2, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2, 2, 0, 1, 0, 0, 0, 2, 2, 0, 1, 2, 0, 2, 3, 1, 1, 3, 2, 0, 0, 2, 1, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 62 and the episode is 3666 and the total_steps are 178877\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 2, 3, 1, 0, 2, 0, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 27 and the episode is 3667 and the total_steps are 178904\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 1, 0, 1, 0, 2, 2, 1, 0, 3, 3, 2, 1, 0, 1, 2, 1, 1, 2, 3, 0, 1, 2, 3, 1, 3, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 33 and the episode is 3668 and the total_steps are 178937\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3668     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6086     |\n",
      "|    total_timesteps  | 178937   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.5     |\n",
      "|    n_updates        | 32234    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 0, 1, 3, 0, 0, 2, 1, 0, 3, 1, 0, 1, 2, 2, 0, 3, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 24 and the episode is 3669 and the total_steps are 178961\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 3, 1, 2, 1, 2, 2, 0, 3, 1, 2, 0, 3, 2, 1, 1, 2, 2, 3, 0, 2, 2, 2, 1, 2, 1, 2, 1, 0, 1, 2, 3, 2, 0, 2, 1, 1, 1, 0, 2, 3, 0, 3, 2, 2, 1, 0, 2, 0, 2, 3, 0, 3, 0, 3, 0, 0, 2, 0, 3, 0, 0, 2, 0, 2, 1, 3, 1, 0, 3, 1, 3, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0, 0, 1, 0, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1080. And steps were 100 and the episode is 3670 and the total_steps are 179061\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 1, 1, 1, 0, 1, 2, 2, 3, 0, 2, 0, 0, 3, 0, 1, 2, 0, 3, 1, 2, 1, 0, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 30 and the episode is 3671 and the total_steps are 179091\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 1, 3, 3, 1, 2, 1, 0, 2, 3, 3, 3, 1, 2, 2, 3, 0, 0, 1, 0, 1, 2, 3, 0, 0, 0, 3, 3, 1, 3, 1, 2, 0, 3, 1, 3, 2, 2, 2, 3, 3, 0, 0, 1, 0, 3, 2, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 54 and the episode is 3672 and the total_steps are 179145\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | -859     |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3672     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6094     |\n",
      "|    total_timesteps  | 179145   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 32286    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 2, 1, 2, 0, 3, 0, 2, 1, 3, 1, 0, 0, 0, 3, 1, 1, 0, 1, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 26 and the episode is 3673 and the total_steps are 179171\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 0, 0, 2, 2, 2, 2, 3, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 15 and the episode is 3674 and the total_steps are 179186\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 0, 1, 1, 2, 3, 1, 3, 0, 3, 1, 3, 3, 2, 1, 1, 3, 3, 0, 0, 2, 1, 0, 1, 3, 2, 0, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 3675 and the total_steps are 179220\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 3, 0, 0, 1, 1, 0, 3, 2, 2, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 25 and the episode is 3676 and the total_steps are 179245\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3676     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6099     |\n",
      "|    total_timesteps  | 179245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.7     |\n",
      "|    n_updates        | 32311    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 0, 2, 0, 0, 2, 1, 2, 3, 1, 0, 1, 0, 0, 2, 1, 2, 0, 0, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 3677 and the total_steps are 179271\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 0, 3, 0, 2, 0, 3, 0, 2, 1, 2, 3, 1, 3, 2, 3, 1, 2, 1, 1, 3, 2, 3, 0, 2, 0, 0, 0, 0, 2, 3, 2, 0, 2, 1, 1, 3, 3, 0, 2, 1, 3, 1, 1, 0, 3, 0, 3, 1, 0, 1, 1, 3, 2, 2, 0, 0, 1, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 65 and the episode is 3678 and the total_steps are 179336\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 1, 2, 3, 3, 3, 3, 1, 0, 3, 0, 2, 0, 3, 3, 0, 1, 1, 0, 2, 0, 3, 3, 0, 3, 0, 3, 0, 0, 1, 2, 3, 2, 2, 3, 1, 0, 2, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 45 and the episode is 3679 and the total_steps are 179381\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 2, 1, 1, 3, 2, 0, 1, 3, 0, 3, 3, 1, 1, 2, 1, 0, 2, 2, 1, 1, 0, 2, 1, 2, 2, 1, 1, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 35 and the episode is 3680 and the total_steps are 179416\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3680     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6106     |\n",
      "|    total_timesteps  | 179416   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.8     |\n",
      "|    n_updates        | 32353    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 0, 3, 0, 0, 2, 3, 0, 2, 0, 1, 0, 2, 0, 1, 3, 3, 3, 3, 1, 0, 0, 3, 1, 3, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3681 and the total_steps are 179448\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 2, 2, 2, 3, 1, 3, 3, 3, 1, 0, 2, 0, 2, 3, 1, 1, 1, 2, 3, 3, 1, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3682 and the total_steps are 179477\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 1, 0, 1, 2, 1, 2, 3, 0, 3, 3, 0, 2, 0, 3, 0, 3, 3, 3, 0, 1, 2, 0, 2, 2, 3, 3, 1, 0, 3, 1, 1, 1, 3, 2, 3, 2, 3, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1043. And steps were 45 and the episode is 3683 and the total_steps are 179522\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 2, 3, 3, 2, 1, 2, 0, 1, 0, 0, 2, 0, 3, 1, 3, 3, 3, 1, 1, 1, 1, 0, 3, 0, 1, 2, 2, 2, 2, 2, 2, 3, 0, 1, 0, 0, 2, 2, 1, 1, 3, 2, 2, 0, 0, 3, 0, 2, 3, 3, 0, 2, 3, 1, 1, 2, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 64 and the episode is 3684 and the total_steps are 179586\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3684     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6113     |\n",
      "|    total_timesteps  | 179586   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.2     |\n",
      "|    n_updates        | 32396    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 0, 1, 3, 3, 1, 3, 2, 2, 0, 2, 1, 3, 2, 1, 0, 1, 1, 2, 0, 3, 3, 2, 1, 3, 2, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 33 and the episode is 3685 and the total_steps are 179619\n",
      "Done condition: collision\n",
      "[1, 3, 2, 0, 2, 0, 1, 3, 0, 2, 0, 3, 0, 1, 2, 0, 0, 2, 2, 3, 1, 3, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 26 and the episode is 3686 and the total_steps are 179645\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 3, 1, 0, 1, 0, 3, 3, 0, 0, 1, 2, 3, 0, 2, 3, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 3, 1, 2, 3, 1, 2, 3, 0, 0, 2, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 43 and the episode is 3687 and the total_steps are 179688\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 2, 2, 3, 0, 1, 1, 2, 1, 2, 2, 1, 2, 3, 2, 3, 1, 2, 1, 3, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 27 and the episode is 3688 and the total_steps are 179715\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3688     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6119     |\n",
      "|    total_timesteps  | 179715   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65.6     |\n",
      "|    n_updates        | 32428    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 3, 1, 1, 2, 3, 0, 1, 0, 2, 1, 0, 3, 1, 3, 3, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 3689 and the total_steps are 179745\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 0, 1, 0, 1, 2, 1, 0, 1, 2, 3, 3, 2, 0, 2, 3, 2, 0, 0, 2, 1, 3, 0, 3, 3, 0, 0, 2, 0, 0, 3, 0, 2, 2, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 41 and the episode is 3690 and the total_steps are 179786\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 1, 1, 3, 2, 1, 0, 0, 0, 0, 1, 3, 2, 3, 3, 1, 1, 0, 2, 1, 2, 0, 2, 3, 2, 3, 2, 3, 0, 3, 2, 0, 3, 2, 1, 3, 3, 0, 2, 2, 0, 0, 3, 2, 3, 3, 1, 2, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 55 and the episode is 3691 and the total_steps are 179841\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 1, 1, 1, 1, 1, 3, 0, 0, 2, 1, 1, 2, 1, 3, 0, 0, 3, 0, 2, 1, 3, 3, 3, 1, 3, 2, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 34 and the episode is 3692 and the total_steps are 179875\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3692     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6126     |\n",
      "|    total_timesteps  | 179875   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 32468    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 1, 2, 3, 3, 2, 0, 1, 1, 2, 0, 1, 3, 1, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 21 and the episode is 3693 and the total_steps are 179896\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 0, 1, 3, 1, 3, 0, 0, 1, 0, 2, 3, 0, 1, 0, 3, 0, 3, 0, 1, 3, 3, 0, 2, 0, 2, 2, 1, 0, 2, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 37 and the episode is 3694 and the total_steps are 179933\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 2, 2, 1, 0, 3, 3, 1, 2, 0, 3, 1, 2, 3, 3, 2, 3, 2, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 25 and the episode is 3695 and the total_steps are 179958\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 3, 2, 2, 3, 3, 2, 1, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 15 and the episode is 3696 and the total_steps are 179973\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3696     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6130     |\n",
      "|    total_timesteps  | 179973   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.84     |\n",
      "|    n_updates        | 32493    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 1, 1, 1, 2, 3, 0, 0, 3, 1, 0, 1, 2, 2, 1, 3, 0, 2, 3, 2, 2, 3, 1, 2, 0, 1, 3, 0, 2, 2, 3, 3, 1, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 40 and the episode is 3697 and the total_steps are 180013\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 2, 3, 1, 2, 1, 2, 2, 1, 1, 3, 2, 3, 2, 0, 2, 2, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 24 and the episode is 3698 and the total_steps are 180037\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 3, 2, 2, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 20 and the episode is 3699 and the total_steps are 180057\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 1, 3, 3, 1, 3, 1, 0, 3, 0, 2, 0, 3, 0, 0, 1, 1, 0, 2, 2, 3, 2, 0, 2, 3, 2, 2, 3, 0, 1, 0, 3, 2, 0, 2, 2, 3, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 44 and the episode is 3700 and the total_steps are 180101\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | -959     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3700     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6135     |\n",
      "|    total_timesteps  | 180101   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.88     |\n",
      "|    n_updates        | 32525    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 1, 3, 1, 0, 2, 0, 0, 3, 0, 3, 3, 0, 0, 2, 2, 1, 2, 3, 2, 1, 3, 0, 1, 3, 2, 3, 3, 0, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 3701 and the total_steps are 180137\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 0, 3, 0, 3, 2, 1, 2, 1, 0, 3, 0, 0, 2, 2, 2, 1, 3, 3, 3, 3, 1, 3, 0, 0, 2, 1, 2, 1, 1, 0, 3, 0, 3, 0, 3, 2, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 44 and the episode is 3702 and the total_steps are 180181\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 1, 0, 1, 0, 3, 3, 0, 0, 0, 2, 2, 3, 0, 2, 1, 0, 3, 1, 3, 3, 2, 2, 2, 0, 1, 0, 1, 3, 1, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 37 and the episode is 3703 and the total_steps are 180218\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 0, 2, 2, 0, 0, 3, 3, 1, 2, 2, 1, 1, 3, 3, 1, 1, 2, 1, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 26 and the episode is 3704 and the total_steps are 180244\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35       |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3704     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6141     |\n",
      "|    total_timesteps  | 180244   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 32560    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 2, 3, 3, 3, 2, 0, 0, 3, 1, 0, 0, 1, 1, 0, 3, 1, 0, 1, 3, 1, 0, 2, 2, 3, 2, 0, 2, 1, 2, 1, 3, 1, 2, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 41 and the episode is 3705 and the total_steps are 180285\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 1, 0, 0, 0, 1, 0, 1, 3, 0, 1, 1, 3, 1, 0, 2, 1, 1, 1, 1, 1, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 3706 and the total_steps are 180313\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 0, 3, 0, 3, 3, 1, 0, 3, 3, 0, 2, 2, 2, 2, 0, 1, 1, 3, 1, 2, 0, 0, 0, 0, 2, 2, 3, 3, 2, 1, 0, 2, 2, 0, 0, 3, 1, 3, 3, 2, 3, 2, 2, 0, 3, 0, 2, 3, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1054. And steps were 56 and the episode is 3707 and the total_steps are 180369\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 1, 2, 2, 0, 3, 1, 0, 0, 2, 2, 2, 3, 3, 0, 0, 1, 3, 1, 3, 2, 1, 2, 3, 0, 2, 1, 0, 2, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 36 and the episode is 3708 and the total_steps are 180405\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | -979     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3708     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6148     |\n",
      "|    total_timesteps  | 180405   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.32     |\n",
      "|    n_updates        | 32601    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 2, 2, 1, 2, 1, 0, 2, 3, 0, 1, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 18 and the episode is 3709 and the total_steps are 180423\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 2, 0, 1, 2, 2, 1, 1, 2, 0, 3, 2, 3, 2, 1, 2, 1, 3, 1, 3, 3, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 28 and the episode is 3710 and the total_steps are 180451\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 2, 0, 1, 2, 3, 3, 1, 0, 3, 1, 3, 2, 2, 1, 3, 3, 0, 0, 2, 1, 1, 1, 2, 3, 2, 1, 0, 0, 1, 1, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 38 and the episode is 3711 and the total_steps are 180489\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 1, 1, 1, 3, 1, 1, 0, 3, 3, 1, 0, 3, 3, 2, 2, 3, 3, 3, 1, 2, 0, 3, 1, 2, 2, 3, 1, 3, 0, 1, 2, 2, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 40 and the episode is 3712 and the total_steps are 180529\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | -978     |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3712     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6154     |\n",
      "|    total_timesteps  | 180529   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.6     |\n",
      "|    n_updates        | 32632    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 3, 0, 0, 3, 1, 0, 1, 1, 1, 0, 2, 2, 3, 2, 0, 1, 0, 1, 2, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 26 and the episode is 3713 and the total_steps are 180555\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 0, 1, 0, 3, 0, 3, 0, 1, 2, 2, 3, 2, 0, 2, 0, 1, 2, 3, 2, 0, 0, 1, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 30 and the episode is 3714 and the total_steps are 180585\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 1, 0, 1, 2, 2, 0, 0, 1, 1, 3, 3, 0, 0, 0, 0, 0, 2, 3, 3, 3, 2, 2, 3, 3, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 3715 and the total_steps are 180617\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 1, 2, 3, 1, 3, 3, 3, 2, 0, 2, 1, 0, 3, 0, 0, 1, 1, 3, 0, 1, 1, 0, 1, 2, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 3716 and the total_steps are 180649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | -978     |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3716     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6159     |\n",
      "|    total_timesteps  | 180649   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.63     |\n",
      "|    n_updates        | 32662    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 1, 3, 1, 3, 3, 1, 1, 3, 0, 3, 3, 1, 2, 1, 3, 0, 2, 0, 1, 1, 1, 3, 2, 1, 0, 0, 2, 1, 0, 2, 3, 1, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 40 and the episode is 3717 and the total_steps are 180689\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 1, 2, 3, 1, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 3, 0, 1, 1, 3, 2, 2, 3, 3, 2, 0, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 34 and the episode is 3718 and the total_steps are 180723\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 3, 0, 0, 0, 1, 2, 3, 0, 1, 3, 1, 3, 3, 0, 1, 1, 1, 3, 1, 0, 2, 3, 3, 3, 1, 1, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 34 and the episode is 3719 and the total_steps are 180757\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 2, 3, 3, 0, 3, 3, 2, 1, 3, 0, 2, 0, 2, 1, 1, 3, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 24 and the episode is 3720 and the total_steps are 180781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3720     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6164     |\n",
      "|    total_timesteps  | 180781   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.7     |\n",
      "|    n_updates        | 32695    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 3, 1, 3, 3, 2, 3, 3, 3, 3, 1, 3, 1, 2, 1, 2, 1, 3, 0, 1, 0, 1, 1, 2, 3, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 32 and the episode is 3721 and the total_steps are 180813\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 2, 1, 3, 2, 0, 0, 2, 1, 3, 1, 2, 3, 1, 0, 3, 2, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 3722 and the total_steps are 180837\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 1, 1, 0, 1, 2, 0, 0, 1, 2, 0, 1, 2, 2, 1, 3, 2, 2, 0, 0, 3, 3, 2, 3, 2, 0, 3, 1, 3, 3, 3, 2, 2, 1, 1, 1, 1, 2, 2, 3, 0, 3, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 49 and the episode is 3723 and the total_steps are 180886\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 2, 2, 0, 2, 2, 1, 0, 1, 3, 1, 1, 1, 1, 3, 3, 2, 3, 3, 0, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 27 and the episode is 3724 and the total_steps are 180913\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3724     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6170     |\n",
      "|    total_timesteps  | 180913   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 32728    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 1, 2, 0, 1, 1, 3, 1, 3, 3, 2, 0, 3, 1, 0, 1, 3, 1, 2, 3, 3, 3, 1, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 30 and the episode is 3725 and the total_steps are 180943\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 2, 1, 3, 0, 3, 3, 1, 3, 3, 0, 1, 3, 2, 2, 3, 0, 1, 3, 1, 1, 1, 2, 3, 0, 3, 3, 3, 0, 0, 3, 1, 0, 0, 0, 0, 1, 0, 3, 1, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 47 and the episode is 3726 and the total_steps are 180990\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 2, 3, 1, 2, 3, 3, 0, 3, 3, 0, 1, 3, 2, 0, 1, 0, 2, 1, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 27 and the episode is 3727 and the total_steps are 181017\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 3, 1, 3, 3, 1, 0, 2, 2, 0, 1, 1, 2, 1, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 21 and the episode is 3728 and the total_steps are 181038\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.9     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3728     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6176     |\n",
      "|    total_timesteps  | 181038   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.43     |\n",
      "|    n_updates        | 32759    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 2, 2, 0, 1, 1, 0, 3, 1, 1, 1, 2, 2, 3, 1, 3, 2, 3, 2, 2, 1, 1, 3, 1, 2, 2, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 33 and the episode is 3729 and the total_steps are 181071\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 2, 3, 2, 3, 1, 1, 2, 1, 3, 3, 1, 3, 1, 2, 1, 2, 1, 0, 3, 2, 0, 1, 3, 1, 0, 0, 3, 2, 2, 2, 1, 2, 3, 0, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 42 and the episode is 3730 and the total_steps are 181113\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 0, 1, 1, 2, 1, 0, 3, 3, 2, 0, 3, 3, 3, 1, 3, 0, 0, 1, 3, 0, 3, 2, 1, 2, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 32 and the episode is 3731 and the total_steps are 181145\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 3, 0, 3, 3, 0, 1, 3, 0, 1, 3, 0, 2, 0, 0, 2, 3, 2, 2, 1, 1, 0, 3, 0, 1, 3, 1, 1, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 35 and the episode is 3732 and the total_steps are 181180\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.4     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3732     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6182     |\n",
      "|    total_timesteps  | 181180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 32794    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 2, 0, 0, 1, 2, 2, 3, 2, 3, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 17 and the episode is 3733 and the total_steps are 181197\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 2, 2, 1, 1, 0, 3, 2, 1, 2, 1, 3, 3, 0, 1, 3, 2, 1, 1, 2, 3, 3, 3, 1, 1, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3734 and the total_steps are 181229\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 2, 0, 0, 0, 2, 1, 3, 0, 0, 1, 1, 1, 2, 3, 0, 2, 1, 2, 1, 0, 0, 2, 2, 2, 3, 3, 3, 3, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 36 and the episode is 3735 and the total_steps are 181265\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 0, 3, 2, 0, 2, 0, 2, 1, 1, 0, 1, 0, 1, 3, 1, 3, 3, 1, 3, 1, 0, 3, 1, 0, 1, 1, 1, 1, 2, 0, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 38 and the episode is 3736 and the total_steps are 181303\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.9     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3736     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6187     |\n",
      "|    total_timesteps  | 181303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.7     |\n",
      "|    n_updates        | 32825    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 0, 1, 1, 1, 1, 3, 3, 0, 0, 1, 0, 3, 1, 0, 3, 1, 0, 3, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 26 and the episode is 3737 and the total_steps are 181329\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 3, 3, 3, 0, 0, 1, 2, 3, 1, 3, 3, 1, 0, 1, 2, 1, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 3738 and the total_steps are 181353\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 0, 1, 1, 0, 3, 1, 0, 2, 0, 3, 3, 0, 0, 2, 1, 1, 3, 1, 2, 0, 1, 2, 1, 0, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 32 and the episode is 3739 and the total_steps are 181385\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 3, 2, 2, 0, 0, 2, 3, 2, 1, 1, 3, 0, 1, 1, 2, 1, 2, 0, 2, 3, 1, 3, 2, 1, 2, 3, 2, 0, 1, 3, 0, 1, 2, 1, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 42 and the episode is 3740 and the total_steps are 181427\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.9     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3740     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6192     |\n",
      "|    total_timesteps  | 181427   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 28.5     |\n",
      "|    n_updates        | 32856    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 2, 1, 3, 0, 1, 2, 2, 0, 3, 3, 2, 2, 0, 3, 3, 1, 0, 1, 2, 2, 2, 3, 0, 3, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 32 and the episode is 3741 and the total_steps are 181459\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 2, 2, 1, 0, 2, 2, 2, 1, 0, 1, 1, 3, 1, 2, 2, 2, 3, 3, 1, 2, 0, 3, 1, 3, 2, 2, 0, 2, 3, 3, 0, 0, 1, 1, 2, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 54 and the episode is 3742 and the total_steps are 181513\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 0, 3, 2, 0, 2, 1, 0, 3, 1, 0, 0, 0, 1, 0, 3, 3, 2, 0, 2, 2, 3, 3, 2, 1, 1, 1, 1, 1, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 3743 and the total_steps are 181549\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 3, 0, 0, 0, 2, 1, 1, 3, 1, 2, 0, 1, 0, 0, 0, 1, 0, 2, 2, 2, 2, 3, 2, 2, 0, 1, 0, 2, 1, 1, 2, 1, 3, 0, 3, 2, 2, 2, 1, 3, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 48 and the episode is 3744 and the total_steps are 181597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.2     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3744     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6200     |\n",
      "|    total_timesteps  | 181597   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.99     |\n",
      "|    n_updates        | 32899    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 3, 1, 1, 3, 0, 0, 0, 1, 2, 3, 2, 3, 2, 3, 3, 3, 2, 1, 0, 2, 3, 3, 1, 0, 1, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 33 and the episode is 3745 and the total_steps are 181630\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 0, 2, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 2, 3, 3, 1, 1, 2, 2, 2, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 3746 and the total_steps are 181658\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 3, 3, 3, 3, 1, 3, 2, 0, 3, 3, 1, 0, 0, 0, 3, 1, 2, 3, 2, 0, 0, 2, 1, 2, 3, 1, 1, 3, 1, 2, 1, 3, 3, 3, 0, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 43 and the episode is 3747 and the total_steps are 181701\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 2, 2, 1, 1, 2, 2, 1, 3, 1, 3, 3, 1, 2, 0, 3, 1, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 24 and the episode is 3748 and the total_steps are 181725\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.6     |\n",
      "|    ep_rew_mean      | -996     |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3748     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6206     |\n",
      "|    total_timesteps  | 181725   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.68     |\n",
      "|    n_updates        | 32931    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 2, 3, 0, 1, 0, 0, 2, 2, 3, 2, 3, 2, 1, 0, 1, 1, 1, 0, 0, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 27 and the episode is 3749 and the total_steps are 181752\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 2, 1, 2, 3, 2, 0, 1, 2, 0, 2, 1, 0, 2, 0, 3, 0, 0, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 3750 and the total_steps are 181778\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 1, 2, 0, 0, 2, 1, 3, 2, 0, 2, 2, 1, 0, 0, 2, 2, 3, 1, 1, 0, 1, 2, 2, 1, 0, 0, 2, 3, 3, 1, 2, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 39 and the episode is 3751 and the total_steps are 181817\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 3, 1, 2, 3, 2, 2, 3, 2, 2, 2, 0, 3, 0, 1, 3, 3, 3, 3, 3, 1, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 3752 and the total_steps are 181845\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.3     |\n",
      "|    ep_rew_mean      | -996     |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3752     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6211     |\n",
      "|    total_timesteps  | 181845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65.5     |\n",
      "|    n_updates        | 32961    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 0, 1, 0, 2, 2, 1, 2, 2, 0, 1, 0, 3, 2, 3, 2, 0, 2, 2, 3, 0, 0, 2, 1, 3, 3, 2, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was 1002. And steps were 31 and the episode is 3753 and the total_steps are 181876\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 2, 1, 3, 2, 1, 0, 3, 2, 3, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 17 and the episode is 3754 and the total_steps are 181893\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 0, 0, 0, 1, 2, 0, 3, 1, 1, 0, 1, 2, 0, 2, 2, 3, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 25 and the episode is 3755 and the total_steps are 181918\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 3, 0, 3, 1, 1, 0, 1, 0, 2, 2, 2, 3, 1, 0, 0, 0, 2, 0, 1, 3, 2, 2, 2, 3, 0, 1, 1, 0, 2, 1, 0, 0, 0, 1, 2, 1, 3, 3, 3, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 47 and the episode is 3756 and the total_steps are 181965\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.4     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3756     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6216     |\n",
      "|    total_timesteps  | 181965   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 32991    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 3, 2, 3, 1, 1, 2, 2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 3, 0, 2, 3, 0, 3, 1, 3, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 32 and the episode is 3757 and the total_steps are 181997\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 1, 0, 2, 1, 1, 2, 2, 3, 0, 1, 2, 3, 0, 3, 1, 3, 2, 3, 0, 0, 3, 0, 0, 1, 3, 3, 3, 2, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 48 and the episode is 3758 and the total_steps are 182045\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 2, 3, 2, 2, 3, 0, 1, 0, 2, 3, 1, 1, 0, 2, 1, 1, 2, 3, 0, 1, 0, 2, 2, 1, 2, 3, 3, 1, 0, 3, 0, 1, 2, 1, 3, 3, 0, 2, 2, 1, 0, 2, 2, 3, 3, 1, 0, 3, 0, 0, 3, 1, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 60 and the episode is 3759 and the total_steps are 182105\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 0, 0, 3, 0, 2, 1, 1, 1, 3, 0, 2, 3, 2, 0, 1, 0, 0, 2, 2, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 27 and the episode is 3760 and the total_steps are 182132\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.8     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3760     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6223     |\n",
      "|    total_timesteps  | 182132   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.5     |\n",
      "|    n_updates        | 33032    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 3, 1, 1, 3, 1, 2, 0, 3, 2, 0, 0, 3, 0, 1, 0, 0, 0, 3, 0, 0, 1, 3, 1, 2, 3, 3, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 41 and the episode is 3761 and the total_steps are 182173\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 0, 0, 2, 0, 3, 0, 2, 1, 0, 0, 3, 0, 1, 2, 2, 0, 3, 0, 0, 1, 3, 2, 3, 3, 0, 3, 3, 1, 0, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 36 and the episode is 3762 and the total_steps are 182209\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 0, 1, 0, 0, 2, 3, 3, 3, 3, 0, 0, 2, 3, 0, 2, 3, 2, 1, 2, 2, 1, 0, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 3763 and the total_steps are 182239\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 0, 1, 2, 2, 2, 1, 0, 1, 0, 1, 1, 3, 1, 1, 3, 1, 1, 2, 1, 1, 2, 1, 0, 1, 2, 3, 1, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 35 and the episode is 3764 and the total_steps are 182274\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.9     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3764     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6229     |\n",
      "|    total_timesteps  | 182274   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.7     |\n",
      "|    n_updates        | 33068    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 3, 1, 3, 3, 2, 1, 0, 2, 2, 3, 2, 3, 1, 3, 1, 3, 3, 0, 0, 2, 2, 2, 3, 3, 2, 3, 3, 3, 1, 0, 2, 3, 3, 2, 3, 0, 0, 2, 1, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 47 and the episode is 3765 and the total_steps are 182321\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 1, 2, 3, 2, 1, 0, 0, 3, 3, 3, 3, 0, 3, 2, 0, 2, 0, 3, 3, 1, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 3766 and the total_steps are 182349\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 2, 1, 1, 2, 2, 3, 2, 2, 0, 0, 3, 2, 1, 0, 2, 0, 0, 1, 1, 3, 1, 1, 2, 2, 2, 3, 1, 3, 2, 1, 2, 1, 3, 0, 3, 0, 0, 3, 1, 3, 3, 1, 2, 3, 0, 3, 0, 1, 1, 1, 0, 0, 3, 1, 2, 1, 0, 1, 1, 2, 0, 2, 3, 3, 3, 1, 0, 2, 1, 3, 1, 0, 1, 1, 3, 2, 3, 0, 0, 2, 0, 3, 1, 3, 1, 1, 0, 2, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1068. And steps were 96 and the episode is 3767 and the total_steps are 182445\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 0, 3, 1, 2, 1, 3, 2, 0, 1, 2, 0, 3, 2, 3, 0, 3, 0, 0, 3, 2, 3, 1, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 3768 and the total_steps are 182475\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3768     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6237     |\n",
      "|    total_timesteps  | 182475   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.78     |\n",
      "|    n_updates        | 33118    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 3, 1, 1, 1, 3, 2, 0, 3, 1, 0, 2, 2, 2, 3, 0, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 23 and the episode is 3769 and the total_steps are 182498\n",
      "Done condition: collision\n",
      "[2, 0, 0, 2, 0, 3, 1, 1, 3, 2, 3, 0, 1, 0, 2, 1, 3, 0, 3, 0, 1, 1, 1, 1, 1, 0, 3, 3, 0, 1, 2, 2, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 36 and the episode is 3770 and the total_steps are 182534\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 2, 2, 2, 1, 2, 0, 0, 0, 3, 1, 1, 0, 0, 2, 1, 2, 1, 0, 0, 1, 1, 0, 2, 0, 1, 1, 0, 3, 1, 2, 2, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 39 and the episode is 3771 and the total_steps are 182573\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 2, 1, 3, 0, 1, 3, 0, 3, 1, 3, 3, 2, 2, 3, 2, 0, 2, 1, 3, 2, 2, 1, 0, 1, 1, 1, 2, 3, 1, 1, 3, 2, 3, 1, 1, 0, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 44 and the episode is 3772 and the total_steps are 182617\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.7     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3772     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6243     |\n",
      "|    total_timesteps  | 182617   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.31     |\n",
      "|    n_updates        | 33154    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 2, 3, 0, 0, 1, 0, 0, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 1, 1, 3, 2, 3, 3, 3, 1, 2, 0, 2, 3, 0, 1, 3, 1, 0, 0, 0, 2, 1, 0, 3, 3, 3, 1, 0, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 52 and the episode is 3773 and the total_steps are 182669\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 2, 0, 0, 3, 0, 3, 0, 1, 1, 1, 0, 2, 3, 1, 1, 0, 2, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 3774 and the total_steps are 182694\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 0, 1, 1, 3, 3, 3, 2, 2, 0, 1, 3, 0, 1, 3, 1, 1, 2, 1, 3, 0, 1, 3, 3, 2, 1, 3, 0, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 35 and the episode is 3775 and the total_steps are 182729\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 3, 1, 0, 1, 0, 0, 3, 3, 2, 2, 0, 3, 0, 1, 3, 0, 1, 1, 1, 3, 0, 1, 3, 1, 3, 3, 2, 2, 2, 1, 1, 2, 3, 3, 1, 2, 2, 3, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 52 and the episode is 3776 and the total_steps are 182781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3776     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6250     |\n",
      "|    total_timesteps  | 182781   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 33195    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 0, 0, 2, 1, 0, 1, 2, 3, 3, 1, 3, 1, 1, 0, 1, 1, 2, 1, 2, 3, 0, 3, 1, 3, 3, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3777 and the total_steps are 182813\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 2, 0, 2, 2, 1, 2, 0, 0, 1, 3, 0, 1, 0, 3, 3, 2, 3, 3, 2, 1, 2, 2, 0, 0, 0, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 33 and the episode is 3778 and the total_steps are 182846\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 0, 1, 0, 2, 0, 3, 1, 2, 3, 1, 3, 3, 1, 3, 2, 1, 2, 3, 3, 1, 2, 0, 0, 0, 3, 1, 3, 1, 1, 2, 1, 3, 2, 1, 3, 2, 3, 2, 2, 3, 0, 2, 0, 1, 0, 0, 3, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -953. And steps were 55 and the episode is 3779 and the total_steps are 182901\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 1, 1, 1, 1, 2, 3, 0, 2, 2, 2, 0, 3, 3, 3, 2, 3, 2, 0, 1, 3, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3780 and the total_steps are 182929\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3780     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6256     |\n",
      "|    total_timesteps  | 182929   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.22     |\n",
      "|    n_updates        | 33232    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 2, 1, 0, 3, 2, 1, 2, 2, 0, 2, 1, 0, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 20 and the episode is 3781 and the total_steps are 182949\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 1, 3, 1, 2, 0, 3, 3, 2, 3, 3, 2, 1, 3, 3, 0, 3, 0, 2, 1, 3, 1, 1, 1, 1, 2, 0, 3, 1, 0, 2, 2, 2, 0, 3, 1, 3, 2, 1, 3, 2, 0, 2, 1, 2, 1, 2, 0, 1, 3, 3, 1, 1, 3, 1, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 62 and the episode is 3782 and the total_steps are 183011\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 3, 0, 3, 3, 2, 2, 2, 1, 0, 0, 3, 0, 1, 1, 2, 0, 1, 1, 2, 0, 1, 1, 3, 2, 3, 0, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 34 and the episode is 3783 and the total_steps are 183045\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 1, 1, 2, 0, 1, 2, 1, 0, 3, 0, 3, 2, 3, 3, 3, 3, 0, 1, 0, 3, 3, 1, 1, 3, 2, 0, 3, 2, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 36 and the episode is 3784 and the total_steps are 183081\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35       |\n",
      "|    ep_rew_mean      | -975     |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3784     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6263     |\n",
      "|    total_timesteps  | 183081   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.9     |\n",
      "|    n_updates        | 33270    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 1, 0, 2, 3, 3, 0, 1, 1, 3, 3, 0, 2, 1, 2, 0, 0, 2, 2, 3, 0, 2, 1, 2, 2, 0, 2, 2, 0, 2, 0, 0, 3, 0, 2, 0, 1, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 44 and the episode is 3785 and the total_steps are 183125\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 0, 3, 0, 2, 3, 1, 3, 2, 3, 2, 3, 1, 0, 1, 2, 2, 2, 3, 2, 2, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 3786 and the total_steps are 183161\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 3, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 3787 and the total_steps are 183177\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 3, 3, 2, 3, 2, 3, 0, 0, 1, 3, 3, 3, 3, 3, 2, 3, 3, 0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 3, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 48 and the episode is 3788 and the total_steps are 183225\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | -974     |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3788     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6269     |\n",
      "|    total_timesteps  | 183225   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63       |\n",
      "|    n_updates        | 33306    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 2, 1, 1, 1, 3, 2, 0, 3, 1, 1, 2, 1, 1, 3, 0, 0, 0, 2, 3, 1, 0, 2, 0, 1, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 3789 and the total_steps are 183257\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 0, 2, 1, 3, 1, 1, 3, 1, 0, 3, 1, 1, 1, 0, 2, 1, 3, 0, 3, 1, 0, 0, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 40 and the episode is 3790 and the total_steps are 183297\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 3, 0, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3, 0, 2, 1, 0, 1, 3, 0, 1, 1, 2, 2, 1, 1, 0, 1, 3, 1, 1, 3, 0, 3, 1, 3, 2, 1, 0, 3, 3, 3, 0, 1, 0, 2, 2, 2, 0, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 56 and the episode is 3791 and the total_steps are 183353\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 1, 1, 0, 2, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 0, 2, 1, 0, 1, 2, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 3792 and the total_steps are 183381\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | -974     |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3792     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6276     |\n",
      "|    total_timesteps  | 183381   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 33345    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 0, 0, 3, 2, 1, 1, 1, 1, 3, 0, 3, 2, 0, 2, 2, 0, 1, 2, 3, 1, 2, 2, 1, 0, 0, 0, 3, 1, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 36 and the episode is 3793 and the total_steps are 183417\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 3, 2, 0, 1, 1, 0, 3, 0, 3, 3, 1, 3, 3, 0, 2, 0, 3, 2, 1, 1, 0, 0, 3, 1, 2, 3, 3, 1, 2, 2, 1, 1, 1, 3, 0, 3, 2, 0, 2, 1, 3, 2, 1, 0, 3, 0, 3, 0, 1, 1, 3, 2, 2, 1, 0, 2, 0, 0, 0, 2, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 68 and the episode is 3794 and the total_steps are 183485\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 1, 1, 0, 1, 3, 2, 3, 0, 1, 1, 3, 0, 1, 1, 1, 1, 3, 1, 0, 1, 3, 0, 1, 3, 1, 1, 1, 3, 0, 2, 0, 2, 0, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 41 and the episode is 3795 and the total_steps are 183526\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 2, 2, 2, 3, 3, 0, 3, 1, 1, 2, 0, 3, 1, 0, 2, 2, 3, 3, 3, 1, 3, 2, 0, 3, 1, 0, 2, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 35 and the episode is 3796 and the total_steps are 183561\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -974     |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3796     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6283     |\n",
      "|    total_timesteps  | 183561   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 33390    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 3, 2, 2, 0, 1, 2, 0, 1, 1, 0, 0, 2, 3, 3, 1, 1, 2, 2, 3, 2, 0, 0, 3, 2, 0, 1, 3, 0, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 3797 and the total_steps are 183597\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 2, 2, 1, 1, 2, 2, 1, 3, 3, 0, 3, 0, 1, 3, 3, 2, 2, 2, 2, 3, 0, 3, 0, 2, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 32 and the episode is 3798 and the total_steps are 183629\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 0, 0, 0, 2, 0, 3, 0, 1, 2, 0, 1, 1, 1, 2, 3, 0, 3, 3, 1, 1, 3, 1, 0, 1, 2, 2, 3, 2, 1, 1, 1, 2, 3, 1, 2, 3, 2, 1, 3, 1, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 48 and the episode is 3799 and the total_steps are 183677\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 3, 1, 1, 0, 1, 2, 0, 2, 1, 2, 2, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1016. And steps were 17 and the episode is 3800 and the total_steps are 183694\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -955     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3800     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6289     |\n",
      "|    total_timesteps  | 183694   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 33423    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 1, 2, 3, 2, 3, 1, 3, 1, 2, 0, 3, 2, 2, 3, 3, 0, 2, 1, 1, 3, 0, 3, 0, 3, 3, 3, 2, 3, 1, 3, 3, 2, 3, 2, 2, 0, 3, 0, 3, 1, 0, 1, 3, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 0, 2, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 63 and the episode is 3801 and the total_steps are 183757\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 2, 0, 2, 3, 1, 2, 2, 3, 1, 0, 0, 3, 0, 1, 0, 3, 1, 3, 0, 3, 3, 3, 1, 0, 3, 0, 0, 1, 2, 2, 2, 2, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 40 and the episode is 3802 and the total_steps are 183797\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 3, 1, 1, 1, 3, 3, 2, 1, 1, 0, 1, 3, 1, 3, 1, 3, 3, 0, 3, 2, 2, 0, 1, 3, 1, 3, 3, 1, 3, 3, 2, 1, 2, 2, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 3803 and the total_steps are 183839\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 3, 1, 2, 2, 3, 2, 2, 3, 0, 1, 1, 1, 3, 0, 2, 1, 3, 1, 0, 0, 3, 1, 0, 0, 0, 1, 0, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was 988. And steps were 33 and the episode is 3804 and the total_steps are 183872\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | -935     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3804     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6296     |\n",
      "|    total_timesteps  | 183872   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 33467    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 0, 0, 2, 1, 2, 0, 1, 3, 0, 1, 2, 3, 0, 0, 1, 1, 0, 2, 3, 0, 1, 2, 3, 3, 3, 0, 3, 1, 3, 2, 2, 2, 0, 1, 0, 0, 1, 2, 0, 0, 3, 0, 2, 1, 2, 2, 2, 2, 3, 1, 3, 3, 0, 3, 2, 0, 2, 3, 3, 2, 0, 3, 2, 1, 2, 2, 2, 0, 2, 1, 3, 3, 2, 2, 2, 1, 2, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1059. And steps were 85 and the episode is 3805 and the total_steps are 183957\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 3, 3, 2, 1, 1, 3, 0, 1, 2, 3, 2, 3, 0, 1, 0, 1, 3, 2, 2, 1, 0, 2, 1, 2, 3, 3, 2, 0, 0, 2, 3, 1, 0, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 41 and the episode is 3806 and the total_steps are 183998\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 0, 1, 2, 0, 0, 1, 0, 1, 3, 2, 1, 0, 1, 3, 0, 0, 0, 1, 2, 3, 3, 3, 0, 1, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 3807 and the total_steps are 184030\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 0, 0, 1, 3, 0, 0, 0, 2, 3, 1, 3, 1, 2, 0, 1, 0, 3, 1, 1, 1, 0, 2, 1, 3, 3, 0, 1, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 35 and the episode is 3808 and the total_steps are 184065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -935     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3808     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6304     |\n",
      "|    total_timesteps  | 184065   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 33516    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 2, 0, 1, 0, 0, 1, 1, 0, 1, 2, 1, 0, 2, 2, 1, 2, 3, 2, 3, 3, 2, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3809 and the total_steps are 184094\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 0, 0, 3, 3, 1, 1, 3, 1, 3, 1, 0, 3, 0, 1, 3, 2, 1, 1, 2, 1, 2, 2, 1, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 31 and the episode is 3810 and the total_steps are 184125\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 3, 2, 1, 0, 2, 0, 2, 3, 3, 3, 1, 1, 0, 3, 2, 0, 2, 2, 3, 2, 0, 0, 3, 2, 3, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 3811 and the total_steps are 184158\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 2, 1, 3, 3, 0, 0, 2, 2, 3, 2, 1, 3, 1, 3, 3, 0, 1, 3, 2, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 27 and the episode is 3812 and the total_steps are 184185\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3812     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6309     |\n",
      "|    total_timesteps  | 184185   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 155      |\n",
      "|    n_updates        | 33546    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 1, 2, 0, 0, 3, 0, 3, 0, 2, 1, 1, 0, 2, 3, 1, 3, 2, 3, 2, 0, 2, 2, 1, 1, 2, 1, 3, 0, 2, 2, 3, 2, 2, 2, 2, 3, 0, 0, 2, 2, 2, 3, 2, 0, 3, 3, 2, 2, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 56 and the episode is 3813 and the total_steps are 184241\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 2, 0, 3, 1, 2, 0, 1, 3, 1, 1, 0, 1, 3, 1, 1, 2, 2, 2, 0, 3, 1, 0, 0, 3, 0, 2, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 34 and the episode is 3814 and the total_steps are 184275\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 0, 0, 1, 1, 3, 1, 2, 0, 2, 1, 3, 3, 3, 0, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 22 and the episode is 3815 and the total_steps are 184297\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 0, 0, 1, 0, 0, 2, 3, 2, 2, 3, 2, 2, 2, 1, 0, 0, 0, 0, 0, 2, 2, 1, 1, 0, 3, 1, 3, 1, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 36 and the episode is 3816 and the total_steps are 184333\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3816     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6315     |\n",
      "|    total_timesteps  | 184333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.7     |\n",
      "|    n_updates        | 33583    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 3, 3, 2, 1, 2, 1, 2, 1, 2, 3, 1, 0, 2, 1, 1, 2, 3, 0, 0, 2, 3, 3, 0, 3, 2, 3, 3, 1, 0, 2, 2, 2, 3, 3, 0, 1, 0, 0, 2, 1, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 3817 and the total_steps are 184381\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 2, 1, 0, 1, 3, 0, 3, 2, 3, 0, 0, 0, 2, 1, 3, 0, 0, 0, 3, 1, 3, 0, 2, 2, 2, 3, 1, 2, 1, 1, 1, 0, 3, 2, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 42 and the episode is 3818 and the total_steps are 184423\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 3, 2, 3, 2, 2, 3, 0, 1, 3, 1, 0, 0, 0, 3, 3, 1, 1, 1, 3, 2, 0, 1, 0, 1, 3, 3, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 34 and the episode is 3819 and the total_steps are 184457\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 0, 0, 2, 1, 2, 2, 3, 0, 3, 3, 1, 3, 3, 0, 1, 2, 2, 2, 3, 0, 3, 0, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 30 and the episode is 3820 and the total_steps are 184487\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.1     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3820     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6321     |\n",
      "|    total_timesteps  | 184487   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.59     |\n",
      "|    n_updates        | 33621    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 2, 2, 3, 2, 0, 1, 2, 3, 0, 1, 2, 1, 1, 2, 1, 0, 2, 0, 1, 0, 1, 2, 2, 3, 0, 0, 1, 1, 0, 1, 1, 3, 1, 3, 3, 2, 1, 2, 0, 1, 3, 2, 2, 0, 2, 0, 2, 1, 0, 3, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 58 and the episode is 3821 and the total_steps are 184545\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 3, 1, 2, 1, 2, 1, 2, 2, 3, 3, 3, 1, 3, 0, 1, 3, 3, 1, 2, 2, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 3822 and the total_steps are 184573\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 1, 1, 0, 1, 1, 1, 2, 0, 3, 0, 0, 0, 1, 2, 0, 3, 3, 0, 0, 2, 1, 2, 1, 2, 0, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 3823 and the total_steps are 184606\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 2, 0, 0, 1, 0, 3, 2, 0, 1, 3, 0, 0, 0, 3, 0, 0, 1, 2, 2, 3, 0, 2, 0, 1, 2, 2, 1, 0, 1, 2, 2, 0, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 40 and the episode is 3824 and the total_steps are 184646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3824     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6328     |\n",
      "|    total_timesteps  | 184646   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.11     |\n",
      "|    n_updates        | 33661    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 2, 3, 2, 3, 0, 1, 2, 0, 3, 1, 1, 3, 2, 1, 0, 1, 2, 0, 3, 2, 3, 2, 2, 3, 0, 0, 2, 1, 3, 0, 3, 2, 2, 1, 0, 1, 2, 0, 2, 1, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 3825 and the total_steps are 184694\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 3, 0, 0, 2, 2, 3, 2, 2, 1, 1, 3, 0, 1, 0, 1, 0, 2, 1, 3, 1, 2, 1, 3, 0, 1, 3, 2, 1, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 36 and the episode is 3826 and the total_steps are 184730\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 3, 3, 1, 3, 2, 3, 1, 0, 0, 2, 3, 0, 0, 0, 0, 2, 2, 1, 3, 1, 1, 1, 0, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 31 and the episode is 3827 and the total_steps are 184761\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 0, 1, 0, 0, 2, 3, 3, 3, 2, 1, 2, 2, 2, 1, 3, 2, 3, 0, 3, 2, 2, 0, 0, 3, 0, 1, 2, 1, 1, 0, 2, 0, 0, 3, 2, 3, 0, 0, 2, 3, 1, 3, 2, 2, 3, 3, 1, 2, 3, 3, 1, 0, 2, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 61 and the episode is 3828 and the total_steps are 184822\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3828     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6335     |\n",
      "|    total_timesteps  | 184822   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.4     |\n",
      "|    n_updates        | 33705    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 3, 1, 0, 3, 2, 2, 1, 1, 0, 3, 3, 2, 0, 2, 1, 0, 2, 3, 2, 0, 2, 2, 3, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 31 and the episode is 3829 and the total_steps are 184853\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 0, 1, 1, 0, 1, 2, 3, 3, 1, 2, 2, 2, 2, 0, 0, 0, 0, 2, 1, 1, 1, 0, 1, 2, 2, 2, 0, 2, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 36 and the episode is 3830 and the total_steps are 184889\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 3, 2, 2, 0, 1, 0, 1, 3, 0, 0, 1, 2, 2, 2, 3, 1, 1, 0, 1, 3, 1, 3, 1, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 31 and the episode is 3831 and the total_steps are 184920\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 2, 0, 1, 2, 2, 1, 2, 0, 3, 3, 0, 2, 0, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 21 and the episode is 3832 and the total_steps are 184941\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3832     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6340     |\n",
      "|    total_timesteps  | 184941   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 33735    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 3, 0, 3, 2, 3, 3, 2, 2, 3, 3, 0, 0, 1, 2, 3, 3, 0, 1, 2, 3, 0, 3, 1, 3, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was 1029. And steps were 30 and the episode is 3833 and the total_steps are 184971\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 0, 0, 1, 1, 2, 0, 3, 3, 2, 0, 2, 0, 0, 0, 1, 0, 3, 1, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 26 and the episode is 3834 and the total_steps are 184997\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 1, 2, 1, 0, 1, 0, 1, 2, 0, 3, 1, 2, 3, 1, 2, 1, 0, 1, 0, 2, 3, 0, 1, 3, 3, 0, 3, 2, 0, 0, 3, 2, 2, 3, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 42 and the episode is 3835 and the total_steps are 185039\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 0, 1, 3, 3, 0, 2, 2, 3, 1, 2, 3, 3, 0, 1, 0, 0, 0, 2, 1, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 27 and the episode is 3836 and the total_steps are 185066\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3836     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6346     |\n",
      "|    total_timesteps  | 185066   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.94     |\n",
      "|    n_updates        | 33766    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 2, 3, 3, 2, 1, 2, 3, 1, 0, 0, 2, 3, 1, 1, 1, 3, 2, 0, 0, 1, 3, 2, 0, 0, 2, 0, 0, 3, 0, 3, 2, 1, 2, 2, 2, 0, 2, 2, 3, 0, 0, 1, 1, 1, 0, 2, 2, 1, 0, 1, 3, 2, 0, 0, 1, 3, 0, 1, 3, 0, 3, 2, 0, 0, 2, 0, 0, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -951. And steps were 75 and the episode is 3837 and the total_steps are 185141\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 2, 3, 1, 0, 3, 0, 2, 2, 0, 0, 3, 1, 3, 3, 2, 0, 1, 3, 1, 0, 3, 1, 1, 0, 0, 3, 1, 3, 2, 2, 0, 3, 3, 3, 3, 0, 1, 1, 0, 2, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 48 and the episode is 3838 and the total_steps are 185189\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 3, 3, 1, 2, 0, 0, 3, 0, 2, 1, 0, 2, 0, 2, 2, 0, 2, 1, 1, 3, 3, 2, 0, 0, 0, 1, 3, 2, 0, 0, 1, 1, 1, 2, 1, 1, 0, 2, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 46 and the episode is 3839 and the total_steps are 185235\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 1, 1, 1, 1, 2, 0, 0, 2, 2, 3, 2, 2, 0, 3, 3, 2, 2, 0, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 3840 and the total_steps are 185261\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3840     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6354     |\n",
      "|    total_timesteps  | 185261   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.14     |\n",
      "|    n_updates        | 33815    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 2, 2, 1, 3, 0, 3, 1, 2, 0, 1, 3, 3, 2, 0, 2, 1, 3, 1, 0, 0, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 3841 and the total_steps are 185289\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 1, 3, 1, 1, 3, 3, 0, 0, 1, 3, 0, 0, 1, 0, 3, 2, 0, 3, 0, 2, 1, 0, 0, 0, 3, 1, 0, 3, 3, 0, 2, 0, 1, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 41 and the episode is 3842 and the total_steps are 185330\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 2, 2, 3, 3, 3, 3, 3, 0, 2, 2, 3, 3, 0, 2, 3, 3, 1, 2, 3, 2, 1, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 29 and the episode is 3843 and the total_steps are 185359\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 3, 2, 3, 3, 3, 2, 0, 2, 0, 3, 0, 1, 0, 2, 2, 1, 3, 1, 1, 0, 0, 3, 0, 1, 0, 0, 1, 3, 1, 1, 1, 2, 2, 3, 1, 3, 1, 2, 3, 0, 0, 2, 2, 3, 2, 1, 1, 2, 1, 2, 3, 1, 2, 1, 3, 0, 0, 2, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 66 and the episode is 3844 and the total_steps are 185425\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3844     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6362     |\n",
      "|    total_timesteps  | 185425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 30.9     |\n",
      "|    n_updates        | 33856    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 1, 2, 3, 1, 2, 2, 2, 0, 2, 0, 3, 0, 0, 1, 1, 0, 1, 3, 1, 2, 0, 2, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 30 and the episode is 3845 and the total_steps are 185455\n",
      "Done condition: collision\n",
      "[3, 0, 0, 1, 1, 2, 1, 2, 2, 0, 2, 0, 1, 0, 0, 1, 0, 3, 3, 3, 2, 3, 2, 2, 0, 2, 1, 0, 1, 1, 1, 2, 0, 1, 2, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 39 and the episode is 3846 and the total_steps are 185494\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 2, 3, 1, 1, 0, 1, 3, 2, 0, 2, 2, 1, 3, 0, 3, 0, 1, 1, 2, 1, 0, 3, 3, 1, 0, 0, 1, 2, 0, 1, 2, 3, 2, 2, 2, 2, 0, 1, 0, 3, 3, 3, 3, 2, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 57 and the episode is 3847 and the total_steps are 185551\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 3, 3, 1, 3, 2, 0, 2, 1, 1, 3, 3, 2, 3, 0, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 22 and the episode is 3848 and the total_steps are 185573\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3848     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6368     |\n",
      "|    total_timesteps  | 185573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.03     |\n",
      "|    n_updates        | 33893    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 1, 0, 2, 2, 3, 2, 0, 1, 3, 0, 3, 3, 1, 1, 0, 3, 1, 3, 0, 3, 3, 1, 3, 0, 0, 3, 3, 0, 1, 0, 3, 0, 2, 2, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 42 and the episode is 3849 and the total_steps are 185615\n",
      "Done condition: collision\n",
      "[0, 0, 1, 2, 3, 2, 0, 1, 0, 1, 1, 2, 3, 2, 3, 1, 3, 3, 2, 3, 1, 1, 2, 2, 0, 1, 2, 1, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 32 and the episode is 3850 and the total_steps are 185647\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 3, 1, 1, 0, 0, 3, 1, 3, 0, 2, 0, 3, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 3851 and the total_steps are 185673\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 0, 1, 0, 3, 2, 1, 2, 0, 1, 2, 3, 1, 3, 1, 2, 0, 3, 2, 3, 2, 0, 0, 3, 2, 1, 0, 3, 1, 2, 2, 2, 0, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 40 and the episode is 3852 and the total_steps are 185713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3852     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6374     |\n",
      "|    total_timesteps  | 185713   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.82     |\n",
      "|    n_updates        | 33928    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 0, 3, 1, 0, 3, 1, 3, 0, 2, 1, 2, 3, 1, 2, 1, 1, 3, 0, 1, 3, 1, 0, 1, 2, 0, 0, 2, 2, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 36 and the episode is 3853 and the total_steps are 185749\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 2, 2, 3, 2, 1, 0, 3, 1, 0, 2, 3, 2, 0, 1, 1, 1, 3, 2, 1, 1, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3854 and the total_steps are 185777\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 0, 3, 0, 2, 1, 1, 2, 3, 0, 3, 0, 0, 1, 3, 1, 2, 1, 0, 3, 3, 3, 1, 3, 0, 3, 2, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 34 and the episode is 3855 and the total_steps are 185811\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 2, 0, 0, 2, 2, 2, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 14 and the episode is 3856 and the total_steps are 185825\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3856     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6379     |\n",
      "|    total_timesteps  | 185825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.6     |\n",
      "|    n_updates        | 33956    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 2, 2, 3, 0, 3, 1, 3, 2, 1, 2, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 18 and the episode is 3857 and the total_steps are 185843\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 1, 0, 2, 1, 0, 0, 2, 3, 3, 2, 0, 1, 3, 3, 1, 0, 0, 0, 1, 2, 3, 0, 3, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 3, 2, 0, 1, 2, 2, 2, 3, 1, 2, 1, 2, 0, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1052. And steps were 54 and the episode is 3858 and the total_steps are 185897\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 2, 3, 1, 3, 3, 3, 0, 1, 0, 2, 2, 2, 3, 0, 0, 3, 1, 0, 3, 3, 2, 2, 3, 0, 0, 0, 3, 0, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 36 and the episode is 3859 and the total_steps are 185933\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 1, 0, 1, 1, 2, 3, 1, 2, 3, 3, 2, 2, 0, 1, 2, 0, 3, 2, 2, 2, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 3860 and the total_steps are 185961\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3860     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6384     |\n",
      "|    total_timesteps  | 185961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.76     |\n",
      "|    n_updates        | 33990    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 3, 0, 3, 3, 2, 0, 0, 0, 0, 1, 1, 3, 3, 0, 2, 3, 2, 0, 0, 0, 3, 3, 1, 2, 0, 2, 1, 0, 1, 3, 1, 2, 2, 3, 0, 2, 1, 1, 1, 1, 1, 2, 0, 1, 2, 3, 3, 2, 0, 2, 0, 3, 2, 1, 0, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1043. And steps were 63 and the episode is 3861 and the total_steps are 186024\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 3, 1, 2, 2, 1, 3, 3, 3, 1, 2, 3, 2, 2, 0, 3, 0, 2, 3, 0, 3, 0, 1, 0, 2, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 3862 and the total_steps are 186056\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 3, 2, 2, 1, 0, 3, 3, 0, 3, 3, 1, 0, 2, 0, 3, 0, 3, 2, 2, 2, 1, 0, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 30 and the episode is 3863 and the total_steps are 186086\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 2, 2, 2, 2, 1, 3, 1, 3, 3, 3, 3, 2, 2, 1, 3, 1, 2, 0, 0, 2, 2, 1, 3, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 31 and the episode is 3864 and the total_steps are 186117\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.4     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3864     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6391     |\n",
      "|    total_timesteps  | 186117   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 34029    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 2, 1, 1, 1, 3, 3, 2, 3, 0, 0, 1, 0, 1, 2, 2, 0, 2, 0, 1, 3, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3865 and the total_steps are 186145\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 1, 2, 2, 1, 3, 3, 3, 0, 1, 2, 1, 2, 2, 1, 2, 2, 0, 3, 0, 2, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 3866 and the total_steps are 186173\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 0, 2, 2, 3, 0, 1, 2, 0, 2, 0, 0, 0, 2, 1, 3, 3, 2, 3, 1, 0, 2, 1, 1, 2, 3, 1, 2, 2, 0, 3, 2, 3, 0, 3, 3, 1, 3, 3, 0, 0, 0, 1, 1, 3, 0, 3, 3, 1, 2, 0, 2, 3, 1, 3, 1, 1, 3, 0, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 66 and the episode is 3867 and the total_steps are 186239\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 0, 3, 0, 0, 1, 1, 0, 2, 2, 2, 0, 0, 2, 1, 2, 2, 0, 1, 2, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 3868 and the total_steps are 186265\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3868     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6397     |\n",
      "|    total_timesteps  | 186265   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 95.1     |\n",
      "|    n_updates        | 34066    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 3, 3, 1, 0, 0, 1, 3, 0, 2, 3, 1, 3, 1, 1, 2, 3, 1, 2, 0, 3, 2, 0, 3, 1, 1, 0, 3, 0, 2, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 37 and the episode is 3869 and the total_steps are 186302\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 3, 1, 0, 0, 0, 3, 1, 2, 1, 3, 1, 2, 3, 1, 1, 1, 3, 2, 3, 3, 2, 0, 2, 3, 3, 0, 0, 3, 0, 1, 3, 0, 2, 2, 2, 3, 1, 3, 1, 2, 1, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 59 and the episode is 3870 and the total_steps are 186361\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 2, 3, 1, 3, 2, 3, 2, 1, 3, 0, 3, 2, 2, 2, 0, 0, 3, 1, 0, 1, 2, 1, 1, 2, 3, 0, 1, 2, 0, 2, 0, 3, 0, 3, 2, 3, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 44 and the episode is 3871 and the total_steps are 186405\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 3, 2, 0, 0, 1, 3, 2, 3, 1, 3, 3, 0, 3, 3, 3, 1, 2, 1, 2, 0, 3, 2, 2, 2, 2, 1, 3, 2, 3, 3, 1, 1, 2, 2, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 42 and the episode is 3872 and the total_steps are 186447\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3872     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6405     |\n",
      "|    total_timesteps  | 186447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 34111    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 2, 1, 1, 0, 1, 2, 1, 3, 1, 1, 2, 1, 0, 0, 1, 1, 0, 1, 2, 3, 1, 0, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 30 and the episode is 3873 and the total_steps are 186477\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 2, 3, 2, 0, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 3874 and the total_steps are 186497\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 2, 1, 0, 1, 1, 3, 3, 2, 3, 3, 2, 0, 3, 3, 1, 2, 1, 0, 0, 3, 0, 2, 1, 3, 3, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 33 and the episode is 3875 and the total_steps are 186530\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 0, 1, 2, 0, 3, 1, 1, 0, 0, 0, 2, 2, 1, 0, 3, 3, 0, 0, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 3876 and the total_steps are 186557\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3876     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6410     |\n",
      "|    total_timesteps  | 186557   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.4      |\n",
      "|    n_updates        | 34139    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 2, 2, 0, 1, 2, 3, 3, 0, 0, 2, 3, 0, 3, 3, 0, 1, 2, 3, 2, 2, 0, 0, 3, 1, 1, 0, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 3877 and the total_steps are 186590\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 2, 1, 3, 2, 0, 3, 0, 0, 3, 3, 3, 2, 0, 3, 3, 2, 2, 0, 1, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 27 and the episode is 3878 and the total_steps are 186617\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 0, 3, 3, 3, 2, 2, 2, 0, 3, 2, 1, 1, 0, 1, 0, 3, 0, 1, 2, 1, 0, 3, 0, 1, 0, 3, 1, 3, 0, 2, 2, 2, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 40 and the episode is 3879 and the total_steps are 186657\n",
      "Done condition: collision\n",
      "[0, 0, 1, 2, 3, 1, 3, 1, 1, 2, 2, 3, 0, 1, 2, 0, 3, 0, 2, 3, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 3880 and the total_steps are 186681\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3880     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6415     |\n",
      "|    total_timesteps  | 186681   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.66     |\n",
      "|    n_updates        | 34170    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 0, 1, 3, 2, 3, 2, 2, 1, 2, 0, 2, 0, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 20 and the episode is 3881 and the total_steps are 186701\n",
      "Done condition: collision\n",
      "[3, 3, 3, 3, 3, 2, 0, 3, 3, 3, 3, 1, 2, 3, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 2, 0, 1, 0, 2, 1, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 34 and the episode is 3882 and the total_steps are 186735\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 2, 1, 3, 1, 1, 3, 3, 1, 0, 0, 0, 2, 0, 2, 2, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 3, 1, 1, 0, 2, 2, 0, 2, 0, 0, 1, 1, 1, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1048. And steps were 50 and the episode is 3883 and the total_steps are 186785\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 2, 1, 2, 2, 3, 2, 1, 1, 0, 1, 1, 2, 0, 0, 0, 0, 2, 1, 3, 2, 2, 2, 2, 0, 1, 2, 3, 1, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 36 and the episode is 3884 and the total_steps are 186821\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3884     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6421     |\n",
      "|    total_timesteps  | 186821   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 34205    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 3, 1, 3, 1, 0, 3, 0, 0, 3, 0, 2, 0, 1, 0, 3, 2, 3, 0, 2, 3, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3885 and the total_steps are 186849\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 2, 1, 0, 1, 2, 2, 3, 2, 0, 2, 3, 1, 2, 0, 2, 0, 2, 2, 2, 2, 0, 1, 2, 1, 1, 0, 3, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 34 and the episode is 3886 and the total_steps are 186883\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 0, 3, 0, 0, 2, 0, 1, 0, 1, 0, 1, 0, 1, 2, 0, 1, 3, 2, 0, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 27 and the episode is 3887 and the total_steps are 186910\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 0, 2, 2, 1, 1, 3, 1, 0, 1, 0, 1, 3, 1, 0, 0, 3, 0, 2, 2, 3, 0, 1, 3, 1, 2, 1, 3, 0, 0, 0, 1, 1, 1, 2, 2, 1, 2, 3, 1, 2, 2, 2, 1, 3, 3, 0, 3, 1, 0, 1, 1, 3, 3, 2, 0, 1, 3, 3, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -950. And steps were 66 and the episode is 3888 and the total_steps are 186976\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3888     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6427     |\n",
      "|    total_timesteps  | 186976   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.7      |\n",
      "|    n_updates        | 34243    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 1, 0, 3, 3, 1, 0, 1, 0, 0, 1, 1, 0, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 2, 2, 0, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 33 and the episode is 3889 and the total_steps are 187009\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 2, 2, 2, 2, 3, 3, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 14 and the episode is 3890 and the total_steps are 187023\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 2, 2, 2, 0, 3, 1, 0, 1, 0, 3, 1, 3, 0, 1, 3, 0, 3, 3, 2, 3, 2, 3, 2, 0, 1, 3, 3, 1, 1, 3, 2, 2, 0, 0, 1, 0, 1, 1, 0, 3, 2, 2, 3, 0, 1, 2, 0, 2, 1, 2, 0, 3, 0, 2, 2, 2, 2, 1, 3, 3, 2, 1, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -956. And steps were 70 and the episode is 3891 and the total_steps are 187093\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 0, 0, 0, 2, 2, 3, 3, 0, 3, 3, 2, 2, 1, 0, 0, 2, 1, 2, 3, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 3, 3, 3, 1, 0, 1, 3, 2, 2, 3, 2, 0, 1, 3, 0, 2, 2, 3, 0, 0, 3, 3, 3, 2, 0, 1, 3, 2, 2, 1, 0, 3, 0, 0, 2, 0, 2, 3, 0, 3, 0, 2, 0, 1, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 84 and the episode is 3892 and the total_steps are 187177\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3892     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6436     |\n",
      "|    total_timesteps  | 187177   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.3     |\n",
      "|    n_updates        | 34294    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 1, 0, 3, 2, 3, 0, 0, 0, 2, 2, 0, 3, 2, 0, 0, 2, 2, 1, 3, 2, 3, 3, 1, 0, 3, 2, 3, 3, 0, 0, 2, 0, 0, 3, 2, 0, 2, 1, 3, 2, 0, 0, 0, 2, 0, 0, 0, 1, 2, 1, 3, 1, 1, 2, 3, 2, 1, 1, 3, 3, 3, 3, 0, 3, 2, 0, 0, 2, 3, 2, 2, 2, 0, 2, 0, 2, 3, 3, 0, 1, 3, 2, 1, 1, 1, 1, 2, 1, 0, 2, 2, 2, 1, 2, 2, 3, 1, 3, 1, 2, 0, 1, 0, 3, 2, 1, 0, 2, 2, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1111. And steps were 117 and the episode is 3893 and the total_steps are 187294\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 3, 1, 2, 2, 2, 3, 3, 3, 2, 1, 2, 0, 1, 0, 3, 1, 3, 1, 1, 3, 1, 0, 0, 1, 2, 3, 3, 2, 0, 0, 1, 1, 3, 0, 1, 0, 2, 3, 2, 3, 3, 3, 2, 1, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 52 and the episode is 3894 and the total_steps are 187346\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 2, 1, 1, 3, 1, 0, 0, 1, 3, 0, 3, 1, 2, 1, 1, 0, 0, 0, 2, 1, 3, 1, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 3895 and the total_steps are 187376\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 0, 1, 3, 0, 1, 3, 2, 0, 0, 3, 2, 1, 2, 3, 0, 3, 2, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 25 and the episode is 3896 and the total_steps are 187401\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.4     |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3896     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6445     |\n",
      "|    total_timesteps  | 187401   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 34350    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 0, 1, 2, 3, 0, 2, 0, 1, 3, 1, 3, 2, 3, 3, 0, 2, 0, 2, 3, 1, 3, 0, 1, 0, 1, 3, 3, 3, 0, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 37 and the episode is 3897 and the total_steps are 187438\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 0, 2, 1, 2, 1, 3, 1, 3, 3, 3, 3, 1, 1, 0, 1, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1, 0, 0, 0, 3, 0, 1, 2, 0, 1, 0, 0, 3, 2, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 2, 0, 3, 2, 2, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 68 and the episode is 3898 and the total_steps are 187506\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 0, 3, 1, 2, 0, 2, 1, 0, 2, 0, 0, 1, 0, 1, 1, 1, 2, 2, 2, 1, 0, 3, 2, 1, 0, 2, 1, 0, 3, 2, 0, 2, 0, 3, 0, 0, 1, 2, 2, 3, 3, 0, 2, 2, 0, 3, 0, 2, 0, 2, 0, 0, 2, 0, 3, 3, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 64 and the episode is 3899 and the total_steps are 187570\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 3, 0, 3, 3, 1, 3, 3, 1, 3, 0, 0, 3, 0, 3, 0, 2, 3, 1, 3, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 3900 and the total_steps are 187597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -964     |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3900     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6453     |\n",
      "|    total_timesteps  | 187597   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.07     |\n",
      "|    n_updates        | 34399    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 1, 1, 3, 1, 2, 2, 1, 3, 2, 2, 1, 3, 1, 1, 0, 1, 3, 2, 2, 3, 1, 1, 0, 2, 2, 3, 3, 1, 1, 1, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 38 and the episode is 3901 and the total_steps are 187635\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 2, 2, 2, 3, 1, 2, 2, 3, 3, 1, 2, 3, 0, 3, 1, 1, 1, 1, 2, 3, 1, 2, 2, 2, 1, 3, 3, 2, 1, 3, 1, 3, 3, 3, 2, 3, 2, 3, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 46 and the episode is 3902 and the total_steps are 187681\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 2, 2, 1, 0, 1, 0, 3, 3, 1, 3, 1, 0, 1, 3, 3, 1, 3, 2, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 3903 and the total_steps are 187705\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 1, 3, 3, 3, 3, 0, 1, 0, 3, 1, 0, 0, 1, 3, 0, 1, 3, 1, 3, 3, 3, 0, 2, 0, 3, 2, 3, 1, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 3904 and the total_steps are 187741\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -963     |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3904     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6459     |\n",
      "|    total_timesteps  | 187741   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 153      |\n",
      "|    n_updates        | 34435    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 3, 1, 2, 1, 3, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 2, 1, 1, 0, 0, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 3905 and the total_steps are 187769\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 0, 2, 2, 3, 1, 1, 3, 1, 0, 3, 1, 2, 3, 0, 1, 1, 0, 0, 0, 3, 2, 2, 2, 2, 3, 0, 1, 0, 2, 0, 2, 1, 3, 0, 1, 2, 2, 2, 3, 1, 1, 1, 3, 1, 2, 2, 1, 3, 2, 3, 3, 1, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 60 and the episode is 3906 and the total_steps are 187829\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 3, 0, 3, 1, 3, 2, 1, 1, 3, 1, 0, 0, 1, 0, 2, 3, 2, 2, 2, 3, 2, 3, 2, 1, 1, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 33 and the episode is 3907 and the total_steps are 187862\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 1, 3, 0, 2, 1, 0, 0, 1, 1, 1, 0, 0, 3, 3, 2, 2, 1, 1, 0, 0, 2, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 29 and the episode is 3908 and the total_steps are 187891\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -963     |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3908     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6465     |\n",
      "|    total_timesteps  | 187891   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.6      |\n",
      "|    n_updates        | 34472    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 2, 0, 1, 0, 1, 1, 1, 1, 3, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 3, 1, 3, 2, 1, 3, 2, 2, 3, 1, 2, 0, 3, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 42 and the episode is 3909 and the total_steps are 187933\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 2, 0, 0, 0, 0, 3, 3, 2, 1, 1, 0, 2, 1, 2, 3, 3, 2, 2, 3, 2, 3, 1, 1, 3, 0, 0, 0, 1, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 3910 and the total_steps are 187969\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 2, 3, 1, 1, 3, 2, 2, 1, 0, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 25 and the episode is 3911 and the total_steps are 187994\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 1, 3, 1, 0, 3, 0, 0, 1, 2, 1, 0, 2, 3, 2, 1, 2, 3, 0, 2, 3, 3, 0, 0, 3, 3, 2, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 34 and the episode is 3912 and the total_steps are 188028\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.4     |\n",
      "|    ep_rew_mean      | -963     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3912     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6470     |\n",
      "|    total_timesteps  | 188028   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.99     |\n",
      "|    n_updates        | 34506    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 0, 2, 1, 3, 1, 2, 3, 2, 2, 3, 3, 2, 3, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 21 and the episode is 3913 and the total_steps are 188049\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 0, 2, 1, 0, 0, 3, 3, 1, 3, 3, 2, 2, 0, 1, 0, 1, 2, 0, 0, 0, 3, 3, 1, 3, 2, 2, 3, 1, 3, 3, 3, 3, 2, 1, 3, 3, 2, 0, 1, 2, 1, 0, 1, 2, 0, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 53 and the episode is 3914 and the total_steps are 188102\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 2, 1, 1, 1, 3, 2, 2, 0, 2, 1, 2, 3, 3, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 21 and the episode is 3915 and the total_steps are 188123\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 3, 1, 3, 3, 3, 1, 3, 1, 0, 2, 2, 1, 3, 3, 0, 0, 2, 1, 0, 2, 2, 2, 2, 0, 1, 3, 3, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 35 and the episode is 3916 and the total_steps are 188158\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -963     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3916     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6476     |\n",
      "|    total_timesteps  | 188158   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.33     |\n",
      "|    n_updates        | 34539    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 3, 3, 3, 2, 3, 2, 0, 2, 2, 2, 0, 3, 0, 3, 0, 2, 1, 3, 2, 0, 0, 2, 2, 3, 2, 1, 1, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 35 and the episode is 3917 and the total_steps are 188193\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 1, 0, 1, 3, 1, 1, 1, 3, 0, 3, 1, 0, 0, 0, 3, 1, 3, 1, 1, 0, 2, 3, 2, 0, 3, 0, 3, 3, 1, 3, 0, 2, 2, 3, 2, 1, 1, 3, 2, 0, 3, 2, 2, 0, 3, 0, 1, 3, 0, 1, 2, 3, 1, 3, 2, 2, 0, 1, 1, 1, 0, 0, 3, 2, 3, 1, 0, 1, 1, 3, 1, 2, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 80 and the episode is 3918 and the total_steps are 188273\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 3, 2, 3, 1, 0, 0, 0, 0, 3, 2, 2, 1, 3, 1, 2, 1, 3, 0, 3, 0, 1, 1, 2, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 31 and the episode is 3919 and the total_steps are 188304\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 3, 3, 3, 0, 0, 0, 1, 3, 1, 1, 2, 3, 3, 0, 3, 0, 0, 1, 3, 3, 3, 2, 2, 2, 1, 0, 0, 2, 0, 3, 2, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 3, 0, 3, 0, 0, 3, 1, 1, 2, 1, 1, 2, 0, 0, 2, 2, 3, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -954. And steps were 66 and the episode is 3920 and the total_steps are 188370\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -962     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3920     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6485     |\n",
      "|    total_timesteps  | 188370   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.4     |\n",
      "|    n_updates        | 34592    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 2, 3, 3, 3, 2, 0, 3, 0, 2, 2, 1, 2, 3, 3, 2, 0, 3, 2, 1, 0, 3, 3, 1, 1, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3921 and the total_steps are 188402\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 1, 3, 3, 3, 1, 3, 0, 0, 1, 2, 1, 1, 3, 3, 2, 0, 3, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 25 and the episode is 3922 and the total_steps are 188427\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 1, 3, 1, 2, 3, 2, 1, 2, 2, 2, 3, 2, 0, 2, 1, 1, 3, 2, 1, 2, 2, 0, 0, 1, 3, 3, 0, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 43 and the episode is 3923 and the total_steps are 188470\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 1, 3, 1, 2, 0, 2, 0, 0, 2, 3, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 18 and the episode is 3924 and the total_steps are 188488\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.4     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3924     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6490     |\n",
      "|    total_timesteps  | 188488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 34621    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 0, 0, 2, 2, 0, 3, 0, 0, 0, 1, 3, 0, 1, 0, 0, 3, 0, 1, 1, 2, 3, 2, 1, 2, 3, 3, 2, 0, 0, 1, 2, 1, 1, 2, 0, 2, 2, 3, 0, 0, 0, 3, 2, 3, 2, 2, 0, 1, 3, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 57 and the episode is 3925 and the total_steps are 188545\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 3, 0, 1, 3, 0, 1, 0, 3, 2, 2, 2, 0, 3, 3, 0, 3, 0, 0, 2, 1, 1, 2, 1, 2, 1, 1, 3, 1, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 3926 and the total_steps are 188581\n",
      "Done condition: collision\n",
      "[1, 3, 2, 3, 0, 2, 2, 2, 2, 1, 3, 0, 2, 3, 3, 1, 3, 3, 2, 3, 2, 0, 1, 1, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3927 and the total_steps are 188609\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 3, 0, 2, 0, 0, 3, 3, 3, 3, 2, 0, 2, 1, 0, 2, 2, 0, 0, 3, 2, 0, 2, 1, 2, 3, 3, 1, 1, 0, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 37 and the episode is 3928 and the total_steps are 188646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3928     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6497     |\n",
      "|    total_timesteps  | 188646   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 34661    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 1, 3, 0, 0, 2, 3, 0, 3, 1, 2, 2, 0, 0, 2, 3, 0, 1, 1, 1, 2, 0, 0, 2, 0, 2, 3, 0, 3, 1, 0, 2, 2, 2, 2, 0, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 43 and the episode is 3929 and the total_steps are 188689\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 1, 0, 3, 2, 1, 0, 0, 1, 1, 1, 3, 0, 0, 3, 0, 1, 3, 2, 0, 1, 1, 3, 3, 0, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 3930 and the total_steps are 188721\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 0, 2, 1, 2, 2, 3, 1, 1, 3, 3, 2, 3, 3, 0, 0, 0, 1, 2, 3, 2, 1, 2, 2, 1, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 32 and the episode is 3931 and the total_steps are 188753\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 0, 0, 3, 0, 2, 2, 2, 3, 0, 2, 1, 3, 1, 0, 2, 1, 2, 0, 0, 2, 3, 3, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 31 and the episode is 3932 and the total_steps are 188784\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.4     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3932     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6502     |\n",
      "|    total_timesteps  | 188784   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.96     |\n",
      "|    n_updates        | 34695    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 2, 3, 1, 1, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 1, 3, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 25 and the episode is 3933 and the total_steps are 188809\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 3, 1, 3, 0, 1, 0, 1, 1, 0, 1, 3, 1, 0, 0, 2, 3, 3, 0, 3, 2, 0, 0, 0, 1, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 3934 and the total_steps are 188841\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 1, 0, 3, 1, 1, 1, 2, 0, 1, 2, 0, 3, 2, 3, 2, 2, 3, 0, 0, 2, 1, 3, 2, 2, 2, 1, 3, 2, 3, 2, 0, 0, 1, 2, 1, 0, 2, 1, 1, 0, 3, 1, 0, 3, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 3935 and the total_steps are 188893\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 0, 2, 3, 0, 1, 2, 0, 1, 3, 3, 2, 1, 3, 0, 3, 2, 3, 2, 3, 3, 0, 3, 3, 3, 1, 3, 3, 0, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 36 and the episode is 3936 and the total_steps are 188929\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -982     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3936     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6508     |\n",
      "|    total_timesteps  | 188929   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.7     |\n",
      "|    n_updates        | 34732    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 2, 1, 0, 0, 0, 0, 2, 1, 3, 0, 3, 1, 0, 1, 1, 0, 0, 0, 3, 2, 2, 0, 3, 3, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 3937 and the total_steps are 188961\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 2, 3, 2, 0, 1, 3, 3, 1, 1, 1, 3, 2, 2, 1, 0, 0, 3, 1, 1, 3, 2, 0, 3, 1, 2, 2, 2, 1, 3, 2, 0, 1, 2, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 41 and the episode is 3938 and the total_steps are 189002\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 1, 3, 3, 2, 2, 2, 2, 0, 1, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 17 and the episode is 3939 and the total_steps are 189019\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 3, 0, 2, 3, 1, 3, 3, 0, 1, 3, 1, 2, 3, 2, 1, 0, 0, 3, 2, 0, 2, 3, 0, 0, 3, 2, 0, 3, 3, 2, 0, 0, 2, 1, 0, 0, 1, 1, 1, 1, 1, 0, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 50 and the episode is 3940 and the total_steps are 189069\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.1     |\n",
      "|    ep_rew_mean      | -982     |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3940     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6514     |\n",
      "|    total_timesteps  | 189069   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.3     |\n",
      "|    n_updates        | 34767    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 2, 0, 0, 1, 1, 0, 2, 3, 0, 1, 1, 2, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 20 and the episode is 3941 and the total_steps are 189089\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 0, 1, 1, 1, 0, 3, 2, 3, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 16 and the episode is 3942 and the total_steps are 189105\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 3, 0, 1, 1, 3, 1, 0, 2, 3, 0, 3, 1, 3, 3, 2, 2, 3, 1, 0, 3, 3, 0, 3, 0, 0, 1, 2, 1, 2, 0, 0, 2, 3, 1, 2, 1, 0, 2, 2, 0, 1, 3, 0, 1, 3, 0, 3, 3, 1, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 57 and the episode is 3943 and the total_steps are 189162\n",
      "Done condition: collision\n",
      "[1, 2, 3, 0, 2, 2, 2, 1, 1, 2, 2, 3, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 3944 and the total_steps are 189178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -982     |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3944     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6518     |\n",
      "|    total_timesteps  | 189178   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.15     |\n",
      "|    n_updates        | 34794    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 0, 1, 2, 3, 3, 1, 0, 3, 1, 3, 3, 1, 1, 0, 1, 1, 2, 3, 3, 0, 2, 2, 0, 0, 1, 2, 1, 3, 2, 2, 0, 0, 2, 3, 0, 1, 2, 2, 3, 1, 0, 0, 2, 1, 3, 2, 1, 3, 2, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -945. And steps were 63 and the episode is 3945 and the total_steps are 189241\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 1, 3, 1, 0, 3, 0, 1, 3, 2, 2, 0, 1, 3, 2, 3, 2, 3, 3, 2, 2, 2, 1, 2, 3, 2, 1, 0, 2, 0, 1, 0, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 39 and the episode is 3946 and the total_steps are 189280\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 2, 3, 3, 3, 2, 0, 0, 3, 1, 0, 1, 1, 1, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 21 and the episode is 3947 and the total_steps are 189301\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 1, 0, 0, 2, 3, 1, 3, 2, 3, 0, 1, 3, 0, 2, 1, 2, 1, 3, 2, 0, 2, 2, 3, 3, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 32 and the episode is 3948 and the total_steps are 189333\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -981     |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3948     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6525     |\n",
      "|    total_timesteps  | 189333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.49     |\n",
      "|    n_updates        | 34833    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 0, 3, 3, 0, 1, 1, 0, 3, 0, 2, 3, 2, 2, 2, 3, 3, 3, 0, 0, 3, 1, 1, 1, 1, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 3949 and the total_steps are 189365\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 3, 0, 2, 2, 2, 2, 2, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 15 and the episode is 3950 and the total_steps are 189380\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 3, 0, 2, 0, 0, 2, 0, 2, 3, 1, 3, 0, 0, 3, 1, 3, 2, 3, 0, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 27 and the episode is 3951 and the total_steps are 189407\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 2, 1, 0, 1, 1, 3, 1, 1, 2, 3, 0, 3, 2, 2, 0, 1, 0, 0, 3, 1, 3, 0, 2, 3, 2, 3, 1, 3, 1, 0, 3, 1, 3, 3, 1, 0, 0, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 45 and the episode is 3952 and the total_steps are 189452\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -981     |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3952     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6530     |\n",
      "|    total_timesteps  | 189452   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.74     |\n",
      "|    n_updates        | 34862    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 3, 0, 0, 3, 3, 2, 1, 2, 0, 2, 3, 3, 2, 0, 3, 3, 2, 1, 3, 1, 3, 0, 2, 2, 2, 2, 0, 2, 0, 3, 3, 0, 1, 0, 3, 3, 0, 0, 2, 1, 3, 3, 3, 2, 3, 1, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 3, 2, 0, 0, 1, 0, 2, 3, 2, 0, 0, 3, 2, 1, 1, 2, 3, 0, 0, 3, 1, 3, 2, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -929. And steps were 101 and the episode is 3953 and the total_steps are 189553\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 0, 1, 1, 3, 3, 3, 1, 3, 1, 0, 0, 3, 0, 3, 2, 0, 2, 3, 0, 1, 1, 0, 1, 1, 2, 2, 1, 3, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 3954 and the total_steps are 189589\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 3, 1, 2, 0, 3, 2, 2, 0, 2, 2, 0, 3, 1, 1, 2, 3, 2, 0, 2, 3, 2, 3, 1, 0, 0, 2, 1, 3, 2, 3, 0, 0, 1, 0, 2, 2, 1, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 45 and the episode is 3955 and the total_steps are 189634\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 2, 0, 3, 1, 1, 2, 1, 2, 3, 0, 3, 1, 2, 0, 2, 3, 1, 3, 3, 1, 1, 2, 2, 0, 0, 3, 1, 1, 0, 0, 2, 2, 2, 3, 2, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 43 and the episode is 3956 and the total_steps are 189677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -980     |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3956     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6539     |\n",
      "|    total_timesteps  | 189677   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 34919    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 3, 1, 2, 1, 3, 0, 3, 2, 1, 3, 0, 3, 0, 3, 2, 3, 0, 0, 2, 3, 3, 1, 1, 2, 0, 2, 2, 3, 1, 2, 0, 0, 2, 3, 1, 1, 3, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 45 and the episode is 3957 and the total_steps are 189722\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 3, 3, 1, 2, 1, 3, 1, 2, 0, 3, 0, 0, 3, 0, 2, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 31 and the episode is 3958 and the total_steps are 189753\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 2, 3, 2, 0, 1, 0, 3, 1, 3, 2, 2, 2, 2, 1, 0, 3, 3, 3, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 1, 2, 2, 1, 3, 2, 1, 0, 1, 2, 2, 3, 2, 3, 1, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 51 and the episode is 3959 and the total_steps are 189804\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 0, 1, 0, 3, 2, 0, 1, 3, 3, 0, 0, 3, 0, 1, 0, 2, 0, 3, 1, 1, 0, 3, 1, 2, 0, 3, 2, 0, 3, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 37 and the episode is 3960 and the total_steps are 189841\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -979     |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3960     |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 6546     |\n",
      "|    total_timesteps  | 189841   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.03     |\n",
      "|    n_updates        | 34960    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 0, 3, 1, 1, 3, 2, 0, 2, 2, 2, 0, 3, 2, 2, 0, 1, 2, 0, 0, 3, 0, 3, 3, 0, 2, 0, 2, 1, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 36 and the episode is 3961 and the total_steps are 189877\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 0, 1, 2, 2, 3, 1, 1, 3, 3, 0, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 18 and the episode is 3962 and the total_steps are 189895\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 1, 2, 3, 3, 0, 2, 0, 1, 1, 2, 0, 3, 0, 2, 2, 3, 2, 0, 3, 1, 2, 0, 3, 1, 1, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 33 and the episode is 3963 and the total_steps are 189928\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 3, 0, 1, 0, 1, 0, 1, 3, 0, 3, 3, 1, 2, 1, 0, 2, 3, 0, 0, 0, 3, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 3964 and the total_steps are 189957\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.4     |\n",
      "|    ep_rew_mean      | -978     |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3964     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6550     |\n",
      "|    total_timesteps  | 189957   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.55     |\n",
      "|    n_updates        | 34989    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 1, 1, 1, 0, 3, 0, 3, 1, 1, 3, 3, 2, 0, 3, 2, 1, 3, 3, 3, 1, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 28 and the episode is 3965 and the total_steps are 189985\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 2, 1, 1, 0, 2, 1, 3, 0, 3, 2, 0, 1, 3, 0, 1, 3, 0, 3, 3, 3, 0, 2, 3, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 31 and the episode is 3966 and the total_steps are 190016\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 2, 3, 1, 1, 3, 2, 0, 2, 2, 1, 0, 2, 2, 2, 3, 0, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 24 and the episode is 3967 and the total_steps are 190040\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 2, 3, 2, 0, 1, 2, 3, 0, 3, 2, 0, 1, 0, 2, 2, 3, 0, 1, 0, 3, 2, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 29 and the episode is 3968 and the total_steps are 190069\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -978     |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3968     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6555     |\n",
      "|    total_timesteps  | 190069   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 35017    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 2, 2, 3, 1, 0, 1, 0, 3, 1, 3, 3, 2, 0, 0, 0, 1, 1, 0, 2, 0, 2, 0, 2, 2, 2, 3, 0, 2, 2, 0, 2, 1, 3, 2, 2, 3, 0, 3, 0, 0, 3, 0, 2, 2, 0, 3, 2, 1, 3, 2, 3, 0, 2, 0, 1, 1, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 64 and the episode is 3969 and the total_steps are 190133\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 2, 0, 1, 2, 1, 2, 0, 3, 3, 2, 3, 2, 0, 0, 1, 1, 0, 2, 2, 1, 2, 1, 1, 3, 1, 0, 3, 3, 0, 2, 2, 3, 3, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 41 and the episode is 3970 and the total_steps are 190174\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 0, 0, 0, 1, 3, 2, 3, 2, 3, 0, 1, 1, 3, 3, 1, 2, 3, 3, 1, 2, 0, 3, 2, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 47 and the episode is 3971 and the total_steps are 190221\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 0, 2, 2, 3, 2, 2, 3, 1, 1, 1, 1, 2, 0, 2, 0, 2, 3, 0, 3, 2, 2, 3, 0, 3, 0, 2, 0, 2, 2, 2, 3, 3, 3, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 41 and the episode is 3972 and the total_steps are 190262\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.1     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3972     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6563     |\n",
      "|    total_timesteps  | 190262   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 35065    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 1, 3, 2, 1, 0, 3, 3, 3, 1, 3, 1, 2, 2, 1, 3, 1, 2, 2, 0, 0, 2, 0, 0, 3, 3, 0, 2, 2, 3, 1, 3, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 39 and the episode is 3973 and the total_steps are 190301\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 2, 2, 3, 2, 3, 0, 0, 1, 1, 3, 1, 3, 0, 2, 2, 3, 1, 1, 1, 2, 3, 2, 2, 3, 3, 3, 1, 1, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 36 and the episode is 3974 and the total_steps are 190337\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 3, 0, 3, 1, 3, 2, 3, 0, 1, 2, 2, 2, 0, 3, 0, 3, 2, 1, 3, 3, 0, 2, 2, 0, 0, 3, 1, 2, 2, 0, 0, 3, 1, 2, 0, 0, 1, 0, 3, 1, 3, 2, 3, 3, 2, 1, 1, 0, 2, 3, 1, 3, 2, 1, 3, 3, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 64 and the episode is 3975 and the total_steps are 190401\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 1, 0, 0, 3, 3, 2, 2, 0, 1, 2, 2, 2, 3, 0, 2, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 24 and the episode is 3976 and the total_steps are 190425\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3976     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6570     |\n",
      "|    total_timesteps  | 190425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 36.3     |\n",
      "|    n_updates        | 35106    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 1, 0, 3, 3, 1, 1, 1, 0, 0, 2, 1, 1, 0, 0, 0, 0, 1, 3, 0, 0, 2, 1, 3, 3, 0, 0, 3, 1, 1, 3, 3, 0, 3, 1, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 3, 0, 3, 1, 2, 1, 2, 3, 1, 3, 3, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1053. And steps were 69 and the episode is 3977 and the total_steps are 190494\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 2, 2, 2, 1, 2, 0, 0, 3, 1, 1, 3, 2, 2, 0, 0, 1, 3, 0, 1, 0, 2, 1, 0, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was 1028. And steps were 29 and the episode is 3978 and the total_steps are 190523\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 3, 0, 0, 2, 2, 0, 1, 2, 2, 1, 0, 1, 2, 2, 0, 0, 1, 3, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 3979 and the total_steps are 190549\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 0, 0, 0, 2, 2, 0, 1, 3, 3, 0, 1, 3, 3, 2, 3, 0, 0, 1, 3, 0, 0, 3, 3, 0, 0, 2, 2, 1, 0, 0, 0, 1, 2, 1, 3, 1, 2, 1, 3, 2, 0, 2, 3, 2, 0, 0, 2, 1, 2, 1, 3, 1, 3, 2, 3, 3, 1, 3, 3, 0, 1, 2, 0, 0, 0, 0, 3, 3, 0, 0, 1, 2, 2, 1, 2, 0, 0, 2, 1, 3, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 88 and the episode is 3980 and the total_steps are 190637\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3980     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6579     |\n",
      "|    total_timesteps  | 190637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 93.3     |\n",
      "|    n_updates        | 35159    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 2, 3, 1, 2, 2, 3, 3, 1, 0, 3, 1, 3, 3, 0, 1, 0, 2, 3, 3, 0, 0, 0, 1, 2, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 3981 and the total_steps are 190669\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 0, 1, 1, 1, 2, 2, 0, 2, 2, 1, 0, 1, 2, 2, 1, 3, 1, 2, 0, 3, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 3982 and the total_steps are 190697\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 2, 3, 2, 1, 1, 1, 3, 3, 0, 0, 3, 1, 0, 2, 1, 3, 1, 0, 1, 2, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 28 and the episode is 3983 and the total_steps are 190725\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 2, 0, 3, 2, 3, 1, 1, 1, 3, 2, 1, 3, 2, 3, 2, 0, 0, 0, 0, 2, 3, 3, 0, 2, 3, 2, 3, 0, 0, 2, 3, 2, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 40 and the episode is 3984 and the total_steps are 190765\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3984     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6585     |\n",
      "|    total_timesteps  | 190765   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.6     |\n",
      "|    n_updates        | 35191    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 0, 0, 0, 3, 3, 3, 0, 1, 1, 2, 2, 1, 0, 1, 1, 3, 1, 1, 0, 0, 3, 2, 2, 3, 0, 3, 0, 1, 1, 0, 3, 2, 0, 2, 3, 0, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 44 and the episode is 3985 and the total_steps are 190809\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 3, 3, 2, 1, 3, 1, 1, 3, 1, 2, 0, 3, 2, 3, 3, 2, 1, 2, 0, 2, 2, 1, 1, 0, 3, 1, 2, 3, 0, 2, 3, 3, 0, 2, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 42 and the episode is 3986 and the total_steps are 190851\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 0, 0, 2, 3, 1, 0, 0, 0, 0, 2, 1, 3, 2, 0, 3, 0, 3, 1, 0, 2, 2, 3, 2, 0, 3, 0, 3, 3, 3, 2, 2, 0, 2, 1, 2, 3, 3, 3, 0, 0, 0, 2, 0, 1, 1, 2, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 54 and the episode is 3987 and the total_steps are 190905\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 1, 0, 0, 0, 0, 2, 3, 1, 2, 3, 0, 2, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 30 and the episode is 3988 and the total_steps are 190935\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3988     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6592     |\n",
      "|    total_timesteps  | 190935   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.2     |\n",
      "|    n_updates        | 35233    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 1, 2, 0, 3, 2, 3, 1, 1, 0, 2, 0, 0, 2, 0, 2, 1, 1, 1, 3, 2, 3, 0, 0, 0, 3, 2, 0, 1, 0, 0, 3, 2, 1, 3, 2, 2, 2, 0, 1, 3, 0, 0, 0, 1, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 58 and the episode is 3989 and the total_steps are 190993\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 3, 2, 0, 0, 1, 0, 2, 3, 2, 3, 0, 0, 3, 1, 2, 2, 0, 1, 3, 0, 2, 1, 2, 0, 0, 0, 0, 3, 0, 1, 2, 2, 1, 2, 2, 2, 0, 1, 0, 0, 2, 3, 2, 1, 2, 2, 0, 2, 0, 2, 3, 2, 0, 2, 0, 1, 3, 3, 0, 2, 1, 2, 3, 2, 3, 3, 1, 2, 0, 0, 2, 3, 1, 3, 2, 1, 1, 3, 0, 0, 0, 3, 1, 0, 1, 0, 1, 0, 2, 2, 2, 3, 2, 1, 3, 2, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 105 and the episode is 3990 and the total_steps are 191098\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 2, 3, 2, 3, 1, 0, 0, 3, 2, 1, 1, 2, 3, 3, 3, 3, 1, 3, 0, 2, 1, 0, 1, 2, 0, 3, 3, 0, 1, 0, 2, 1, 2, 3, 0, 2, 0, 3, 3, 2, 3, 2, 0, 1, 2, 0, 3, 2, 2, 0, 2, 3, 3, 1, 3, 0, 0, 3, 2, 0, 1, 0, 0, 2, 2, 3, 1, 2, 3, 3, 0, 2, 1, 3, 0, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1055. And steps were 83 and the episode is 3991 and the total_steps are 191181\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 0, 0, 3, 2, 0, 0, 0, 1, 0, 1, 3, 2, 0, 1, 3, 0, 3, 1, 0, 3, 3, 3, 3, 3, 0, 3, 0, 1, 0, 3, 3, 3, 2, 2, 3, 3, 1, 3, 0, 0, 3, 3, 2, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 58 and the episode is 3992 and the total_steps are 191239\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3992     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6604     |\n",
      "|    total_timesteps  | 191239   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.52     |\n",
      "|    n_updates        | 35309    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 0, 1, 0, 2, 3, 3, 2, 3, 0, 0, 2, 3, 1, 0, 1, 2, 3, 3, 1, 3, 2, 2, 2, 3, 0, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 3993 and the total_steps are 191272\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 2, 2, 3, 3, 2, 0, 0, 2, 1, 0, 2, 2, 0, 3, 0, 2, 2, 2, 1, 2, 3, 2, 0, 3, 2, 2, 1, 2, 3, 2, 0, 3, 2, 2, 2, 2, 2, 3, 0, 3, 2, 2, 1, 1, 0, 2, 3, 0, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 56 and the episode is 3994 and the total_steps are 191328\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 3, 2, 3, 3, 2, 0, 0, 0, 3, 0, 2, 0, 0, 3, 3, 3, 0, 1, 0, 2, 1, 1, 3, 0, 1, 1, 2, 0, 0, 1, 1, 3, 0, 3, 2, 2, 0, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 45 and the episode is 3995 and the total_steps are 191373\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 2, 0, 3, 0, 1, 1, 3, 0, 1, 0, 0, 1, 1, 0, 3, 0, 2, 3, 1, 0, 1, 2, 0, 1, 2, 3, 0, 3, 0, 0, 0, 0, 3, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 41 and the episode is 3996 and the total_steps are 191414\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3996     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6612     |\n",
      "|    total_timesteps  | 191414   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.6     |\n",
      "|    n_updates        | 35353    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 0, 2, 2, 2, 0, 1, 3, 3, 1, 0, 3, 2, 1, 3, 3, 0, 1, 3, 2, 1, 2, 1, 0, 0, 0, 2, 3, 2, 3, 1, 0, 3, 0, 1, 3, 3, 2, 2, 0, 2, 0, 0, 1, 3, 3, 2, 0, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 55 and the episode is 3997 and the total_steps are 191469\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 1, 0, 1, 1, 1, 2, 0, 0, 0, 0, 2, 3, 3, 2, 2, 3, 3, 0, 2, 0, 3, 1, 0, 2, 1, 1, 2, 2, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 3998 and the total_steps are 191505\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 2, 0, 2, 3, 2, 0, 3, 0, 3, 2, 0, 1, 1, 0, 2, 2, 3, 0, 2, 3, 0, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 29 and the episode is 3999 and the total_steps are 191534\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 0, 1, 2, 3, 3, 3, 3, 0, 1, 2, 1, 3, 1, 1, 0, 0, 2, 2, 1, 0, 1, 1, 0, 3, 1, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 4000 and the total_steps are 191567\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -957     |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4000     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6618     |\n",
      "|    total_timesteps  | 191567   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.09     |\n",
      "|    n_updates        | 35391    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 1, 0, 2, 3, 1, 2, 0, 3, 1, 1, 0, 2, 3, 3, 1, 3, 3, 2, 0, 0, 0, 3, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 30 and the episode is 4001 and the total_steps are 191597\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 0, 1, 2, 1, 3, 3, 2, 2, 0, 0, 0, 2, 2, 2, 3, 1, 0, 1, 1, 2, 1, 3, 2, 0, 1, 3, 0, 3, 1, 0, 1, 3, 1, 1, 3, 0, 1, 3, 2, 1, 3, 0, 2, 1, 2, 0, 1, 2, 1, 3, 3, 2, 1, 0, 2, 1, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 64 and the episode is 4002 and the total_steps are 191661\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 1, 0, 1, 3, 1, 1, 2, 3, 2, 2, 3, 2, 1, 3, 3, 0, 2, 2, 0, 2, 2, 2, 3, 3, 1, 1, 0, 1, 1, 3, 3, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 40 and the episode is 4003 and the total_steps are 191701\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 2, 3, 3, 3, 0, 2, 3, 3, 3, 3, 2, 1, 3, 2, 3, 0, 1, 2, 1, 1, 3, 0, 0, 2, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 31 and the episode is 4004 and the total_steps are 191732\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4004     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6625     |\n",
      "|    total_timesteps  | 191732   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 35432    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 0, 1, 2, 1, 1, 3, 0, 2, 2, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 17 and the episode is 4005 and the total_steps are 191749\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 1, 3, 3, 1, 1, 1, 3, 1, 2, 0, 1, 1, 2, 3, 2, 2, 0, 3, 0, 3, 2, 3, 2, 3, 0, 3, 0, 3, 2, 0, 0, 3, 0, 0, 3, 0, 3, 2, 3, 0, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 48 and the episode is 4006 and the total_steps are 191797\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 2, 3, 1, 1, 0, 0, 3, 0, 0, 0, 3, 2, 3, 2, 3, 3, 3, 3, 0, 1, 0, 2, 1, 2, 1, 3, 1, 2, 2, 0, 3, 1, 1, 2, 0, 1, 1, 3, 2, 0, 1, 3, 1, 1, 1, 1, 2, 0, 2, 3, 1, 1, 3, 3, 2, 2, 3, 2, 3, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -949. And steps were 67 and the episode is 4007 and the total_steps are 191864\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 1, 2, 0, 2, 2, 2, 1, 0, 3, 1, 3, 3, 2, 0, 2, 2, 0, 2, 2, 3, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 4008 and the total_steps are 191892\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4008     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6632     |\n",
      "|    total_timesteps  | 191892   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 35472    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 2, 3, 0, 1, 1, 2, 2, 3, 1, 3, 2, 1, 3, 2, 2, 0, 2, 3, 0, 0, 3, 1, 1, 1, 2, 0, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 34 and the episode is 4009 and the total_steps are 191926\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 2, 3, 2, 3, 3, 3, 1, 3, 2, 2, 0, 0, 2, 1, 3, 1, 0, 3, 2, 2, 0, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 29 and the episode is 4010 and the total_steps are 191955\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 1, 2, 3, 2, 0, 2, 1, 3, 1, 0, 1, 2, 3, 1, 1, 3, 3, 0, 2, 1, 3, 1, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 30 and the episode is 4011 and the total_steps are 191985\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 0, 2, 3, 3, 2, 1, 0, 3, 1, 0, 0, 2, 3, 0, 2, 0, 2, 3, 0, 3, 2, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 29 and the episode is 4012 and the total_steps are 192014\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4012     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6638     |\n",
      "|    total_timesteps  | 192014   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.74     |\n",
      "|    n_updates        | 35503    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 1, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 1, 0, 1, 3, 1, 1, 3, 0, 0, 2, 1, 2, 3, 2, 1, 3, 1, 0, 3, 0, 1, 3, 2, 2, 2, 1, 1, 0, 0, 0, 3, 1, 0, 3, 2, 1, 3, 3, 3, 2, 0, 2, 3, 2, 2, 1, 2, 3, 1, 3, 2, 3, 0, 1, 0, 3, 3, 2, 1, 1, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -922. And steps were 82 and the episode is 4013 and the total_steps are 192096\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 2, 2, 0, 0, 1, 2, 1, 3, 1, 0, 3, 2, 2, 3, 0, 2, 2, 1, 3, 0, 0, 0, 3, 0, 2, 0, 3, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was 970. And steps were 33 and the episode is 4014 and the total_steps are 192129\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 2, 3, 3, 3, 1, 3, 2, 0, 1, 0, 2, 2, 2, 2, 0, 0, 2, 1, 2, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 27 and the episode is 4015 and the total_steps are 192156\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 0, 0, 1, 0, 1, 3, 1, 2, 3, 2, 0, 0, 2, 3, 2, 3, 0, 2, 2, 2, 3, 0, 3, 2, 0, 2, 1, 2, 3, 1, 2, 2, 3, 3, 1, 3, 3, 3, 0, 3, 0, 2, 1, 3, 2, 0, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1, 3, 0, 3, 2, 1, 3, 1, 0, 1, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -945. And steps were 73 and the episode is 4016 and the total_steps are 192229\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -955     |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4016     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6647     |\n",
      "|    total_timesteps  | 192229   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.14     |\n",
      "|    n_updates        | 35557    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 0, 3, 2, 2, 3, 0, 2, 3, 1, 0, 0, 3, 0, 3, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4017 and the total_steps are 192257\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 0, 1, 3, 1, 0, 1, 2, 0, 2, 3, 1, 2, 2, 0, 0, 3, 1, 0, 3, 3, 0, 2, 3, 0, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 32 and the episode is 4018 and the total_steps are 192289\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 1, 2, 2, 0, 1, 1, 0, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 0, 0, 1, 0, 1, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was 999. And steps were 28 and the episode is 4019 and the total_steps are 192317\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 1, 1, 2, 1, 0, 0, 3, 3, 2, 1, 1, 0, 3, 0, 1, 2, 3, 2, 3, 3, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 28 and the episode is 4020 and the total_steps are 192345\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -936     |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4020     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6652     |\n",
      "|    total_timesteps  | 192345   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.4     |\n",
      "|    n_updates        | 35586    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 3, 1, 1, 1, 3, 0, 0, 2, 3, 3, 2, 2, 3, 3, 1, 0, 0, 1, 0, 3, 2, 0, 0, 3, 1, 3, 3, 2, 2, 1, 0, 1, 2, 0, 2, 1, 2, 1, 3, 3, 1, 1, 0, 2, 2, 1, 2, 0, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 56 and the episode is 4021 and the total_steps are 192401\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 1, 0, 0, 0, 3, 1, 2, 3, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 4022 and the total_steps are 192417\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 0, 1, 0, 0, 1, 0, 3, 1, 3, 1, 2, 1, 0, 3, 0, 3, 3, 3, 2, 3, 0, 3, 1, 1, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 32 and the episode is 4023 and the total_steps are 192449\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 2, 1, 3, 1, 3, 0, 1, 3, 0, 1, 0, 3, 3, 1, 2, 0, 2, 1, 1, 2, 1, 1, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was 1027. And steps were 28 and the episode is 4024 and the total_steps are 192477\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -915     |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4024     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6657     |\n",
      "|    total_timesteps  | 192477   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.2      |\n",
      "|    n_updates        | 35619    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 2, 0, 0, 2, 1, 2, 3, 3, 2, 2, 0, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4025 and the total_steps are 192505\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 0, 2, 2, 3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 2, 1, 0, 2, 1, 0, 0, 1, 3, 1, 2, 3, 3, 0, 2, 1, 3, 0, 0, 0, 0, 1, 2, 1, 3, 2, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 47 and the episode is 4026 and the total_steps are 192552\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 1, 3, 1, 3, 0, 0, 3, 0, 2, 1, 3, 0, 2, 0, 1, 0, 3, 2, 0, 2, 2, 1, 2, 0, 1, 1, 3, 1, 1, 0, 0, 3, 2, 3, 2, 3, 1, 3, 0, 0, 0, 0, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 50 and the episode is 4027 and the total_steps are 192602\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 1, 1, 3, 1, 1, 1, 2, 1, 0, 3, 1, 1, 2, 2, 2, 3, 2, 1, 3, 1, 0, 1, 0, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 31 and the episode is 4028 and the total_steps are 192633\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -915     |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4028     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6664     |\n",
      "|    total_timesteps  | 192633   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.13     |\n",
      "|    n_updates        | 35658    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 0, 2, 3, 1, 0, 0, 1, 1, 0, 1, 0, 3, 0, 3, 3, 2, 3, 3, 1, 2, 1, 3, 2, 1, 2, 0, 2, 2, 0, 0, 1, 0, 2, 0, 1, 2, 2, 2, 0, 2, 0, 2, 2, 3, 3, 0, 3, 3, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 56 and the episode is 4029 and the total_steps are 192689\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 3, 3, 3, 3, 2, 2, 0, 3, 0, 1, 2, 2, 2, 0, 0, 3, 1, 3, 3, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 4030 and the total_steps are 192717\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 3, 3, 3, 0, 1, 0, 0, 2, 1, 0, 3, 3, 2, 0, 2, 3, 0, 2, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 24 and the episode is 4031 and the total_steps are 192741\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 0, 2, 3, 3, 2, 3, 1, 3, 3, 3, 2, 1, 0, 0, 2, 1, 2, 2, 2, 1, 2, 1, 0, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 4032 and the total_steps are 192772\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4032     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6670     |\n",
      "|    total_timesteps  | 192772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.71     |\n",
      "|    n_updates        | 35692    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 3, 0, 1, 3, 3, 2, 0, 3, 3, 0, 0, 1, 0, 1, 1, 0, 1, 3, 2, 2, 0, 3, 2, 3, 0, 3, 3, 1, 3, 1, 1, 2, 3, 1, 0, 3, 3, 1, 1, 1, 1, 3, 2, 1, 2, 2, 0, 2, 2, 2, 1, 3, 1, 3, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1060. And steps were 62 and the episode is 4033 and the total_steps are 192834\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 1, 3, 3, 3, 3, 3, 2, 2, 1, 3, 2, 0, 1, 2, 2, 3, 0, 1, 1, 2, 3, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 29 and the episode is 4034 and the total_steps are 192863\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 3, 2, 0, 0, 3, 0, 0, 1, 0, 0, 2, 0, 3, 2, 0, 0, 1, 0, 3, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 3, 0, 1, 1, 0, 1, 1, 2, 3, 2, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 47 and the episode is 4035 and the total_steps are 192910\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 2, 1, 2, 0, 1, 1, 0, 3, 2, 2, 1, 0, 0, 1, 2, 3, 0, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 25 and the episode is 4036 and the total_steps are 192935\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -895     |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4036     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6677     |\n",
      "|    total_timesteps  | 192935   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.7     |\n",
      "|    n_updates        | 35733    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 1, 0, 1, 2, 1, 2, 3, 3, 3, 3, 3, 1, 3, 0, 0, 3, 1, 0, 1, 2, 3, 2, 3, 0, 1, 0, 1, 3, 2, 3, 2, 0, 1, 1, 2, 1, 2, 1, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 46 and the episode is 4037 and the total_steps are 192981\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 1, 3, 3, 3, 0, 1, 0, 3, 0, 2, 1, 2, 3, 1, 0, 3, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 24 and the episode is 4038 and the total_steps are 193005\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 2, 2, 0, 0, 2, 2, 2, 3, 1, 3, 3, 0, 3, 2, 3, 3, 2, 1, 1, 0, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4039 and the total_steps are 193033\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 1, 2, 3, 3, 0, 3, 0, 3, 2, 3, 2, 0, 1, 2, 0, 3, 0, 1, 0, 1, 1, 2, 1, 3, 3, 1, 3, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 4040 and the total_steps are 193068\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4040     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6683     |\n",
      "|    total_timesteps  | 193068   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.61     |\n",
      "|    n_updates        | 35766    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 1, 1, 1, 1, 1, 3, 3, 0, 1, 2, 0, 1, 1, 1, 3, 0, 2, 1, 2, 1, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4041 and the total_steps are 193096\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 2, 2, 2, 2, 1, 3, 2, 3, 1, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 17 and the episode is 4042 and the total_steps are 193113\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 1, 3, 2, 0, 1, 2, 1, 1, 3, 3, 0, 3, 1, 1, 2, 1, 2, 2, 2, 1, 3, 2, 3, 2, 1, 0, 0, 2, 3, 2, 2, 2, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 40 and the episode is 4043 and the total_steps are 193153\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 2, 2, 2, 3, 0, 2, 3, 1, 1, 0, 3, 2, 1, 0, 2, 0, 3, 0, 3, 2, 3, 0, 0, 1, 1, 1, 0, 1, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4044 and the total_steps are 193189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4044     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6688     |\n",
      "|    total_timesteps  | 193189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 35797    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 2, 3, 1, 3, 0, 2, 2, 1, 3, 3, 0, 2, 0, 1, 2, 0, 0, 3, 3, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 0, 0, 3, 1, 3, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 44 and the episode is 4045 and the total_steps are 193233\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 3, 1, 0, 0, 1, 1, 2, 2, 2, 0, 1, 2, 1, 2, 1, 1, 0, 2, 0, 3, 3, 3, 3, 3, 2, 3, 2, 0, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 4046 and the total_steps are 193269\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 0, 3, 3, 1, 2, 3, 1, 1, 3, 1, 2, 0, 2, 0, 2, 2, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 24 and the episode is 4047 and the total_steps are 193293\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 3, 2, 0, 1, 0, 1, 0, 0, 0, 0, 3, 1, 1, 0, 1, 1, 3, 2, 0, 0, 1, 3, 2, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 4048 and the total_steps are 193324\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4048     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6694     |\n",
      "|    total_timesteps  | 193324   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 35830    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 0, 2, 2, 3, 1, 1, 2, 3, 2, 3, 1, 0, 0, 2, 2, 2, 2, 0, 2, 2, 3, 1, 2, 3, 1, 0, 3, 0, 0, 3, 0, 2, 0, 3, 0, 3, 3, 0, 2, 3, 3, 2, 2, 2, 1, 3, 3, 1, 1, 1, 1, 3, 0, 1, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 62 and the episode is 4049 and the total_steps are 193386\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 2, 2, 0, 2, 0, 1, 3, 0, 1, 3, 1, 3, 1, 0, 0, 0, 3, 1, 3, 3, 1, 1, 2, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 31 and the episode is 4050 and the total_steps are 193417\n",
      "Done condition: collision\n",
      "[1, 1, 3, 0, 0, 0, 0, 3, 0, 3, 2, 0, 0, 1, 0, 1, 0, 2, 2, 3, 2, 2, 3, 2, 1, 3, 0, 0, 2, 0, 0, 1, 1, 1, 2, 3, 3, 0, 0, 1, 3, 3, 2, 3, 0, 0, 1, 1, 2, 2, 3, 0, 1, 2, 1, 3, 0, 2, 0, 3, 2, 1, 2, 2, 2, 1, 0, 3, 1, 1, 1, 3, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 76 and the episode is 4051 and the total_steps are 193493\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 0, 2, 1, 1, 0, 0, 3, 1, 3, 3, 1, 3, 1, 0, 1, 1, 3, 1, 3, 2, 3, 0, 0, 3, 2, 2, 1, 3, 1, 0, 2, 3, 1, 1, 2, 2, 3, 0, 1, 0, 0, 2, 1, 3, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 52 and the episode is 4052 and the total_steps are 193545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4052     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6703     |\n",
      "|    total_timesteps  | 193545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.78     |\n",
      "|    n_updates        | 35886    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 1, 0, 3, 2, 0, 1, 0, 2, 0, 1, 1, 3, 2, 1, 0, 3, 0, 3, 0, 3, 2, 1, 3, 2, 3, 0, 0, 1, 2, 2, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 37 and the episode is 4053 and the total_steps are 193582\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 1, 1, 1, 0, 0, 2, 2, 2, 1, 3, 2, 0, 1, 2, 3, 3, 2, 2, 0, 0, 2, 2, 3, 3, 2, 1, 0, 2, 0, 2, 3, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 39 and the episode is 4054 and the total_steps are 193621\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 2, 1, 1, 3, 3, 1, 1, 2, 3, 2, 1, 3, 2, 0, 1, 1, 1, 2, 0, 1, 0, 0, 0, 2, 1, 3, 2, 0, 3, 2, 0, 2, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 40 and the episode is 4055 and the total_steps are 193661\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 1, 1, 1, 3, 3, 0, 2, 0, 3, 2, 0, 3, 3, 3, 2, 0, 0, 3, 3, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 27 and the episode is 4056 and the total_steps are 193688\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4056     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6709     |\n",
      "|    total_timesteps  | 193688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.62     |\n",
      "|    n_updates        | 35921    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 2, 3, 1, 2, 2, 3, 2, 2, 1, 1, 1, 2, 0, 3, 2, 1, 0, 3, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 25 and the episode is 4057 and the total_steps are 193713\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 3, 1, 1, 3, 1, 1, 0, 1, 3, 1, 2, 2, 0, 0, 3, 0, 1, 0, 1, 3, 0, 0, 2, 1, 2, 0, 1, 1, 1, 2, 3, 2, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 40 and the episode is 4058 and the total_steps are 193753\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 1, 1, 1, 1, 3, 1, 0, 3, 1, 2, 1, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 0, 3, 2, 0, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 34 and the episode is 4059 and the total_steps are 193787\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 0, 1, 1, 1, 1, 1, 0, 1, 1, 3, 2, 1, 3, 2, 2, 2, 3, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4060 and the total_steps are 193812\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4060     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6715     |\n",
      "|    total_timesteps  | 193812   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.15     |\n",
      "|    n_updates        | 35952    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 2, 3, 2, 2, 2, 3, 0, 2, 2, 2, 3, 1, 2, 2, 1, 2, 0, 3, 1, 3, 3, 1, 0, 1, 3, 2, 0, 2, 2, 1, 1, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 39 and the episode is 4061 and the total_steps are 193851\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 2, 0, 2, 1, 0, 0, 1, 3, 2, 0, 2, 2, 2, 3, 1, 2, 3, 2, 3, 0, 1, 3, 0, 1, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 41 and the episode is 4062 and the total_steps are 193892\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 3, 1, 1, 3, 1, 1, 2, 1, 1, 3, 3, 3, 2, 2, 1, 1, 2, 0, 2, 1, 1, 0, 1, 3, 0, 1, 0, 2, 3, 3, 0, 2, 0, 2, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 42 and the episode is 4063 and the total_steps are 193934\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 1, 2, 0, 3, 0, 2, 0, 1, 3, 1, 1, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 27 and the episode is 4064 and the total_steps are 193961\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4064     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6721     |\n",
      "|    total_timesteps  | 193961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 30.3     |\n",
      "|    n_updates        | 35990    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 1, 1, 1, 1, 0, 1, 0, 0, 0, 2, 2, 1, 3, 3, 1, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 4065 and the total_steps are 193982\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 2, 2, 1, 3, 2, 2, 1, 3, 2, 0, 1, 0, 0, 2, 1, 1, 2, 1, 2, 2, 0, 2, 3, 3, 0, 0, 2, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 4066 and the total_steps are 194017\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 0, 3, 2, 3, 0, 1, 1, 3, 1, 0, 0, 0, 3, 0, 0, 1, 0, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 25 and the episode is 4067 and the total_steps are 194042\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 1, 0, 2, 2, 3, 2, 2, 2, 2, 3, 3, 2, 1, 0, 3, 2, 1, 2, 2, 1, 0, 2, 0, 0, 1, 3, 1, 0, 1, 3, 1, 1, 2, 3, 3, 2, 3, 0, 1, 3, 1, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1047. And steps were 49 and the episode is 4068 and the total_steps are 194091\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4068     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6727     |\n",
      "|    total_timesteps  | 194091   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.78     |\n",
      "|    n_updates        | 36022    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 3, 2, 1, 2, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 0, 2, 0, 0, 3, 3, 1, 1, 3, 0, 3, 3, 2, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 34 and the episode is 4069 and the total_steps are 194125\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 3, 0, 3, 1, 2, 2, 3, 0, 2, 3, 0, 2, 3, 0, 1, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 23 and the episode is 4070 and the total_steps are 194148\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 1, 1, 0, 1, 0, 1, 1, 0, 3, 2, 2, 2, 3, 1, 1, 3, 3, 1, 1, 0, 2, 2, 1, 2, 3, 0, 2, 1, 3, 2, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 38 and the episode is 4071 and the total_steps are 194186\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 2, 0, 2, 3, 1, 1, 0, 2, 1, 0, 3, 2, 3, 3, 0, 1, 2, 0, 0, 3, 0, 0, 0, 2, 3, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 33 and the episode is 4072 and the total_steps are 194219\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4072     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6732     |\n",
      "|    total_timesteps  | 194219   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.3     |\n",
      "|    n_updates        | 36054    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 3, 3, 1, 0, 1, 0, 1, 3, 2, 3, 3, 3, 0, 1, 0, 1, 0, 0, 2, 1, 3, 3, 3, 3, 3, 0, 3, 2, 2, 2, 0, 2, 0, 3, 1, 3, 0, 1, 2, 0, 1, 2, 3, 1, 2, 0, 3, 0, 3, 0, 0, 1, 2, 1, 1, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 63 and the episode is 4073 and the total_steps are 194282\n",
      "Done condition: collision\n",
      "[1, 1, 3, 1, 2, 3, 3, 2, 0, 3, 0, 1, 1, 1, 2, 3, 2, 3, 0, 1, 2, 1, 2, 3, 1, 1, 1, 2, 0, 1, 2, 1, 1, 0, 1, 1, 0, 2, 0, 1, 3, 2, 1, 1, 3, 1, 3, 2, 2, 0, 2, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 55 and the episode is 4074 and the total_steps are 194337\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 0, 1, 2, 0, 3, 0, 2, 0, 2, 3, 1, 1, 2, 1, 2, 2, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 4075 and the total_steps are 194361\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 3, 2, 0, 2, 0, 1, 2, 1, 0, 2, 2, 2, 0, 1, 2, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 24 and the episode is 4076 and the total_steps are 194385\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4076     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6740     |\n",
      "|    total_timesteps  | 194385   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 36096    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 2, 2, 0, 0, 2, 3, 0, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 0, 2, 3, 3, 2, 2, 0, 0, 1, 3, 2, 2, 3, 2, 0, 0, 0, 1, 0, 3, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 45 and the episode is 4077 and the total_steps are 194430\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 3, 0, 0, 0, 3, 1, 1, 1, 1, 3, 0, 0, 0, 1, 2, 0, 1, 0, 3, 0, 1, 3, 0, 3, 2, 2, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 34 and the episode is 4078 and the total_steps are 194464\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 0, 3, 0, 2, 2, 1, 0, 2, 0, 0, 2, 3, 1, 2, 0, 0, 2, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 25 and the episode is 4079 and the total_steps are 194489\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 2, 3, 0, 0, 0, 3, 3, 3, 3, 3, 0, 2, 3, 3, 2, 2, 3, 3, 0, 3, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 28 and the episode is 4080 and the total_steps are 194517\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4080     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6746     |\n",
      "|    total_timesteps  | 194517   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.86     |\n",
      "|    n_updates        | 36129    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 3, 1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 3, 3, 2, 0, 0, 3, 1, 3, 3, 0, 1, 2, 2, 1, 1, 2, 1, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 36 and the episode is 4081 and the total_steps are 194553\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 2, 2, 1, 0, 2, 0, 3, 1, 2, 3, 1, 3, 3, 2, 3, 3, 1, 0, 3, 0, 3, 1, 1, 1, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 4082 and the total_steps are 194585\n",
      "Done condition: collision\n",
      "[3, 1, 3, 1, 0, 3, 1, 3, 3, 0, 2, 0, 1, 1, 3, 2, 2, 3, 0, 2, 1, 0, 0, 1, 2, 3, 1, 2, 2, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 33 and the episode is 4083 and the total_steps are 194618\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 2, 1, 1, 0, 0, 1, 3, 2, 3, 3, 3, 1, 2, 1, 3, 0, 2, 3, 2, 0, 2, 0, 3, 2, 2, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 33 and the episode is 4084 and the total_steps are 194651\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4084     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6751     |\n",
      "|    total_timesteps  | 194651   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.29     |\n",
      "|    n_updates        | 36162    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 2, 3, 0, 1, 2, 1, 1, 2, 3, 3, 0, 1, 0, 3, 1, 1, 1, 1, 0, 3, 3, 1, 0, 1, 1, 3, 2, 3, 0, 3, 0, 0, 3, 2, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 42 and the episode is 4085 and the total_steps are 194693\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 3, 3, 2, 2, 1, 1, 2, 1, 1, 3, 3, 2, 0, 2, 3, 3, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 4086 and the total_steps are 194717\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 1, 3, 0, 3, 2, 2, 3, 3, 0, 1, 2, 3, 1, 0, 1, 2, 1, 0, 0, 2, 2, 3, 0, 0, 1, 3, 3, 1, 3, 0, 3, 2, 3, 1, 2, 1, 0, 1, 2, 3, 3, 0, 2, 3, 2, 3, 0, 3, 1, 3, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 58 and the episode is 4087 and the total_steps are 194775\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 2, 1, 0, 1, 3, 3, 2, 0, 0, 1, 2, 2, 2, 0, 1, 1, 2, 3, 2, 0, 0, 3, 0, 1, 3, 0, 2, 1, 3, 0, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 38 and the episode is 4088 and the total_steps are 194813\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4088     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6759     |\n",
      "|    total_timesteps  | 194813   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.8     |\n",
      "|    n_updates        | 36203    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 0, 3, 3, 3, 3, 0, 3, 3, 2, 0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 0, 2, 1, 0, 1, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4089 and the total_steps are 194845\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 2, 3, 1, 2, 1, 0, 1, 0, 0, 3, 0, 3, 0, 1, 2, 3, 2, 0, 0, 0, 3, 0, 3, 3, 2, 3, 2, 3, 1, 3, 0, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 39 and the episode is 4090 and the total_steps are 194884\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 3, 1, 2, 3, 1, 0, 0, 0, 2, 2, 1, 1, 1, 3, 0, 0, 0, 0, 1, 2, 1, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 4091 and the total_steps are 194913\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 3, 1, 2, 1, 1, 0, 0, 1, 3, 3, 2, 2, 1, 1, 3, 0, 1, 1, 1, 2, 2, 1, 2, 0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 1, 2, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 44 and the episode is 4092 and the total_steps are 194957\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.2     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4092     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6765     |\n",
      "|    total_timesteps  | 194957   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.5     |\n",
      "|    n_updates        | 36239    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 1, 1, 3, 0, 3, 1, 2, 0, 3, 3, 0, 0, 1, 1, 3, 3, 2, 0, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 4093 and the total_steps are 194983\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 1, 1, 3, 3, 3, 0, 1, 1, 2, 2, 2, 0, 1, 3, 2, 2, 2, 0, 0, 3, 0, 1, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 30 and the episode is 4094 and the total_steps are 195013\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 2, 1, 0, 3, 1, 2, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 4095 and the total_steps are 195045\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 3, 2, 2, 1, 3, 0, 3, 3, 1, 1, 1, 3, 2, 2, 2, 2, 3, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4096 and the total_steps are 195070\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -896     |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4096     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6770     |\n",
      "|    total_timesteps  | 195070   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65.3     |\n",
      "|    n_updates        | 36267    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 2, 2, 3, 3, 1, 1, 1, 1, 3, 0, 1, 3, 0, 3, 0, 3, 1, 3, 3, 0, 1, 3, 1, 1, 1, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 33 and the episode is 4097 and the total_steps are 195103\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 2, 2, 3, 2, 2, 0, 3, 1, 3, 1, 0, 1, 1, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 22 and the episode is 4098 and the total_steps are 195125\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 0, 1, 2, 1, 2, 2, 0, 0, 3, 1, 2, 1, 3, 1, 3, 3, 0, 1, 0, 0, 2, 0, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 28 and the episode is 4099 and the total_steps are 195153\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 1, 2, 1, 1, 1, 0, 3, 0, 3, 1, 2, 1, 3, 0, 1, 0, 1, 0, 3, 3, 0, 1, 3, 2, 3, 0, 1, 1, 1, 0, 3, 0, 3, 2, 1, 3, 2, 0, 0, 0, 0, 3, 3, 2, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 52 and the episode is 4100 and the total_steps are 195205\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4100     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6776     |\n",
      "|    total_timesteps  | 195205   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 36301    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 0, 2, 1, 2, 1, 1, 2, 1, 2, 3, 1, 2, 0, 0, 2, 1, 0, 1, 2, 1, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4101 and the total_steps are 195233\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 3, 1, 1, 2, 1, 0, 0, 2, 1, 0, 3, 0, 3, 2, 3, 0, 3, 2, 3, 3, 2, 0, 0, 2, 2, 1, 0, 3, 3, 3, 2, 0, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 40 and the episode is 4102 and the total_steps are 195273\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 2, 2, 3, 0, 2, 3, 3, 2, 3, 3, 1, 0, 1, 0, 0, 1, 3, 3, 1, 3, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4103 and the total_steps are 195301\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 1, 2, 2, 1, 3, 3, 1, 3, 2, 0, 2, 1, 0, 0, 0, 2, 2, 2, 0, 1, 0, 1, 2, 1, 3, 2, 3, 3, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 36 and the episode is 4104 and the total_steps are 195337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4104     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6781     |\n",
      "|    total_timesteps  | 195337   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 36334    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 3, 2, 3, 2, 3, 0, 3, 2, 0, 3, 1, 0, 3, 0, 2, 3, 2, 0, 2, 3, 3, 0, 1, 1, 3, 1, 0, 0, 2, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 37 and the episode is 4105 and the total_steps are 195374\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 3, 0, 3, 3, 2, 2, 2, 0, 3, 1, 1, 2, 1, 3, 3, 2, 2, 0, 0, 3, 3, 1, 3, 2, 1, 1, 2, 3, 1, 0, 0, 2, 0, 1, 0, 3, 3, 3, 1, 2, 0, 0, 3, 3, 3, 3, 2, 2, 0, 0, 0, 3, 1, 3, 0, 2, 0, 1, 2, 1, 2, 3, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 83 and the episode is 4106 and the total_steps are 195457\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 2, 1, 2, 0, 1, 3, 1, 2, 1, 1, 3, 2, 3, 1, 0, 2, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 1, 1, 2, 2, 3, 3, 3, 3, 3, 1, 0, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 45 and the episode is 4107 and the total_steps are 195502\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 1, 2, 2, 0, 3, 0, 1, 2, 2, 0, 2, 3, 3, 3, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 2, 2, 0, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 35 and the episode is 4108 and the total_steps are 195537\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.5     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4108     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6790     |\n",
      "|    total_timesteps  | 195537   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.96     |\n",
      "|    n_updates        | 36384    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 1, 2, 0, 1, 1, 2, 3, 3, 3, 2, 3, 3, 3, 0, 0, 2, 0, 2, 1, 1, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 4109 and the total_steps are 195565\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 1, 0, 2, 0, 1, 0, 1, 0, 1, 2, 1, 0, 1, 2, 1, 1, 0, 1, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 4110 and the total_steps are 195589\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 1, 1, 3, 0, 1, 3, 0, 3, 2, 0, 3, 3, 0, 1, 1, 2, 1, 0, 3, 3, 3, 3, 3, 3, 1, 2, 1, 0, 1, 3, 2, 3, 0, 0, 0, 0, 0, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 45 and the episode is 4111 and the total_steps are 195634\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 1, 1, 3, 0, 3, 0, 2, 0, 1, 1, 0, 1, 2, 2, 1, 3, 2, 3, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 4112 and the total_steps are 195658\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | -836     |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4112     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6795     |\n",
      "|    total_timesteps  | 195658   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.2     |\n",
      "|    n_updates        | 36414    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 3, 0, 1, 3, 0, 1, 1, 1, 2, 1, 2, 3, 3, 1, 1, 3, 2, 1, 1, 2, 0, 1, 3, 3, 0, 1, 3, 3, 2, 0, 1, 3, 1, 0, 2, 3, 0, 3, 1, 0, 0, 0, 3, 1, 3, 2, 2, 2, 1, 0, 2, 1, 3, 0, 2, 3, 3, 3, 1, 0, 3, 0, 0, 3, 2, 1, 1, 2, 3, 2, 3, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -933. And steps were 79 and the episode is 4113 and the total_steps are 195737\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 1, 2, 1, 3, 2, 0, 2, 3, 3, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 3, 0, 1, 0, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 4114 and the total_steps are 195769\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 1, 0, 1, 2, 1, 3, 2, 3, 2, 3, 1, 0, 2, 3, 1, 3, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 4115 and the total_steps are 195793\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 0, 0, 3, 2, 0, 3, 3, 3, 0, 3, 2, 1, 1, 0, 1, 3, 3, 2, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was 1001. And steps were 24 and the episode is 4116 and the total_steps are 195817\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -837     |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4116     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6802     |\n",
      "|    total_timesteps  | 195817   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.39     |\n",
      "|    n_updates        | 36454    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 2, 1, 0, 3, 2, 3, 0, 2, 2, 3, 1, 0, 2, 0, 3, 0, 0, 2, 2, 3, 3, 1, 3, 1, 2, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 32 and the episode is 4117 and the total_steps are 195849\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 1, 2, 0, 1, 1, 0, 3, 1, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 3, 3, 2, 1, 3, 2, 2, 3, 3, 3, 1, 3, 3, 2, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 40 and the episode is 4118 and the total_steps are 195889\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 1, 2, 0, 2, 1, 3, 1, 1, 0, 3, 0, 1, 1, 0, 1, 2, 1, 3, 1, 0, 1, 0, 0, 0, 0, 2, 3, 1, 2, 1, 1, 2, 0, 0, 0, 3, 3, 0, 2, 2, 2, 1, 2, 3, 3, 3, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 54 and the episode is 4119 and the total_steps are 195943\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 2, 3, 0, 0, 1, 0, 3, 2, 1, 1, 1, 1, 3, 3, 2, 2, 1, 2, 3, 1, 3, 0, 1, 2, 1, 1, 1, 0, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 36 and the episode is 4120 and the total_steps are 195979\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4120     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6808     |\n",
      "|    total_timesteps  | 195979   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.44     |\n",
      "|    n_updates        | 36494    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 2, 0, 0, 3, 3, 2, 3, 2, 0, 2, 2, 0, 3, 2, 3, 1, 0, 0, 2, 2, 1, 0, 3, 3, 2, 2, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 34 and the episode is 4121 and the total_steps are 196013\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 2, 0, 1, 2, 2, 3, 3, 1, 0, 0, 3, 2, 3, 2, 2, 3, 0, 0, 1, 3, 3, 0, 1, 3, 0, 1, 1, 1, 0, 3, 1, 0, 0, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 41 and the episode is 4122 and the total_steps are 196054\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 0, 0, 0, 3, 2, 2, 1, 0, 1, 3, 1, 2, 0, 2, 3, 2, 0, 2, 1, 2, 3, 1, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 30 and the episode is 4123 and the total_steps are 196084\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 0, 0, 2, 3, 1, 1, 3, 3, 1, 3, 3, 0, 3, 1, 0, 2, 2, 0, 0, 0, 2, 2, 3, 0, 1, 0, 2, 2, 2, 2, 2, 0, 3, 0, 2, 2, 0, 2, 2, 3, 1, 2, 2, 0, 0, 0, 1, 2, 3, 1, 2, 1, 2, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 61 and the episode is 4124 and the total_steps are 196145\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.7     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4124     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6815     |\n",
      "|    total_timesteps  | 196145   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.85     |\n",
      "|    n_updates        | 36536    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 3, 2, 2, 0, 3, 2, 1, 1, 2, 3, 2, 1, 2, 3, 2, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 23 and the episode is 4125 and the total_steps are 196168\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 2, 2, 2, 3, 0, 0, 3, 3, 2, 1, 3, 3, 3, 1, 1, 2, 0, 3, 2, 0, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4126 and the total_steps are 196196\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 1, 1, 1, 0, 1, 3, 3, 1, 0, 1, 2, 3, 3, 1, 1, 1, 1, 2, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 26 and the episode is 4127 and the total_steps are 196222\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 0, 1, 1, 2, 0, 2, 1, 0, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 15 and the episode is 4128 and the total_steps are 196237\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4128     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6819     |\n",
      "|    total_timesteps  | 196237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65.9     |\n",
      "|    n_updates        | 36559    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 3, 3, 1, 0, 1, 2, 3, 0, 3, 0, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4129 and the total_steps are 196265\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 2, 2, 2, 2, 1, 1, 2, 0, 0, 2, 2, 0, 3, 0, 3, 2, 3, 1, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 4130 and the total_steps are 196289\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 2, 3, 0, 1, 0, 0, 1, 0, 0, 2, 1, 3, 2, 1, 2, 3, 3, 0, 0, 2, 0, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 29 and the episode is 4131 and the total_steps are 196318\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 1, 2, 2, 1, 0, 3, 3, 1, 2, 1, 1, 3, 1, 1, 1, 0, 2, 3, 2, 1, 2, 1, 0, 1, 2, 2, 3, 0, 2, 0, 0, 2, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 4132 and the total_steps are 196358\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4132     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6825     |\n",
      "|    total_timesteps  | 196358   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.8     |\n",
      "|    n_updates        | 36589    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 0, 2, 3, 3, 3, 0, 3, 2, 2, 2, 2, 0, 1, 3, 2, 3, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 22 and the episode is 4133 and the total_steps are 196380\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 3, 0, 0, 0, 1, 2, 2, 2, 2, 1, 3, 3, 1, 0, 1, 3, 2, 1, 2, 1, 3, 1, 2, 1, 1, 2, 3, 1, 2, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 37 and the episode is 4134 and the total_steps are 196417\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 3, 1, 1, 0, 1, 3, 3, 0, 3, 2, 0, 2, 3, 2, 2, 3, 1, 0, 0, 2, 2, 1, 0, 1, 1, 2, 1, 2, 3, 0, 1, 2, 2, 2, 3, 2, 1, 2, 0, 1, 2, 3, 1, 0, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 52 and the episode is 4135 and the total_steps are 196469\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 3, 3, 0, 1, 2, 3, 3, 1, 2, 2, 1, 1, 2, 2, 3, 2, 1, 2, 0, 1, 0, 2, 3, 2, 0, 1, 2, 0, 2, 2, 3, 2, 1, 1, 0, 2, 3, 0, 0, 1, 1, 3, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 0, 2, 0, 1, 1, 0, 1, 0, 0, 3, 1, 3, 0, 3, 1, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 75 and the episode is 4136 and the total_steps are 196544\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4136     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6832     |\n",
      "|    total_timesteps  | 196544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 36635    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 2, 2, 2, 2, 1, 3, 0, 3, 3, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 17 and the episode is 4137 and the total_steps are 196561\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 2, 1, 1, 1, 2, 3, 3, 3, 0, 1, 0, 2, 2, 1, 2, 2, 1, 1, 2, 3, 0, 1, 0, 3, 1, 3, 1, 0, 3, 2, 2, 0, 1, 0, 0, 1, 3, 1, 0, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 2, 3, 2, 0, 0, 0, 0, 0, 3, 0, 2, 3, 1, 3, 2, 2, 2, 3, 2, 1, 1, 1, 3, 2, 2, 2, 2, 1, 0, 3, 3, 1, 1, 0, 1, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -932. And steps were 96 and the episode is 4138 and the total_steps are 196657\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 0, 1, 3, 2, 3, 2, 3, 0, 3, 2, 2, 0, 2, 3, 1, 0, 1, 0, 0, 2, 1, 0, 2, 1, 0, 0, 1, 0, 3, 0, 2, 0, 2, 2, 0, 0, 0, 1, 1, 0, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 48 and the episode is 4139 and the total_steps are 196705\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 1, 0, 3, 2, 0, 2, 2, 2, 1, 3, 0, 3, 0, 2, 1, 1, 3, 3, 2, 2, 1, 2, 2, 3, 2, 3, 3, 1, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4140 and the total_steps are 196741\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.7     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4140     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6841     |\n",
      "|    total_timesteps  | 196741   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.5     |\n",
      "|    n_updates        | 36685    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0, 2, 1, 1, 2, 3, 2, 2, 2, 1, 1, 0, 3, 1, 0, 2, 1, 3, 1, 2, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 36 and the episode is 4141 and the total_steps are 196777\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 0, 3, 0, 1, 3, 2, 1, 3, 1, 3, 0, 3, 2, 0, 0, 0, 3, 0, 2, 1, 2, 3, 1, 3, 2, 0, 1, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 35 and the episode is 4142 and the total_steps are 196812\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 2, 2, 0, 1, 0, 0, 0, 2, 2, 1, 2, 2, 2, 1, 3, 3, 2, 0, 2, 1, 3, 2, 3, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 31 and the episode is 4143 and the total_steps are 196843\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 0, 3, 3, 2, 0, 3, 1, 3, 2, 1, 1, 2, 0, 3, 2, 3, 2, 1, 1, 1, 0, 1, 1, 0, 0, 2, 0, 3, 2, 0, 1, 1, 0, 2, 0, 1, 1, 2, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 46 and the episode is 4144 and the total_steps are 196889\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4144     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6847     |\n",
      "|    total_timesteps  | 196889   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 36722    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 0, 2, 2, 2, 3, 0, 1, 2, 0, 0, 1, 3, 0, 3, 2, 1, 3, 3, 3, 1, 3, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 29 and the episode is 4145 and the total_steps are 196918\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 3, 1, 2, 1, 2, 2, 3, 1, 2, 2, 2, 2, 0, 1, 2, 3, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 24 and the episode is 4146 and the total_steps are 196942\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 0, 3, 3, 3, 2, 0, 3, 3, 2, 2, 3, 3, 2, 1, 1, 2, 2, 1, 3, 1, 0, 3, 1, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 31 and the episode is 4147 and the total_steps are 196973\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 2, 3, 1, 1, 2, 0, 2, 3, 0, 2, 0, 1, 0, 3, 3, 3, 3, 1, 0, 3, 2, 2, 1, 1, 0, 3, 1, 0, 0, 1, 1, 3, 3, 3, 1, 2, 0, 0, 1, 0, 2, 0, 0, 3, 1, 3, 1, 1, 3, 3, 0, 2, 3, 0, 2, 0, 0, 0, 0, 2, 3, 3, 2, 2, 1, 3, 3, 0, 2, 3, 2, 3, 3, 2, 3, 2, 0, 1, 3, 2, 3, 3, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 90 and the episode is 4148 and the total_steps are 197063\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4148     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6854     |\n",
      "|    total_timesteps  | 197063   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.49     |\n",
      "|    n_updates        | 36765    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 2, 3, 0, 3, 3, 2, 0, 1, 0, 2, 1, 3, 0, 2, 0, 3, 3, 2, 3, 2, 1, 2, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 30 and the episode is 4149 and the total_steps are 197093\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 0, 2, 0, 0, 2, 2, 1, 2, 1, 1, 2, 0, 2, 1, 1, 3, 3, 1, 0, 2, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 4150 and the total_steps are 197121\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 0, 2, 2, 1, 3, 1, 2, 1, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 4151 and the total_steps are 197137\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 2, 2, 1, 3, 1, 2, 3, 3, 3, 2, 2, 0, 2, 2, 2, 1, 3, 0, 2, 2, 2, 2, 3, 0, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 32 and the episode is 4152 and the total_steps are 197169\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4152     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6859     |\n",
      "|    total_timesteps  | 197169   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.6     |\n",
      "|    n_updates        | 36792    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 2, 1, 2, 2, 1, 2, 0, 0, 2, 0, 3, 0, 2, 1, 0, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 22 and the episode is 4153 and the total_steps are 197191\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 0, 3, 2, 2, 0, 0, 0, 2, 1, 3, 3, 2, 1, 2, 1, 1, 2, 1, 0, 3, 0, 2, 3, 1, 0, 1, 2, 2, 2, 0, 2, 1, 2, 1, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 42 and the episode is 4154 and the total_steps are 197233\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 1, 3, 1, 0, 1, 2, 2, 1, 0, 1, 1, 0, 2, 2, 2, 3, 3, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4155 and the total_steps are 197265\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 2, 1, 0, 1, 2, 0, 0, 2, 3, 0, 1, 3, 3, 2, 1, 3, 2, 2, 1, 0, 0, 2, 3, 2, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 32 and the episode is 4156 and the total_steps are 197297\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4156     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6865     |\n",
      "|    total_timesteps  | 197297   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.02     |\n",
      "|    n_updates        | 36824    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 1, 3, 0, 2, 0, 1, 2, 0, 2, 0, 1, 1, 0, 2, 1, 3, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 24 and the episode is 4157 and the total_steps are 197321\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 1, 3, 1, 1, 2, 2, 2, 3, 2, 0, 3, 2, 1, 2, 3, 2, 0, 3, 0, 3, 2, 2, 3, 3, 2, 1, 2, 2, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 36 and the episode is 4158 and the total_steps are 197357\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 2, 2, 1, 2, 1, 2, 0, 2, 3, 3, 2, 1, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 4159 and the total_steps are 197388\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 0, 3, 3, 1, 1, 2, 0, 1, 1, 0, 0, 2, 1, 3, 1, 0, 1, 0, 0, 3, 0, 2, 0, 3, 3, 3, 1, 2, 0, 0, 3, 3, 1, 2, 2, 1, 1, 2, 2, 0, 3, 0, 2, 1, 3, 0, 1, 2, 2, 1, 0, 2, 2, 1, 3, 2, 3, 0, 3, 2, 0, 1, 0, 3, 2, 1, 3, 2, 0, 2, 3, 0, 2, 1, 3, 0, 1, 0, 3, 0, 1, 3, 3, 0, 0, 2, 3, 2, 1, 2, 2, 2, 0, 0, 1, 2, 3, 3, 2, 1, 0, 0, 2, 3, 1, 2, 1, 0, 2, 1, 0, 2, 1, 2, 1, 2, 3, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -881. And steps were 125 and the episode is 4160 and the total_steps are 197513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | -874     |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4160     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6874     |\n",
      "|    total_timesteps  | 197513   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 30.8     |\n",
      "|    n_updates        | 36878    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 0, 0, 0, 2, 1, 2, 1, 2, 1, 3, 2, 3, 1, 1, 1, 1, 3, 3, 2, 3, 2, 0, 0, 2, 2, 2, 3, 3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 3, 3, 0, 2, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 49 and the episode is 4161 and the total_steps are 197562\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 3, 2, 3, 2, 0, 0, 1, 3, 0, 3, 3, 0, 1, 2, 3, 1, 1, 2, 1, 1, 0, 0, 2, 0, 0, 3, 1, 3, 1, 2, 2, 0, 1, 3, 3, 3, 3, 2, 0, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 59 and the episode is 4162 and the total_steps are 197621\n",
      "Done condition: collision\n",
      "[0, 2, 2, 3, 0, 1, 3, 1, 1, 1, 0, 2, 3, 1, 0, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 3, 3, 1, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 4163 and the total_steps are 197653\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 2, 2, 1, 1, 3, 2, 1, 3, 3, 0, 2, 0, 1, 1, 2, 0, 3, 0, 1, 2, 0, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 29 and the episode is 4164 and the total_steps are 197682\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.2     |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4164     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6881     |\n",
      "|    total_timesteps  | 197682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.61     |\n",
      "|    n_updates        | 36920    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 3, 3, 3, 2, 0, 3, 1, 2, 0, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was 988. And steps were 15 and the episode is 4165 and the total_steps are 197697\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 2, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1, 0, 0, 0, 0, 2, 2, 3, 3, 1, 3, 1, 2, 2, 0, 0, 0, 3, 0, 0, 1, 3, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 40 and the episode is 4166 and the total_steps are 197737\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 0, 1, 3, 3, 0, 3, 3, 0, 1, 2, 2, 1, 2, 3, 3, 1, 0, 3, 0, 2, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4167 and the total_steps are 197765\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 1, 3, 0, 2, 0, 3, 1, 3, 2, 0, 2, 1, 1, 3, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 3, 3, 3, 2, 1, 2, 0, 3, 1, 1, 1, 3, 3, 2, 0, 1, 0, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 60 and the episode is 4168 and the total_steps are 197825\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -874     |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4168     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6887     |\n",
      "|    total_timesteps  | 197825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 36956    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 2, 3, 2, 3, 1, 3, 1, 2, 1, 1, 3, 3, 3, 1, 1, 3, 1, 0, 0, 2, 0, 2, 1, 3, 0, 1, 2, 2, 2, 2, 1, 0, 3, 2, 0, 1, 1, 1, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 46 and the episode is 4169 and the total_steps are 197871\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 1, 3, 3, 1, 0, 2, 0, 2, 0, 3, 1, 1, 3, 3, 2, 3, 3, 3, 2, 0, 0, 1, 1, 1, 2, 2, 1, 1, 0, 0, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 4170 and the total_steps are 197909\n",
      "Done condition: collision\n",
      "[3, 1, 3, 1, 1, 1, 1, 3, 2, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 3, 1, 3, 3, 2, 2, 2, 3, 2, 3, 0, 1, 3, 2, 3, 0, 0, 2, 0, 1, 2, 1, 1, 3, 1, 3, 3, 1, 0, 0, 2, 1, 2, 3, 2, 2, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -944. And steps were 60 and the episode is 4171 and the total_steps are 197969\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 2, 3, 1, 0, 3, 0, 2, 3, 2, 1, 3, 3, 2, 1, 1, 3, 2, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4172 and the total_steps are 197994\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -874     |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4172     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6894     |\n",
      "|    total_timesteps  | 197994   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.3     |\n",
      "|    n_updates        | 36998    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 1, 1, 3, 1, 0, 3, 0, 2, 2, 1, 0, 0, 3, 1, 2, 2, 1, 3, 2, 2, 2, 0, 0, 2, 1, 1, 2, 1, 0, 3, 2, 2, 1, 3, 0, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 43 and the episode is 4173 and the total_steps are 198037\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 2, 3, 3, 2, 3, 2, 2, 1, 3, 0, 2, 2, 2, 3, 1, 3, 0, 2, 2, 3, 2, 3, 0, 3, 0, 1, 3, 0, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4174 and the total_steps are 198073\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 0, 0, 0, 0, 0, 2, 3, 2, 1, 0, 0, 0, 0, 1, 2, 2, 2, 3, 2, 0, 0, 3, 1, 0, 2, 3, 3, 2, 1, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 36 and the episode is 4175 and the total_steps are 198109\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 1, 1, 2, 2, 3, 2, 1, 0, 2, 0, 2, 1, 1, 2, 1, 3, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 24 and the episode is 4176 and the total_steps are 198133\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4176     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6900     |\n",
      "|    total_timesteps  | 198133   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 37033    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 0, 3, 1, 2, 1, 3, 1, 2, 0, 0, 2, 2, 0, 3, 0, 3, 2, 1, 0, 1, 1, 2, 3, 3, 0, 1, 2, 1, 2, 3, 3, 2, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 40 and the episode is 4177 and the total_steps are 198173\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 3, 0, 1, 1, 1, 0, 1, 3, 2, 0, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was 987. And steps were 16 and the episode is 4178 and the total_steps are 198189\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 3, 3, 0, 1, 0, 1, 0, 2, 3, 1, 0, 2, 3, 3, 3, 1, 0, 2, 0, 3, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 28 and the episode is 4179 and the total_steps are 198217\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 2, 0, 2, 1, 0, 0, 0, 2, 2, 0, 0, 1, 3, 1, 2, 3, 2, 2, 2, 3, 3, 3, 1, 3, 2, 0, 0, 0, 1, 3, 3, 0, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 40 and the episode is 4180 and the total_steps are 198257\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -856     |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4180     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6905     |\n",
      "|    total_timesteps  | 198257   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.82     |\n",
      "|    n_updates        | 37064    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 1, 2, 1, 0, 1, 2, 2, 3, 1, 3, 0, 2, 3, 3, 2, 3, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 22 and the episode is 4181 and the total_steps are 198279\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 1, 2, 1, 3, 2, 1, 0, 3, 0, 1, 2, 2, 3, 1, 2, 0, 2, 2, 0, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 27 and the episode is 4182 and the total_steps are 198306\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 0, 1, 3, 2, 0, 0, 2, 0, 2, 3, 0, 1, 0, 1, 3, 0, 3, 3, 0, 1, 2, 3, 1, 3, 2, 2, 1, 1, 2, 3, 1, 1, 1, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -965. And steps were 41 and the episode is 4183 and the total_steps are 198347\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 2, 1, 0, 0, 3, 0, 3, 3, 3, 3, 1, 3, 2, 2, 1, 2, 2, 1, 3, 3, 1, 3, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 30 and the episode is 4184 and the total_steps are 198377\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -836     |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4184     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6910     |\n",
      "|    total_timesteps  | 198377   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 67.3     |\n",
      "|    n_updates        | 37094    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 0, 1, 1, 0, 2, 1, 1, 1, 3, 3, 2, 3, 1, 3, 1, 0, 3, 0, 0, 0, 2, 3, 0, 2, 0, 2, 2, 2, 3, 1, 0, 0, 1, 1, 2, 2, 1, 3, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 46 and the episode is 4185 and the total_steps are 198423\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 2, 1, 1, 3, 0, 2, 3, 1, 3, 1, 3, 3, 0, 3, 2, 2, 0, 2, 3, 0, 0, 0, 2, 0, 3, 1, 0, 0, 2, 2, 2, 1, 3, 2, 2, 3, 0, 2, 0, 3, 0, 2, 2, 1, 1, 2, 3, 2, 0, 2, 1, 0, 2, 3, 0, 2, 0, 1, 2, 2, 2, 1, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 71 and the episode is 4186 and the total_steps are 198494\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 2, 2, 1, 1, 2, 2, 3, 2, 1, 0, 3, 2, 3, 1, 3, 1, 3, 0, 3, 1, 2, 0, 2, 2, 1, 1, 0, 1, 3, 3, 0, 2, 0, 3, 2, 0, 2, 0, 2, 0, 0, 3, 2, 1, 3, 2, 3, 2, 1, 3, 2, 2, 3, 1, 2, 3, 0, 0, 2, 0, 0, 3, 1, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 71 and the episode is 4187 and the total_steps are 198565\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 2, 3, 0, 1, 3, 3, 1, 0, 3, 0, 3, 0, 0, 0, 0, 0, 2, 1, 2, 3, 1, 0, 1, 2, 0, 3, 2, 1, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 36 and the episode is 4188 and the total_steps are 198601\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -836     |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4188     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6919     |\n",
      "|    total_timesteps  | 198601   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 37150    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 2, 0, 1, 1, 1, 1, 3, 0, 2, 0, 2, 1, 1, 0, 3, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 23 and the episode is 4189 and the total_steps are 198624\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 3, 1, 0, 3, 1, 3, 1, 2, 2, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 17 and the episode is 4190 and the total_steps are 198641\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 2, 3, 0, 1, 3, 2, 2, 1, 1, 1, 2, 1, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 20 and the episode is 4191 and the total_steps are 198661\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 1, 1, 1, 3, 3, 1, 0, 0, 2, 2, 2, 3, 2, 1, 1, 0, 3, 3, 2, 0, 3, 1, 3, 2, 3, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 33 and the episode is 4192 and the total_steps are 198694\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -836     |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4192     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6924     |\n",
      "|    total_timesteps  | 198694   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.23     |\n",
      "|    n_updates        | 37173    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 3, 2, 3, 2, 3, 1, 3, 0, 3, 1, 0, 2, 0, 0, 3, 1, 1, 3, 1, 0, 1, 1, 0, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 4193 and the total_steps are 198725\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 2, 1, 3, 2, 1, 3, 0, 2, 1, 3, 1, 0, 3, 3, 3, 1, 0, 2, 1, 3, 2, 1, 0, 2, 2, 1, 3, 3, 3, 1, 0, 2, 1, 1, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 4194 and the total_steps are 198777\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 1, 0, 2, 2, 3, 0, 1, 2, 2, 1, 1, 0, 1, 0, 3, 0, 1, 2, 2, 3, 0, 0, 0, 2, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 31 and the episode is 4195 and the total_steps are 198808\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 0, 3, 2, 3, 0, 1, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 2, 1, 2, 2, 1, 2, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 33 and the episode is 4196 and the total_steps are 198841\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -836     |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4196     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6930     |\n",
      "|    total_timesteps  | 198841   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 37210    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 0, 3, 3, 2, 0, 1, 0, 0, 0, 3, 0, 1, 1, 1, 3, 2, 2, 2, 3, 3, 2, 2, 0, 0, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4197 and the total_steps are 198873\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 3, 1, 3, 3, 2, 1, 1, 2, 0, 2, 2, 3, 1, 2, 2, 3, 2, 2, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 4198 and the total_steps are 198899\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 0, 1, 1, 1, 3, 2, 0, 2, 1, 1, 0, 3, 3, 3, 1, 2, 2, 1, 2, 3, 3, 2, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 30 and the episode is 4199 and the total_steps are 198929\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 2, 3, 1, 1, 1, 3, 2, 2, 1, 1, 0, 0, 0, 1, 2, 0, 2, 1, 1, 1, 0, 3, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 30 and the episode is 4200 and the total_steps are 198959\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4200     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6935     |\n",
      "|    total_timesteps  | 198959   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 37239    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 3, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 1, 1, 0, 0, 0, 3, 3, 2, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 27 and the episode is 4201 and the total_steps are 198986\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 0, 2, 3, 3, 0, 1, 0, 3, 0, 0, 3, 1, 1, 0, 1, 2, 0, 1, 2, 2, 2, 0, 3, 0, 0, 2, 2, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 35 and the episode is 4202 and the total_steps are 199021\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 3, 1, 1, 0, 1, 0, 2, 2, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 4203 and the total_steps are 199037\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 1, 2, 0, 2, 0, 0, 1, 0, 0, 3, 2, 3, 1, 1, 2, 0, 2, 1, 0, 3, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4204 and the total_steps are 199065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4204     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6940     |\n",
      "|    total_timesteps  | 199065   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.48     |\n",
      "|    n_updates        | 37266    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 2, 3, 0, 3, 0, 3, 1, 0, 2, 3, 0, 3, 1, 0, 1, 2, 1, 1, 0, 3, 2, 3, 2, 2, 0, 0, 1, 3, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 36 and the episode is 4205 and the total_steps are 199101\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 3, 0, 3, 1, 2, 3, 3, 1, 0, 0, 2, 3, 0, 2, 2, 0, 1, 1, 3, 3, 3, 3, 3, 2, 2, 3, 0, 3, 1, 1, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 45 and the episode is 4206 and the total_steps are 199146\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 0, 3, 1, 2, 0, 2, 3, 3, 2, 0, 1, 2, 1, 1, 2, 0, 3, 1, 3, 1, 1, 3, 3, 2, 3, 0, 2, 2, 2, 3, 1, 2, 0, 0, 3, 0, 1, 1, 2, 1, 3, 2, 2, 3, 2, 1, 3, 3, 3, 2, 2, 1, 2, 0, 2, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 63 and the episode is 4207 and the total_steps are 199209\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 0, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 2, 3, 3, 1, 1, 1, 0, 1, 2, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 4208 and the total_steps are 199235\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | -836     |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4208     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6947     |\n",
      "|    total_timesteps  | 199235   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.3     |\n",
      "|    n_updates        | 37308    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 2, 2, 0, 0, 3, 1, 0, 0, 3, 3, 2, 3, 1, 0, 0, 3, 2, 1, 0, 3, 0, 1, 2, 1, 2, 2, 2, 2, 2, 3, 3, 1, 1, 3, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 42 and the episode is 4209 and the total_steps are 199277\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 0, 3, 2, 3, 1, 2, 1, 3, 2, 2, 1, 3, 2, 1, 1, 2, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 24 and the episode is 4210 and the total_steps are 199301\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 2, 3, 0, 1, 2, 3, 0, 1, 3, 0, 2, 1, 0, 3, 1, 0, 0, 2, 1, 0, 1, 3, 2, 1, 2, 3, 3, 2, 1, 2, 3, 1, 2, 2, 1, 2, 2, 2, 0, 1, 1, 1, 2, 0, 2, 3, 0, 3, 2, 3, 2, 3, 2, 0, 2, 2, 2, 0, 1, 3, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -938. And steps were 68 and the episode is 4211 and the total_steps are 199369\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 1, 1, 2, 0, 1, 3, 0, 0, 3, 3, 1, 1, 1, 1, 3, 0, 1, 0, 2, 2, 3, 2, 1, 3, 3, 0, 3, 2, 1, 2, 0, 0, 2, 0, 3, 1, 0, 1, 3, 1, 1, 2, 3, 1, 3, 2, 1, 2, 0, 0, 2, 0, 2, 0, 0, 3, 1, 2, 1, 2, 0, 2, 0, 1, 3, 3, 0, 1, 1, 2, 3, 0, 2, 3, 2, 3, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -938. And steps were 84 and the episode is 4212 and the total_steps are 199453\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4212     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6956     |\n",
      "|    total_timesteps  | 199453   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.61     |\n",
      "|    n_updates        | 37363    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 3, 0, 3, 2, 3, 3, 1, 3, 2, 1, 3, 1, 3, 0, 0, 2, 2, 0, 1, 2, 3, 3, 1, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 31 and the episode is 4213 and the total_steps are 199484\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 3, 2, 2, 2, 0, 2, 0, 0, 3, 2, 0, 2, 1, 0, 3, 2, 3, 3, 2, 3, 3, 0, 2, 3, 0, 0, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 2, 3, 0, 2, 2, 1, 2, 1, 0, 0, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 53 and the episode is 4214 and the total_steps are 199537\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 3, 0, 1, 0, 0, 0, 0, 0, 0, 3, 1, 2, 0, 3, 3, 2, 2, 3, 2, 0, 2, 1, 0, 1, 3, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was 1030. And steps were 31 and the episode is 4215 and the total_steps are 199568\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 2, 3, 0, 2, 1, 3, 1, 2, 1, 3, 0, 0, 3, 0, 2, 0, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 22 and the episode is 4216 and the total_steps are 199590\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -854     |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4216     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6962     |\n",
      "|    total_timesteps  | 199590   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 37397    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 3, 0, 2, 3, 0, 0, 1, 3, 2, 0, 3, 1, 1, 0, 0, 3, 3, 1, 0, 1, 3, 0, 1, 2, 0, 1, 3, 1, 0, 2, 2, 1, 0, 0, 3, 3, 1, 1, 3, 1, 2, 2, 0, 1, 1, 0, 3, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 55 and the episode is 4217 and the total_steps are 199645\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 1, 1, 1, 0, 2, 3, 3, 1, 2, 1, 0, 1, 1, 0, 2, 0, 2, 2, 3, 3, 0, 2, 1, 1, 0, 0, 1, 2, 0, 0, 1, 2, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 40 and the episode is 4218 and the total_steps are 199685\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 2, 1, 3, 1, 1, 1, 3, 3, 1, 3, 0, 3, 3, 2, 2, 1, 0, 3, 2, 3, 0, 0, 0, 3, 2, 1, 1, 1, 0, 3, 3, 3, 2, 1, 1, 3, 0, 3, 2, 0, 2, 0, 3, 3, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 52 and the episode is 4219 and the total_steps are 199737\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 0, 2, 1, 2, 2, 3, 2, 3, 1, 3, 1, 0, 0, 0, 1, 2, 3, 3, 3, 1, 3, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4220 and the total_steps are 199765\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -855     |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4220     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6970     |\n",
      "|    total_timesteps  | 199765   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.07     |\n",
      "|    n_updates        | 37441    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 2, 3, 2, 3, 3, 3, 1, 2, 3, 0, 3, 2, 1, 1, 2, 1, 2, 3, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 4221 and the total_steps are 199791\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 1, 3, 2, 0, 0, 3, 3, 2, 2, 3, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 18 and the episode is 4222 and the total_steps are 199809\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 1, 3, 3, 2, 0, 1, 1, 2, 3, 0, 3, 2, 3, 0, 2, 3, 2, 2, 1, 0, 3, 2, 2, 2, 3, 0, 2, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -969. And steps were 35 and the episode is 4223 and the total_steps are 199844\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 3, 2, 1, 1, 1, 0, 1, 0, 3, 3, 2, 0, 2, 0, 0, 0, 2, 1, 2, 1, 0, 2, 3, 1, 2, 0, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 33 and the episode is 4224 and the total_steps are 199877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -855     |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4224     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6974     |\n",
      "|    total_timesteps  | 199877   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.42     |\n",
      "|    n_updates        | 37469    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 3, 3, 2, 3, 3, 2, 1, 0, 3, 3, 1, 1, 2, 1, 3, 3, 2, 1, 3, 3, 2, 3, 1, 0, 0, 3, 0, 0, 0, 3, 1, 0, 3, 2, 3, 0, 2, 2, 2, 0, 1, 3, 1, 1, 2, 3, 1, 1, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1054. And steps were 56 and the episode is 4225 and the total_steps are 199933\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 3, 0, 3, 1, 2, 3, 0, 0, 1, 0, 0, 2, 0, 3, 0, 2, 0, 3, 3, 0, 2, 1, 0, 3, 1, 2, 0, 2, 0, 0, 3, 1, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 4226 and the total_steps are 199973\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 3, 3, 3, 2, 1, 3, 0, 2, 0, 2, 1, 3, 2, 0, 1, 1, 1, 3, 1, 3, 1, 0, 3, 2, 2, 1, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 34 and the episode is 4227 and the total_steps are 200007\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 2, 1, 0, 3, 0, 3, 0, 3, 2, 1, 1, 2, 2, 3, 0, 0, 2, 0, 2, 0, 2, 0, 2, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 31 and the episode is 4228 and the total_steps are 200038\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -856     |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4228     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6982     |\n",
      "|    total_timesteps  | 200038   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.39     |\n",
      "|    n_updates        | 37509    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 3, 3, 1, 1, 3, 2, 2, 3, 3, 3, 0, 3, 1, 3, 1, 3, 1, 1, 0, 1, 3, 0, 1, 1, 1, 3, 2, 3, 2, 2, 0, 3, 3, 0, 2, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 43 and the episode is 4229 and the total_steps are 200081\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 0, 2, 1, 3, 1, 3, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 3, 0, 0, 0, 1, 1, 2, 2, 3, 3, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 4230 and the total_steps are 200117\n",
      "Done condition: collision\n",
      "[2, 0, 1, 2, 2, 1, 0, 2, 2, 0, 2, 3, 1, 3, 2, 1, 2, 3, 2, 2, 0, 2, 2, 3, 0, 3, 1, 2, 2, 2, 3, 2, 1, 1, 2, 0, 1, 3, 2, 0, 2, 3, 0, 2, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 48 and the episode is 4231 and the total_steps are 200165\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 0, 1, 1, 0, 2, 1, 2, 0, 1, 0, 3, 1, 3, 3, 0, 3, 0, 2, 1, 2, 2, 0, 3, 1, 1, 3, 3, 2, 1, 0, 2, 3, 0, 0, 1, 3, 0, 1, 1, 3, 0, 2, 0, 3, 3, 3, 3, 0, 2, 1, 0, 0, 3, 3, 3, 1, 0, 2, 3, 2, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -944. And steps were 68 and the episode is 4232 and the total_steps are 200233\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4232     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6990     |\n",
      "|    total_timesteps  | 200233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.9     |\n",
      "|    n_updates        | 37558    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 3, 1, 1, 2, 0, 2, 1, 1, 3, 3, 1, 0, 2, 2, 3, 3, 2, 0, 2, 1, 2, 2, 3, 3, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 32 and the episode is 4233 and the total_steps are 200265\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 1, 2, 0, 0, 1, 2, 3, 3, 3, 1, 0, 2, 0, 3, 0, 0, 2, 3, 2, 1, 2, 1, 3, 1, 0, 2, 2, 3, 1, 1, 0, 3, 2, 3, 1, 3, 0, 0, 1, 3, 3, 0, 1, 0, 2, 1, 2, 0, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 56 and the episode is 4234 and the total_steps are 200321\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 0, 1, 2, 2, 0, 3, 1, 0, 2, 2, 3, 0, 2, 1, 1, 1, 0, 1, 2, 2, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 27 and the episode is 4235 and the total_steps are 200348\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 0, 2, 3, 3, 2, 3, 2, 1, 0, 2, 3, 1, 1, 2, 0, 0, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 3, 1, 2, 2, 2, 1, 1, 0, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 42 and the episode is 4236 and the total_steps are 200390\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -874     |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4236     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 6997     |\n",
      "|    total_timesteps  | 200390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.5     |\n",
      "|    n_updates        | 37597    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 0, 3, 1, 2, 3, 1, 0, 3, 1, 2, 2, 1, 0, 2, 2, 2, 2, 3, 3, 3, 1, 0, 3, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 31 and the episode is 4237 and the total_steps are 200421\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 0, 0, 1, 2, 1, 3, 2, 3, 0, 3, 3, 2, 1, 1, 2, 1, 1, 3, 3, 1, 2, 0, 3, 1, 1, 0, 2, 0, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 4238 and the total_steps are 200457\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 1, 0, 3, 0, 3, 0, 0, 0, 0, 2, 2, 0, 2, 2, 3, 3, 0, 1, 1, 2, 0, 0, 0, 1, 2, 0, 3, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 35 and the episode is 4239 and the total_steps are 200492\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 0, 0, 1, 3, 3, 1, 3, 1, 1, 3, 0, 1, 0, 0, 2, 0, 0, 1, 3, 1, 1, 1, 3, 1, 0, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 4240 and the total_steps are 200525\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4240     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7002     |\n",
      "|    total_timesteps  | 200525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.1      |\n",
      "|    n_updates        | 37631    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 2, 3, 0, 1, 3, 0, 2, 1, 0, 0, 1, 3, 3, 0, 2, 3, 0, 0, 3, 0, 1, 2, 3, 2, 3, 2, 0, 3, 2, 1, 3, 1, 1, 1, 3, 2, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 44 and the episode is 4241 and the total_steps are 200569\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 3, 1, 0, 1, 2, 1, 0, 2, 1, 2, 0, 1, 3, 2, 1, 1, 0, 3, 2, 2, 0, 1, 2, 2, 1, 1, 1, 1, 0, 2, 1, 2, 3, 3, 3, 0, 0, 3, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 46 and the episode is 4242 and the total_steps are 200615\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 3, 1, 3, 1, 3, 1, 0, 2, 2, 3, 2, 0, 1, 2, 2, 1, 2, 0, 2, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 27 and the episode is 4243 and the total_steps are 200642\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 1, 2, 2, 2, 3, 1, 1, 2, 3, 2, 0, 0, 3, 3, 1, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 23 and the episode is 4244 and the total_steps are 200665\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -874     |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4244     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7008     |\n",
      "|    total_timesteps  | 200665   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.9     |\n",
      "|    n_updates        | 37666    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 0, 2, 0, 2, 2, 3, 0, 0, 0, 2, 3, 1, 1, 0, 3, 1, 3, 1, 2, 2, 3, 3, 2, 0, 2, 3, 2, 1, 1, 3, 3, 2, 0, 1, 3, 1, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 44 and the episode is 4245 and the total_steps are 200709\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 0, 3, 2, 0, 3, 1, 1, 1, 3, 3, 3, 1, 0, 2, 1, 2, 3, 2, 3, 0, 2, 1, 3, 1, 1, 1, 3, 2, 2, 2, 0, 2, 3, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 41 and the episode is 4246 and the total_steps are 200750\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 0, 0, 1, 0, 2, 2, 0, 1, 2, 1, 0, 2, 1, 1, 2, 0, 0, 3, 3, 2, 1, 3, 3, 1, 0, 2, 0, 0, 0, 3, 2, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 39 and the episode is 4247 and the total_steps are 200789\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 1, 1, 3, 2, 1, 2, 2, 3, 2, 3, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 3, 0, 3, 2, 0, 2, 0, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 36 and the episode is 4248 and the total_steps are 200825\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4248     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7015     |\n",
      "|    total_timesteps  | 200825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.7     |\n",
      "|    n_updates        | 37706    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 3, 2, 1, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1, 2, 0, 2, 2, 0, 2, 2, 1, 0, 1, 2, 3, 2, 3, 2, 1, 0, 2, 3, 2, 1, 0, 1, 3, 0, 2, 2, 3, 0, 2, 0, 1, 0, 2, 3, 3, 3, 2, 2, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 60 and the episode is 4249 and the total_steps are 200885\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 2, 1, 1, 3, 1, 1, 1, 1, 2, 2, 3, 3, 2, 3, 2, 0, 2, 0, 0, 0, 3, 3, 1, 2, 1, 0, 0, 1, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 36 and the episode is 4250 and the total_steps are 200921\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 1, 3, 3, 3, 3, 2, 0, 2, 1, 3, 2, 3, 3, 2, 3, 0, 0, 3, 3, 2, 0, 1, 1, 0, 0, 1, 3, 0, 2, 1, 1, 0, 1, 0, 1, 2, 1, 3, 1, 0, 3, 1, 2, 2, 2, 0, 0, 2, 3, 0, 0, 1, 3, 2, 3, 0, 1, 2, 0, 2, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 68 and the episode is 4251 and the total_steps are 200989\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 2, 3, 0, 1, 1, 3, 0, 1, 1, 1, 1, 3, 3, 3, 2, 1, 0, 3, 0, 0, 0, 2, 1, 2, 3, 1, 0, 0, 1, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1035. And steps were 37 and the episode is 4252 and the total_steps are 201026\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -875     |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4252     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7023     |\n",
      "|    total_timesteps  | 201026   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 94.4     |\n",
      "|    n_updates        | 37756    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 3, 0, 1, 2, 0, 0, 3, 1, 2, 2, 0, 3, 2, 2, 1, 0, 1, 2, 1, 2, 0, 2, 1, 0, 1, 0, 0, 0, 0, 2, 3, 3, 1, 3, 0, 2, 3, 0, 3, 1, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 4253 and the total_steps are 201074\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 0, 1, 3, 3, 2, 3, 0, 0, 3, 2, 0, 1, 0, 2, 3, 1, 1, 3, 0, 0, 2, 0, 0, 3, 3, 0, 1, 2, 0, 2, 3, 2, 1, 1, 3, 0, 3, 1, 3, 3, 0, 1, 2, 0, 3, 0, 3, 3, 3, 1, 1, 2, 3, 2, 2, 1, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 64 and the episode is 4254 and the total_steps are 201138\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 0, 2, 3, 1, 1, 1, 3, 3, 2, 3, 2, 2, 0, 2, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 2, 0, 3, 2, 3, 2, 1, 2, 1, 1, 0, 2, 3, 1, 0, 1, 1, 0, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 51 and the episode is 4255 and the total_steps are 201189\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 1, 2, 3, 1, 2, 3, 0, 2, 2, 0, 0, 3, 3, 1, 1, 1, 3, 2, 2, 2, 1, 2, 0, 3, 0, 2, 3, 0, 2, 3, 2, 3, 1, 1, 1, 3, 2, 1, 3, 0, 2, 3, 3, 0, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 52 and the episode is 4256 and the total_steps are 201241\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4256     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7032     |\n",
      "|    total_timesteps  | 201241   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.59     |\n",
      "|    n_updates        | 37810    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 1, 1, 0, 1, 0, 2, 0, 2, 3, 1, 0, 3, 1, 2, 1, 3, 0, 1, 1, 2, 3, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 29 and the episode is 4257 and the total_steps are 201270\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 1, 2, 2, 3, 3, 0, 0, 0, 1, 1, 1, 2, 3, 3, 2, 0, 3, 2, 2, 1, 0, 1, 3, 0, 3, 1, 0, 3, 3, 2, 1, 1, 1, 0, 3, 1, 0, 0, 0, 3, 1, 1, 3, 2, 2, 0, 1, 1, 3, 3, 2, 2, 2, 0, 0, 1, 3, 1, 2, 3, 1, 1, 2, 2, 0, 2, 3, 0, 3, 2, 0, 0, 3, 3, 2, 1, 3, 2, 2, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1065. And steps were 87 and the episode is 4258 and the total_steps are 201357\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 3, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 3, 3, 3, 3, 2, 0, 1, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 4259 and the total_steps are 201381\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 3, 2, 1, 3, 2, 1, 0, 0, 0, 2, 1, 1, 2, 2, 1, 2, 2, 0, 3, 0, 1, 0, 1, 2, 2, 0, 2, 2, 0, 2, 2, 1, 1, 1, 1, 1, 0, 2, 2, 3, 1, 2, 3, 2, 2, 2, 3, 3, 0, 2, 0, 0, 1, 1, 1, 3, 3, 0, 1, 1, 1, 3, 2, 2, 2, 0, 3, 3, 0, 1, 2, 0, 3, 0, 0, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 83 and the episode is 4260 and the total_steps are 201464\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4260     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7042     |\n",
      "|    total_timesteps  | 201464   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 37865    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 2, 0, 1, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 22 and the episode is 4261 and the total_steps are 201486\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 2, 3, 0, 2, 1, 0, 1, 0, 3, 0, 3, 0, 2, 2, 1, 0, 3, 2, 3, 1, 0, 2, 0, 3, 2, 0, 0, 0, 3, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 37 and the episode is 4262 and the total_steps are 201523\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 2, 1, 2, 3, 0, 1, 1, 2, 0, 3, 3, 2, 1, 1, 3, 1, 1, 2, 2, 2, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4263 and the total_steps are 201551\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0, 1, 2, 2, 3, 0, 3, 2, 1, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 32 and the episode is 4264 and the total_steps are 201583\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -858     |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4264     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7047     |\n",
      "|    total_timesteps  | 201583   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.98     |\n",
      "|    n_updates        | 37895    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 0, 3, 3, 1, 3, 3, 2, 0, 1, 1, 1, 3, 0, 3, 2, 0, 3, 3, 1, 2, 1, 1, 2, 2, 2, 0, 2, 0, 1, 2, 2, 3, 2, 2, 1, 0, 2, 1, 0, 0, 2, 0, 2, 0, 1, 1, 2, 2, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 56 and the episode is 4265 and the total_steps are 201639\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 3, 1, 2, 3, 2, 2, 3, 3, 2, 3, 0, 3, 2, 2, 1, 0, 3, 2, 1, 1, 1, 3, 2, 2, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4266 and the total_steps are 201671\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 0, 0, 1, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 3, 3, 2, 3, 3, 1, 1, 2, 1, 1, 0, 2, 3, 2, 0, 2, 0, 2, 2, 3, 2, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 42 and the episode is 4267 and the total_steps are 201713\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 1, 3, 1, 2, 0, 2, 1, 3, 3, 3, 2, 3, 2, 0, 1, 3, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 24 and the episode is 4268 and the total_steps are 201737\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4268     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7054     |\n",
      "|    total_timesteps  | 201737   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.8     |\n",
      "|    n_updates        | 37934    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 2, 1, 1, 0, 1, 1, 3, 0, 0, 3, 0, 3, 0, 3, 0, 2, 1, 3, 3, 2, 3, 0, 2, 0, 0, 1, 2, 3, 0, 0, 1, 1, 2, 2, 1, 0, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 44 and the episode is 4269 and the total_steps are 201781\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 1, 3, 1, 1, 3, 2, 1, 1, 2, 1, 3, 2, 0, 1, 2, 3, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 4270 and the total_steps are 201805\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 0, 2, 1, 0, 3, 1, 0, 3, 2, 2, 1, 0, 0, 1, 0, 2, 2, 0, 3, 1, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 28 and the episode is 4271 and the total_steps are 201833\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 1, 0, 0, 3, 1, 3, 2, 2, 3, 0, 1, 0, 0, 1, 2, 0, 1, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4272 and the total_steps are 201858\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4272     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7059     |\n",
      "|    total_timesteps  | 201858   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 35.4     |\n",
      "|    n_updates        | 37964    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 2, 0, 1, 2, 2, 0, 0, 2, 0, 0, 1, 1, 2, 0, 1, 0, 1, 1, 3, 2, 1, 3, 2, 2, 1, 3, 1, 2, 3, 3, 3, 3, 3, 1, 0, 3, 3, 3, 0, 0, 3, 2, 0, 0, 1, 1, 3, 1, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 56 and the episode is 4273 and the total_steps are 201914\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 1, 1, 2, 0, 1, 0, 0, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 1, 3, 0, 2, 0, 3, 2, 0, 2, 3, 3, 1, 2, 2, 2, 2, 2, 1, 3, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 3, 1, 1, 2, 0, 0, 1, 3, 3, 2, 3, 1, 0, 0, 1, 1, 3, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 75 and the episode is 4274 and the total_steps are 201989\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 0, 2, 2, 0, 1, 3, 0, 0, 0, 1, 3, 1, 3, 1, 1, 2, 3, 2, 0, 2, 1, 2, 2, 1, 0, 1, 2, 0, 2, 1, 1, 3, 2, 3, 2, 3, 1, 2, 0, 0, 0, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 49 and the episode is 4275 and the total_steps are 202038\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 2, 0, 1, 3, 1, 0, 3, 3, 2, 0, 0, 1, 1, 1, 0, 3, 1, 2, 1, 1, 0, 0, 3, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 4276 and the total_steps are 202069\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4276     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7068     |\n",
      "|    total_timesteps  | 202069   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 93.8     |\n",
      "|    n_updates        | 38017    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 1, 0, 1, 0, 2, 3, 1, 3, 2, 1, 0, 3, 1, 3, 0, 0, 3, 2, 0, 3, 1, 3, 3, 1, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 4277 and the total_steps are 202101\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 0, 1, 3, 1, 1, 2, 1, 0, 0, 2, 0, 2, 1, 2, 0, 1, 1, 3, 3, 2, 1, 1, 3, 0, 1, 2, 2, 2, 3, 3, 2, 2, 1, 2, 2, 1, 2, 0, 1, 3, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 48 and the episode is 4278 and the total_steps are 202149\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 1, 3, 0, 1, 0, 0, 1, 1, 0, 3, 2, 2, 0, 2, 0, 1, 3, 1, 2, 1, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 4279 and the total_steps are 202177\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 3, 3, 1, 1, 0, 1, 3, 3, 0, 1, 0, 1, 1, 2, 0, 1, 2, 2, 0, 3, 3, 0, 2, 1, 1, 3, 0, 3, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 36 and the episode is 4280 and the total_steps are 202213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4280     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7074     |\n",
      "|    total_timesteps  | 202213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 36.2     |\n",
      "|    n_updates        | 38053    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 3, 2, 2, 3, 1, 3, 2, 2, 1, 0, 1, 2, 3, 3, 2, 1, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 4281 and the total_steps are 202237\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 3, 0, 1, 3, 2, 1, 3, 0, 3, 3, 2, 2, 2, 1, 0, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 33 and the episode is 4282 and the total_steps are 202270\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 0, 3, 0, 0, 1, 1, 1, 0, 0, 2, 0, 3, 3, 2, 3, 0, 3, 0, 2, 3, 2, 1, 1, 0, 3, 2, 2, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 4283 and the total_steps are 202305\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 2, 1, 0, 3, 3, 0, 3, 3, 0, 3, 2, 3, 1, 3, 2, 0, 3, 2, 2, 2, 3, 3, 2, 0, 1, 2, 2, 1, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 36 and the episode is 4284 and the total_steps are 202341\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4284     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7080     |\n",
      "|    total_timesteps  | 202341   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.48     |\n",
      "|    n_updates        | 38085    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 3, 2, 3, 1, 3, 2, 1, 2, 0, 3, 1, 2, 1, 2, 2, 2, 2, 2, 3, 3, 0, 2, 1, 3, 1, 1, 2, 3, 0, 1, 1, 2, 0, 3, 0, 3, 1, 2, 2, 2, 0, 2, 3, 0, 1, 0, 1, 2, 3, 2, 2, 3, 0, 1, 1, 1, 2, 2, 0, 1, 2, 2, 0, 2, 1, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 73 and the episode is 4285 and the total_steps are 202414\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 2, 2, 2, 0, 1, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 1, 2, 3, 2, 3, 3, 3, 0, 3, 1, 3, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 35 and the episode is 4286 and the total_steps are 202449\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 0, 3, 3, 3, 1, 3, 2, 0, 0, 1, 1, 0, 0, 3, 2, 0, 0, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 25 and the episode is 4287 and the total_steps are 202474\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 0, 1, 3, 3, 0, 1, 0, 2, 2, 0, 3, 0, 3, 3, 2, 1, 3, 1, 2, 0, 0, 2, 3, 1, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 4288 and the total_steps are 202505\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4288     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7087     |\n",
      "|    total_timesteps  | 202505   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.5     |\n",
      "|    n_updates        | 38126    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 0, 2, 3, 3, 2, 0, 2, 1, 1, 2, 3, 2, 1, 0, 3, 0, 3, 1, 1, 2, 2, 2, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 4289 and the total_steps are 202533\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 0, 1, 3, 2, 3, 0, 2, 3, 3, 0, 3, 1, 2, 3, 2, 2, 3, 1, 2, 1, 1, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 4290 and the total_steps are 202562\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 1, 2, 1, 0, 1, 0, 3, 3, 0, 2, 3, 3, 3, 1, 2, 1, 2, 0, 0, 3, 2, 0, 3, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 4291 and the total_steps are 202593\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 0, 0, 2, 1, 0, 1, 1, 0, 0, 2, 1, 2, 2, 1, 3, 1, 2, 3, 1, 1, 1, 0, 0, 0, 1, 1, 3, 0, 0, 2, 1, 0, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 40 and the episode is 4292 and the total_steps are 202633\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.4     |\n",
      "|    ep_rew_mean      | -921     |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4292     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7092     |\n",
      "|    total_timesteps  | 202633   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 38158    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 0, 3, 2, 2, 1, 1, 1, 3, 1, 0, 0, 2, 2, 1, 3, 0, 3, 0, 2, 2, 1, 0, 3, 1, 3, 3, 3, 2, 0, 1, 1, 0, 3, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 2, 1, 2, 1, 2, 3, 0, 0, 3, 2, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -959. And steps were 61 and the episode is 4293 and the total_steps are 202694\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 3, 1, 1, 1, 3, 0, 1, 1, 3, 3, 1, 2, 3, 0, 2, 3, 0, 1, 0, 3, 0, 0, 1, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 31 and the episode is 4294 and the total_steps are 202725\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 0, 0, 1, 1, 2, 2, 2, 1, 3, 1, 3, 0, 3, 3, 1, 1, 2, 2, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 4295 and the total_steps are 202751\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 3, 3, 1, 2, 0, 1, 1, 2, 3, 2, 3, 1, 3, 1, 3, 1, 0, 0, 1, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 0, 1, 0, 1, 1, 1, 2, 3, 3, 0, 0, 0, 2, 2, 2, 3, 2, 3, 1, 2, 2, 3, 0, 0, 2, 0, 0, 3, 3, 0, 0, 2, 1, 0, 2, 2, 3, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -920. And steps were 82 and the episode is 4296 and the total_steps are 202833\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4296     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7100     |\n",
      "|    total_timesteps  | 202833   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.6     |\n",
      "|    n_updates        | 38208    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 1, 1, 2, 1, 2, 3, 2, 2, 2, 1, 3, 2, 1, 0, 0, 1, 0, 3, 2, 1, 0, 2, 2, 2, 3, 1, 0, 3, 1, 3, 3, 3, 1, 2, 3, 0, 0, 1, 0, 3, 1, 1, 1, 3, 0, 3, 3, 3, 2, 3, 2, 3, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 60 and the episode is 4297 and the total_steps are 202893\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 3, 3, 1, 2, 0, 3, 3, 0, 0, 3, 3, 0, 1, 1, 3, 1, 3, 1, 0, 1, 0, 0, 3, 1, 2, 3, 0, 2, 0, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 37 and the episode is 4298 and the total_steps are 202930\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 0, 0, 0, 3, 2, 0, 0, 2, 2, 1, 0, 2, 2, 1, 3, 2, 2, 2, 3, 3, 3, 3, 2, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 31 and the episode is 4299 and the total_steps are 202961\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 3, 2, 1, 3, 1, 0, 3, 2, 1, 3, 0, 0, 3, 0, 1, 2, 0, 0, 2, 0, 1, 0, 3, 2, 2, 1, 3, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 4300 and the total_steps are 202996\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.4     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4300     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7107     |\n",
      "|    total_timesteps  | 202996   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.06     |\n",
      "|    n_updates        | 38248    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 3, 3, 0, 0, 0, 3, 2, 3, 3, 2, 0, 0, 3, 3, 1, 0, 2, 2, 2, 0, 0, 0, 3, 3, 3, 3, 1, 0, 1, 0, 3, 1, 3, 0, 1, 2, 0, 2, 1, 0, 2, 0, 0, 3, 0, 2, 2, 0, 2, 0, 2, 0, 1, 3, 1, 0, 0, 2, 3, 0, 2, 0, 1, 3, 0, 2, 1, 1, 0, 3, 0, 2, 1, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1049. And steps were 81 and the episode is 4301 and the total_steps are 203077\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 2, 1, 3, 2, 2, 2, 0, 3, 1, 3, 2, 2, 2, 2, 1, 1, 0, 2, 1, 3, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 4302 and the total_steps are 203105\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 2, 2, 2, 1, 1, 0, 3, 1, 2, 3, 0, 0, 2, 3, 0, 0, 0, 1, 3, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 4303 and the total_steps are 203132\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 3, 1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 2, 2, 3, 1, 1, 1, 3, 0, 0, 0, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 4304 and the total_steps are 203161\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4304     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7115     |\n",
      "|    total_timesteps  | 203161   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.83     |\n",
      "|    n_updates        | 38290    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 3, 3, 0, 1, 3, 0, 1, 0, 1, 0, 1, 0, 3, 2, 0, 2, 2, 1, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1001. And steps were 24 and the episode is 4305 and the total_steps are 203185\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 0, 2, 0, 3, 1, 3, 1, 1, 3, 2, 1, 1, 1, 2, 1, 0, 1, 3, 1, 0, 1, 2, 2, 1, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 32 and the episode is 4306 and the total_steps are 203217\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 3, 0, 2, 2, 3, 0, 1, 0, 0, 2, 2, 0, 2, 2, 3, 0, 0, 3, 1, 2, 3, 1, 1, 3, 1, 0, 2, 3, 1, 0, 1, 2, 0, 1, 1, 2, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 4307 and the total_steps are 203261\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 3, 0, 3, 1, 3, 0, 3, 2, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 3, 0, 3, 2, 0, 2, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 4308 and the total_steps are 203293\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4308     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7120     |\n",
      "|    total_timesteps  | 203293   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31       |\n",
      "|    n_updates        | 38323    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 0, 3, 2, 2, 2, 2, 3, 1, 3, 3, 1, 0, 3, 3, 0, 0, 0, 2, 3, 2, 3, 1, 3, 2, 3, 1, 3, 2, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4309 and the total_steps are 203329\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 0, 1, 1, 0, 3, 3, 2, 0, 2, 2, 3, 3, 2, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 21 and the episode is 4310 and the total_steps are 203350\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 1, 2, 1, 0, 0, 1, 0, 3, 2, 0, 1, 1, 0, 0, 2, 3, 3, 3, 1, 3, 1, 0, 1, 3, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 32 and the episode is 4311 and the total_steps are 203382\n",
      "Done condition: collision\n",
      "[1, 0, 2, 0, 0, 1, 3, 2, 2, 2, 2, 3, 0, 2, 0, 1, 2, 1, 1, 2, 0, 3, 2, 3, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4312 and the total_steps are 203410\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4312     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7125     |\n",
      "|    total_timesteps  | 203410   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.7     |\n",
      "|    n_updates        | 38352    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 3, 1, 2, 2, 3, 0, 2, 3, 3, 2, 0, 1, 1, 0, 0, 0, 3, 0, 2, 2, 2, 1, 1, 3, 2, 1, 0, 3, 2, 3, 0, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 39 and the episode is 4313 and the total_steps are 203449\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 2, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 3, 3, 1, 0, 2, 0, 3, 2, 1, 0, 2, 2, 2, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4314 and the total_steps are 203481\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 0, 2, 2, 3, 1, 1, 0, 3, 1, 2, 0, 1, 0, 2, 0, 3, 3, 3, 1, 3, 1, 2, 0, 0, 2, 0, 3, 2, 3, 1, 1, 2, 1, 1, 0, 0, 2, 0, 2, 0, 2, 2, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 50 and the episode is 4315 and the total_steps are 203531\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 1, 3, 1, 0, 1, 2, 3, 3, 1, 3, 2, 3, 0, 0, 2, 1, 1, 3, 0, 2, 3, 2, 3, 1, 3, 1, 1, 2, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 36 and the episode is 4316 and the total_steps are 203567\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -964     |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4316     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7132     |\n",
      "|    total_timesteps  | 203567   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.99     |\n",
      "|    n_updates        | 38391    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 1, 1, 0, 0, 1, 2, 3, 0, 1, 3, 2, 1, 0, 2, 3, 2, 2, 2, 3, 1, 0, 0, 1, 3, 2, 0, 0, 1, 2, 2, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 4317 and the total_steps are 203605\n",
      "Done condition: collision\n",
      "[3, 1, 2, 0, 0, 2, 1, 0, 3, 2, 2, 3, 0, 2, 1, 0, 0, 0, 3, 2, 3, 3, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 26 and the episode is 4318 and the total_steps are 203631\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 1, 3, 0, 3, 3, 2, 2, 1, 0, 1, 2, 1, 0, 1, 1, 2, 3, 1, 0, 2, 3, 0, 2, 1, 2, 0, 0, 3, 3, 2, 0, 2, 0, 1, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 42 and the episode is 4319 and the total_steps are 203673\n",
      "Done condition: collision\n",
      "[1, 1, 0, 3, 1, 2, 2, 3, 3, 3, 3, 0, 2, 2, 2, 1, 0, 3, 0, 0, 1, 0, 0, 3, 2, 0, 0, 0, 3, 3, 1, 2, 0, 1, 1, 0, 3, 2, 3, 0, 3, 2, 3, 3, 0, 0, 3, 2, 1, 0, 3, 0, 3, 1, 1, 1, 2, 3, 2, 1, 3, 3, 0, 3, 3, 3, 1, 1, 0, 0, 1, 1, 3, 0, 3, 1, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 80 and the episode is 4320 and the total_steps are 203753\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -964     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4320     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7140     |\n",
      "|    total_timesteps  | 203753   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.9     |\n",
      "|    n_updates        | 38438    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 2, 3, 0, 3, 2, 0, 1, 1, 0, 1, 2, 1, 3, 2, 2, 3, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 4321 and the total_steps are 203777\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 1, 3, 2, 3, 0, 3, 3, 2, 2, 1, 2, 1, 1, 3, 3, 1, 1, 0, 1, 1, 0, 2, 3, 1, 1, 1, 2, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 35 and the episode is 4322 and the total_steps are 203812\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 0, 1, 1, 1, 3, 1, 0, 0, 0, 1, 3, 1, 3, 2, 0, 3, 0, 1, 0, 2, 1, 3, 0, 3, 3, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 33 and the episode is 4323 and the total_steps are 203845\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 3, 2, 3, 0, 2, 0, 0, 3, 1, 3, 2, 2, 3, 1, 0, 3, 2, 2, 0, 2, 2, 3, 2, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 31 and the episode is 4324 and the total_steps are 203876\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -964     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4324     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7145     |\n",
      "|    total_timesteps  | 203876   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62       |\n",
      "|    n_updates        | 38468    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 1, 0, 0, 3, 0, 2, 1, 3, 1, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 27 and the episode is 4325 and the total_steps are 203903\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 1, 3, 1, 2, 0, 1, 1, 2, 3, 0, 1, 2, 0, 0, 0, 3, 0, 0, 3, 3, 3, 2, 1, 2, 3, 2, 1, 2, 3, 3, 3, 3, 0, 0, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 4326 and the total_steps are 203945\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 0, 1, 2, 2, 0, 2, 3, 1, 0, 3, 1, 3, 1, 0, 3, 2, 3, 2, 0, 0, 1, 3, 3, 2, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 4327 and the total_steps are 203977\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 3, 3, 3, 1, 1, 2, 0, 1, 2, 1, 3, 1, 2, 2, 3, 2, 3, 3, 2, 2, 2, 0, 1, 3, 3, 2, 0, 1, 2, 3, 3, 3, 2, 1, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 4328 and the total_steps are 204019\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -964     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4328     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7151     |\n",
      "|    total_timesteps  | 204019   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 38504    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 3, 2, 0, 2, 0, 1, 2, 2, 1, 0, 0, 0, 3, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1018. And steps were 19 and the episode is 4329 and the total_steps are 204038\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 3, 0, 1, 3, 3, 3, 1, 1, 0, 3, 2, 1, 1, 1, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 22 and the episode is 4330 and the total_steps are 204060\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 0, 3, 2, 3, 1, 1, 0, 1, 1, 2, 3, 2, 1, 3, 3, 3, 3, 3, 0, 2, 2, 1, 3, 2, 0, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 33 and the episode is 4331 and the total_steps are 204093\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 3, 0, 2, 0, 0, 0, 2, 1, 2, 1, 1, 3, 3, 0, 2, 1, 2, 0, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 25 and the episode is 4332 and the total_steps are 204118\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | -944     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4332     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7156     |\n",
      "|    total_timesteps  | 204118   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.81     |\n",
      "|    n_updates        | 38529    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 1, 0, 3, 0, 3, 3, 1, 3, 2, 2, 3, 3, 1, 0, 1, 3, 3, 2, 0, 0, 0, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4333 and the total_steps are 204146\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 1, 1, 3, 1, 1, 1, 0, 1, 0, 1, 3, 2, 1, 0, 1, 2, 2, 0, 2, 1, 3, 0, 0, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 1, 2, 1, 3, 1, 2, 3, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 48 and the episode is 4334 and the total_steps are 204194\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 0, 1, 0, 2, 3, 2, 3, 0, 1, 2, 1, 3, 0, 1, 2, 0, 1, 1, 2, 1, 0, 2, 0, 3, 1, 3, 3, 3, 3, 3, 2, 1, 3, 1, 2, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 43 and the episode is 4335 and the total_steps are 204237\n",
      "Done condition: collision\n",
      "[2, 3, 2, 0, 0, 0, 3, 1, 0, 0, 3, 0, 3, 0, 3, 3, 1, 0, 2, 2, 0, 1, 1, 2, 0, 2, 0, 3, 1, 1, 3, 2, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 36 and the episode is 4336 and the total_steps are 204273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -946     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4336     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7163     |\n",
      "|    total_timesteps  | 204273   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.19     |\n",
      "|    n_updates        | 38568    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 0, 1, 2, 1, 1, 3, 3, 1, 3, 0, 1, 1, 0, 0, 3, 0, 3, 0, 0, 1, 3, 2, 2, 0, 0, 2, 0, 0, 0, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 37 and the episode is 4337 and the total_steps are 204310\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 3, 2, 2, 1, 1, 1, 2, 1, 1, 0, 2, 3, 0, 1, 2, 2, 0, 0, 0, 2, 2, 0, 1, 2, 1, 0, 0, 2, 0, 1, 2, 0, 2, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 41 and the episode is 4338 and the total_steps are 204351\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 3, 3, 0, 3, 2, 1, 3, 0, 2, 1, 0, 1, 3, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 21 and the episode is 4339 and the total_steps are 204372\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 3, 1, 3, 2, 2, 0, 0, 2, 2, 0, 3, 2, 1, 1, 2, 1, 3, 1, 1, 3, 1, 2, 1, 3, 3, 2, 0, 0, 0, 1, 1, 2, 2, 1, 2, 0, 3, 3, 0, 0, 3, 1, 2, 0, 0, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1051. And steps were 53 and the episode is 4340 and the total_steps are 204425\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -946     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4340     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7169     |\n",
      "|    total_timesteps  | 204425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.99     |\n",
      "|    n_updates        | 38606    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 2, 0, 1, 0, 3, 2, 3, 1, 0, 1, 2, 2, 2, 0, 0, 0, 2, 2, 1, 0, 3, 3, 3, 2, 1, 2, 2, 0, 3, 2, 0, 3, 0, 0, 1, 2, 0, 0, 1, 0, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 48 and the episode is 4341 and the total_steps are 204473\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 1, 2, 2, 0, 1, 2, 3, 0, 2, 2, 1, 1, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 26 and the episode is 4342 and the total_steps are 204499\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 3, 3, 0, 0, 1, 1, 3, 1, 1, 3, 1, 3, 1, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was 1018. And steps were 19 and the episode is 4343 and the total_steps are 204518\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 0, 1, 2, 2, 1, 0, 0, 1, 3, 2, 0, 0, 0, 3, 1, 2, 2, 1, 2, 2, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 27 and the episode is 4344 and the total_steps are 204545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | -926     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4344     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7175     |\n",
      "|    total_timesteps  | 204545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.04     |\n",
      "|    n_updates        | 38636    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 1, 3, 0, 3, 2, 2, 2, 1, 1, 3, 3, 0, 0, 1, 1, 1, 1, 2, 2, 1, 2, 0, 2, 2, 0, 1, 3, 2, 0, 0, 3, 0, 0, 3, 0, 1, 0, 3, 0, 1, 1, 2, 1, 0, 3, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 52 and the episode is 4345 and the total_steps are 204597\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 3, 0, 3, 3, 3, 2, 0, 2, 3, 0, 1, 0, 1, 0, 2, 3, 1, 3, 1, 1, 1, 0, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 30 and the episode is 4346 and the total_steps are 204627\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 0, 1, 3, 2, 3, 0, 2, 1, 0, 3, 3, 2, 1, 0, 1, 1, 1, 2, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 4347 and the total_steps are 204653\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 3, 1, 3, 2, 3, 0, 2, 3, 2, 2, 1, 3, 3, 0, 2, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was 1013. And steps were 20 and the episode is 4348 and the total_steps are 204673\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -906     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4348     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7180     |\n",
      "|    total_timesteps  | 204673   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 66.1     |\n",
      "|    n_updates        | 38668    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 1, 2, 2, 0, 0, 1, 2, 3, 0, 3, 0, 3, 2, 2, 0, 2, 1, 0, 0, 2, 0, 3, 1, 2, 1, 3, 3, 1, 2, 0, 3, 0, 3, 2, 1, 1, 3, 3, 3, 0, 2, 0, 1, 3, 3, 1, 3, 1, 1, 2, 1, 1, 0, 1, 3, 1, 2, 3, 2, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 65 and the episode is 4349 and the total_steps are 204738\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 0, 0, 2, 0, 3, 2, 1, 2, 0, 3, 2, 3, 3, 3, 2, 2, 0, 0, 0, 0, 1, 3, 3, 0, 0, 3, 3, 2, 1, 2, 2, 0, 1, 2, 3, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 43 and the episode is 4350 and the total_steps are 204781\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 0, 3, 3, 3, 0, 1, 0, 3, 2, 1, 0, 1, 1, 0, 1, 2, 3, 0, 0, 2, 0, 1, 0, 3, 0, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 30 and the episode is 4351 and the total_steps are 204811\n",
      "Done condition: collision\n",
      "[0, 1, 0, 3, 3, 3, 3, 0, 1, 0, 0, 3, 3, 3, 3, 0, 2, 0, 1, 1, 0, 1, 0, 1, 3, 3, 0, 0, 3, 0, 0, 3, 0, 2, 1, 1, 0, 1, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 42 and the episode is 4352 and the total_steps are 204853\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -906     |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4352     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7188     |\n",
      "|    total_timesteps  | 204853   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.39     |\n",
      "|    n_updates        | 38713    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 1, 1, 1, 2, 1, 1, 0, 3, 3, 3, 0, 1, 2, 2, 1, 1, 3, 0, 0, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 27 and the episode is 4353 and the total_steps are 204880\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 2, 2, 0, 1, 3, 0, 0, 0, 0, 0, 3, 0, 1, 2, 3, 0, 3, 3, 1, 3, 2, 2, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 29 and the episode is 4354 and the total_steps are 204909\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 2, 2, 1, 1, 2, 1, 0, 2, 3, 3, 0, 0, 1, 3, 3, 3, 3, 3, 0, 1, 1, 2, 0, 3, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 33 and the episode is 4355 and the total_steps are 204942\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 3, 3, 0, 1, 1, 1, 0, 1, 2, 1, 0, 1, 1, 3, 1, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 4356 and the total_steps are 204963\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.2     |\n",
      "|    ep_rew_mean      | -885     |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4356     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7192     |\n",
      "|    total_timesteps  | 204963   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 38740    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 1, 1, 2, 2, 3, 1, 0, 1, 2, 3, 3, 2, 0, 0, 3, 2, 1, 2, 2, 1, 3, 2, 1, 1, 3, 3, 3, 1, 2, 3, 2, 2, 2, 3, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 4357 and the total_steps are 205005\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 3, 1, 3, 3, 0, 0, 1, 1, 2, 2, 2, 2, 2, 0, 1, 1, 0, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 25 and the episode is 4358 and the total_steps are 205030\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 1, 2, 2, 2, 2, 2, 1, 2, 0, 3, 0, 0, 0, 2, 2, 1, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 23 and the episode is 4359 and the total_steps are 205053\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 0, 2, 0, 0, 2, 3, 2, 2, 0, 0, 0, 1, 2, 3, 2, 3, 2, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 25 and the episode is 4360 and the total_steps are 205078\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | -905     |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4360     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7198     |\n",
      "|    total_timesteps  | 205078   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.2      |\n",
      "|    n_updates        | 38769    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 1, 0, 2, 1, 1, 2, 3, 2, 2, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was 988. And steps were 15 and the episode is 4361 and the total_steps are 205093\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 2, 0, 0, 2, 2, 1, 3, 1, 0, 1, 1, 0, 3, 3, 1, 0, 2, 0, 0, 1, 1, 0, 2, 2, 2, 0, 3, 0, 3, 0, 1, 1, 0, 2, 0, 0, 2, 1, 3, 1, 0, 3, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 60 and the episode is 4362 and the total_steps are 205153\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 1, 3, 2, 2, 0, 3, 1, 3, 1, 0, 3, 0, 0, 0, 3, 1, 2, 2, 1, 3, 2, 1, 3, 2, 2, 3, 3, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 35 and the episode is 4363 and the total_steps are 205188\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 1, 3, 3, 0, 0, 3, 1, 0, 3, 3, 2, 2, 1, 0, 1, 3, 2, 0, 0, 2, 0, 3, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 3, 3, 0, 0, 1, 2, 3, 3, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 52 and the episode is 4364 and the total_steps are 205240\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -884     |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4364     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7204     |\n",
      "|    total_timesteps  | 205240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.53     |\n",
      "|    n_updates        | 38809    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 3, 0, 1, 0, 0, 0, 1, 3, 2, 1, 2, 3, 2, 3, 2, 3, 3, 0, 2, 3, 2, 0, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 29 and the episode is 4365 and the total_steps are 205269\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 2, 1, 0, 0, 2, 1, 1, 0, 0, 1, 0, 1, 1, 2, 1, 2, 2, 3, 2, 3, 2, 1, 2, 0, 1, 0, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 34 and the episode is 4366 and the total_steps are 205303\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 3, 1, 2, 2, 1, 2, 1, 1, 0, 0, 1, 0, 1, 2, 2, 2, 1, 2, 0, 3, 0, 3, 3, 3, 3, 1, 3, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 35 and the episode is 4367 and the total_steps are 205338\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 2, 3, 1, 1, 2, 3, 2, 3, 1, 0, 0, 1, 3, 1, 3, 0, 3, 1, 2, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 4368 and the total_steps are 205365\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | -884     |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4368     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7210     |\n",
      "|    total_timesteps  | 205365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 38841    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 3, 2, 0, 1, 3, 3, 0, 3, 2, 0, 3, 0, 1, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 20 and the episode is 4369 and the total_steps are 205385\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 1, 0, 0, 0, 2, 1, 3, 3, 2, 2, 0, 1, 0, 3, 2, 0, 0, 0, 2, 2, 1, 2, 2, 0, 2, 0, 1, 0, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 36 and the episode is 4370 and the total_steps are 205421\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 0, 0, 3, 2, 0, 3, 2, 1, 2, 1, 3, 2, 3, 3, 3, 1, 0, 2, 2, 3, 2, 0, 2, 3, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 4371 and the total_steps are 205453\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 0, 3, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 0, 1, 1, 2, 0, 1, 0, 3, 3, 1, 0, 1, 0, 2, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 36 and the episode is 4372 and the total_steps are 205489\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | -883     |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4372     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7215     |\n",
      "|    total_timesteps  | 205489   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 38872    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 2, 3, 1, 1, 3, 0, 3, 1, 3, 3, 0, 3, 1, 3, 0, 1, 2, 0, 1, 3, 0, 3, 3, 3, 0, 3, 2, 2, 3, 0, 1, 0, 0, 1, 1, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 3, 3, 0, 0, 2, 2, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 59 and the episode is 4373 and the total_steps are 205548\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 2, 3, 1, 2, 3, 3, 2, 1, 0, 0, 2, 2, 3, 3, 0, 2, 1, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1022. And steps were 23 and the episode is 4374 and the total_steps are 205571\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 2, 1, 3, 2, 2, 3, 1, 1, 3, 3, 3, 2, 0, 3, 0, 0, 0, 1, 2, 1, 0, 3, 0, 3, 3, 2, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 34 and the episode is 4375 and the total_steps are 205605\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 1, 0, 3, 3, 1, 2, 2, 0, 0, 3, 3, 2, 1, 1, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 22 and the episode is 4376 and the total_steps are 205627\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | -863     |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4376     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7221     |\n",
      "|    total_timesteps  | 205627   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 94.9     |\n",
      "|    n_updates        | 38906    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 0, 0, 1, 3, 2, 3, 1, 2, 0, 0, 1, 2, 2, 2, 3, 1, 3, 1, 1, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 27 and the episode is 4377 and the total_steps are 205654\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 3, 3, 3, 0, 0, 3, 2, 3, 0, 3, 1, 0, 0, 3, 1, 0, 1, 1, 3, 3, 1, 2, 2, 3, 3, 1, 1, 1, 0, 1, 3, 3, 2, 2, 3, 3, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 43 and the episode is 4378 and the total_steps are 205697\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 0, 0, 0, 0, 0, 1, 3, 3, 3, 3, 2, 3, 3, 0, 0, 1, 3, 1, 1, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 4379 and the total_steps are 205722\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 3, 0, 1, 1, 0, 0, 3, 2, 3, 0, 3, 1, 3, 2, 2, 3, 1, 0, 0, 3, 3, 3, 0, 0, 3, 1, 1, 2, 1, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 37 and the episode is 4380 and the total_steps are 205759\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | -842     |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4380     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7227     |\n",
      "|    total_timesteps  | 205759   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.46     |\n",
      "|    n_updates        | 38939    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 3, 2, 2, 2, 2, 2, 2, 3, 0, 3, 1, 0, 2, 2, 0, 3, 2, 0, 2, 1, 0, 3, 3, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 31 and the episode is 4381 and the total_steps are 205790\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 0, 0, 1, 3, 2, 1, 2, 2, 0, 0, 3, 0, 1, 3, 3, 1, 2, 3, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 27 and the episode is 4382 and the total_steps are 205817\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 3, 1, 0, 3, 2, 0, 0, 0, 2, 3, 3, 1, 2, 1, 2, 2, 3, 0, 2, 3, 1, 0, 0, 0, 3, 3, 2, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 35 and the episode is 4383 and the total_steps are 205852\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 1, 3, 1, 3, 0, 3, 0, 1, 2, 3, 3, 3, 2, 0, 0, 1, 1, 1, 0, 0, 2, 0, 2, 3, 1, 3, 3, 1, 1, 0, 3, 0, 0, 3, 3, 3, 0, 2, 1, 2, 0, 1, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 3, 0, 3, 2, 1, 1, 0, 1, 0, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 69 and the episode is 4384 and the total_steps are 205921\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | -841     |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4384     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7234     |\n",
      "|    total_timesteps  | 205921   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.8     |\n",
      "|    n_updates        | 38980    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 1, 1, 2, 0, 2, 0, 1, 1, 0, 2, 0, 2, 0, 0, 1, 2, 1, 3, 0, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 0, 3, 2, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 40 and the episode is 4385 and the total_steps are 205961\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 1, 3, 1, 3, 3, 1, 0, 3, 1, 3, 2, 1, 0, 1, 2, 2, 1, 2, 3, 3, 3, 3, 3, 3, 0, 3, 1, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 34 and the episode is 4386 and the total_steps are 205995\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 2, 1, 1, 3, 3, 2, 3, 2, 0, 2, 3, 0, 3, 1, 2, 1, 2, 0, 1, 2, 3, 2, 0, 3, 0, 0, 2, 3, 0, 0, 0, 0, 0, 2, 0, 3, 2, 1, 3, 1, 3, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 50 and the episode is 4387 and the total_steps are 206045\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 0, 3, 1, 3, 1, 1, 0, 0, 0, 1, 3, 2, 2, 1, 2, 2, 0, 0, 3, 0, 2, 1, 2, 2, 2, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 33 and the episode is 4388 and the total_steps are 206078\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | -841     |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4388     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7241     |\n",
      "|    total_timesteps  | 206078   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.6     |\n",
      "|    n_updates        | 39019    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 0, 3, 0, 3, 1, 2, 3, 1, 3, 1, 2, 2, 3, 3, 0, 0, 3, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 25 and the episode is 4389 and the total_steps are 206103\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 1, 0, 2, 1, 3, 1, 1, 0, 1, 2, 3, 3, 0, 3, 2, 2, 2, 1, 0, 1, 1, 0, 2, 0, 3, 0, 2, 0, 0, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 37 and the episode is 4390 and the total_steps are 206140\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 2, 0, 0, 0, 1, 2, 0, 1, 1, 3, 0, 1, 3, 0, 3, 2, 0, 0, 0, 2, 2, 2, 0, 3, 0, 2, 3, 3, 0, 2, 3, 0, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 40 and the episode is 4391 and the total_steps are 206180\n",
      "Done condition: collision\n",
      "[2, 2, 2, 0, 1, 1, 3, 2, 1, 0, 3, 3, 0, 2, 2, 1, 1, 0, 0, 3, 0, 3, 0, 1, 2, 2, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 4392 and the total_steps are 206209\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | -841     |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4392     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7247     |\n",
      "|    total_timesteps  | 206209   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 39052    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 2, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 0, 0, 1, 3, 3, 3, 1, 3, 2, 0, 0, 0, 1, 2, 3, 3, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 45 and the episode is 4393 and the total_steps are 206254\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 0, 0, 2, 2, 3, 3, 3, 1, 3, 2, 1, 0, 1, 0, 3, 0, 0, 2, 0, 3, 0, 2, 2, 2, 2, 3, 0, 3, 2, 3, 3, 3, 3, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -967. And steps were 41 and the episode is 4394 and the total_steps are 206295\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 3, 2, 1, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 3, 2, 3, 2, 0, 0, 3, 3, 3, 0, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 30 and the episode is 4395 and the total_steps are 206325\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 0, 0, 0, 0, 2, 0, 0, 3, 1, 3, 0, 2, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was 1016. And steps were 17 and the episode is 4396 and the total_steps are 206342\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | -821     |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4396     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7252     |\n",
      "|    total_timesteps  | 206342   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 39085    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 3, 3, 1, 3, 2, 0, 2, 1, 3, 3, 3, 0, 2, 2, 3, 3, 1, 1, 3, 2, 1, 0, 3, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 31 and the episode is 4397 and the total_steps are 206373\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 0, 1, 1, 3, 0, 0, 3, 3, 1, 2, 3, 3, 1, 0, 0, 2, 3, 0, 2, 3, 2, 2, 3, 1, 0, 0, 2, 3, 2, 1, 1, 3, 1, 1, 0, 2, 1, 0, 2, 3, 2, 1, 3, 1, 1, 2, 1, 0, 2, 2, 2, 1, 3, 1, 2, 2, 2, 2, 2, 0, 0, 1, 0, 3, 3, 1, 2, 1, 0, 2, 2, 1, 2, 3, 0, 3, 2, 1, 1, 1, 1, 0, 3, 1, 3, 3, 3, 3, 1, 2, 1, 1, 2, 1, 0, 3, 0, 0, 1, 2, 1, 2, 0, 0, 0, 1, 2, 3, 2, 3, 2, 2, 2, 2, 1, 2, 0, 1, 0, 2, 1, 3, 2, 1, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 132 and the episode is 4398 and the total_steps are 206505\n",
      "Done condition: collision\n",
      "[3, 0, 0, 1, 2, 0, 2, 0, 1, 0, 0, 2, 2, 1, 2, 0, 0, 1, 3, 1, 1, 3, 2, 2, 0, 3, 3, 2, 2, 0, 1, 2, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 36 and the episode is 4399 and the total_steps are 206541\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 3, 3, 0, 3, 0, 1, 1, 3, 2, 3, 0, 1, 3, 0, 2, 2, 1, 0, 2, 2, 3, 3, 1, 1, 3, 2, 1, 2, 1, 3, 2, 1, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 40 and the episode is 4400 and the total_steps are 206581\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -820     |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4400     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7262     |\n",
      "|    total_timesteps  | 206581   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.8     |\n",
      "|    n_updates        | 39145    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 2, 3, 1, 2, 0, 3, 2, 0, 0, 3, 3, 1, 3, 1, 0, 1, 3, 2, 2, 3, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 27 and the episode is 4401 and the total_steps are 206608\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 3, 3, 2, 1, 0, 0, 0, 2, 2, 0, 1, 0, 2, 2, 0, 3, 1, 2, 0, 3, 3, 1, 3, 2, 0, 0, 3, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 34 and the episode is 4402 and the total_steps are 206642\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 1, 0, 1, 0, 3, 3, 0, 0, 2, 2, 0, 3, 0, 2, 3, 2, 0, 3, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 26 and the episode is 4403 and the total_steps are 206668\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 3, 1, 2, 1, 3, 0, 3, 1, 1, 2, 3, 3, 2, 3, 3, 2, 0, 2, 3, 2, 0, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 29 and the episode is 4404 and the total_steps are 206697\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | -819     |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4404     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7268     |\n",
      "|    total_timesteps  | 206697   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 55.5     |\n",
      "|    n_updates        | 39174    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 2, 0, 0, 3, 0, 0, 1, 1, 0, 2, 3, 1, 0, 2, 3, 2, 3, 0, 0, 2, 2, 3, 0, 3, 3, 0, 1, 1, 0, 1, 0, 1, 3, 1, 2, 1, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 44 and the episode is 4405 and the total_steps are 206741\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 3, 3, 2, 2, 3, 3, 1, 2, 1, 2, 1, 0, 1, 3, 2, 1, 0, 3, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 26 and the episode is 4406 and the total_steps are 206767\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 3, 2, 1, 2, 2, 0, 3, 1, 3, 0, 3, 0, 2, 1, 2, 0, 1, 0, 3, 3, 2, 2, 1, 3, 0, 3, 0, 3, 0, 3, 3, 0, 1, 2, 3, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 44 and the episode is 4407 and the total_steps are 206811\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 2, 2, 3, 3, 3, 2, 3, 1, 2, 0, 0, 2, 1, 3, 0, 2, 3, 3, 1, 3, 2, 2, 2, 1, 1, 3, 1, 2, 1, 2, 2, 1, 2, 1, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 42 and the episode is 4408 and the total_steps are 206853\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | -838     |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4408     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7275     |\n",
      "|    total_timesteps  | 206853   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.73     |\n",
      "|    n_updates        | 39213    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 3, 2, 3, 3, 0, 2, 2, 1, 0, 0, 3, 3, 0, 3, 2, 3, 1, 3, 0, 1, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 4409 and the total_steps are 206881\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 1, 2, 2, 0, 1, 2, 1, 3, 0, 0, 2, 2, 0, 1, 3, 0, 3, 3, 0, 3, 0, 2, 3, 2, 1, 2, 2, 0, 3, 0, 2, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 39 and the episode is 4410 and the total_steps are 206920\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 3, 1, 1, 1, 1, 3, 2, 0, 3, 1, 0, 0, 0, 0, 0, 0, 3, 1, 2, 1, 1, 0, 1, 1, 3, 0, 0, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 34 and the episode is 4411 and the total_steps are 206954\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 3, 3, 0, 0, 3, 2, 2, 0, 0, 0, 3, 0, 1, 0, 0, 2, 1, 0, 1, 1, 0, 1, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 4412 and the total_steps are 206984\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | -838     |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4412     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7280     |\n",
      "|    total_timesteps  | 206984   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.2     |\n",
      "|    n_updates        | 39245    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 0, 0, 1, 0, 0, 2, 2, 0, 3, 0, 3, 0, 1, 3, 1, 1, 3, 3, 0, 2, 2, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 29 and the episode is 4413 and the total_steps are 207013\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 0, 3, 0, 2, 1, 2, 2, 0, 2, 1, 3, 2, 0, 0, 3, 2, 0, 1, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 4414 and the total_steps are 207039\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 0, 3, 0, 3, 1, 0, 3, 2, 2, 3, 0, 1, 2, 0, 3, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 23 and the episode is 4415 and the total_steps are 207062\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 1, 0, 1, 3, 0, 0, 2, 1, 0, 1, 0, 0, 3, 0, 0, 3, 2, 3, 2, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 27 and the episode is 4416 and the total_steps are 207089\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | -838     |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4416     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7285     |\n",
      "|    total_timesteps  | 207089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.5      |\n",
      "|    n_updates        | 39272    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 0, 3, 2, 1, 1, 1, 1, 3, 2, 2, 0, 0, 1, 3, 3, 3, 1, 0, 3, 1, 0, 2, 0, 2, 1, 3, 3, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 35 and the episode is 4417 and the total_steps are 207124\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 2, 2, 0, 3, 0, 0, 2, 1, 1, 1, 3, 3, 2, 3, 0, 0, 0, 0, 0, 1, 3, 1, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 30 and the episode is 4418 and the total_steps are 207154\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 1, 0, 0, 0, 0, 2, 3, 2, 2, 1, 3, 0, 2, 1, 2, 2, 0, 2, 0, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 27 and the episode is 4419 and the total_steps are 207181\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 2, 3, 0, 1, 2, 1, 3, 0, 0, 2, 2, 2, 2, 1, 1, 1, 3, 1, 2, 0, 3, 0, 3, 2, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 32 and the episode is 4420 and the total_steps are 207213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.6     |\n",
      "|    ep_rew_mean      | -837     |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4420     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7290     |\n",
      "|    total_timesteps  | 207213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 35.1     |\n",
      "|    n_updates        | 39303    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 2, 2, 3, 2, 1, 3, 2, 0, 2, 1, 3, 1, 3, 2, 0, 1, 2, 2, 0, 0, 1, 3, 2, 2, 2, 2, 2, 1, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 36 and the episode is 4421 and the total_steps are 207249\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 0, 0, 3, 2, 1, 3, 1, 0, 3, 3, 3, 2, 3, 3, 0, 2, 2, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 25 and the episode is 4422 and the total_steps are 207274\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 1, 0, 0, 2, 1, 1, 1, 1, 3, 3, 2, 0, 3, 0, 0, 0, 0, 3, 1, 1, 2, 3, 2, 1, 1, 2, 1, 2, 1, 0, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 38 and the episode is 4423 and the total_steps are 207312\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 0, 2, 1, 2, 0, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 2, 1, 3, 3, 2, 0, 1, 0, 1, 1, 2, 1, 0, 1, 0, 3, 1, 3, 1, 3, 1, 0, 1, 0, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 46 and the episode is 4424 and the total_steps are 207358\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.8     |\n",
      "|    ep_rew_mean      | -837     |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4424     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7296     |\n",
      "|    total_timesteps  | 207358   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.17     |\n",
      "|    n_updates        | 39339    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 2, 0, 0, 0, 3, 1, 0, 2, 0, 1, 0, 0, 2, 3, 0, 3, 2, 2, 1, 3, 1, 0, 3, 2, 3, 3, 2, 0, 0, 1, 2, 2, 3, 0, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 4425 and the total_steps are 207399\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 1, 0, 2, 1, 3, 3, 2, 3, 2, 1, 0, 0, 3, 3, 2, 3, 3, 0, 3, 3, 3, 3, 2, 0, 3, 1, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 34 and the episode is 4426 and the total_steps are 207433\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 0, 3, 3, 0, 2, 0, 3, 1, 2, 1, 3, 2, 0, 0, 0, 2, 2, 2, 0, 3, 3, 0, 2, 2, 3, 2, 2, 0, 2, 2, 0, 1, 2, 2, 3, 2, 0, 3, 0, 0, 0, 1, 2, 3, 1, 0, 3, 1, 1, 1, 3, 3, 0, 3, 3, 1, 2, 2, 0, 3, 3, 1, 2, 2, 2, 1, 3, 2, 0, 2, 0, 2, 2, 3, 1, 2, 1, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 85 and the episode is 4427 and the total_steps are 207518\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 2, 2, 1, 3, 1, 1, 3, 0, 3, 0, 0, 2, 2, 2, 2, 2, 1, 3, 1, 0, 0, 2, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1017. And steps were 28 and the episode is 4428 and the total_steps are 207546\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | -817     |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4428     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7304     |\n",
      "|    total_timesteps  | 207546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.52     |\n",
      "|    n_updates        | 39386    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 3, 0, 1, 2, 3, 0, 1, 1, 0, 0, 2, 1, 2, 1, 1, 0, 3, 3, 1, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 27 and the episode is 4429 and the total_steps are 207573\n",
      "Done condition: collision\n",
      "[2, 0, 1, 3, 0, 3, 0, 2, 3, 2, 0, 2, 0, 1, 2, 3, 1, 3, 2, 2, 2, 3, 1, 2, 1, 2, 0, 0, 2, 3, 0, 3, 2, 3, 0, 1, 0, 2, 1, 1, 3, 3, 1, 1, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 48 and the episode is 4430 and the total_steps are 207621\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 0, 0, 3, 2, 3, 0, 3, 2, 1, 2, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 3, 1, 3, 2, 3, 2, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 35 and the episode is 4431 and the total_steps are 207656\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 0, 1, 3, 0, 3, 2, 0, 0, 2, 1, 0, 0, 2, 0, 3, 3, 0, 0, 3, 3, 1, 1, 0, 2, 1, 0, 0, 0, 2, 1, 2, 3, 3, 0, 3, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 42 and the episode is 4432 and the total_steps are 207698\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | -837     |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4432     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7310     |\n",
      "|    total_timesteps  | 207698   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.49     |\n",
      "|    n_updates        | 39424    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 2, 2, 0, 3, 0, 3, 0, 3, 1, 2, 2, 1, 0, 2, 1, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 23 and the episode is 4433 and the total_steps are 207721\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 0, 3, 3, 1, 0, 0, 1, 1, 3, 2, 1, 3, 1, 2, 2, 3, 2, 3, 2, 2, 3, 3, 0, 3, 2, 3, 2, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 4434 and the total_steps are 207756\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 1, 2, 1, 0, 3, 1, 0, 3, 3, 3, 1, 3, 3, 2, 3, 0, 2, 2, 1, 2, 2, 0, 0, 1, 0, 3, 2, 0, 3, 1, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 37 and the episode is 4435 and the total_steps are 207793\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 1, 1, 1, 2, 1, 2, 2, 3, 0, 2, 3, 2, 1, 2, 1, 3, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 24 and the episode is 4436 and the total_steps are 207817\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | -836     |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4436     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7316     |\n",
      "|    total_timesteps  | 207817   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.1      |\n",
      "|    n_updates        | 39454    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 2, 2, 1, 2, 2, 1, 1, 3, 2, 1, 2, 3, 0, 3, 3, 2, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 24 and the episode is 4437 and the total_steps are 207841\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 0, 2, 3, 1, 0, 0, 3, 3, 3, 3, 3, 1, 3, 2, 0, 2, 3, 3, 2, 1, 3, 3, 3, 2, 2, 0, 1, 3, 2, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 37 and the episode is 4438 and the total_steps are 207878\n",
      "Done condition: collision\n",
      "[2, 3, 3, 0, 0, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 2, 3, 3, 2, 1, 2, 2, 2, 2, 0, 2, 3, 1, 2, 2, 2, 1, 3, 2, 2, 0, 1, 1, 2, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1041. And steps were 43 and the episode is 4439 and the total_steps are 207921\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 1, 1, 1, 0, 3, 1, 3, 3, 3, 2, 1, 1, 2, 3, 2, 1, 2, 3, 1, 1, 1, 1, 2, 0, 0, 0, 1, 0, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 36 and the episode is 4440 and the total_steps are 207957\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | -836     |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4440     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7322     |\n",
      "|    total_timesteps  | 207957   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.5     |\n",
      "|    n_updates        | 39489    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 2, 2, 2, 2, 0, 1, 2, 2, 3, 0, 1, 3, 2, 2, 0, 0, 2, 2, 0, 3, 3, 2, 2, 0, 1, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 33 and the episode is 4441 and the total_steps are 207990\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 3, 0, 0, 2, 3, 2, 1, 2, 0, 1, 3, 3, 0, 1, 0, 1, 3, 2, 0, 3, 0, 0, 2, 2, 0, 3, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 34 and the episode is 4442 and the total_steps are 208024\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 0, 3, 0, 3, 2, 1, 1, 2, 2, 3, 1, 3, 0, 3, 3, 1, 3, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 25 and the episode is 4443 and the total_steps are 208049\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 1, 1, 0, 3, 3, 3, 0, 1, 3, 1, 3, 3, 0, 2, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was 1019. And steps were 20 and the episode is 4444 and the total_steps are 208069\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | -836     |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4444     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7327     |\n",
      "|    total_timesteps  | 208069   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.4     |\n",
      "|    n_updates        | 39517    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 3, 3, 1, 2, 2, 0, 0, 3, 2, 2, 2, 0, 1, 0, 3, 1, 3, 2, 3, 2, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 4445 and the total_steps are 208097\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 0, 1, 0, 3, 3, 2, 2, 0, 1, 0, 3, 2, 3, 3, 2, 2, 1, 2, 3, 0, 3, 2, 1, 3, 3, 3, 1, 0, 2, 1, 3, 3, 1, 1, 2, 2, 2, 3, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 3, 0, 1, 1, 2, 2, 2, 2, 0, 0, 0, 3, 2, 2, 2, 2, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1074. And steps were 76 and the episode is 4446 and the total_steps are 208173\n",
      "Done condition: collision\n",
      "[0, 0, 2, 0, 0, 1, 0, 0, 0, 3, 3, 1, 1, 2, 2, 2, 1, 2, 3, 0, 0, 2, 1, 0, 0, 2, 3, 1, 2, 2, 3, 3, 3, 2, 1, 3, 2, 1, 2, 0, 2, 2, 3, 0, 3, 3, 1, 0, 1, 0, 3, 2, 1, 2, 3, 3, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 60 and the episode is 4447 and the total_steps are 208233\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 3, 3, 2, 3, 2, 1, 1, 3, 3, 2, 1, 2, 0, 0, 3, 1, 2, 1, 2, 3, 2, 3, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 4448 and the total_steps are 208262\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4448     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7335     |\n",
      "|    total_timesteps  | 208262   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64       |\n",
      "|    n_updates        | 39565    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 1, 1, 1, 3, 0, 2, 2, 1, 0, 0, 0, 3, 2, 2, 2, 3, 2, 2, 0, 0, 1, 1, 2, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 31 and the episode is 4449 and the total_steps are 208293\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 2, 1, 2, 2, 1, 3, 2, 0, 3, 1, 3, 1, 1, 3, 3, 2, 0, 2, 3, 1, 0, 2, 1, 1, 3, 3, 0, 2, 3, 3, 2, 3, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 40 and the episode is 4450 and the total_steps are 208333\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 0, 2, 3, 2, 3, 3, 1, 3, 2, 3, 3, 3, 3, 2, 0, 1, 1, 3, 0, 1, 1, 0, 0, 0, 1, 3, 2, 2, 3, 1, 0, 2, 0, 1, 1, 1, 1, 3, 3, 0, 0, 1, 1, 3, 0, 2, 1, 1, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 55 and the episode is 4451 and the total_steps are 208388\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 0, 1, 1, 0, 1, 3, 2, 1, 1, 0, 3, 0, 0, 1, 0, 3, 3, 2, 1, 3, 2, 2, 1, 0, 3, 1, 3, 2, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 3, 1, 1, 0, 3, 1, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 53 and the episode is 4452 and the total_steps are 208441\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4452     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7343     |\n",
      "|    total_timesteps  | 208441   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.4     |\n",
      "|    n_updates        | 39610    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 1, 1, 3, 2, 1, 2, 3, 0, 0, 1, 3, 1, 2, 3, 2, 1, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 24 and the episode is 4453 and the total_steps are 208465\n",
      "Done condition: collision\n",
      "[3, 3, 1, 0, 1, 1, 3, 0, 1, 0, 1, 0, 3, 3, 3, 1, 3, 3, 2, 1, 2, 3, 0, 3, 2, 1, 0, 3, 0, 3, 0, 2, 3, 1, 3, 3, 2, 3, 0, 3, 1, 2, 3, 2, 1, 3, 3, 0, 0, 2, 1, 2, 0, 1, 2, 0, 3, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 61 and the episode is 4454 and the total_steps are 208526\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 1, 1, 0, 1, 2, 3, 0, 3, 2, 1, 2, 0, 3, 2, 1, 2, 2, 3, 1, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 27 and the episode is 4455 and the total_steps are 208553\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 3, 1, 0, 0, 1, 1, 3, 2, 3, 1, 3, 2, 1, 0, 2, 0, 3, 2, 1, 3, 1, 1, 1, 0, 3, 2, 2, 2, 2, 3, 2, 1, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 40 and the episode is 4456 and the total_steps are 208593\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4456     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7349     |\n",
      "|    total_timesteps  | 208593   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.22     |\n",
      "|    n_updates        | 39648    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 0, 1, 3, 0, 1, 0, 2, 3, 1, 3, 0, 0, 3, 1, 0, 3, 0, 2, 0, 0, 2, 3, 3, 0, 2, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 32 and the episode is 4457 and the total_steps are 208625\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 1, 3, 2, 2, 3, 0, 3, 1, 2, 2, 0, 1, 1, 1, 3, 2, 3, 1, 2, 0, 1, 1, 1, 0, 3, 0, 2, 3, 0, 1, 1, 2, 1, 1, 3, 3, 0, 1, 2, 0, 1, 3, 0, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1048. And steps were 50 and the episode is 4458 and the total_steps are 208675\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 2, 2, 3, 2, 0, 1, 3, 0, 3, 1, 1, 0, 0, 3, 3, 3, 0, 3, 2, 3, 1, 2, 3, 3, 1, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 4459 and the total_steps are 208707\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 2, 1, 0, 2, 0, 2, 0, 2, 1, 3, 3, 1, 1, 2, 0, 2, 0, 3, 2, 1, 1, 3, 1, 3, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 33 and the episode is 4460 and the total_steps are 208740\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4460     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7355     |\n",
      "|    total_timesteps  | 208740   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 39684    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 3, 1, 2, 3, 3, 2, 2, 2, 3, 1, 2, 3, 3, 3, 2, 1, 2, 1, 2, 1, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 28 and the episode is 4461 and the total_steps are 208768\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 1, 3, 1, 3, 2, 3, 3, 0, 0, 2, 0, 2, 0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4462 and the total_steps are 208796\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 0, 0, 0, 2, 2, 2, 0, 1, 2, 2, 3, 1, 3, 1, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 22 and the episode is 4463 and the total_steps are 208818\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 0, 1, 2, 0, 0, 3, 0, 3, 1, 3, 1, 3, 1, 2, 1, 3, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 4464 and the total_steps are 208839\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4464     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7360     |\n",
      "|    total_timesteps  | 208839   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.97     |\n",
      "|    n_updates        | 39709    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 3, 1, 1, 3, 3, 3, 3, 1, 0, 2, 3, 3, 0, 1, 0, 1, 1, 2, 3, 1, 0, 3, 1, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 30 and the episode is 4465 and the total_steps are 208869\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 1, 2, 1, 2, 2, 0, 1, 3, 2, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 4466 and the total_steps are 208897\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 1, 0, 3, 1, 2, 2, 1, 1, 1, 0, 3, 1, 1, 0, 3, 1, 1, 1, 0, 2, 3, 0, 3, 2, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 4467 and the total_steps are 208929\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 3, 1, 1, 0, 1, 3, 2, 0, 3, 3, 2, 0, 3, 1, 2, 0, 1, 1, 3, 3, 3, 1, 0, 2, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4468 and the total_steps are 208961\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4468     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7365     |\n",
      "|    total_timesteps  | 208961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.17     |\n",
      "|    n_updates        | 39740    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 0, 2, 3, 2, 2, 3, 0, 3, 1, 3, 1, 1, 2, 3, 1, 2, 0, 1, 0, 0, 1, 2, 0, 1, 2, 0, 1, 1, 3, 0, 0, 2, 1, 1, 1, 3, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 44 and the episode is 4469 and the total_steps are 209005\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 0, 0, 2, 0, 0, 2, 1, 3, 2, 2, 1, 0, 3, 0, 2, 0, 3, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 25 and the episode is 4470 and the total_steps are 209030\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 0, 0, 3, 2, 0, 3, 2, 3, 3, 2, 2, 2, 0, 1, 2, 1, 1, 0, 0, 1, 2, 2, 2, 0, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 4471 and the total_steps are 209061\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 3, 3, 2, 0, 2, 3, 3, 1, 3, 1, 1, 1, 1, 2, 3, 2, 1, 2, 0, 0, 1, 2, 3, 0, 3, 2, 2, 3, 0, 1, 3, 1, 0, 3, 2, 2, 3, 3, 1, 2, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 1, 2, 0, 1, 0, 3, 1, 1, 2, 0, 1, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -931. And steps were 73 and the episode is 4472 and the total_steps are 209134\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.5     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4472     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7372     |\n",
      "|    total_timesteps  | 209134   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.87     |\n",
      "|    n_updates        | 39783    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 0, 0, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 4473 and the total_steps are 209158\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 1, 3, 0, 3, 1, 2, 1, 2, 2, 2, 0, 0, 2, 3, 2, 1, 0, 2, 0, 0, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4474 and the total_steps are 209186\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 0, 1, 1, 0, 3, 1, 2, 1, 2, 0, 0, 3, 3, 2, 3, 1, 1, 3, 0, 2, 2, 0, 2, 2, 0, 1, 3, 2, 2, 2, 2, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 39 and the episode is 4475 and the total_steps are 209225\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 3, 3, 0, 1, 2, 1, 0, 3, 2, 0, 3, 3, 3, 3, 1, 0, 2, 0, 3, 3, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4476 and the total_steps are 209253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4476     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7377     |\n",
      "|    total_timesteps  | 209253   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 39813    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 3, 1, 0, 0, 0, 3, 3, 1, 0, 2, 0, 2, 0, 2, 3, 1, 3, 2, 1, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 4477 and the total_steps are 209280\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 1, 1, 1, 3, 0, 0, 3, 1, 3, 2, 3, 2, 2, 0, 0, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 23 and the episode is 4478 and the total_steps are 209303\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 2, 0, 0, 0, 0, 0, 1, 3, 1, 3, 1, 1, 3, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was 1015. And steps were 18 and the episode is 4479 and the total_steps are 209321\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 0, 2, 2, 1, 3, 1, 1, 0, 2, 0, 0, 2, 3, 2, 0, 0, 2, 2, 3, 0, 3, 3, 0, 0, 1, 2, 0, 1, 1, 0, 2, 3, 1, 0, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 52 and the episode is 4480 and the total_steps are 209373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4480     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7382     |\n",
      "|    total_timesteps  | 209373   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 39843    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 3, 1, 0, 0, 3, 2, 0, 2, 1, 3, 3, 3, 1, 2, 3, 3, 3, 0, 0, 1, 1, 1, 3, 1, 2, 2, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1009. And steps were 33 and the episode is 4481 and the total_steps are 209406\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 3, 0, 2, 2, 0, 2, 3, 1, 0, 3, 0, 0, 0, 1, 0, 1, 3, 1, 1, 0, 1, 2, 3, 2, 3, 1, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 34 and the episode is 4482 and the total_steps are 209440\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 2, 0, 2, 3, 1, 1, 1, 3, 2, 1, 3, 0, 3, 0, 1, 2, 0, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 25 and the episode is 4483 and the total_steps are 209465\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 3, 1, 1, 1, 0, 0, 3, 0, 2, 1, 1, 3, 3, 3, 3, 3, 1, 0, 2, 1, 1, 2, 2, 2, 3, 3, 2, 3, 0, 1, 0, 1, 2, 0, 0, 1, 2, 1, 3, 2, 3, 2, 1, 2, 0, 2, 2, 3, 2, 3, 0, 2, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 60 and the episode is 4484 and the total_steps are 209525\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4484     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7389     |\n",
      "|    total_timesteps  | 209525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 39881    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 2, 2, 3, 3, 0, 1, 2, 0, 0, 2, 0, 3, 2, 2, 1, 2, 1, 0, 3, 2, 1, 1, 0, 3, 2, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 4485 and the total_steps are 209557\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 2, 0, 3, 2, 3, 1, 2, 3, 0, 3, 0, 2, 3, 1, 1, 0, 3, 2, 1, 0, 1, 3, 2, 2, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 32 and the episode is 4486 and the total_steps are 209589\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 0, 2, 0, 3, 2, 1, 0, 3, 0, 2, 3, 1, 0, 2, 3, 2, 0, 0, 0, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 27 and the episode is 4487 and the total_steps are 209616\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 3, 2, 2, 3, 0, 1, 1, 0, 1, 0, 3, 1, 3, 2, 0, 1, 0, 0, 3, 2, 2, 3, 2, 1, 0, 0, 2, 1, 1, 1, 2, 1, 3, 2, 2, 2, 0, 3, 2, 3, 1, 3, 0, 1, 3, 0, 1, 1, 0, 1, 2, 2, 1, 3, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 62 and the episode is 4488 and the total_steps are 209678\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4488     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7395     |\n",
      "|    total_timesteps  | 209678   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.25     |\n",
      "|    n_updates        | 39919    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 3, 2, 3, 0, 1, 0, 2, 1, 1, 0, 2, 1, 3, 0, 2, 3, 1, 0, 1, 0, 1, 0, 3, 0, 0, 0, 0, 1, 3, 3, 1, 1, 2, 1, 1, 3, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 44 and the episode is 4489 and the total_steps are 209722\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 0, 2, 3, 3, 1, 2, 2, 3, 1, 0, 1, 1, 2, 3, 3, 0, 2, 1, 0, 0, 3, 1, 0, 2, 0, 0, 2, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 35 and the episode is 4490 and the total_steps are 209757\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 2, 1, 2, 3, 0, 2, 0, 2, 1, 2, 0, 2, 3, 1, 2, 0, 0, 0, 3, 0, 2, 3, 2, 0, 2, 1, 1, 0, 3, 0, 1, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 39 and the episode is 4491 and the total_steps are 209796\n",
      "Done condition: collision\n",
      "[1, 3, 1, 1, 0, 3, 1, 1, 1, 0, 3, 2, 3, 0, 1, 1, 0, 0, 0, 3, 0, 1, 0, 3, 0, 1, 3, 0, 1, 3, 3, 1, 0, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 37 and the episode is 4492 and the total_steps are 209833\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4492     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7402     |\n",
      "|    total_timesteps  | 209833   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.7     |\n",
      "|    n_updates        | 39958    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 1, 2, 2, 1, 1, 0, 3, 2, 3, 1, 2, 3, 0, 3, 2, 2, 1, 0, 2, 1, 0, 3, 3, 1, 0, 3, 1, 1, 1, 1, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4493 and the total_steps are 209869\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 0, 1, 0, 3, 0, 2, 3, 3, 0, 3, 3, 0, 3, 3, 2, 3, 0, 0, 3, 3, 1, 1, 0, 2, 0, 1, 3, 1, 2, 1, 0, 2, 3, 1, 1, 1, 2, 1, 3, 2, 3, 2, 3, 0, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 52 and the episode is 4494 and the total_steps are 209921\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 0, 2, 2, 0, 1, 1, 0, 2, 2, 3, 0, 2, 1, 0, 1, 0, 1, 2, 3, 0, 2, 1, 1, 3, 2, 0, 3, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1040. And steps were 42 and the episode is 4495 and the total_steps are 209963\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 3, 1, 3, 3, 2, 2, 1, 1, 2, 1, 2, 0, 1, 2, 0, 2, 1, 0, 3, 3, 2, 0, 1, 2, 1, 2, 1, 2, 0, 1, 2, 3, 0, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 40 and the episode is 4496 and the total_steps are 210003\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 4496     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7409     |\n",
      "|    total_timesteps  | 210003   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.83     |\n",
      "|    n_updates        | 40000    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 0, 3, 1, 3, 2, 2, 2, 3, 1, 2, 0, 1, 1, 2, 2, 0, 2, 1, 1, 0, 2, 3, 0, 0, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 30 and the episode is 4497 and the total_steps are 210033\n",
      "Done condition: collision\n",
      "[3, 3, 1, 2, 1, 2, 1, 0, 3, 3, 3, 2, 1, 1, 3, 2, 0, 3, 0, 2, 0, 2, 1, 1, 3, 3, 3, 0, 2, 2, 2, 3, 0, 0, 2, 3, 3, 3, 3, 2, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 4498 and the total_steps are 210077\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 1, 2, 2, 3, 2, 3, 1, 2, 0, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was 989. And steps were 14 and the episode is 4499 and the total_steps are 210091\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 3, 2, 2, 3, 3, 3, 3, 0, 0, 0, 1, 2, 0, 1, 2, 1, 1, 2, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 4500 and the total_steps are 210117\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 4500     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7414     |\n",
      "|    total_timesteps  | 210117   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 91.5     |\n",
      "|    n_updates        | 40029    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 0, 1, 0, 2, 1, 0, 0, 2, 2, 3, 3, 1, 3, 0, 3, 2, 2, 2, 2, 3, 0, 3, 0, 2, 2, 3, 1, 3, 0, 1, 1, 3, 0, 1, 0, 1, 2, 2, 1, 0, 1, 1, 0, 1, 2, 0, 2, 0, 1, 2, 0, 2, 3, 2, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 62 and the episode is 4501 and the total_steps are 210179\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 2, 1, 1, 0, 2, 3, 1, 1, 1, 1, 3, 2, 2, 3, 3, 0, 3, 2, 3, 1, 3, 3, 3, 1, 0, 0, 1, 3, 0, 1, 2, 3, 1, 1, 0, 3, 3, 1, 3, 1, 2, 1, 3, 1, 3, 3, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 54 and the episode is 4502 and the total_steps are 210233\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 2, 3, 1, 2, 0, 1, 1, 0, 0, 3, 1, 3, 1, 2, 3, 3, 3, 1, 3, 1, 1, 3, 3, 2, 3, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 33 and the episode is 4503 and the total_steps are 210266\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 2, 2, 3, 1, 3, 0, 3, 2, 3, 3, 0, 0, 0, 3, 3, 3, 2, 0, 2, 2, 3, 1, 3, 0, 2, 2, 1, 2, 1, 2, 1, 2, 3, 2, 0, 3, 1, 3, 2, 3, 3, 2, 2, 0, 0, 3, 0, 0, 1, 2, 2, 3, 3, 2, 2, 3, 0, 0, 3, 0, 3, 1, 3, 0, 1, 2, 2, 0, 2, 0, 0, 3, 0, 3, 1, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -935. And steps were 83 and the episode is 4504 and the total_steps are 210349\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.5     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 4504     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7423     |\n",
      "|    total_timesteps  | 210349   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65.6     |\n",
      "|    n_updates        | 40087    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 1, 2, 3, 3, 3, 2, 0, 0, 2, 0, 2, 1, 1, 3, 1, 1, 1, 2, 3, 2, 2, 3, 0, 3, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 32 and the episode is 4505 and the total_steps are 210381\n",
      "Done condition: collision\n",
      "[1, 2, 3, 3, 0, 3, 3, 2, 1, 3, 3, 1, 2, 2, 2, 0, 0, 1, 1, 3, 0, 3, 0, 0, 2, 1, 1, 1, 0, 2, 3, 1, 3, 0, 0, 3, 0, 0, 3, 0, 3, 1, 0, 3, 3, 0, 2, 3, 1, 0, 3, 3, 3, 1, 1, 2, 0, 0, 1, 3, 0, 0, 0, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 67 and the episode is 4506 and the total_steps are 210448\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 3, 0, 1, 1, 2, 0, 1, 1, 2, 2, 3, 2, 3, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 21 and the episode is 4507 and the total_steps are 210469\n",
      "Done condition: collision\n",
      "[3, 3, 0, 0, 1, 0, 1, 3, 3, 2, 3, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 0, 3, 0, 1, 2, 2, 1, 0, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 33 and the episode is 4508 and the total_steps are 210502\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.5     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 4508     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7429     |\n",
      "|    total_timesteps  | 210502   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.38     |\n",
      "|    n_updates        | 40125    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 1, 2, 0, 2, 1, 2, 3, 2, 2, 2, 3, 0, 3, 3, 1, 1, 3, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 23 and the episode is 4509 and the total_steps are 210525\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 0, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 1, 2, 0, 1, 2, 2, 3, 0, 0, 0, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4510 and the total_steps are 210553\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 0, 3, 2, 3, 2, 0, 0, 3, 0, 2, 3, 3, 3, 2, 3, 0, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 24 and the episode is 4511 and the total_steps are 210577\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 2, 3, 1, 2, 3, 0, 3, 0, 1, 2, 3, 1, 0, 1, 3, 0, 2, 0, 3, 2, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 29 and the episode is 4512 and the total_steps are 210606\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 4512     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7434     |\n",
      "|    total_timesteps  | 210606   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.4      |\n",
      "|    n_updates        | 40151    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 2, 2, 3, 2, 2, 2, 1, 2, 0, 1, 3, 0, 1, 1, 0, 1, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 24 and the episode is 4513 and the total_steps are 210630\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 2, 3, 0, 0, 0, 0, 1, 3, 3, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 1, 3, 0, 2, 2, 2, 3, 0, 3, 0, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 37 and the episode is 4514 and the total_steps are 210667\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 1, 1, 0, 3, 3, 0, 2, 3, 3, 0, 1, 3, 3, 0, 0, 1, 2, 3, 1, 1, 3, 2, 1, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 4515 and the total_steps are 210697\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 1, 3, 2, 2, 1, 1, 2, 3, 0, 3, 2, 0, 1, 0, 1, 3, 1, 3, 0, 2, 0, 3, 0, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1, 3, 2, 3, 2, 3, 0, 2, 2, 3, 3, 0, 1, 3, 0, 2, 1, 3, 3, 1, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 60 and the episode is 4516 and the total_steps are 210757\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.7     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 4516     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7440     |\n",
      "|    total_timesteps  | 210757   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.95     |\n",
      "|    n_updates        | 40189    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 0, 0, 1, 3, 3, 3, 1, 1, 2, 2, 3, 3, 3, 1, 2, 1, 1, 3, 1, 0, 1, 2, 0, 1, 3, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4517 and the total_steps are 210789\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 0, 0, 2, 1, 1, 0, 3, 3, 3, 2, 3, 1, 3, 3, 2, 0, 3, 1, 1, 3, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4518 and the total_steps are 210817\n",
      "Done condition: collision\n",
      "[1, 2, 3, 1, 1, 3, 0, 3, 2, 2, 1, 1, 3, 1, 0, 0, 0, 0, 3, 2, 2, 3, 3, 0, 2, 0, 2, 2, 1, 1, 3, 1, 1, 2, 2, 1, 2, 0, 2, 3, 3, 3, 2, 2, 0, 0, 1, 3, 0, 0, 3, 1, 3, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 1, 3, 1, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1048. And steps were 72 and the episode is 4519 and the total_steps are 210889\n",
      "Done condition: collision\n",
      "[3, 1, 3, 0, 0, 1, 2, 1, 0, 1, 0, 0, 1, 2, 0, 2, 3, 2, 2, 2, 1, 1, 1, 2, 1, 3, 2, 2, 2, 0, 0, 0, 2, 1, 1, 1, 3, 3, 3, 1, 2, 0, 0, 0, 2, 2, 2, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 51 and the episode is 4520 and the total_steps are 210940\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 4520     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7448     |\n",
      "|    total_timesteps  | 210940   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 57.9     |\n",
      "|    n_updates        | 40234    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 1, 2, 3, 0, 0, 1, 2, 3, 2, 1, 0, 2, 0, 1, 3, 0, 0, 2, 2, 1, 3, 1, 3, 2, 3, 1, 0, 3, 1, 3, 2, 0, 2, 3, 3, 1, 1, 3, 3, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 43 and the episode is 4521 and the total_steps are 210983\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 3, 3, 1, 0, 2, 2, 0, 0, 2, 3, 1, 0, 3, 1, 2, 1, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was 1019. And steps were 22 and the episode is 4522 and the total_steps are 211005\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 1, 1, 1, 3, 2, 0, 3, 1, 1, 2, 3, 1, 0, 0, 3, 0, 1, 2, 0, 1, 0, 2, 3, 3, 2, 2, 2, 2, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 36 and the episode is 4523 and the total_steps are 211041\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 2, 2, 0, 0, 0, 1, 3, 3, 1, 0, 3, 3, 0, 0, 0, 1, 0, 1, 2, 1, 2, 0, 3, 1, 0, 2, 2, 2, 3, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 3, 2, 1, 3, 1, 2, 3, 1, 2, 2, 2, 2, 2, 2, 0, 3, 2, 2, 2, 2, 0, 0, 1, 2, 0, 2, 0, 1, 3, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 76 and the episode is 4524 and the total_steps are 211117\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4524     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7456     |\n",
      "|    total_timesteps  | 211117   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.35     |\n",
      "|    n_updates        | 40279    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 2, 0, 2, 2, 3, 3, 1, 3, 2, 2, 1, 2, 0, 2, 2, 2, 3, 0, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 26 and the episode is 4525 and the total_steps are 211143\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 2, 3, 0, 0, 1, 1, 2, 0, 1, 1, 3, 0, 1, 2, 0, 0, 0, 0, 1, 3, 3, 2, 1, 3, 0, 0, 2, 0, 0, 0, 1, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 46 and the episode is 4526 and the total_steps are 211189\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 2, 2, 1, 3, 0, 0, 3, 3, 3, 0, 3, 0, 2, 1, 3, 3, 2, 1, 2, 0, 2, 1, 3, 2, 2, 2, 2, 2, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4527 and the total_steps are 211225\n",
      "Done condition: collision\n",
      "[1, 3, 3, 2, 3, 3, 2, 3, 3, 1, 0, 3, 1, 3, 0, 3, 3, 3, 3, 3, 1, 3, 1, 0, 2, 1, 0, 0, 2, 2, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 33 and the episode is 4528 and the total_steps are 211258\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.1     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4528     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7462     |\n",
      "|    total_timesteps  | 211258   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.4     |\n",
      "|    n_updates        | 40314    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 3, 2, 1, 0, 3, 0, 3, 0, 2, 1, 2, 3, 0, 2, 1, 2, 3, 1, 1, 1, 0, 2, 0, 1, 3, 1, 2, 3, 1, 3, 3, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 39 and the episode is 4529 and the total_steps are 211297\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 3, 3, 3, 2, 2, 1, 2, 2, 2, 2, 0, 0, 3, 3, 3, 1, 1, 2, 1, 3, 1, 2, 1, 3, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 31 and the episode is 4530 and the total_steps are 211328\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 1, 1, 1, 3, 0, 1, 3, 0, 3, 1, 1, 3, 1, 0, 2, 0, 3, 3, 2, 1, 0, 0, 3, 1, 3, 1, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 33 and the episode is 4531 and the total_steps are 211361\n",
      "Done condition: collision\n",
      "[0, 2, 1, 0, 3, 1, 0, 1, 1, 3, 2, 3, 1, 0, 1, 2, 3, 1, 2, 3, 1, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4532 and the total_steps are 211386\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.9     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4532     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7468     |\n",
      "|    total_timesteps  | 211386   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.24     |\n",
      "|    n_updates        | 40346    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 2, 0, 2, 1, 1, 3, 0, 1, 2, 0, 1, 1, 0, 2, 0, 3, 1, 3, 3, 0, 1, 1, 3, 2, 2, 2, 2, 2, 0, 1, 0, 2, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 40 and the episode is 4533 and the total_steps are 211426\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 3, 0, 1, 3, 2, 3, 0, 0, 2, 2, 3, 3, 1, 0, 2, 1, 1, 3, 0, 2, 2, 3, 2, 2, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 31 and the episode is 4534 and the total_steps are 211457\n",
      "Done condition: collision\n",
      "[2, 1, 2, 0, 1, 2, 2, 3, 3, 1, 0, 1, 2, 1, 3, 0, 2, 0, 2, 2, 0, 3, 3, 0, 3, 3, 2, 1, 1, 3, 2, 3, 2, 2, 0, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 39 and the episode is 4535 and the total_steps are 211496\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 2, 0, 3, 0, 2, 0, 1, 2, 1, 1, 3, 1, 2, 1, 2, 2, 0, 2, 0, 0, 3, 2, 0, 3, 0, 3, 3, 2, 1, 1, 0, 3, 3, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 4536 and the total_steps are 211537\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.2     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4536     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7474     |\n",
      "|    total_timesteps  | 211537   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 40384    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 2, 2, 3, 2, 2, 0, 2, 0, 1, 0, 1, 0, 2, 3, 2, 3, 3, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 4537 and the total_steps are 211569\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 2, 2, 1, 3, 3, 1, 1, 3, 0, 2, 0, 2, 0, 1, 2, 2, 0, 3, 0, 3, 2, 1, 0, 2, 3, 3, 2, 1, 1, 3, 0, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 1, 1, 0, 1, 3, 0, 1, 2, 2, 0, 0, 3, 0, 0, 3, 3, 3, 1, 2, 3, 0, 1, 3, 2, 3, 0, 1, 3, 3, 2, 0, 0, 2, 0, 2, 0, 1, 1, 1, 2, 3, 0, 0, 3, 3, 0, 2, 0, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -906. And steps were 96 and the episode is 4538 and the total_steps are 211665\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 2, 3, 0, 3, 0, 2, 2, 0, 3, 3, 0, 1, 2, 2, 3, 1, 2, 0, 0, 2, 3, 0, 0, 2, 1, 2, 3, 2, 0, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 36 and the episode is 4539 and the total_steps are 211701\n",
      "Done condition: collision\n",
      "[3, 2, 0, 0, 1, 0, 2, 0, 0, 1, 1, 3, 3, 1, 3, 3, 1, 1, 3, 2, 2, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 34 and the episode is 4540 and the total_steps are 211735\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4540     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7482     |\n",
      "|    total_timesteps  | 211735   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 40433    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 3, 1, 0, 0, 1, 0, 0, 3, 1, 2, 2, 3, 0, 0, 3, 1, 1, 0, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 4541 and the total_steps are 211759\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 0, 3, 0, 2, 3, 2, 2, 1, 1, 2, 2, 1, 3, 2, 3, 0, 3, 1, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 4542 and the total_steps are 211785\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 3, 1, 0, 1, 1, 1, 1, 2, 3, 0, 3, 0, 1, 3, 0, 3, 1, 0, 1, 3, 0, 1, 3, 0, 1, 3, 3, 0, 3, 3, 2, 3, 0, 3, 1, 0, 1, 1, 2, 1, 2, 1, 2, 3, 1, 0, 0, 2, 0, 0, 0, 2, 3, 3, 3, 3, 3, 2, 3, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -941. And steps were 67 and the episode is 4543 and the total_steps are 211852\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 0, 3, 3, 1, 0, 3, 2, 3, 0, 1, 0, 0, 0, 3, 2, 3, 3, 0, 3, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 35 and the episode is 4544 and the total_steps are 211887\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4544     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7489     |\n",
      "|    total_timesteps  | 211887   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 66.4     |\n",
      "|    n_updates        | 40471    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 0, 2, 0, 2, 0, 3, 1, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 34 and the episode is 4545 and the total_steps are 211921\n",
      "Done condition: collision\n",
      "[0, 3, 2, 2, 2, 2, 2, 2, 0, 3, 3, 2, 2, 0, 1, 1, 0, 3, 1, 3, 2, 0, 0, 2, 3, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 3, 2, 2, 1, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 45 and the episode is 4546 and the total_steps are 211966\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 0, 1, 1, 1, 2, 3, 2, 1, 2, 0, 2, 2, 3, 0, 3, 0, 2, 1, 2, 1, 0, 3, 0, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 31 and the episode is 4547 and the total_steps are 211997\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 2, 3, 3, 3, 0, 0, 3, 2, 1, 1, 2, 3, 2, 3, 3, 3, 1, 1, 1, 1, 3, 0, 0, 1, 1, 3, 3, 2, 1, 0, 2, 1, 3, 1, 1, 2, 0, 0, 3, 2, 2, 1, 1, 0, 1, 0, 2, 3, 3, 3, 3, 3, 0, 1, 1, 0, 2, 2, 0, 1, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 68 and the episode is 4548 and the total_steps are 212065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4548     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7496     |\n",
      "|    total_timesteps  | 212065   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.95     |\n",
      "|    n_updates        | 40516    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 3, 0, 2, 0, 0, 2, 2, 0, 2, 0, 3, 3, 2, 0, 1, 0, 3, 0, 2, 2, 3, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4549 and the total_steps are 212093\n",
      "Done condition: collision\n",
      "[1, 0, 2, 2, 2, 1, 0, 3, 3, 1, 1, 2, 1, 2, 3, 1, 3, 3, 0, 2, 3, 2, 2, 1, 0, 0, 1, 1, 2, 2, 0, 2, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4550 and the total_steps are 212129\n",
      "Done condition: collision\n",
      "[2, 2, 2, 3, 3, 2, 3, 0, 0, 2, 2, 2, 0, 1, 2, 1, 2, 0, 2, 0, 2, 0, 1, 2, 3, 2, 2, 1, 1, 2, 2, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 4551 and the total_steps are 212164\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 2, 3, 1, 1, 3, 1, 3, 0, 1, 1, 2, 3, 3, 2, 2, 0, 2, 2, 1, 0, 3, 1, 2, 3, 1, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 33 and the episode is 4552 and the total_steps are 212197\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4552     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7502     |\n",
      "|    total_timesteps  | 212197   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.6     |\n",
      "|    n_updates        | 40549    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 1, 1, 0, 3, 1, 1, 3, 3, 1, 2, 0, 3, 3, 1, 2, 0, 2, 2, 2, 3, 0, 3, 2, 2, 3, 1, 1, 1, 2, 3, 1, 3, 3, 2, 0, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 43 and the episode is 4553 and the total_steps are 212240\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 3, 3, 1, 1, 0, 0, 0, 2, 3, 3, 0, 0, 1, 0, 3, 3, 0, 2, 0, 0, 2, 0, 2, 3, 0, 2, 0, 0, 3, 0, 1, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 39 and the episode is 4554 and the total_steps are 212279\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 3, 2, 1, 3, 1, 2, 2, 0, 3, 0, 1, 3, 3, 0, 1, 3, 2, 2, 2, 3, 1, 0, 1, 2, 2, 1, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 34 and the episode is 4555 and the total_steps are 212313\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 0, 3, 0, 1, 0, 3, 3, 2, 1, 2, 0, 3, 2, 1, 1, 0, 3, 3, 3, 2, 3, 2, 0, 2, 3, 1, 1, 2, 2, 0, 3, 0, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 40 and the episode is 4556 and the total_steps are 212353\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4556     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7509     |\n",
      "|    total_timesteps  | 212353   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 36.5     |\n",
      "|    n_updates        | 40588    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 0, 1, 0, 1, 1, 1, 2, 0, 0, 2, 0, 3, 3, 0, 3, 2, 1, 0, 2, 1, 2, 2, 3, 3, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 40 and the episode is 4557 and the total_steps are 212393\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 1, 0, 1, 3, 3, 3, 2, 3, 2, 3, 1, 1, 0, 0, 1, 0, 0, 2, 3, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 26 and the episode is 4558 and the total_steps are 212419\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 1, 3, 0, 0, 3, 3, 3, 3, 1, 1, 0, 0, 0, 3, 2, 2, 3, 3, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 26 and the episode is 4559 and the total_steps are 212445\n",
      "Done condition: collision\n",
      "[3, 0, 2, 3, 1, 1, 3, 3, 0, 0, 0, 3, 0, 2, 1, 3, 3, 0, 3, 2, 1, 3, 1, 0, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4560 and the total_steps are 212473\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4560     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7514     |\n",
      "|    total_timesteps  | 212473   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.64     |\n",
      "|    n_updates        | 40618    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 3, 2, 2, 2, 2, 2, 1, 1, 2, 3, 3, 0, 2, 2, 0, 3, 3, 3, 0, 2, 0, 1, 0, 0, 1, 2, 2, 0, 2, 3, 0, 1, 3, 1, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 41 and the episode is 4561 and the total_steps are 212514\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 0, 1, 0, 2, 1, 3, 3, 2, 0, 3, 2, 0, 1, 0, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 3, 1, 1, 0, 2, 0, 2, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 39 and the episode is 4562 and the total_steps are 212553\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 0, 3, 3, 2, 1, 3, 3, 1, 1, 2, 0, 1, 3, 2, 0, 1, 3, 1, 2, 1, 2, 0, 1, 1, 2, 1, 1, 2, 1, 0, 2, 1, 0, 3, 3, 3, 0, 3, 2, 0, 3, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 49 and the episode is 4563 and the total_steps are 212602\n",
      "Done condition: collision\n",
      "[2, 3, 3, 2, 3, 0, 2, 2, 3, 1, 3, 1, 1, 3, 0, 1, 2, 1, 1, 0, 3, 1, 2, 0, 0, 1, 3, 1, 0, 0, 2, 3, 3, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1035. And steps were 37 and the episode is 4564 and the total_steps are 212639\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4564     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7521     |\n",
      "|    total_timesteps  | 212639   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 94.6     |\n",
      "|    n_updates        | 40659    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 1, 2, 2, 3, 3, 3, 3, 2, 1, 1, 3, 1, 0, 3, 3, 3, 0, 3, 2, 0, 2, 0, 1, 1, 2, 0, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 34 and the episode is 4565 and the total_steps are 212673\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 2, 1, 1, 0, 2, 1, 3, 3, 2, 1, 3, 3, 1, 1, 3, 3, 0, 2, 3, 2, 3, 0, 0, 0, 2, 3, 0, 0, 2, 2, 3, 1, 1, 2, 1, 0, 3, 3, 2, 0, 0, 0, 0, 2, 3, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 52 and the episode is 4566 and the total_steps are 212725\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 1, 0, 1, 0, 3, 1, 2, 1, 3, 2, 2, 2, 0, 0, 3, 0, 3, 0, 1, 2, 3, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 4567 and the total_steps are 212753\n",
      "Done condition: collision\n",
      "[2, 2, 0, 0, 2, 2, 1, 3, 3, 3, 0, 3, 2, 2, 2, 3, 1, 2, 2, 2, 0, 3, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 4568 and the total_steps are 212785\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4568     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7528     |\n",
      "|    total_timesteps  | 212785   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.28     |\n",
      "|    n_updates        | 40696    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 2, 1, 1, 0, 3, 3, 2, 2, 0, 0, 2, 0, 3, 0, 3, 2, 3, 1, 0, 1, 2, 3, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 4569 and the total_steps are 212814\n",
      "Done condition: collision\n",
      "[2, 2, 2, 2, 3, 0, 2, 3, 1, 1, 1, 3, 3, 3, 1, 2, 0, 3, 2, 3, 3, 3, 1, 1, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 27 and the episode is 4570 and the total_steps are 212841\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 3, 1, 3, 2, 0, 2, 1, 0, 1, 3, 3, 1, 0, 2, 3, 1, 1, 3, 2, 1, 3, 3, 0, 2, 0, 0, 2, 0, 3, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 37 and the episode is 4571 and the total_steps are 212878\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 3, 2, 2, 1, 1, 0, 1, 2, 2, 0, 3, 2, 2, 0, 0, 1, 0, 1, 3, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 27 and the episode is 4572 and the total_steps are 212905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4572     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7533     |\n",
      "|    total_timesteps  | 212905   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.59     |\n",
      "|    n_updates        | 40726    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 1, 3, 2, 3, 3, 2, 2, 2, 1, 1, 1, 3, 3, 0, 1, 2, 2, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 25 and the episode is 4573 and the total_steps are 212930\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 0, 3, 3, 2, 2, 2, 0, 1, 3, 0, 2, 1, 3, 3, 2, 2, 0, 0, 1, 1, 1, 3, 2, 3, 2, 2, 2, 1, 0, 1, 0, 2, 3, 1, 0, 1, 1, 0, 3, 1, 2, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 48 and the episode is 4574 and the total_steps are 212978\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 0, 0, 3, 3, 1, 2, 3, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 15 and the episode is 4575 and the total_steps are 212993\n",
      "Done condition: collision\n",
      "[2, 2, 2, 1, 0, 2, 3, 2, 1, 3, 3, 2, 1, 2, 2, 3, 0, 0, 0, 1, 2, 2, 3, 3, 2, 2, 2, 0, 3, 2, 1, 1, 3, 3, 0, 0, 1, 0, 3, 0, 3, 3, 3, 1, 1, 2, 2, 1, 1, 2, 2, 2, 3, 0, 0, 1, 2, 1, 3, 2, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 64 and the episode is 4576 and the total_steps are 213057\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4576     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7539     |\n",
      "|    total_timesteps  | 213057   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.3     |\n",
      "|    n_updates        | 40764    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 1, 2, 0, 3, 2, 0, 3, 3, 2, 2, 3, 2, 3, 0, 1, 3, 2, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4577 and the total_steps are 213082\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 0, 0, 2, 0, 2, 0, 0, 3, 3, 3, 1, 1, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 3, 3, 0, 2, 3, 2, 3, 1, 0, 3, 0, 1, 2, 2, 2, 0, 2, 0, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 55 and the episode is 4578 and the total_steps are 213137\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 0, 3, 3, 1, 1, 2, 1, 0, 3, 0, 0, 3, 0, 0, 2, 2, 1, 1, 1, 1, 3, 2, 2, 0, 1, 3, 2, 2, 1, 1, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 38 and the episode is 4579 and the total_steps are 213175\n",
      "Done condition: collision\n",
      "[0, 1, 2, 1, 0, 1, 2, 0, 0, 2, 3, 2, 0, 1, 1, 1, 3, 2, 0, 2, 1, 0, 3, 1, 0, 0, 2, 3, 1, 3, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 4580 and the total_steps are 213209\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.4     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4580     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7546     |\n",
      "|    total_timesteps  | 213209   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.8     |\n",
      "|    n_updates        | 40802    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 1, 3, 2, 0, 1, 2, 1, 1, 1, 1, 0, 3, 0, 0, 2, 0, 2, 0, 3, 1, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 28 and the episode is 4581 and the total_steps are 213237\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 2, 3, 3, 1, 3, 1, 0, 2, 2, 2, 1, 1, 3, 2, 2, 3, 2, 1, 3, 3, 2, 1, 1, 3, 3, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 32 and the episode is 4582 and the total_steps are 213269\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 2, 3, 1, 0, 1, 1, 3, 3, 0, 0, 0, 3, 1, 3, 0, 3, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 4583 and the total_steps are 213293\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 3, 3, 3, 0, 2, 3, 1, 3, 0, 3, 0, 2, 2, 0, 3, 1, 1, 2, 1, 1, 3, 1, 2, 1, 2, 2, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 40 and the episode is 4584 and the total_steps are 213333\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.1     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4584     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7551     |\n",
      "|    total_timesteps  | 213333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.8     |\n",
      "|    n_updates        | 40833    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 3, 3, 2, 2, 0, 2, 1, 3, 3, 3, 3, 3, 0, 1, 2, 0, 3, 2, 1, 0, 3, 2, 1, 3, 1, 0, 0, 0, 2, 3, 0, 3, 1, 1, 2, 1, 3, 2, 2, 2, 2, 1, 2, 3, 1, 1, 2, 0, 0, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -955. And steps were 57 and the episode is 4585 and the total_steps are 213390\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 2, 0, 3, 3, 0, 1, 3, 0, 0, 3, 1, 3, 0, 2, 3, 2, 3, 1, 2, 3, 2, 3, 2, 3, 1, 0, 2, 0, 2, 0, 2, 3, 0, 0, 1, 0, 0, 0, 1, 3, 1, 0, 2, 2, 0, 1, 3, 1, 1, 3, 0, 0, 1, 0, 2, 0, 1, 1, 1, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 67 and the episode is 4586 and the total_steps are 213457\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 0, 3, 2, 2, 0, 1, 3, 1, 1, 3, 3, 3, 3, 0, 0, 0, 2, 2, 0, 3, 2, 2, 0, 0, 2, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 33 and the episode is 4587 and the total_steps are 213490\n",
      "Done condition: collision\n",
      "[2, 2, 3, 0, 3, 3, 3, 3, 3, 0, 2, 0, 1, 1, 1, 3, 0, 2, 0, 2, 2, 0, 1, 3, 3, 0, 1, 2, 2, 2, 2, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 35 and the episode is 4588 and the total_steps are 213525\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4588     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7559     |\n",
      "|    total_timesteps  | 213525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.6     |\n",
      "|    n_updates        | 40881    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 3, 0, 0, 0, 0, 1, 0, 0, 3, 3, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 2, 1, 2, 2, 1, 0, 0, 3, 1, 1, 0, 3, 1, 2, 1, 0, 1, 1, 0, 2, 3, 3, 1, 0, 3, 0, 1, 1, 2, 3, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 58 and the episode is 4589 and the total_steps are 213583\n",
      "Done condition: collision\n",
      "[0, 1, 0, 0, 1, 1, 2, 2, 0, 0, 1, 3, 2, 3, 0, 3, 1, 0, 2, 0, 3, 1, 2, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 27 and the episode is 4590 and the total_steps are 213610\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 2, 3, 1, 3, 0, 3, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 3, 0, 3, 2, 2, 3, 3, 2, 3, 3, 3, 0, 1, 1, 2, 3, 2, 0, 1, 2, 0, 1, 3, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 48 and the episode is 4591 and the total_steps are 213658\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 0, 1, 2, 1, 1, 3, 3, 3, 0, 3, 1, 1, 3, 2, 3, 3, 3, 0, 2, 0, 1, 0, 0, 0, 3, 2, 2, 2, 1, 2, 1, 0, 0, 1, 2, 1, 1, 1, 1, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 47 and the episode is 4592 and the total_steps are 213705\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4592     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7566     |\n",
      "|    total_timesteps  | 213705   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.82     |\n",
      "|    n_updates        | 40926    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 1, 0, 2, 3, 3, 0, 1, 0, 1, 2, 2, 3, 1, 2, 3, 0, 1, 3, 0, 2, 0, 1, 1, 0, 0, 3, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 4593 and the total_steps are 213737\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 0, 2, 3, 2, 1, 1, 2, 2, 2, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 4594 and the total_steps are 213753\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 2, 0, 1, 2, 2, 2, 0, 3, 1, 2, 1, 2, 2, 0, 3, 3, 1, 2, 2, 1, 0, 3, 0, 0, 2, 2, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 34 and the episode is 4595 and the total_steps are 213787\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 0, 2, 0, 0, 1, 3, 3, 2, 2, 3, 0, 3, 2, 3, 0, 2, 2, 2, 3, 3, 2, 2, 0, 1, 0, 2, 1, 3, 3, 0, 0, 3, 0, 3, 3, 2, 1, 0, 0, 3, 1, 1, 3, 3, 2, 1, 2, 3, 3, 0, 2, 3, 2, 3, 3, 1, 3, 1, 3, 0, 0, 0, 2, 0, 1, 3, 0, 3, 0, 0, 1, 0, 1, 2, 3, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1059. And steps were 83 and the episode is 4596 and the total_steps are 213870\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.7     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4596     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7573     |\n",
      "|    total_timesteps  | 213870   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.4     |\n",
      "|    n_updates        | 40967    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 3, 2, 0, 2, 3, 2, 3, 2, 2, 1, 3, 1, 0, 3, 1, 3, 2, 1, 2, 1, 2, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 27 and the episode is 4597 and the total_steps are 213897\n",
      "Done condition: collision\n",
      "[1, 1, 3, 2, 2, 2, 2, 0, 3, 1, 3, 3, 0, 3, 2, 1, 0, 3, 1, 1, 2, 1, 1, 3, 3, 3, 3, 0, 0, 2, 2, 0, 0, 3, 2, 0, 3, 1, 2, 2, 0, 2, 3, 3, 3, 3, 3, 0, 3, 1, 0, 3, 3, 1, 3, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 59 and the episode is 4598 and the total_steps are 213956\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 2, 2, 3, 0, 3, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 2, 0, 0, 2, 3, 0, 3, 0, 1, 3, 2, 2, 1, 3, 0, 2, 0, 3, 2, 3, 3, 2, 0, 1, 3, 2, 2, 2, 2, 3, 1, 0, 3, 0, 2, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 57 and the episode is 4599 and the total_steps are 214013\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 1, 1, 3, 3, 3, 0, 2, 0, 2, 2, 2, 1, 1, 3, 3, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 24 and the episode is 4600 and the total_steps are 214037\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -958     |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4600     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7580     |\n",
      "|    total_timesteps  | 214037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 41009    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 2, 0, 2, 1, 0, 1, 2, 2, 0, 3, 0, 1, 2, 0, 3, 2, 3, 2, 1, 0, 1, 2, 2, 2, 3, 3, 3, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 33 and the episode is 4601 and the total_steps are 214070\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 1, 2, 2, 3, 0, 1, 3, 1, 1, 3, 0, 3, 2, 2, 1, 2, 2, 2, 1, 0, 3, 1, 3, 2, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4602 and the total_steps are 214102\n",
      "Done condition: collision\n",
      "[2, 0, 3, 3, 0, 0, 1, 1, 1, 1, 0, 1, 3, 1, 1, 2, 0, 2, 2, 3, 1, 3, 3, 1, 2, 1, 2, 3, 0, 2, 1, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1033. And steps were 35 and the episode is 4603 and the total_steps are 214137\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 2, 1, 2, 2, 1, 2, 0, 2, 0, 3, 1, 3, 1, 2, 1, 1, 2, 3, 3, 0, 1, 1, 1, 0, 3, 0, 3, 2, 1, 1, 1, 2, 2, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 41 and the episode is 4604 and the total_steps are 214178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4604     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7586     |\n",
      "|    total_timesteps  | 214178   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2        |\n",
      "|    n_updates        | 41044    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 1, 2, 0, 0, 2, 0, 0, 3, 3, 2, 0, 3, 1, 1, 1, 0, 1, 2, 1, 1, 2, 2, 3, 3, 0, 3, 0, 2, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 36 and the episode is 4605 and the total_steps are 214214\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 1, 1, 0, 3, 1, 0, 0, 1, 2, 0, 2, 0, 1, 3, 1, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 23 and the episode is 4606 and the total_steps are 214237\n",
      "Done condition: collision\n",
      "[3, 1, 3, 2, 3, 2, 3, 1, 0, 2, 0, 0, 2, 3, 1, 2, 3, 3, 3, 2, 0, 0, 2, 0, 2, 0, 0, 2, 1, 3, 3, 0, 1, 3, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 38 and the episode is 4607 and the total_steps are 214275\n",
      "Done condition: collision\n",
      "[0, 3, 0, 3, 3, 1, 1, 2, 1, 3, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 3, 0, 2, 1, 1, 0, 2, 3, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 4608 and the total_steps are 214307\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4608     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7592     |\n",
      "|    total_timesteps  | 214307   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.9     |\n",
      "|    n_updates        | 41076    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 2, 3, 1, 1, 2, 3, 3, 0, 3, 3, 1, 3, 1, 1, 2, 0, 1, 1, 2, 3, 2, 1, 1, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 4609 and the total_steps are 214337\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 1, 0, 1, 1, 3, 0, 1, 1, 1, 3, 0, 3, 2, 2, 0, 0, 3, 1, 3, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 26 and the episode is 4610 and the total_steps are 214363\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 1, 0, 3, 1, 1, 1, 0, 2, 2, 2, 0, 1, 2, 0, 2, 0, 3, 2, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 26 and the episode is 4611 and the total_steps are 214389\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 0, 1, 0, 0, 2, 1, 3, 2, 2, 0, 3, 3, 0, 2, 3, 1, 2, 3, 0, 2, 0, 3, 0, 3, 1, 1, 3, 0, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 4612 and the total_steps are 214425\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4612     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7597     |\n",
      "|    total_timesteps  | 214425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.57     |\n",
      "|    n_updates        | 41106    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 2, 0, 3, 3, 2, 3, 1, 3, 1, 3, 0, 2, 3, 2, 3, 2, 2, 2, 2, 3, 0, 1, 0, 3, 1, 0, 2, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 35 and the episode is 4613 and the total_steps are 214460\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 3, 3, 0, 1, 2, 1, 1, 1, 3, 2, 1, 0, 1, 3, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was 985. And steps were 18 and the episode is 4614 and the total_steps are 214478\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 2, 1, 1, 0, 3, 0, 3, 2, 1, 1, 2, 3, 2, 0, 1, 2, 0, 0, 0, 0, 1, 2, 1, 0, 0, 2, 0, 0, 1, 2, 1, 2, 1, 2, 3, 3, 1, 0, 2, 2, 0, 1, 2, 2, 0, 0, 0, 2, 0, 2, 2, 0, 1, 0, 1, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1067. And steps were 69 and the episode is 4615 and the total_steps are 214547\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 1, 0, 1, 0, 1, 1, 0, 1, 2, 0, 3, 2, 1, 3, 3, 3, 2, 1, 2, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 26 and the episode is 4616 and the total_steps are 214573\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4616     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7603     |\n",
      "|    total_timesteps  | 214573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.6     |\n",
      "|    n_updates        | 41143    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 3, 2, 0, 3, 0, 3, 3, 1, 0, 1, 3, 0, 3, 1, 2, 3, 1, 1, 3, 2, 3, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 4617 and the total_steps are 214602\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 0, 1, 3, 0, 0, 1, 3, 0, 0, 1, 3, 0, 0, 2, 1, 1, 3, 2, 3, 3, 1, 0, 1, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 30 and the episode is 4618 and the total_steps are 214632\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 2, 1, 3, 3, 1, 3, 2, 2, 0, 3, 1, 1, 2, 3, 3, 1, 1, 3, 0, 0, 0, 0, 1, 3, 3, 0, 2, 0, 0, 3, 0, 3, 0, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 41 and the episode is 4619 and the total_steps are 214673\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 1, 2, 3, 0, 3, 1, 3, 1, 1, 2, 2, 2, 1, 3, 2, 2, 2, 3, 3, 3, 1, 3, 1, 1, 3, 1, 1, 2, 3, 1, 1, 0, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 40 and the episode is 4620 and the total_steps are 214713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4620     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7610     |\n",
      "|    total_timesteps  | 214713   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 41178    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 3, 1, 3, 3, 3, 1, 2, 0, 0, 0, 1, 0, 1, 0, 3, 0, 2, 1, 3, 2, 1, 1, 2, 0, 3, 1, 2, 0, 2, 0, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 38 and the episode is 4621 and the total_steps are 214751\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 2, 1, 3, 0, 1, 3, 2, 3, 3, 3, 2, 2, 3, 0, 0, 0, 0, 0, 3, 2, 3, 2, 2, 0, 1, 2, 1, 1, 3, 1, 1, 3, 3, 1, 0, 3, 3, 0, 3, 0, 0, 3, 3, 3, 3, 1, 0, 1, 1, 3, 0, 2, 2, 0, 2, 1, 3, 0, 3, 1, 2, 3, 2, 3, 0, 1, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 74 and the episode is 4622 and the total_steps are 214825\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 0, 0, 0, 2, 2, 3, 3, 1, 2, 2, 2, 0, 3, 0, 3, 0, 0, 3, 2, 3, 1, 0, 1, 1, 0, 2, 3, 2, 0, 1, 0, 0, 1, 0, 3, 3, 2, 3, 1, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 47 and the episode is 4623 and the total_steps are 214872\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 3, 2, 3, 3, 1, 0, 0, 2, 0, 1, 1, 2, 2, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 21 and the episode is 4624 and the total_steps are 214893\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -962     |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4624     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7618     |\n",
      "|    total_timesteps  | 214893   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 41223    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 2, 3, 1, 3, 0, 1, 0, 2, 3, 2, 0, 0, 2, 2, 1, 2, 2, 2, 0, 3, 3, 3, 1, 1, 2, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 4625 and the total_steps are 214925\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 1, 3, 3, 1, 3, 0, 1, 3, 2, 3, 0, 0, 0, 2, 3, 2, 2, 1, 3, 2, 2, 3, 0, 0, 1, 1, 2, 3, 2, 0, 3, 1, 1, 0, 3, 0, 2, 3, 0, 1, 1, 0, 2, 0, 3, 3, 0, 2, 2, 3, 1, 2, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 60 and the episode is 4626 and the total_steps are 214985\n",
      "Done condition: collision\n",
      "[1, 1, 1, 2, 2, 2, 1, 1, 3, 3, 1, 0, 3, 3, 3, 3, 3, 0, 2, 0, 0, 3, 0, 0, 1, 3, 1, 0, 0, 2, 3, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 35 and the episode is 4627 and the total_steps are 215020\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 1, 1, 3, 3, 2, 2, 1, 1, 1, 1, 1, 3, 3, 2, 1, 2, 2, 2, 1, 2, 3, 3, 2, 1, 3, 1, 3, 1, 0, 0, 3, 0, 1, 1, 1, 2, 0, 0, 2, 1, 1, 0, 3, 3, 0, 3, 3, 1, 1, 2, 0, 0, 0, 3, 2, 1, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 64 and the episode is 4628 and the total_steps are 215084\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.3     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4628     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7625     |\n",
      "|    total_timesteps  | 215084   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 41270    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 1, 3, 2, 1, 2, 0, 0, 3, 2, 3, 2, 1, 0, 2, 1, 2, 1, 2, 1, 3, 3, 3, 0, 0, 3, 0, 0, 1, 2, 0, 3, 0, 2, 0, 3, 2, 3, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 45 and the episode is 4629 and the total_steps are 215129\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 3, 3, 3, 0, 1, 3, 1, 3, 3, 1, 3, 0, 3, 0, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4630 and the total_steps are 215161\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 1, 0, 3, 2, 3, 2, 1, 1, 1, 0, 1, 2, 1, 1, 3, 0, 3, 2, 2, 3, 3, 0, 1, 3, 3, 3, 3, 0, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 35 and the episode is 4631 and the total_steps are 215196\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 3, 3, 1, 1, 1, 3, 3, 3, 1, 2, 0, 2, 0, 0, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 29 and the episode is 4632 and the total_steps are 215225\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.4     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4632     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7631     |\n",
      "|    total_timesteps  | 215225   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 41306    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 2, 3, 3, 3, 1, 3, 0, 3, 1, 2, 2, 1, 2, 0, 0, 0, 3, 3, 0, 2, 2, 0, 1, 1, 0, 1, 1, 2, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 36 and the episode is 4633 and the total_steps are 215261\n",
      "Done condition: collision\n",
      "[1, 0, 2, 1, 1, 3, 2, 2, 3, 3, 3, 1, 3, 1, 1, 2, 2, 3, 0, 0, 1, 2, 2, 1, 0, 1, 1, 3, 1, 3, 3, 1, 0, 3, 0, 3, 3, 2, 0, 0, 1, 3, 0, 3, 0, 0, 1, 0, 3, 3, 2, 3, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 56 and the episode is 4634 and the total_steps are 215317\n",
      "Done condition: collision\n",
      "[0, 0, 0, 3, 3, 2, 1, 0, 2, 0, 3, 2, 1, 0, 2, 3, 1, 2, 0, 3, 0, 0, 2, 3, 2, 2, 3, 0, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 32 and the episode is 4635 and the total_steps are 215349\n",
      "Done condition: collision\n",
      "[1, 2, 1, 3, 2, 3, 0, 1, 3, 0, 1, 2, 3, 3, 3, 0, 0, 3, 2, 3, 1, 0, 0, 1, 0, 1, 2, 1, 0, 3, 0, 2, 3, 1, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 39 and the episode is 4636 and the total_steps are 215388\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.5     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4636     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7638     |\n",
      "|    total_timesteps  | 215388   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.6     |\n",
      "|    n_updates        | 41346    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 1, 1, 3, 2, 2, 2, 0, 1, 3, 3, 0, 3, 0, 1, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 22 and the episode is 4637 and the total_steps are 215410\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 0, 2, 2, 3, 3, 1, 3, 3, 1, 3, 2, 3, 0, 2, 3, 3, 3, 0, 0, 3, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 4638 and the total_steps are 215438\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 2, 0, 1, 1, 2, 2, 1, 2, 2, 1, 0, 3, 2, 2, 1, 2, 3, 0, 3, 1, 1, 1, 1, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 31 and the episode is 4639 and the total_steps are 215469\n",
      "Done condition: collision\n",
      "[3, 0, 1, 0, 3, 0, 0, 1, 1, 2, 1, 1, 3, 1, 0, 0, 3, 0, 0, 0, 2, 2, 0, 3, 2, 2, 2, 2, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 4640 and the total_steps are 215501\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4640     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7644     |\n",
      "|    total_timesteps  | 215501   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.7      |\n",
      "|    n_updates        | 41375    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 3, 2, 2, 1, 0, 3, 2, 0, 2, 3, 1, 0, 2, 0, 2, 3, 0, 0, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 25 and the episode is 4641 and the total_steps are 215526\n",
      "Done condition: collision\n",
      "[1, 2, 2, 3, 3, 3, 3, 2, 3, 2, 1, 1, 2, 3, 2, 2, 1, 3, 1, 2, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 24 and the episode is 4642 and the total_steps are 215550\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 2, 0, 1, 1, 2, 2, 0, 1, 0, 3, 2, 2, 2, 0, 3, 1, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 23 and the episode is 4643 and the total_steps are 215573\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 2, 1, 1, 0, 0, 2, 3, 0, 3, 1, 3, 3, 3, 3, 2, 1, 2, 3, 1, 1, 0, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 28 and the episode is 4644 and the total_steps are 215601\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.1     |\n",
      "|    ep_rew_mean      | -982     |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4644     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7648     |\n",
      "|    total_timesteps  | 215601   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 121      |\n",
      "|    n_updates        | 41400    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 1, 2, 0, 1, 3, 0, 0, 3, 2, 1, 2, 0, 0, 1, 0, 3, 1, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 25 and the episode is 4645 and the total_steps are 215626\n",
      "Done condition: collision\n",
      "[3, 0, 0, 0, 3, 2, 2, 2, 1, 3, 1, 2, 1, 0, 2, 0, 3, 2, 2, 2, 2, 3, 3, 3, 3, 0, 0, 1, 3, 0, 2, 3, 3, 3, 0, 2, 1, 1, 3, 2, 2, 1, 2, 1, 0, 2, 1, 1, 3, 0, 3, 1, 1, 0, 2, 3, 2, 0, 3, 3, 2, 1, 2, 0, 3, 2, 3, 0, 0, 0, 1, 3, 1, 3, 0, 1, 0, 1, 1, 0, 1, 2, 0, 3, 2, 2, 0, 0, 1, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 93 and the episode is 4646 and the total_steps are 215719\n",
      "Done condition: collision\n",
      "[2, 2, 1, 2, 0, 2, 2, 0, 3, 0, 0, 3, 0, 3, 3, 1, 1, 0, 3, 1, 2, 2, 2, 0, 3, 2, 1, 3, 1, 0, 0, 1, 1, 0, 0, 2, 3, 1, 2, 1, 3, 2, 1, 2, 2, 1, 2, 0, 3, 3, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -950. And steps were 54 and the episode is 4647 and the total_steps are 215773\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 3, 1, 3, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 4648 and the total_steps are 215789\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.2     |\n",
      "|    ep_rew_mean      | -981     |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4648     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7656     |\n",
      "|    total_timesteps  | 215789   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.6     |\n",
      "|    n_updates        | 41447    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 3, 2, 2, 1, 1, 0, 1, 2, 3, 0, 1, 1, 1, 3, 0, 3, 2, 3, 0, 0, 2, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was 1001. And steps were 26 and the episode is 4649 and the total_steps are 215815\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 0, 3, 2, 1, 3, 3, 0, 2, 0, 0, 1, 3, 1, 0, 3, 3, 1, 1, 1, 0, 0, 0, 3, 3, 0, 0, 1, 0, 0, 3, 3, 1, 2, 3, 0, 3, 2, 1, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 52 and the episode is 4650 and the total_steps are 215867\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 3, 3, 0, 3, 3, 3, 1, 0, 0, 3, 2, 3, 0, 1, 0, 0, 0, 0, 1, 2, 1, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 4651 and the total_steps are 215895\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 0, 1, 0, 3, 2, 2, 2, 2, 2, 3, 1, 1, 3, 3, 2, 3, 1, 0, 2, 1, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 27 and the episode is 4652 and the total_steps are 215922\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.2     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4652     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7662     |\n",
      "|    total_timesteps  | 215922   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 41480    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 3, 0, 2, 0, 2, 3, 2, 2, 1, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 0, 2, 1, 0, 2, 1, 3, 1, 2, 2, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 4653 and the total_steps are 215958\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 2, 0, 3, 2, 3, 2, 0, 0, 1, 0, 3, 3, 0, 1, 2, 3, 2, 3, 2, 3, 1, 2, 1, 3, 3, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 33 and the episode is 4654 and the total_steps are 215991\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 0, 1, 0, 0, 1, 0, 2, 2, 3, 0, 2, 3, 2, 2, 3, 3, 1, 3, 0, 1, 2, 3, 3, 2, 2, 1, 2, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 35 and the episode is 4655 and the total_steps are 216026\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 3, 1, 0, 2, 2, 2, 3, 3, 2, 2, 1, 0, 3, 1, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1021. And steps were 23 and the episode is 4656 and the total_steps are 216049\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4656     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7668     |\n",
      "|    total_timesteps  | 216049   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.4     |\n",
      "|    n_updates        | 41512    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 2, 2, 3, 2, 3, 1, 2, 0, 0, 1, 3, 3, 3, 3, 3, 3, 1, 1, 2, 2, 0, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 29 and the episode is 4657 and the total_steps are 216078\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 2, 3, 2, 0, 2, 0, 3, 3, 2, 0, 0, 2, 2, 3, 0, 1, 3, 3, 2, 1, 3, 3, 0, 2, 1, 0, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 34 and the episode is 4658 and the total_steps are 216112\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 2, 2, 2, 3, 3, 2, 0, 2, 2, 0, 3, 1, 3, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 21 and the episode is 4659 and the total_steps are 216133\n",
      "Done condition: collision\n",
      "[3, 2, 2, 3, 1, 2, 1, 0, 2, 0, 3, 2, 0, 1, 3, 0, 3, 0, 3, 1, 1, 2, 2, 2, 2, 1, 3, 0, 2, 3, 1, 0, 1, 1, 3, 2, 1, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 40 and the episode is 4660 and the total_steps are 216173\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4660     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7673     |\n",
      "|    total_timesteps  | 216173   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.4     |\n",
      "|    n_updates        | 41543    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 1, 2, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 0, 1, 0, 2, 2, 2, 0, 1, 0, 1, 3, 2, 1, 2, 1, 3, 2, 2, 2, 0, 2, 1, 0, 1, 0, 1, 3, 3, 1, 1, 3, 1, 1, 2, 2, 0, 0, 1, 1, 3, 3, 0, 2, 0, 2, 1, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -952. And steps were 66 and the episode is 4661 and the total_steps are 216239\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 2, 0, 2, 2, 2, 1, 2, 2, 1, 3, 3, 1, 2, 2, 1, 0, 2, 0, 3, 3, 2, 0, 1, 2, 3, 2, 3, 1, 1, 3, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 38 and the episode is 4662 and the total_steps are 216277\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 1, 3, 3, 3, 1, 0, 0, 0, 2, 2, 3, 3, 1, 0, 3, 0, 1, 2, 3, 3, 1, 3, 3, 0, 1, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 32 and the episode is 4663 and the total_steps are 216309\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 0, 2, 0, 2, 3, 0, 3, 0, 2, 3, 3, 0, 3, 2, 0, 1, 0, 3, 2, 2, 3, 0, 0, 1, 0, 0, 0, 0, 3, 3, 3, 0, 2, 2, 1, 2, 1, 0, 1, 1, 3, 2, 2, 2, 0, 0, 2, 0, 2, 0, 1, 0, 1, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 60 and the episode is 4664 and the total_steps are 216369\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4664     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7681     |\n",
      "|    total_timesteps  | 216369   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.73     |\n",
      "|    n_updates        | 41592    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 2, 1, 0, 2, 3, 0, 3, 3, 3, 3, 0, 0, 0, 1, 3, 2, 1, 1, 3, 0, 0, 0, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 4665 and the total_steps are 216399\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 3, 1, 2, 0, 0, 1, 0, 1, 3, 1, 0, 0, 1, 0, 2, 3, 3, 3, 2, 2, 0, 1, 0, 1, 2, 2, 0, 3, 3, 3, 2, 1, 2, 2, 3, 1, 0, 0, 0, 3, 3, 0, 2, 2, 1, 1, 0, 1, 2, 0, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 58 and the episode is 4666 and the total_steps are 216457\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 2, 0, 0, 0, 3, 3, 2, 3, 2, 3, 1, 3, 3, 2, 2, 3, 2, 3, 3, 2, 3, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 4667 and the total_steps are 216485\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 2, 1, 0, 1, 3, 2, 0, 2, 1, 1, 3, 0, 2, 1, 1, 2, 1, 1, 1, 2, 1, 3, 2, 0, 3, 2, 0, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 35 and the episode is 4668 and the total_steps are 216520\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4668     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7688     |\n",
      "|    total_timesteps  | 216520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 41629    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 1, 3, 2, 3, 2, 2, 3, 0, 1, 2, 2, 1, 3, 1, 0, 1, 2, 1, 2, 2, 2, 3, 0, 0, 2, 2, 0, 3, 2, 1, 3, 3, 3, 3, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 4669 and the total_steps are 216561\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 3, 2, 0, 2, 1, 0, 3, 3, 3, 1, 0, 2, 0, 1, 0, 1, 0, 2, 3, 1, 1, 3, 0, 1, 1, 3, 0, 1, 2, 0, 1, 3, 0, 0, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 42 and the episode is 4670 and the total_steps are 216603\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 1, 0, 1, 0, 3, 3, 3, 0, 1, 3, 1, 3, 3, 0, 0, 0, 0, 0, 2, 1, 3, 0, 0, 3, 2, 3, 3, 2, 2, 2, 1, 1, 1, 2, 1, 1, 3, 1, 0, 0, 0, 0, 3, 3, 2, 0, 1, 0, 0, 0, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1038. And steps were 58 and the episode is 4671 and the total_steps are 216661\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 0, 0, 1, 0, 1, 2, 1, 2, 1, 0, 0, 3, 0, 3, 3, 1, 3, 2, 1, 2, 3, 2, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 36 and the episode is 4672 and the total_steps are 216697\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4672     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7696     |\n",
      "|    total_timesteps  | 216697   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 41674    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 3, 1, 1, 1, 1, 3, 3, 2, 1, 1, 1, 3, 3, 3, 2, 0, 0, 2, 2, 2, 0, 1, 1, 1, 2, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 33 and the episode is 4673 and the total_steps are 216730\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 3, 1, 1, 2, 1, 2, 1, 0, 0, 1, 2, 3, 3, 3, 1, 1, 2, 0, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was 980. And steps were 23 and the episode is 4674 and the total_steps are 216753\n",
      "Done condition: collision\n",
      "[2, 3, 3, 1, 2, 3, 1, 1, 2, 2, 2, 2, 3, 0, 3, 1, 0, 2, 2, 3, 2, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4675 and the total_steps are 216778\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 3, 2, 0, 0, 2, 2, 3, 2, 0, 1, 3, 0, 1, 1, 0, 3, 0, 3, 3, 3, 1, 0, 2, 1, 3, 2, 1, 2, 3, 1, 1, 1, 2, 1, 1, 0, 3, 0, 1, 2, 1, 0, 0, 3, 3, 0, 3, 2, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 55 and the episode is 4676 and the total_steps are 216833\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4676     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7702     |\n",
      "|    total_timesteps  | 216833   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.8     |\n",
      "|    n_updates        | 41708    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 0, 3, 0, 0, 3, 2, 0, 3, 0, 1, 3, 2, 2, 3, 1, 3, 3, 0, 1, 1, 3, 0, 3, 2, 2, 3, 3, 0, 1, 2, 1, 2, 0, 0, 1, 2, 0, 3, 2, 0, 1, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 49 and the episode is 4677 and the total_steps are 216882\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 1, 0, 2, 0, 1, 0, 0, 2, 3, 2, 0, 3, 3, 2, 3, 1, 3, 1, 2, 0, 1, 1, 3, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 31 and the episode is 4678 and the total_steps are 216913\n",
      "Done condition: collision\n",
      "[3, 2, 1, 0, 2, 3, 3, 1, 3, 0, 0, 0, 2, 1, 2, 0, 3, 2, 0, 0, 2, 0, 0, 2, 2, 2, 1, 3, 1, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 32 and the episode is 4679 and the total_steps are 216945\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 3, 1, 3, 1, 3, 0, 2, 3, 3, 3, 3, 1, 3, 0, 3, 1, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 32 and the episode is 4680 and the total_steps are 216977\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4680     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7708     |\n",
      "|    total_timesteps  | 216977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 58.9     |\n",
      "|    n_updates        | 41744    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 0, 1, 3, 3, 2, 0, 0, 2, 2, 2, 3, 0, 1, 3, 2, 2, 1, 1, 0, 3, 1, 3, 0, 3, 3, 2, 2, 0, 0, 2, 3, 1, 0, 1, 1, 3, 2, 3, 3, 3, 3, 2, 2, 3, 0, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 52 and the episode is 4681 and the total_steps are 217029\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 1, 1, 3, 3, 2, 0, 0, 2, 2, 2, 1, 3, 3, 0, 2, 3, 0, 2, 2, 0, 3, 1, 0, 0, 1, 3, 0, 3, 2, 0, 2, 1, 1, 1, 0, 1, 0, 0, 2, 1, 2, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 49 and the episode is 4682 and the total_steps are 217078\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 0, 1, 3, 0, 3, 2, 2, 0, 3, 3, 0, 3, 3, 1, 3, 0, 1, 2, 1, 1, 1, 2, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 27 and the episode is 4683 and the total_steps are 217105\n",
      "Done condition: collision\n",
      "[2, 2, 0, 2, 1, 2, 2, 0, 1, 3, 3, 0, 2, 2, 3, 1, 1, 1, 1, 0, 2, 3, 2, 0, 0, 1, 1, 1, 0, 2, 0, 3, 0, 0, 2, 2, 0, 3, 1, 1, 2, 2, 3, 0, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 48 and the episode is 4684 and the total_steps are 217153\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4684     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7716     |\n",
      "|    total_timesteps  | 217153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 66.7     |\n",
      "|    n_updates        | 41788    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 0, 0, 2, 1, 2, 2, 0, 0, 2, 0, 2, 1, 3, 3, 0, 0, 2, 1, 3, 1, 2, 3, 2, 1, 1, 3, 3, 1, 1, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 36 and the episode is 4685 and the total_steps are 217189\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 0, 1, 3, 3, 3, 3, 3, 0, 0, 3, 2, 1, 0, 3, 0, 1, 2, 1, 1, 0, 1, 0, 2, 3, 2, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4686 and the total_steps are 217221\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 1, 1, 2, 1, 3, 3, 1, 1, 2, 3, 2, 3, 1, 3, 2, 0, 3, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 32 and the episode is 4687 and the total_steps are 217253\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 2, 2, 2, 2, 0, 3, 0, 3, 2, 2, 2, 0, 3, 2, 3, 1, 3, 2, 0, 0, 0, 3, 1, 0, 1, 3, 1, 0, 3, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4688 and the total_steps are 217289\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4688     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7721     |\n",
      "|    total_timesteps  | 217289   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.19     |\n",
      "|    n_updates        | 41822    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 0, 2, 1, 3, 2, 3, 3, 0, 1, 1, 0, 1, 1, 3, 0, 3, 3, 1, 3, 1, 2, 2, 1, 0, 0, 3, 0, 1, 2, 3, 3, 3, 3, 3, 0, 0, 3, 3, 1, 3, 1, 0, 2, 3, 2, 0, 2, 3, 3, 1, 2, 2, 3, 1, 3, 1, 0, 0, 1, 0, 1, 2, 3, 2, 3, 3, 1, 0, 0, 3, 2, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1055. And steps were 79 and the episode is 4689 and the total_steps are 217368\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 2, 3, 2, 0, 3, 1, 2, 1, 3, 0, 3, 3, 1, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 21 and the episode is 4690 and the total_steps are 217389\n",
      "Done condition: collision\n",
      "[3, 2, 3, 2, 3, 1, 3, 2, 2, 2, 2, 0, 2, 2, 0, 2, 3, 0, 0, 1, 1, 2, 1, 2, 3, 1, 0, 0, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 32 and the episode is 4691 and the total_steps are 217421\n",
      "Done condition: collision\n",
      "[1, 1, 0, 0, 0, 0, 3, 1, 1, 2, 2, 3, 3, 0, 3, 2, 1, 0, 0, 3, 1, 0, 2, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 27 and the episode is 4692 and the total_steps are 217448\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4692     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7728     |\n",
      "|    total_timesteps  | 217448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.1     |\n",
      "|    n_updates        | 41861    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 0, 1, 3, 0, 1, 0, 3, 0, 2, 1, 3, 3, 3, 2, 0, 1, 2, 2, 1, 1, 3, 3, 1, 0, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 31 and the episode is 4693 and the total_steps are 217479\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 3, 1, 2, 3, 0, 3, 1, 1, 2, 1, 1, 0, 1, 2, 1, 3, 1, 0, 0, 1, 0, 2, 0, 2, 0, 1, 2, 2, 0, 3, 3, 1, 3, 3, 0, 1, 1, 0, 0, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 46 and the episode is 4694 and the total_steps are 217525\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 1, 3, 0, 2, 3, 1, 2, 3, 1, 2, 2, 1, 0, 3, 2, 2, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 24 and the episode is 4695 and the total_steps are 217549\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 2, 1, 3, 0, 0, 3, 0, 0, 2, 0, 0, 2, 2, 3, 0, 1, 0, 1, 0, 0, 2, 1, 1, 0, 0, 1, 3, 0, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4696 and the total_steps are 217585\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.1     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4696     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7735     |\n",
      "|    total_timesteps  | 217585   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.32     |\n",
      "|    n_updates        | 41896    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 3, 0, 2, 1, 1, 3, 0, 0, 3, 3, 3, 3, 1, 2, 1, 3, 3, 0, 0, 3, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4697 and the total_steps are 217613\n",
      "Done condition: collision\n",
      "[3, 3, 3, 1, 1, 0, 2, 2, 2, 0, 3, 3, 1, 0, 1, 0, 2, 0, 3, 2, 2, 0, 3, 0, 3, 0, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 29 and the episode is 4698 and the total_steps are 217642\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 3, 3, 3, 3, 2, 1, 0, 0, 1, 1, 2, 2, 2, 3, 2, 2, 0, 2, 0, 3, 3, 1, 3, 0, 0, 3, 3, 1, 1, 0, 2, 2, 2, 1, 0, 3, 0, 2, 3, 3, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 47 and the episode is 4699 and the total_steps are 217689\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 3, 0, 0, 2, 3, 1, 3, 2, 0, 1, 0, 0, 1, 1, 2, 1, 1, 3, 1, 2, 2, 1, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was 1009. And steps were 28 and the episode is 4700 and the total_steps are 217717\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | -923     |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4700     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7741     |\n",
      "|    total_timesteps  | 217717   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.71     |\n",
      "|    n_updates        | 41929    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 3, 0, 1, 1, 3, 1, 3, 3, 3, 1, 1, 2, 3, 2, 0, 0, 2, 3, 0, 1, 0, 3, 1, 1, 2, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 33 and the episode is 4701 and the total_steps are 217750\n",
      "Done condition: collision\n",
      "[0, 1, 2, 3, 2, 2, 2, 2, 0, 3, 0, 3, 2, 1, 2, 2, 2, 0, 3, 2, 0, 3, 2, 0, 3, 1, 3, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 31 and the episode is 4702 and the total_steps are 217781\n",
      "Done condition: collision\n",
      "[3, 0, 2, 0, 2, 2, 2, 2, 3, 0, 2, 1, 3, 2, 0, 3, 3, 2, 3, 1, 2, 3, 2, 3, 3, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 29 and the episode is 4703 and the total_steps are 217810\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 3, 0, 2, 2, 3, 2, 2, 1, 3, 2, 2, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 19 and the episode is 4704 and the total_steps are 217829\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.5     |\n",
      "|    ep_rew_mean      | -922     |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4704     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7746     |\n",
      "|    total_timesteps  | 217829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 41957    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 2, 0, 1, 0, 0, 0, 3, 1, 2, 1, 2, 2, 2, 2, 2, 0, 2, 0, 3, 3, 1, 0, 3, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 31 and the episode is 4705 and the total_steps are 217860\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 3, 1, 3, 0, 1, 1, 0, 1, 2, 2, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 29 and the episode is 4706 and the total_steps are 217889\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 3, 2, 1, 0, 2, 1, 3, 2, 3, 2, 0, 0, 3, 3, 0, 3, 2, 3, 0, 0, 0, 1, 1, 2, 1, 1, 0, 2, 3, 0, 2, 3, 2, 3, 1, 3, 1, 2, 2, 3, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1046. And steps were 48 and the episode is 4707 and the total_steps are 217937\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 0, 2, 0, 1, 2, 3, 1, 3, 3, 1, 1, 2, 3, 3, 0, 3, 0, 3, 3, 3, 0, 0, 3, 3, 2, 3, 1, 1, 1, 3, 3, 1, 2, 2, 2, 2, 0, 1, 2, 1, 2, 2, 0, 2, 0, 3, 3, 3, 3, 3, 2, 1, 2, 2, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 62 and the episode is 4708 and the total_steps are 217999\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.9     |\n",
      "|    ep_rew_mean      | -923     |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4708     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7753     |\n",
      "|    total_timesteps  | 217999   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 41999    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 1, 3, 0, 1, 3, 0, 1, 2, 3, 1, 3, 3, 0, 2, 2, 2, 2, 0, 2, 2, 1, 1, 3, 3, 3, 1, 2, 3, 2, 1, 2, 0, 0, 0, 2, 1, 2, 1, 2, 1, 3, 3, 1, 0, 0, 1, 2, 2, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 56 and the episode is 4709 and the total_steps are 218055\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 1, 1, 1, 2, 2, 1, 2, 3, 2, 0, 1, 0, 0, 3, 1, 1, 2, 1, 3, 3, 0, 3, 3, 3, 1, 2, 0, 3, 0, 3, 1, 2, 3, 1, 1, 3, 0, 3, 2, 2, 1, 2, 1, 2, 0, 0, 0, 1, 3, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 57 and the episode is 4710 and the total_steps are 218112\n",
      "Done condition: collision\n",
      "[0, 1, 1, 1, 1, 3, 1, 3, 0, 1, 3, 1, 3, 3, 3, 1, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 20 and the episode is 4711 and the total_steps are 218132\n",
      "Done condition: collision\n",
      "[1, 2, 0, 3, 2, 0, 3, 0, 1, 1, 0, 2, 1, 3, 1, 0, 2, 3, 1, 1, 0, 1, 3, 2, 1, 2, 2, 3, 0, 3, 0, 1, 2, 1, 1, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 38 and the episode is 4712 and the total_steps are 218170\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -923     |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4712     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7761     |\n",
      "|    total_timesteps  | 218170   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.4     |\n",
      "|    n_updates        | 42042    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 2, 0, 1, 0, 0, 0, 3, 0, 3, 0, 1, 3, 1, 3, 0, 0, 0, 3, 1, 2, 1, 1, 1, 1, 2, 0, 3, 0, 0, 1, 1, 0, 0, 3, 0, 2, 3, 2, 0, 2, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 48 and the episode is 4713 and the total_steps are 218218\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 0, 3, 1, 3, 1, 0, 3, 0, 2, 0, 0, 0, 3, 3, 0, 3, 3, 0, 3, 1, 2, 1, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1029. And steps were 31 and the episode is 4714 and the total_steps are 218249\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 2, 3, 3, 1, 1, 2, 1, 3, 1, 0, 2, 0, 2, 0, 2, 3, 1, 0, 2, 1, 2, 1, 3, 3, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 32 and the episode is 4715 and the total_steps are 218281\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 1, 1, 1, 3, 3, 1, 1, 0, 1, 0, 1, 3, 2, 2, 3, 3, 1, 3, 1, 1, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 4716 and the total_steps are 218309\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4716     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7767     |\n",
      "|    total_timesteps  | 218309   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.2     |\n",
      "|    n_updates        | 42077    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 0, 0, 3, 2, 2, 1, 1, 1, 3, 1, 1, 3, 0, 2, 1, 2, 0, 1, 2, 1, 0, 3, 2, 1, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 32 and the episode is 4717 and the total_steps are 218341\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 1, 1, 3, 2, 0, 0, 0, 0, 0, 0, 3, 3, 1, 2, 0, 2, 2, 2, 3, 2, 1, 0, 2, 3, 1, 3, 0, 2, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 36 and the episode is 4718 and the total_steps are 218377\n",
      "Done condition: collision\n",
      "[3, 3, 2, 2, 2, 0, 2, 0, 1, 0, 3, 3, 0, 1, 3, 0, 2, 1, 3, 2, 2, 2, 1, 0, 2, 1, 2, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 30 and the episode is 4719 and the total_steps are 218407\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 2, 3, 0, 2, 3, 2, 2, 2, 2, 0, 2, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 18 and the episode is 4720 and the total_steps are 218425\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.1     |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4720     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7772     |\n",
      "|    total_timesteps  | 218425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.71     |\n",
      "|    n_updates        | 42106    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 2, 3, 2, 0, 3, 1, 0, 2, 0, 0, 0, 0, 1, 3, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 29 and the episode is 4721 and the total_steps are 218454\n",
      "Done condition: collision\n",
      "[3, 3, 3, 0, 3, 2, 3, 2, 3, 3, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 3, 0, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 27 and the episode is 4722 and the total_steps are 218481\n",
      "Done condition: collision\n",
      "[2, 0, 2, 3, 2, 3, 3, 2, 2, 2, 0, 2, 3, 0, 0, 2, 2, 2, 0, 3, 2, 0, 1, 2, 0, 1, 0, 2, 2, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4723 and the total_steps are 218513\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 1, 3, 0, 2, 2, 1, 0, 3, 2, 0, 3, 0, 1, 2, 0, 0, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 4724 and the total_steps are 218537\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4724     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7777     |\n",
      "|    total_timesteps  | 218537   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.21     |\n",
      "|    n_updates        | 42134    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 2, 0, 3, 2, 3, 3, 0, 0, 3, 1, 3, 1, 0, 0, 0, 1, 2, 3, 1, 1, 1, 2, 2, 0, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 32 and the episode is 4725 and the total_steps are 218569\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 2, 0, 1, 1, 1, 2, 1, 3, 0, 2, 3, 0, 2, 1, 1, 0, 2, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 24 and the episode is 4726 and the total_steps are 218593\n",
      "Done condition: collision\n",
      "[2, 3, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 1, 2, 2, 3, 3, 3, 0, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 24 and the episode is 4727 and the total_steps are 218617\n",
      "Done condition: collision\n",
      "[2, 1, 2, 1, 1, 3, 3, 0, 2, 1, 1, 3, 1, 0, 3, 3, 1, 1, 0, 0, 1, 0, 2, 1, 3, 3, 3, 0, 3, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 34 and the episode is 4728 and the total_steps are 218651\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4728     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7782     |\n",
      "|    total_timesteps  | 218651   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.7     |\n",
      "|    n_updates        | 42162    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 0, 0, 0, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 3, 3, 2, 1, 1, 3, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 34 and the episode is 4729 and the total_steps are 218685\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 1, 0, 2, 1, 2, 2, 2, 3, 0, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 17 and the episode is 4730 and the total_steps are 218702\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 3, 2, 1, 3, 0, 2, 2, 3, 3, 2, 2, 1, 0, 1, 1, 3, 2, 0, 3, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 27 and the episode is 4731 and the total_steps are 218729\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 3, 2, 3, 2, 1, 1, 1, 3, 0, 2, 2, 2, 0, 1, 3, 1, 1, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4732 and the total_steps are 218754\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4732     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7787     |\n",
      "|    total_timesteps  | 218754   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.3     |\n",
      "|    n_updates        | 42188    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 1, 3, 2, 1, 1, 0, 0, 3, 0, 2, 3, 3, 2, 1, 2, 3, 1, 0, 2, 3, 1, 1, 3, 0, 3, 2, 2, 2, 0, 0, 3, 1, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1037. And steps were 39 and the episode is 4733 and the total_steps are 218793\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 1, 1, 2, 2, 3, 2, 3, 3, 0, 3, 2, 2, 2, 1, 3, 0, 1, 3, 0, 3, 0, 0, 0, 1, 0, 0, 2, 2, 2, 2, 0, 1, 2, 1, 1, 3, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 44 and the episode is 4734 and the total_steps are 218837\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 1, 1, 3, 3, 3, 3, 0, 0, 3, 3, 1, 1, 2, 0, 3, 1, 2, 2, 2, 1, 0, 2, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was 976. And steps were 27 and the episode is 4735 and the total_steps are 218864\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 0, 3, 0, 1, 0, 3, 1, 0, 3, 1, 1, 2, 2, 0, 3, 1, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was 1020. And steps were 21 and the episode is 4736 and the total_steps are 218885\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35       |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4736     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7792     |\n",
      "|    total_timesteps  | 218885   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 42221    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 0, 0, 1, 0, 0, 3, 0, 3, 0, 0, 1, 1, 2, 1, 0, 0, 1, 1, 0, 3, 2, 1, 0, 3, 0, 0, 1, 2, 0, 2, 3, 1, 2, 1, 2, 3, 0, 1, 3, 1, 1, 0, 1, 0, 1, 3, 2, 1, 3, 3, 0, 0, 1, 2, 2, 2, 2, 3, 1, 2, 3, 3, 2, 1, 2, 2, 0, 3, 0, 2, 1, 0, 2, 2, 2, 2, 1, 3, 1, 1, 3, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1062. And steps were 88 and the episode is 4737 and the total_steps are 218973\n",
      "Done condition: collision\n",
      "[3, 1, 2, 2, 1, 1, 2, 1, 3, 0, 3, 3, 3, 0, 2, 0, 1, 1, 0, 2, 0, 3, 3, 3, 0, 1, 2, 3, 3, 3, 3, 0, 0, 3, 0, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 38 and the episode is 4738 and the total_steps are 219011\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 0, 3, 2, 0, 3, 3, 3, 1, 1, 3, 1, 1, 2, 0, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1018. And steps were 19 and the episode is 4739 and the total_steps are 219030\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 2, 1, 2, 1, 2, 3, 1, 0, 1, 1, 0, 3, 1, 0, 3, 2, 2, 1, 3, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 4740 and the total_steps are 219057\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | -883     |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4740     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7800     |\n",
      "|    total_timesteps  | 219057   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.44     |\n",
      "|    n_updates        | 42264    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 3, 0, 0, 0, 2, 1, 3, 1, 0, 3, 2, 0, 3, 3, 3, 0, 3, 0, 2, 1, 0, 1, 3, 2, 1, 2, 0, 0, 0, 3, 1, 0, 2, 1, 1, 3, 0, 2, 3, 0, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 48 and the episode is 4741 and the total_steps are 219105\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 1, 3, 2, 3, 2, 3, 0, 1, 1, 2, 2, 0, 2, 0, 0, 3, 0, 2, 2, 1, 2, 0, 0, 3, 3, 3, 2, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 32 and the episode is 4742 and the total_steps are 219137\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 3, 0, 0, 2, 2, 2, 3, 2, 3, 0, 1, 2, 0, 2, 1, 0, 2, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 24 and the episode is 4743 and the total_steps are 219161\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 3, 2, 0, 3, 3, 0, 2, 3, 3, 2, 1, 2, 3, 2, 3, 1, 1, 1, 3, 3, 2, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4744 and the total_steps are 219189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -883     |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4744     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7806     |\n",
      "|    total_timesteps  | 219189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.34     |\n",
      "|    n_updates        | 42297    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 3, 3, 0, 1, 1, 3, 2, 2, 3, 2, 0, 1, 0, 1, 0, 1, 0, 2, 3, 3, 1, 0, 2, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 4745 and the total_steps are 219225\n",
      "Done condition: collision\n",
      "[2, 3, 0, 0, 1, 1, 0, 1, 3, 2, 3, 0, 3, 1, 0, 3, 2, 3, 2, 2, 0, 3, 2, 3, 3, 1, 3, 3, 2, 3, 3, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 34 and the episode is 4746 and the total_steps are 219259\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 1, 3, 3, 0, 1, 3, 2, 3, 1, 3, 3, 2, 0, 0, 1, 0, 1, 1, 3, 1, 2, 0, 3, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 30 and the episode is 4747 and the total_steps are 219289\n",
      "Done condition: collision\n",
      "[1, 3, 3, 0, 2, 1, 0, 3, 2, 1, 2, 3, 1, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 17 and the episode is 4748 and the total_steps are 219306\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | -883     |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4748     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7811     |\n",
      "|    total_timesteps  | 219306   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.2     |\n",
      "|    n_updates        | 42326    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 3, 1, 3, 3, 2, 3, 3, 1, 2, 3, 0, 1, 1, 2, 0, 2, 3, 3, 1, 1, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 27 and the episode is 4749 and the total_steps are 219333\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 1, 3, 0, 0, 1, 0, 1, 0, 0, 1, 0, 3, 3, 2, 3, 3, 2, 1, 3, 3, 3, 2, 2, 2, 2, 0, 0, 0, 3, 1, 2, 3, 3, 3, 0, 0, 2, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 45 and the episode is 4750 and the total_steps are 219378\n",
      "Done condition: collision\n",
      "[1, 3, 2, 2, 2, 0, 0, 3, 2, 1, 3, 0, 2, 2, 1, 2, 1, 2, 1, 1, 3, 0, 2, 0, 2, 0, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 30 and the episode is 4751 and the total_steps are 219408\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 1, 2, 1, 3, 0, 2, 2, 2, 0, 0, 0, 2, 1, 1, 3, 0, 0, 3, 2, 3, 1, 3, 3, 3, 2, 3, 3, 0, 1, 1, 2, 2, 1, 3, 3, 1, 1, 2, 1, 0, 3, 1, 0, 3, 3, 0, 2, 1, 3, 2, 3, 1, 2, 1, 0, 2, 2, 2, 3, 3, 0, 0, 0, 2, 0, 1, 1, 0, 2, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 77 and the episode is 4752 and the total_steps are 219485\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | -903     |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4752     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7818     |\n",
      "|    total_timesteps  | 219485   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 42371    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 0, 3, 0, 2, 1, 3, 2, 1, 3, 3, 0, 3, 1, 1, 3, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 0, 2, 0, 1, 0, 1, 3, 1, 0, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 41 and the episode is 4753 and the total_steps are 219526\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 1, 2, 0, 1, 3, 3, 3, 2, 3, 1, 1, 0, 3, 0, 2, 1, 3, 3, 3, 1, 3, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 29 and the episode is 4754 and the total_steps are 219555\n",
      "Done condition: collision\n",
      "[2, 1, 3, 3, 0, 2, 1, 0, 2, 0, 2, 2, 1, 2, 2, 3, 3, 0, 1, 3, 0, 0, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 26 and the episode is 4755 and the total_steps are 219581\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 1, 1, 1, 1, 2, 0, 1, 3, 3, 0, 3, 3, 3, 0, 2, 2, 1, 2, 1, 2, 3, 1, 3, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 0, 3, 2, 2, 0, 0, 3, 1, 3, 0, 2, 3, 2, 3, 0, 3, 1, 1, 3, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 0, 3, 2, 3, 3, 0, 1, 0, 1, 2, 0, 2, 1, 0, 1, 2, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -926. And steps were 88 and the episode is 4756 and the total_steps are 219669\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -903     |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4756     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7826     |\n",
      "|    total_timesteps  | 219669   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.7     |\n",
      "|    n_updates        | 42417    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 0, 0, 3, 1, 2, 0, 0, 0, 0, 0, 3, 0, 0, 2, 1, 1, 1, 1, 2, 1, 0, 2, 3, 0, 1, 3, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1020. And steps were 44 and the episode is 4757 and the total_steps are 219713\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 2, 0, 1, 2, 3, 3, 2, 1, 2, 1, 3, 1, 1, 0, 2, 0, 1, 0, 2, 2, 2, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 28 and the episode is 4758 and the total_steps are 219741\n",
      "Done condition: collision\n",
      "[2, 3, 2, 1, 3, 3, 1, 3, 3, 3, 0, 1, 3, 3, 3, 2, 3, 2, 2, 0, 2, 1, 3, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 27 and the episode is 4759 and the total_steps are 219768\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 3, 0, 1, 0, 0, 3, 3, 3, 2, 3, 2, 1, 3, 1, 2, 2, 2, 1, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 26 and the episode is 4760 and the total_steps are 219794\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -903     |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4760     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7832     |\n",
      "|    total_timesteps  | 219794   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.4     |\n",
      "|    n_updates        | 42448    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 0, 0, 3, 3, 2, 1, 2, 2, 0, 3, 0, 1, 1, 0, 2, 3, 3, 0, 1, 0, 3, 3, 3, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 31 and the episode is 4761 and the total_steps are 219825\n",
      "Done condition: collision\n",
      "[1, 3, 0, 3, 2, 2, 0, 3, 3, 1, 3, 3, 3, 0, 2, 3, 3, 3, 2, 2, 3, 2, 2, 0, 3, 2, 3, 0, 2, 2, 2, 0, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 36 and the episode is 4762 and the total_steps are 219861\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 0, 2, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 2, 0, 3, 0, 3, 1, 1, 1, 0, 0, 2, 0, 0, 2, 1, 3, 3, 1, 2, 1, 1, 2, 3, 2, 1, 0, 2, 0, 2, 1, 0, 1, 2, 0, 3, 2, 0, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1055. And steps were 57 and the episode is 4763 and the total_steps are 219918\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 0, 2, 2, 1, 2, 1, 1, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 15 and the episode is 4764 and the total_steps are 219933\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | -904     |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4764     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7838     |\n",
      "|    total_timesteps  | 219933   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.2     |\n",
      "|    n_updates        | 42483    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 0, 1, 2, 3, 3, 3, 3, 3, 0, 1, 1, 0, 2, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 3, 3, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 4765 and the total_steps are 219965\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 0, 3, 2, 0, 1, 1, 3, 3, 2, 3, 1, 3, 2, 2, 0, 1, 1, 1, 2, 1, 3, 0, 3, 2, 1, 0, 0, 3, 0, 1, 3, 2, 3, 1, 0, 1, 1, 3, 0, 3, 2, 0, 0, 0, 0, 3, 0, 3, 2, 1, 0, 1, 1, 2, 3, 2, 3, 2, 2, 2, 2, 0, 1, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1069. And steps were 71 and the episode is 4766 and the total_steps are 220036\n",
      "Done condition: collision\n",
      "[0, 1, 0, 2, 2, 2, 2, 2, 2, 3, 1, 1, 1, 0, 1, 1, 1, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 21 and the episode is 4767 and the total_steps are 220057\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 1, 3, 1, 1, 3, 3, 3, 2, 0, 3, 0, 3, 2, 0, 1, 1, 0, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 24 and the episode is 4768 and the total_steps are 220081\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | -905     |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4768     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7845     |\n",
      "|    total_timesteps  | 220081   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 42520    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 3, 1, 3, 1, 1, 1, 3, 1, 1, 2, 1, 0, 1, 1, 1, 1, 3, 0, 1, 0, 0, 1]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 4769 and the total_steps are 220105\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 3, 2, 0, 3, 2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 3, 3, 1, 1, 0, 0, 3, 0, 3, 2, 2, 0, 2, 1, 2, 3, 1, 1, 0, 3, 3, 0, 3, 0, 2, 1, 2, 1, 2, 0, 3, 1, 1, 1, 1, 0, 0, 2, 2, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 60 and the episode is 4770 and the total_steps are 220165\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 3, 0, 2, 2, 1, 0, 1, 1, 0, 0, 1, 3, 3, 0, 1, 3, 0, 1, 2, 0, 0, 0, 2, 1, 2, 0, 2, 2, 3, 2, 1, 2, 2, 2, 3, 3, 2, 3, 3, 2, 1, 0, 0, 0, 1, 1, 3, 2, 1, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 57 and the episode is 4771 and the total_steps are 220222\n",
      "Done condition: collision\n",
      "[2, 3, 2, 2, 3, 0, 2, 0, 2, 2, 0, 3, 0, 3, 1, 0, 2, 1, 3, 1, 1, 2, 2, 0, 1, 3, 3, 1, 3, 0, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 31 and the episode is 4772 and the total_steps are 220253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | -882     |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4772     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7852     |\n",
      "|    total_timesteps  | 220253   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 42563    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 2, 1, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 2, 2, 0, 3, 2, 1, 0, 3, 2, 1, 3, 2, 3, 3, 0, 2, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 36 and the episode is 4773 and the total_steps are 220289\n",
      "Done condition: collision\n",
      "[1, 1, 2, 3, 3, 3, 2, 3, 1, 0, 0, 1, 0, 2, 3, 0, 2, 3, 1, 3, 1, 1, 0, 1, 2, 3, 1, 0, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 31 and the episode is 4774 and the total_steps are 220320\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 3, 3, 3, 0, 0, 1, 2, 3, 3, 3, 1, 0, 3, 1, 1, 1, 3, 3, 0, 2, 1, 3, 3, 2, 2, 3, 2, 1, 2, 2, 3, 2, 3, 2, 0, 1, 3, 3, 2, 0, 2, 0, 3, 1, 1, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -962. And steps were 52 and the episode is 4775 and the total_steps are 220372\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 0, 1, 2, 3, 1, 2, 1, 0, 1, 0, 2, 0, 1, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 0, 2, 2, 1, 2, 0, 2, 2, 3, 1, 3, 2, 0, 2, 3, 2, 3, 3, 1, 3, 1, 2, 1, 1, 3, 3, 2, 2, 3, 0, 0, 0, 1, 2, 2, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 65 and the episode is 4776 and the total_steps are 220437\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4776     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7860     |\n",
      "|    total_timesteps  | 220437   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65.1     |\n",
      "|    n_updates        | 42609    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 3, 3, 3, 2, 2, 1, 0, 0, 1, 3, 1, 0, 3, 0, 3, 1, 2, 1, 0, 0, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 28 and the episode is 4777 and the total_steps are 220465\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 1, 1, 2, 2, 3, 3, 1, 3, 2, 0, 0, 3, 0, 2, 0, 2, 0, 1, 1, 2, 3, 0, 0, 2, 0, 1, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 34 and the episode is 4778 and the total_steps are 220499\n",
      "Done condition: collision\n",
      "[3, 0, 3, 2, 0, 3, 1, 1, 0, 3, 1, 1, 3, 0, 2, 2, 3, 0, 1, 2, 1, 0, 2, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 4779 and the total_steps are 220525\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 0, 0, 2, 1, 3, 0, 1, 2, 0, 2, 1, 0, 3, 0, 1, 1, 2, 3, 0, 2, 2, 0, 2, 1, 1, 1, 0, 3, 2, 0, 2, 1, 2, 0, 3, 2, 0, 1, 2, 2, 0, 1, 3, 1, 0, 0, 0, 1, 0, 0, 3, 3, 1, 1, 1, 3, 3, 2, 2, 0, 2, 2, 2, 0, 2, 2, 3, 3, 1, 0, 0, 2, 0, 1, 0, 3, 1, 3, 2, 0, 1, 0, 3, 3, 1, 1, 2, 2, 1, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -938. And steps were 96 and the episode is 4780 and the total_steps are 220621\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4780     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7868     |\n",
      "|    total_timesteps  | 220621   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 61.6     |\n",
      "|    n_updates        | 42655    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 2, 0, 3, 2, 1, 1, 2, 3, 1, 3, 0, 1, 2, 0, 0, 3, 3, 0, 3, 1, 1, 3, 1, 0, 2, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 4781 and the total_steps are 220651\n",
      "Done condition: collision\n",
      "[3, 2, 2, 2, 0, 0, 0, 3, 1, 3, 3, 3, 3, 3, 1, 2, 0, 2, 1, 0, 2, 1, 1, 2, 1, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 28 and the episode is 4782 and the total_steps are 220679\n",
      "Done condition: collision\n",
      "[0, 2, 2, 0, 1, 1, 1, 3, 0, 1, 2, 2, 1, 3, 3, 3, 1, 2, 2, 2, 2, 2, 1, 1, 1, 0, 1, 0, 2, 2, 3, 3, 3, 1, 3, 1, 3, 3, 1, 2, 2, 3, 3, 0, 3, 3, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 50 and the episode is 4783 and the total_steps are 220729\n",
      "Done condition: collision\n",
      "[3, 0, 1, 1, 0, 2, 2, 3, 3, 3, 0, 1, 3, 2, 1, 0, 3, 1, 1, 3, 2, 2, 3, 1, 0, 3, 1, 2, 1, 3, 1, 1, 2, 3, 2, 0, 3, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 40 and the episode is 4784 and the total_steps are 220769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4784     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7875     |\n",
      "|    total_timesteps  | 220769   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 42692    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 0, 3, 3, 3, 1, 2, 1, 1, 0, 1, 0, 2, 0, 3, 2, 1, 2, 1, 0, 2, 3, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 28 and the episode is 4785 and the total_steps are 220797\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[0, 1, 1, 1, 0, 3, 3, 0, 0, 3, 3, 2, 3, 3, 0, 2, 3, 0, 2, 0, 1, 2, 0, 3]\n",
      "The environmnet has been reset. The total reward was 1023. And steps were 24 and the episode is 4786 and the total_steps are 220821\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 2, 0, 1, 1, 2, 3, 2, 0, 2, 3, 3, 1, 3, 3, 0, 3, 2, 3, 1, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 27 and the episode is 4787 and the total_steps are 220848\n",
      "Done condition: collision\n",
      "[2, 2, 3, 3, 1, 1, 3, 3, 2, 3, 3, 2, 1, 1, 3, 1, 2, 0, 3, 3, 3, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4788 and the total_steps are 220873\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4788     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7879     |\n",
      "|    total_timesteps  | 220873   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.02     |\n",
      "|    n_updates        | 42718    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 3, 0, 3, 1, 0, 0, 1, 0, 2, 3, 3, 0, 3, 1, 1, 2, 1, 0, 0, 2, 3, 2, 3, 3, 0, 2, 2, 1, 1, 1, 1, 3, 0, 3, 1, 0, 0, 3, 3, 3, 0, 3, 2, 1, 1, 0, 2, 3, 1, 0, 3, 1, 1, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 60 and the episode is 4789 and the total_steps are 220933\n",
      "Done condition: collision\n",
      "[3, 3, 1, 1, 1, 1, 1, 3, 2, 3, 1, 0, 0, 0, 3, 3, 0, 0, 3, 0, 1, 3, 1, 3, 2, 1, 2, 3, 0, 3, 3, 0, 0, 2, 1, 3, 0, 3, 2, 2, 0, 1, 3, 1, 2, 1, 0, 1, 1, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 53 and the episode is 4790 and the total_steps are 220986\n",
      "Done condition: collision\n",
      "[3, 0, 2, 2, 0, 2, 1, 0, 0, 3, 0, 3, 3, 1, 2, 1, 1, 1, 3, 3, 0, 1, 2, 2, 2, 2, 2, 3, 1, 2, 3, 1, 2, 1, 1, 0, 0, 1, 0, 1, 3, 2, 1, 3, 0, 2, 3, 2, 3, 0, 0, 1, 1, 2, 1, 1, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 59 and the episode is 4791 and the total_steps are 221045\n",
      "Done condition: collision\n",
      "[3, 0, 1, 3, 0, 2, 3, 1, 1, 1, 3, 0, 3, 2, 3, 0, 0, 0, 0, 2, 2, 1, 2, 2, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 27 and the episode is 4792 and the total_steps are 221072\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4792     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7888     |\n",
      "|    total_timesteps  | 221072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.7     |\n",
      "|    n_updates        | 42767    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 2, 0, 1, 0, 0, 3, 0, 3, 3, 1, 1, 3, 3, 0, 1, 0, 0, 2, 3, 3, 2, 0, 0, 1, 2, 2, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1011. And steps were 29 and the episode is 4793 and the total_steps are 221101\n",
      "Done condition: collision\n",
      "[2, 1, 0, 3, 3, 2, 2, 2, 0, 0, 3, 1, 3, 0, 2, 0, 2, 3, 2, 2, 1, 2, 2, 2, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 28 and the episode is 4794 and the total_steps are 221129\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 2, 3, 3, 2, 2, 1, 2, 1, 1, 1, 2, 0, 1, 2, 1, 0, 0, 2, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 26 and the episode is 4795 and the total_steps are 221155\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 3, 1, 1, 3, 0, 0, 2, 3, 2, 3, 3, 2, 3, 3, 2, 1, 2, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 25 and the episode is 4796 and the total_steps are 221180\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4796     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7893     |\n",
      "|    total_timesteps  | 221180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.86     |\n",
      "|    n_updates        | 42794    |\n",
      "----------------------------------\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 0, 2, 1, 3, 1, 1, 3, 2, 3, 1, 1, 1, 2, 2, 0, 1, 3, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4797 and the total_steps are 221205\n",
      "Done condition: collision\n",
      "[2, 1, 2, 3, 1, 1, 1, 3, 1, 2, 0, 3, 3, 1, 1, 3, 0, 1, 0, 2, 0, 0, 0, 3, 3, 3, 0, 3, 0, 2, 0, 3, 1, 2, 0, 0, 1, 0, 0, 2, 0, 1, 3, 0, 2, 0, 2, 3, 3, 3, 1, 2, 3, 1, 3, 2, 3, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -957. And steps were 61 and the episode is 4798 and the total_steps are 221266\n",
      "Done condition: collision\n",
      "[2, 0, 0, 1, 1, 1, 3, 1, 1, 3, 3, 2, 1, 3, 3, 2, 0, 3, 0, 3, 0, 0, 2, 2, 2, 2, 3, 3, 3, 3, 1, 2, 0, 3, 3, 0, 2, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 41 and the episode is 4799 and the total_steps are 221307\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 1, 1, 3, 1, 0, 3, 2, 2, 2, 2, 2, 1, 3, 2, 0, 1, 3, 3, 3, 3, 0, 0, 3, 2, 2, 3, 2, 1, 1, 3, 1, 2, 0, 2, 1, 0, 0, 1, 1, 1, 0, 2, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 50 and the episode is 4800 and the total_steps are 221357\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4800     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7900     |\n",
      "|    total_timesteps  | 221357   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 65.3     |\n",
      "|    n_updates        | 42839    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 0, 1, 0, 1, 0, 2, 3, 3, 0, 1, 0, 2, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4801 and the total_steps are 221385\n",
      "Done condition: collision\n",
      "[1, 3, 0, 2, 0, 2, 2, 3, 0, 3, 0, 2, 1, 0, 0, 3, 3, 0, 3, 1, 1, 1, 0, 0, 2, 2, 1, 0, 1, 1, 0, 2, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 44 and the episode is 4802 and the total_steps are 221429\n",
      "Done condition: collision\n",
      "[2, 2, 1, 3, 0, 3, 0, 3, 0, 2, 3, 2, 1, 0, 1, 0, 2, 2, 3, 0, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 4803 and the total_steps are 221453\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 3, 3, 1, 3, 3, 1, 0, 0, 3, 0, 2, 3, 0, 2, 0, 0, 3, 3, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4804 and the total_steps are 221478\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.5     |\n",
      "|    ep_rew_mean      | -900     |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4804     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7906     |\n",
      "|    total_timesteps  | 221478   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.66     |\n",
      "|    n_updates        | 42869    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 2, 2, 1, 2, 2, 2, 3, 2, 1, 0, 3, 1, 3, 0, 0, 2, 3, 3, 3, 2, 3, 1, 3, 0, 2, 1, 3, 3, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 35 and the episode is 4805 and the total_steps are 221513\n",
      "Done condition: collision\n",
      "[3, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 2, 0, 2, 2, 2, 3, 1, 0, 2, 1, 3, 3, 2, 0, 3, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 4806 and the total_steps are 221545\n",
      "Done condition: collision\n",
      "[0, 3, 0, 2, 0, 2, 0, 3, 3, 2, 2, 1, 2, 2, 1, 0, 0, 2, 3, 2, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 24 and the episode is 4807 and the total_steps are 221569\n",
      "Done condition: collision\n",
      "[0, 2, 1, 3, 1, 2, 0, 1, 3, 0, 2, 3, 2, 3, 2, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 19 and the episode is 4808 and the total_steps are 221588\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4808     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7911     |\n",
      "|    total_timesteps  | 221588   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.98     |\n",
      "|    n_updates        | 42896    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 3, 3, 1, 0, 3, 1, 0, 1, 2, 3, 0, 1, 2, 0, 0, 3, 0, 1, 1, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 26 and the episode is 4809 and the total_steps are 221614\n",
      "Done condition: collision\n",
      "[2, 1, 3, 2, 0, 1, 2, 0, 3, 3, 2, 0, 3, 3, 3, 3, 2, 2, 1, 3, 2, 3, 3, 2, 1, 3, 2, 1, 0, 0, 3, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 42 and the episode is 4810 and the total_steps are 221656\n",
      "Done condition: collision\n",
      "[1, 3, 1, 2, 3, 1, 1, 3, 0, 1, 2, 2, 0, 1, 0, 3, 2, 0, 3, 2, 2, 3, 1, 1, 3, 3, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -995. And steps were 29 and the episode is 4811 and the total_steps are 221685\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 1, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 2, 1, 0, 3, 2, 2, 2, 2, 0, 0, 1, 1, 3, 2, 0, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 33 and the episode is 4812 and the total_steps are 221718\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4812     |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 7917     |\n",
      "|    total_timesteps  | 221718   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 42929    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 1, 1, 1, 3, 3, 0, 1, 0, 1, 2, 3, 1, 3, 2, 3, 2, 1, 3, 3, 0, 1, 2, 0, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 31 and the episode is 4813 and the total_steps are 221749\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 1, 3, 1, 1, 2, 2, 3, 2, 0, 1, 2, 0, 2, 1, 3, 1, 2, 0, 0, 2, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 4814 and the total_steps are 221777\n",
      "Done condition: collision\n",
      "[1, 0, 0, 2, 2, 2, 2, 2, 0, 3, 3, 0, 2, 0, 1, 3, 2, 1, 2, 2, 0, 3, 2, 0, 0, 2, 1, 0, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4815 and the total_steps are 221809\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 3, 1, 0, 2, 2, 0, 1, 1, 3, 1, 3, 2, 3, 3, 3, 0, 2, 3, 2, 1, 2, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -978. And steps were 28 and the episode is 4816 and the total_steps are 221837\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | -898     |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4816     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 7923     |\n",
      "|    total_timesteps  | 221837   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 62.9     |\n",
      "|    n_updates        | 42959    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 2, 1, 0, 3, 2, 1, 1, 1, 3, 1, 1, 3, 2, 2, 2, 0, 1, 3, 2, 2, 2, 0, 2, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was 975. And steps were 28 and the episode is 4817 and the total_steps are 221865\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 1, 1, 0, 3, 3, 3, 0, 3, 0, 3, 0, 2, 3, 3, 2, 0, 1, 1, 2, 0, 2, 1, 1, 3, 2, 0, 2, 3, 2, 1, 0, 1, 3, 2, 3, 0, 1, 3, 0, 3, 1, 2, 2, 3, 3, 1, 0, 1, 3, 2, 2, 3, 0, 1, 1, 0, 1, 3, 3, 0, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -947. And steps were 67 and the episode is 4818 and the total_steps are 221932\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 2, 2, 3, 2, 0, 0, 2, 1, 3, 2, 1, 3, 3, 1, 1, 3, 0, 2, 1, 1, 2, 2, 1, 1, 1, 1, 3, 2, 0, 3, 1, 1, 0, 0, 1, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -970. And steps were 42 and the episode is 4819 and the total_steps are 221974\n",
      "Done condition: collision\n",
      "[3, 1, 0, 1, 1, 1, 3, 1, 0, 1, 0, 3, 2, 2, 3, 0, 0, 1, 1, 0, 1, 0, 0, 0, 2, 3, 0, 0, 0, 1, 2, 3, 3, 2, 0, 3, 2, 0, 2, 0, 3, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 44 and the episode is 4820 and the total_steps are 222018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4820     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 7930     |\n",
      "|    total_timesteps  | 222018   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 28.7     |\n",
      "|    n_updates        | 43004    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 0, 3, 0, 0, 1, 2, 2, 0, 0, 1, 3, 0, 2, 1, 1, 2, 3, 1, 3, 1, 0, 0, 1, 3, 2, 3, 1, 2, 1, 1, 0, 3, 0, 1, 2, 2, 3, 0, 3, 3, 1, 3, 1, 2, 3, 1, 0, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -961. And steps were 55 and the episode is 4821 and the total_steps are 222073\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 3, 0, 1, 3, 3, 0, 3, 0, 3, 3, 0, 2, 3, 3, 0, 2, 3, 2, 1, 3, 3, 3, 0, 3, 3, 0, 3, 1, 0, 0, 2, 0, 2, 1, 2, 0, 2, 1, 3, 3, 3, 1, 1, 2, 1, 3, 0, 3, 3, 1, 0, 2, 0, 2, 3, 2, 2, 3, 3, 2, 1, 3, 2, 1, 3, 2, 2, 1, 1, 3, 1, 0, 0, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1044. And steps were 80 and the episode is 4822 and the total_steps are 222153\n",
      "Done condition: collision\n",
      "[1, 1, 0, 1, 3, 0, 0, 1, 2, 0, 3, 0, 3, 0, 1, 2, 0, 1, 2, 0, 1, 1, 1, 1, 0, 3, 2, 0, 1, 2, 2, 0, 0, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4823 and the total_steps are 222189\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 3, 0, 3, 3, 3, 0, 2, 1, 1, 2, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 24 and the episode is 4824 and the total_steps are 222213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | -878     |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4824     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 7939     |\n",
      "|    total_timesteps  | 222213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 119      |\n",
      "|    n_updates        | 43053    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 0, 0, 2, 3, 3, 2, 2, 1, 2, 2, 2, 2, 0, 3, 1, 3, 2, 1, 3, 3, 1, 0, 2, 1, 2, 1, 1, 0, 3, 0, 3, 0, 1, 1, 1, 2, 0, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 44 and the episode is 4825 and the total_steps are 222257\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 0, 0, 3, 1, 0, 1, 3, 2, 0, 3, 2, 3, 2, 1, 1, 1, 0, 1, 0, 2, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4826 and the total_steps are 222285\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 1, 1, 1, 3, 0, 1, 1, 0, 3, 3, 1, 1, 2, 1, 0, 1, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 24 and the episode is 4827 and the total_steps are 222309\n",
      "Done condition: collision\n",
      "[0, 2, 2, 1, 1, 1, 0, 0, 3, 2, 3, 1, 3, 0, 3, 0, 2, 2, 1, 1, 3, 2, 0, 3, 3, 1, 2, 1, 2, 3, 1, 0, 1, 2, 0, 2, 1, 1, 0, 1, 1, 1, 0, 0, 0, 3, 0, 3, 1, 3, 1, 0, 1, 1, 2, 2, 0, 3, 2, 3, 1, 0, 1, 1, 1, 0, 0, 0, 2, 2, 0, 3, 2, 1, 3, 2, 0, 1, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1057. And steps were 81 and the episode is 4828 and the total_steps are 222390\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4828     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 7947     |\n",
      "|    total_timesteps  | 222390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 43097    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 0, 1, 1, 3, 1, 3, 2, 0, 3, 2, 1, 0, 3, 0, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 0, 3, 1, 2, 3, 1, 0, 0, 2, 2, 2, 2, 3, 3, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -972. And steps were 48 and the episode is 4829 and the total_steps are 222438\n",
      "Done condition: collision\n",
      "[0, 0, 2, 2, 3, 2, 2, 1, 0, 2, 1, 3, 0, 3, 3, 2, 0, 0, 3, 2, 3, 2, 1, 1, 2, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 29 and the episode is 4830 and the total_steps are 222467\n",
      "Done condition: collision\n",
      "[0, 1, 1, 0, 1, 1, 2, 1, 2, 0, 0, 1, 3, 2, 1, 0, 2, 1, 3, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 23 and the episode is 4831 and the total_steps are 222490\n",
      "Done condition: collision\n",
      "[3, 3, 0, 3, 2, 0, 1, 3, 3, 0, 0, 2, 2, 1, 2, 0, 1, 2, 3, 3, 3, 0, 0, 1, 0, 3, 3, 3, 0, 3, 0, 0, 1, 3, 2, 2, 1, 0, 3, 0, 0, 1, 0, 3, 0, 1, 0, 3, 1, 0, 0, 0, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1035. And steps were 55 and the episode is 4832 and the total_steps are 222545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -879     |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4832     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 7955     |\n",
      "|    total_timesteps  | 222545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.15     |\n",
      "|    n_updates        | 43136    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 3, 2, 0, 2, 1, 1, 2, 0, 3, 3, 2, 2, 0, 3, 1, 3, 1, 0, 1, 0, 0, 3, 1, 3, 0, 2, 1, 0, 0, 1, 1, 1, 3, 0, 0, 1, 3, 3, 2, 3, 1, 3, 1, 2, 1, 0, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1018. And steps were 52 and the episode is 4833 and the total_steps are 222597\n",
      "Done condition: collision\n",
      "[2, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 2, 1, 3, 2, 3, 2, 3, 2, 0, 2, 2, 1, 1, 3, 0, 0, 2, 1, 1, 2, 2, 1, 2, 3, 1, 2, 0, 1, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 44 and the episode is 4834 and the total_steps are 222641\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 1, 1, 1, 0, 1, 2, 3, 2, 2, 2, 0, 2, 1, 1, 2, 1, 3, 2, 0, 2, 1, 2, 2, 3, 3, 3, 2, 2, 0, 0, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -968. And steps were 38 and the episode is 4835 and the total_steps are 222679\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 1, 0, 3, 3, 3, 2, 3, 0, 1, 2, 1, 2, 1, 3, 2, 2, 1, 2, 1, 0, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 28 and the episode is 4836 and the total_steps are 222707\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4836     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 7962     |\n",
      "|    total_timesteps  | 222707   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2        |\n",
      "|    n_updates        | 43176    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 0, 3, 1, 1, 1, 2, 1, 1, 3, 0, 3, 3, 3, 1, 0, 0, 3, 3, 2, 1, 3, 2, 1, 0, 3, 0, 0, 1, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 32 and the episode is 4837 and the total_steps are 222739\n",
      "Done condition: collision\n",
      "[1, 0, 3, 1, 1, 1, 3, 2, 1, 0, 3, 1, 2, 3, 0, 0, 3, 3, 1, 3, 3, 2, 1, 0, 1, 1, 2, 0, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 31 and the episode is 4838 and the total_steps are 222770\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 0, 1, 2, 2, 3, 3, 3, 3, 2, 1, 0, 1, 3, 3, 1, 2, 1, 0, 3, 1, 2, 2, 0, 0, 0, 1, 2, 2, 0, 1, 3, 1, 3, 1, 0, 0, 2, 3, 3, 3, 3, 0, 2, 3, 0, 0, 1, 3, 1, 2, 3, 0, 2, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1016. And steps were 60 and the episode is 4839 and the total_steps are 222830\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 1, 3, 1, 2, 0, 3, 3, 3, 2, 3, 1, 3, 1, 0, 0, 1, 2, 2, 0, 1, 1, 2, 2, 1, 3, 3, 2, 3, 1, 2, 3, 3, 2, 3, 1, 3, 1, 2, 0, 3, 0, 0, 2, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 51 and the episode is 4840 and the total_steps are 222881\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4840     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 7970     |\n",
      "|    total_timesteps  | 222881   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 36       |\n",
      "|    n_updates        | 43220    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 2, 3, 2, 3, 1, 1, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 12 and the episode is 4841 and the total_steps are 222893\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 2, 2, 2, 2, 0, 2, 1, 3, 3, 3, 3, 2, 2, 3, 1, 0, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 24 and the episode is 4842 and the total_steps are 222917\n",
      "Done condition: collision\n",
      "[2, 1, 3, 1, 1, 3, 1, 1, 2, 0, 3, 1, 1, 3, 2, 3, 1, 0, 2, 3, 3, 3, 0, 0, 2, 1, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 30 and the episode is 4843 and the total_steps are 222947\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 2, 1, 1, 1, 3, 3, 0, 1, 3, 2, 0, 3, 0, 3, 3, 0, 0, 3, 2, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 4844 and the total_steps are 222974\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4844     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 7975     |\n",
      "|    total_timesteps  | 222974   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 30.9     |\n",
      "|    n_updates        | 43243    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 1, 2, 1, 3, 1, 0, 0, 1, 1, 0, 1, 3, 1, 3, 0, 2, 2, 3, 3, 2, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 4845 and the total_steps are 223001\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 1, 3, 0, 1, 1, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0, 3, 0, 1, 1, 2, 2, 3, 1, 1, 0, 2, 1, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 35 and the episode is 4846 and the total_steps are 223036\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 3, 0, 2, 0, 0, 2, 3, 1, 0, 0, 0, 0, 2, 1, 0, 2, 3, 0, 0, 0, 0, 2, 1, 3, 0, 0, 3, 2, 1, 1, 1, 3, 2, 2, 1, 2, 3, 3, 1, 0, 0, 0, 3, 3, 3, 3, 2, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 54 and the episode is 4847 and the total_steps are 223090\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 2, 0, 0, 3, 3, 3, 2, 0, 0, 2, 0, 0, 3, 3, 3, 3, 3, 0, 3, 1, 2, 1, 1, 0, 3, 2, 0, 2, 3, 0, 1, 0, 2, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 51 and the episode is 4848 and the total_steps are 223141\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.4     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4848     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 7982     |\n",
      "|    total_timesteps  | 223141   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.7     |\n",
      "|    n_updates        | 43285    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 1, 3, 1, 1, 3, 2, 2, 3, 3, 0, 0, 0, 3, 2, 2, 1, 3, 1, 1, 3, 1, 1, 3, 3, 0, 3, 0, 1, 2, 2, 2, 0, 2, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 4849 and the total_steps are 223182\n",
      "Done condition: collision\n",
      "[2, 2, 1, 1, 2, 0, 1, 0, 3, 1, 2, 1, 3, 1, 0, 3, 1, 3, 2, 2, 0, 3, 0, 0, 3, 3, 1, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 31 and the episode is 4850 and the total_steps are 223213\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 3, 3, 1, 1, 3, 1, 1, 2, 2, 2, 2, 3, 0, 1, 1, 2, 0, 1, 3, 1, 2, 0, 0, 0, 3, 3, 1, 1, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4851 and the total_steps are 223249\n",
      "Done condition: collision\n",
      "[0, 1, 0, 1, 2, 0, 0, 0, 2, 0, 2, 1, 0, 1, 3, 0, 3, 1, 3, 3, 0, 1, 3, 2, 3, 3, 0, 0, 0, 3, 2, 2, 2, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 36 and the episode is 4852 and the total_steps are 223285\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4852     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 7989     |\n",
      "|    total_timesteps  | 223285   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.18     |\n",
      "|    n_updates        | 43321    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 0, 0, 0, 2, 1, 2, 1, 2, 0, 1, 0, 2, 0, 2, 3, 3, 2, 2, 3, 0, 3, 0, 3, 1, 2, 0, 0, 3, 1, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 36 and the episode is 4853 and the total_steps are 223321\n",
      "Done condition: collision\n",
      "[0, 3, 1, 3, 0, 3, 3, 1, 0, 0, 1, 3, 3, 1, 1, 0, 0, 3, 2, 0, 1, 2, 1, 1, 0, 3, 2, 1, 0, 2, 3, 3, 0, 1, 1, 1, 0, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 40 and the episode is 4854 and the total_steps are 223361\n",
      "Done condition: collision\n",
      "[1, 2, 2, 2, 3, 2, 3, 3, 1, 0, 2, 3, 2, 2, 3, 1, 3, 2, 3, 1, 0, 2, 0, 3, 0, 2, 0, 3, 0, 0, 3, 2, 0, 3, 2, 0, 0, 2, 2, 0, 0, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 44 and the episode is 4855 and the total_steps are 223405\n",
      "Done condition: collision\n",
      "[1, 3, 0, 0, 2, 3, 1, 0, 2, 0, 0, 2, 3, 3, 0, 2, 0, 0, 1, 0, 3, 0, 0, 2, 2, 2, 3, 2, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 31 and the episode is 4856 and the total_steps are 223436\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4856     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 7995     |\n",
      "|    total_timesteps  | 223436   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 43358    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 0, 2, 3, 2, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 1, 1, 1, 3, 1, 0, 2, 1, 0, 0, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -997. And steps were 31 and the episode is 4857 and the total_steps are 223467\n",
      "Done condition: collision\n",
      "[0, 2, 0, 2, 2, 0, 1, 0, 0, 0, 1, 0, 3, 1, 2, 0, 1, 3, 2, 1, 3, 2, 2, 2, 3, 1, 3, 0, 2, 3, 0, 0, 3, 1, 2, 1, 0, 0, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 42 and the episode is 4858 and the total_steps are 223509\n",
      "Done condition: collision\n",
      "[1, 1, 1, 0, 1, 0, 1, 3, 2, 0, 3, 0, 3, 3, 0, 2, 3, 1, 1, 2, 2, 2, 3, 2, 3, 2, 1, 1, 3, 0, 3, 1, 0, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 36 and the episode is 4859 and the total_steps are 223545\n",
      "Done condition: collision\n",
      "[0, 3, 3, 3, 1, 2, 3, 3, 2, 0, 2, 2, 3, 1, 0, 1, 1, 0, 1, 1, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4860 and the total_steps are 223570\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4860     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8001     |\n",
      "|    total_timesteps  | 223570   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 28.1     |\n",
      "|    n_updates        | 43392    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 0, 1, 0, 3, 1, 0, 3, 2, 0, 1, 3, 0, 3, 1, 2, 0, 0, 1, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 26 and the episode is 4861 and the total_steps are 223596\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 0, 1, 0, 2, 2, 0, 0, 1, 1, 3, 0, 2, 1, 2, 2, 2, 1, 2, 0, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 26 and the episode is 4862 and the total_steps are 223622\n",
      "Done condition: collision\n",
      "[2, 2, 0, 1, 3, 0, 3, 2, 0, 3, 3, 0, 2, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 17 and the episode is 4863 and the total_steps are 223639\n",
      "Done condition: collision\n",
      "[1, 3, 1, 3, 0, 3, 0, 1, 0, 0, 1, 0, 1, 1, 2, 3, 3, 0, 2, 2, 3, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1022. And steps were 24 and the episode is 4864 and the total_steps are 223663\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4864     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8006     |\n",
      "|    total_timesteps  | 223663   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.39     |\n",
      "|    n_updates        | 43415    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 1, 1, 3, 1, 0, 3, 1, 3, 2, 0, 0, 3, 2, 2, 3, 2, 2, 2, 1, 1, 3, 0, 0, 0, 2, 0, 1, 0, 2, 2, 3, 0, 1, 0, 2, 0, 1, 3, 0, 1, 3, 3, 0, 3, 2, 3, 1, 3, 2, 3, 3, 0, 1, 1, 1, 0, 3, 1, 1, 1, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 66 and the episode is 4865 and the total_steps are 223729\n",
      "Done condition: collision\n",
      "[3, 3, 3, 2, 2, 3, 2, 2, 3, 3, 2, 3, 0, 3, 0, 0, 2, 2, 0, 3, 0, 2, 3, 2, 0, 3, 2, 2, 0, 0, 2, 1, 3, 1, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1034. And steps were 36 and the episode is 4866 and the total_steps are 223765\n",
      "Done condition: collision\n",
      "[3, 1, 3, 1, 1, 2, 0, 2, 2, 2, 1, 2, 3, 1, 2, 2, 3, 2, 3, 1, 1, 1, 3, 1, 2, 1, 2, 1, 3, 0, 3, 2, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1003. And steps were 35 and the episode is 4867 and the total_steps are 223800\n",
      "Done condition: collision\n",
      "[1, 2, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1, 3, 2, 3, 3, 3, 2, 3, 0, 1, 2, 3, 2, 0, 0, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 4868 and the total_steps are 223829\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4868     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8013     |\n",
      "|    total_timesteps  | 223829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 63.9     |\n",
      "|    n_updates        | 43457    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 3, 2, 2, 0, 0, 1, 2, 3, 0, 3, 0, 1, 0, 0, 2, 0, 2, 2, 1, 2, 3, 2, 3, 2, 1, 3, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 32 and the episode is 4869 and the total_steps are 223861\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 0, 2, 3, 1, 0, 0, 2, 0, 1, 1, 0, 0, 3, 2, 2, 2, 2, 1, 1, 1, 3, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1027. And steps were 29 and the episode is 4870 and the total_steps are 223890\n",
      "Done condition: collision\n",
      "[2, 2, 1, 0, 1, 0, 0, 2, 3, 2, 2, 0, 0, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 4871 and the total_steps are 223906\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 1, 3, 1, 2, 2, 2, 2, 3, 0, 2, 0, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 19 and the episode is 4872 and the total_steps are 223925\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.7     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4872     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8017     |\n",
      "|    total_timesteps  | 223925   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 43481    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 0, 1, 2, 2, 1, 1, 2, 1, 2, 1, 0, 2, 3, 1, 2, 2, 2, 1, 3, 3, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 25 and the episode is 4873 and the total_steps are 223950\n",
      "Done condition: collision\n",
      "[2, 0, 2, 1, 3, 1, 0, 1, 1, 2, 1, 3, 2, 2, 1, 1, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 19 and the episode is 4874 and the total_steps are 223969\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 3, 1, 1, 3, 2, 3, 1, 1, 2, 1, 3, 3, 3, 3, 2, 1, 0, 1, 0, 2, 3, 1, 2, 1, 2, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 32 and the episode is 4875 and the total_steps are 224001\n",
      "Done condition: collision\n",
      "[2, 1, 0, 2, 0, 3, 1, 0, 3, 0, 0, 3, 2, 2, 2, 0, 2, 2, 3, 3, 3, 0, 0, 1, 3, 2, 2, 0, 0, 1, 0, 2, 1, 2, 3, 3, 1, 0, 1, 2, 0, 0, 0, 0, 0, 3, 3, 0, 1, 1, 1, 0, 3, 3, 2, 1, 2, 2, 3, 2, 1, 2, 2, 2, 1, 2, 2, 0, 2, 1, 2, 2, 2, 1, 0, 2, 2, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -948. And steps were 80 and the episode is 4876 and the total_steps are 224081\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | -960     |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4876     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8024     |\n",
      "|    total_timesteps  | 224081   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34       |\n",
      "|    n_updates        | 43520    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 3, 1, 3, 1, 1, 1, 1, 1, 0, 2, 3, 3, 3, 1, 3, 2, 3, 0, 2, 0, 0, 0, 2, 0, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -987. And steps were 31 and the episode is 4877 and the total_steps are 224112\n",
      "Done condition: collision\n",
      "[2, 0, 1, 1, 1, 3, 3, 3, 0, 0, 1, 0, 0, 3, 1, 0, 0, 2, 3, 1, 3, 2, 2, 0, 0, 2, 0, 0, 3, 2, 2, 1, 1, 3, 2, 1, 2, 0, 3, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 42 and the episode is 4878 and the total_steps are 224154\n",
      "Done condition: collision\n",
      "[2, 3, 1, 1, 1, 0, 3, 2, 2, 3, 0, 3, 3, 2, 1, 1, 3, 3, 3, 2, 2, 3, 0, 1, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 27 and the episode is 4879 and the total_steps are 224181\n",
      "Done condition: collision\n",
      "[0, 1, 2, 2, 1, 0, 2, 2, 0, 0, 0, 0, 2, 1, 0, 1, 1, 3, 3, 3, 2, 0, 1, 3, 3, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4880 and the total_steps are 224209\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4880     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8031     |\n",
      "|    total_timesteps  | 224209   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 43552    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 1, 0, 0, 0, 3, 0, 1, 1, 0, 1, 2, 3, 3, 2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was 1025. And steps were 26 and the episode is 4881 and the total_steps are 224235\n",
      "Done condition: collision\n",
      "[1, 2, 1, 1, 1, 2, 1, 3, 3, 0, 0, 3, 1, 0, 0, 0, 2, 2, 3, 3, 2, 1, 3, 0, 1, 1, 2, 3, 1, 2, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 34 and the episode is 4882 and the total_steps are 224269\n",
      "Done condition: collision\n",
      "[3, 3, 3, 3, 1, 1, 3, 1, 0, 1, 3, 0, 0, 0, 3, 1, 3, 0, 0, 2, 0, 2, 0, 0, 0, 3, 1, 0, 2, 3, 0, 3, 3, 3, 1, 3, 2, 2, 3, 3, 1, 3, 0, 0, 2, 3, 2, 1, 0, 1, 1, 0, 3, 3, 2, 2, 0, 1, 3, 0, 2, 2, 0, 2, 2, 1, 1, 3, 1, 3, 1, 0, 3, 2, 0, 0, 1, 2, 2, 1, 1, 3, 0, 3, 1, 3, 1, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1087. And steps were 89 and the episode is 4883 and the total_steps are 224358\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 1, 2, 1, 3, 1, 2, 0, 0, 1, 2, 3, 3, 2, 3, 1, 3, 0, 2, 1, 1, 1, 3, 2, 1, 3, 2, 3, 2, 1, 2, 1, 3, 0, 2, 3, 0, 0, 2, 2, 2, 2, 3, 3, 2, 3, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 51 and the episode is 4884 and the total_steps are 224409\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4884     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8040     |\n",
      "|    total_timesteps  | 224409   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 43602    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 1, 2, 2, 3, 2, 3, 0, 3, 0, 0, 0, 0, 1, 2, 3, 1, 2, 3, 3, 3, 3, 1, 3, 3, 0, 2, 0, 2, 1, 2, 0, 3, 1, 1, 3, 3, 0, 1, 3, 3, 2, 3, 0, 0, 1, 0, 0, 0, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1028. And steps were 52 and the episode is 4885 and the total_steps are 224461\n",
      "Done condition: collision\n",
      "[0, 1, 1, 3, 1, 1, 0, 1, 2, 3, 1, 2, 0, 3, 0, 1, 2, 3, 2, 2, 1, 0, 1, 3, 0, 2, 1, 1, 2, 3, 0, 2, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 36 and the episode is 4886 and the total_steps are 224497\n",
      "Done condition: collision\n",
      "[0, 3, 1, 2, 2, 1, 1, 0, 3, 3, 1, 1, 0, 0, 1, 1, 2, 2, 0, 0, 3, 3, 0, 0, 1, 3, 1, 1, 0, 0, 1, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 35 and the episode is 4887 and the total_steps are 224532\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 1, 3, 2, 2, 1, 2, 3, 1, 1, 3, 3, 0, 3, 2, 2, 3, 3, 0, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 25 and the episode is 4888 and the total_steps are 224557\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4888     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8046     |\n",
      "|    total_timesteps  | 224557   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.68     |\n",
      "|    n_updates        | 43639    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 0, 3, 1, 0, 2, 2, 3, 0, 2, 1, 3, 2, 2, 3, 1, 3, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1019. And steps were 21 and the episode is 4889 and the total_steps are 224578\n",
      "Done condition: collision\n",
      "[1, 0, 0, 1, 1, 0, 2, 3, 0, 1, 2, 0, 3, 2, 2, 2, 1, 1, 3, 0, 2, 3, 1, 0, 2, 3, 1, 0, 2, 1, 1, 3, 3, 0, 2, 2, 0, 3, 3, 3, 3, 3, 0, 3, 1, 3, 1, 1, 1, 1, 2, 0, 3, 1, 2]\n",
      "The environmnet has been reset. The total reward was -971. And steps were 55 and the episode is 4890 and the total_steps are 224633\n",
      "Done condition: collision\n",
      "[3, 2, 0, 1, 3, 0, 3, 3, 3, 2, 3, 1, 1, 3, 2, 0, 1, 1, 2, 2, 0, 1, 0, 0, 3, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 28 and the episode is 4891 and the total_steps are 224661\n",
      "Done condition: collision\n",
      "[1, 1, 3, 3, 0, 0, 2, 1, 2, 3, 0, 1, 1, 3, 1, 1, 2, 2, 2, 2, 1, 3, 1, 0, 1, 0, 2, 1, 2, 2, 0, 3, 3, 0, 2, 2, 2, 1, 0, 3, 0, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1043. And steps were 45 and the episode is 4892 and the total_steps are 224706\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | -962     |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4892     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8053     |\n",
      "|    total_timesteps  | 224706   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.4     |\n",
      "|    n_updates        | 43676    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 0, 0, 1, 1, 0, 0, 3, 2, 1, 2, 2, 1, 1, 2, 1, 2, 0, 3, 0, 2, 1, 2, 1, 3, 0, 1, 1, 1, 0, 2, 3, 1, 2, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 37 and the episode is 4893 and the total_steps are 224743\n",
      "Done condition: collision\n",
      "[3, 0, 3, 0, 1, 0, 1, 3, 0, 3, 0, 2, 1, 1, 3, 0, 2, 0, 0, 3, 1, 3, 0, 1, 2, 3, 2, 0, 1, 3, 2, 2, 3, 1, 1]\n",
      "The environmnet has been reset. The total reward was -977. And steps were 35 and the episode is 4894 and the total_steps are 224778\n",
      "Done condition: collision\n",
      "[1, 1, 2, 1, 3, 3, 0, 0, 1, 3, 3, 2, 2, 1, 3, 3, 1, 1, 3, 2, 2, 1, 0, 3, 2, 1, 2, 2, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -979. And steps were 31 and the episode is 4895 and the total_steps are 224809\n",
      "Done condition: collision\n",
      "[1, 3, 3, 3, 3, 3, 1, 0, 0, 0, 2, 1, 3, 1, 2, 2, 1, 0, 0, 2, 2, 0, 1, 0, 3, 1, 3, 1, 0]\n",
      "The environmnet has been reset. The total reward was -973. And steps were 29 and the episode is 4896 and the total_steps are 224838\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -962     |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4896     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8059     |\n",
      "|    total_timesteps  | 224838   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 31.8     |\n",
      "|    n_updates        | 43709    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 3, 3, 1, 2, 2, 2, 1, 1, 0, 2, 3, 0, 3, 2, 3, 2, 3, 2, 3, 1, 3, 0, 3, 2, 2, 2, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 31 and the episode is 4897 and the total_steps are 224869\n",
      "Done condition: collision\n",
      "[2, 1, 3, 0, 0, 1, 0, 1, 3, 2, 1, 0, 3, 1, 1, 2, 0, 3, 2, 1, 1, 3, 0, 2, 3, 2, 0, 2, 2, 3, 3, 2, 0, 2, 2, 2, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 40 and the episode is 4898 and the total_steps are 224909\n",
      "Done condition: collision\n",
      "[1, 3, 1, 0, 3, 0, 0, 2, 2, 2, 1, 0, 1, 2, 1, 3, 3, 3, 2, 2, 3, 3, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 26 and the episode is 4899 and the total_steps are 224935\n",
      "Done condition: collision\n",
      "[3, 0, 0, 2, 1, 3, 2, 0, 0, 2, 2, 3, 3, 1, 0, 3, 0, 1, 2, 0, 3, 0, 2, 0, 2, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 29 and the episode is 4900 and the total_steps are 224964\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | -962     |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4900     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8064     |\n",
      "|    total_timesteps  | 224964   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 154      |\n",
      "|    n_updates        | 43740    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 2, 1, 3, 2, 1, 2, 3, 3, 0, 3, 0, 1, 2, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 18 and the episode is 4901 and the total_steps are 224982\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 0, 2, 2, 3, 2, 3, 3, 1, 0, 3, 1, 3, 0, 2, 0, 0, 2, 0, 3, 1, 1, 3, 1, 2, 1, 3, 1, 0, 0, 2, 0, 1, 0, 3, 3, 0, 1, 2, 0, 2, 0, 2]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 46 and the episode is 4902 and the total_steps are 225028\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 3, 3, 3, 3, 2, 0, 1, 1, 2, 1, 2, 0, 3, 1, 3, 2, 1, 3, 2, 1, 1, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1039. And steps were 41 and the episode is 4903 and the total_steps are 225069\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 0, 0, 3, 2, 3, 2, 0, 2, 2, 3, 0, 0, 1, 1, 3, 2, 3, 0, 0, 1, 0, 2, 3, 3, 2, 2, 2, 0, 2, 1, 1, 0, 0, 0, 2, 2, 2, 1, 3, 1, 1, 2, 2, 2, 1, 3, 1, 2, 1, 3, 2, 3, 1, 2, 2, 2, 0, 0, 1, 2, 3, 2, 3, 3, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1042. And steps were 72 and the episode is 4904 and the total_steps are 225141\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4904     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8072     |\n",
      "|    total_timesteps  | 225141   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 93.1     |\n",
      "|    n_updates        | 43785    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 2, 1, 2, 1, 2, 0, 3, 3, 0, 3, 3, 3, 1, 2, 2, 2, 3, 1, 3, 3, 0, 1, 0, 3, 3, 2, 1, 0, 0, 3, 0, 2, 3, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 40 and the episode is 4905 and the total_steps are 225181\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 2, 0, 1, 1, 3, 0, 2, 2, 2, 3, 0, 3, 2, 0, 2, 0, 3, 2, 1, 3, 0, 1, 0, 1, 3, 1, 1, 2]\n",
      "The environmnet has been reset. The total reward was -1030. And steps were 32 and the episode is 4906 and the total_steps are 225213\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 3, 0, 1, 1, 3, 2, 2, 0, 1, 0, 3, 2, 0, 3, 3, 2, 3, 2, 1, 2, 0, 3, 2, 3, 3, 0, 0, 2, 3, 1, 3, 2, 2, 2, 1, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 41 and the episode is 4907 and the total_steps are 225254\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[1, 0, 0, 0, 2, 1, 3, 3, 1, 3, 2, 3, 2, 0, 2, 1, 0, 3, 3, 3, 2, 1, 1, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 27 and the episode is 4908 and the total_steps are 225281\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.9     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4908     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8079     |\n",
      "|    total_timesteps  | 225281   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.13     |\n",
      "|    n_updates        | 43820    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 0, 3, 3, 1, 2, 2, 2, 3, 2, 0, 1, 1, 2, 2, 2, 2, 2, 3, 0, 1, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4909 and the total_steps are 225309\n",
      "Done condition: collision\n",
      "[3, 1, 0, 0, 1, 2, 3, 0, 3, 1, 1, 3, 1, 1, 1, 2, 0, 3, 3, 2, 3, 0, 1, 3, 2, 2, 1, 2, 1, 0, 2, 3, 3, 1, 1, 0, 3, 2, 3, 0, 3, 1, 1, 0, 0, 0, 0, 0, 1, 2, 3, 0, 1, 2, 1, 1, 3, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 61 and the episode is 4910 and the total_steps are 225370\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 0, 2, 2, 3, 0, 3, 1, 3, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 2, 1, 3, 1, 2, 3, 0, 2, 3, 3, 0, 1, 1, 2, 3, 0, 3, 0, 0, 1, 0, 3, 1, 0, 1, 3, 0, 1, 3, 1, 3, 3, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 59 and the episode is 4911 and the total_steps are 225429\n",
      "Done condition: collision\n",
      "[3, 0, 3, 1, 1, 3, 1, 3, 3, 2, 0, 3, 0, 1, 2, 3, 1, 1, 3, 2, 2, 0, 0, 2, 0, 3, 0, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 1, 2, 2, 1, 1, 1, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 52 and the episode is 4912 and the total_steps are 225481\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -962     |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4912     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8087     |\n",
      "|    total_timesteps  | 225481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.38     |\n",
      "|    n_updates        | 43870    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 0, 0, 2, 3, 3, 3, 3, 3, 2, 0, 2, 2, 1, 2, 3, 0, 0, 2, 2, 3, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 28 and the episode is 4913 and the total_steps are 225509\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 2, 3, 0, 2, 1, 1, 1, 2, 0, 0, 2, 0, 3, 1, 2, 0, 3, 3, 2, 3, 2, 2, 3, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 30 and the episode is 4914 and the total_steps are 225539\n",
      "Done condition: collision\n",
      "[0, 3, 2, 3, 1, 3, 1, 3, 1, 1, 1, 3, 2, 2, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -982. And steps were 26 and the episode is 4915 and the total_steps are 225565\n",
      "Done condition: collision\n",
      "[2, 0, 3, 1, 2, 2, 1, 2, 2, 0, 1, 1, 3, 1, 3, 1, 1, 0, 3, 2, 1, 1, 3, 3, 2, 0, 0]\n",
      "The environmnet has been reset. The total reward was -985. And steps were 27 and the episode is 4916 and the total_steps are 225592\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | -962     |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4916     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8092     |\n",
      "|    total_timesteps  | 225592   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.8      |\n",
      "|    n_updates        | 43897    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 3, 3, 3, 0, 3, 1, 3, 1, 0, 0, 1, 2, 3, 2, 0, 1, 1, 3, 1, 3, 2, 3, 1, 0, 2, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 31 and the episode is 4917 and the total_steps are 225623\n",
      "Done condition: collision\n",
      "[2, 2, 3, 2, 2, 2, 3, 0, 0, 0, 0, 2, 2, 1, 3, 0, 1, 1, 1, 2, 1, 2, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 26 and the episode is 4918 and the total_steps are 225649\n",
      "Done condition: collision\n",
      "[1, 1, 1, 3, 1, 3, 1, 1, 1, 3, 1, 1, 1, 3, 1, 2, 1, 2, 1, 1, 0, 2, 0, 3, 3, 2, 0, 0, 3, 0, 3, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 34 and the episode is 4919 and the total_steps are 225683\n",
      "Done condition: collision\n",
      "[3, 1, 1, 1, 2, 1, 3, 3, 0, 1, 2, 2, 1, 1, 0, 2, 2, 1, 0, 3, 1, 0, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1024. And steps were 26 and the episode is 4920 and the total_steps are 225709\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.9     |\n",
      "|    ep_rew_mean      | -982     |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4920     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8098     |\n",
      "|    total_timesteps  | 225709   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.2     |\n",
      "|    n_updates        | 43927    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 0, 1, 2, 1, 1, 0, 2, 1, 3, 1, 1, 0, 0, 3, 3, 2, 1, 1, 0, 0, 0, 3, 1, 2, 2, 3, 2, 1, 0, 0, 3, 2, 3, 2, 3, 1, 0, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -960. And steps were 44 and the episode is 4921 and the total_steps are 225753\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[1, 3, 1, 3, 1, 0, 0, 1, 2, 2, 0, 2, 0, 3, 3, 3, 2, 3, 1, 1, 3, 2, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 4922 and the total_steps are 225778\n",
      "Done condition: collision\n",
      "[3, 3, 2, 1, 3, 3, 3, 1, 1, 0, 3, 0, 3, 0, 0, 1, 3, 2, 0, 0, 1, 2, 2, 0, 2, 1, 2, 2, 3, 3, 0, 0, 1, 2, 3, 2, 1, 3, 3, 1, 3, 3, 2, 0, 3, 2, 2, 1, 1, 0, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 53 and the episode is 4923 and the total_steps are 225831\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 1, 3, 2, 0, 2, 3, 3, 0, 3, 3, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 18 and the episode is 4924 and the total_steps are 225849\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | -961     |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4924     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8104     |\n",
      "|    total_timesteps  | 225849   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.2     |\n",
      "|    n_updates        | 43962    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[3, 2, 3, 2, 2, 0, 2, 2, 1, 1, 2, 3, 2, 2, 0, 0, 0, 2, 0, 1, 2, 2, 2, 2, 1]\n",
      "The environmnet has been reset. The total reward was 1024. And steps were 25 and the episode is 4925 and the total_steps are 225874\n",
      "Done condition: collision\n",
      "[3, 2, 3, 0, 2, 0, 2, 3, 3, 1, 2, 0, 0, 0, 2, 3, 1, 3, 2, 3, 3, 1, 1, 2, 0, 3, 2, 1, 3, 0, 1, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 33 and the episode is 4926 and the total_steps are 225907\n",
      "Done condition: collision\n",
      "[3, 3, 2, 0, 1, 2, 0, 2, 2, 2, 0, 3, 2, 3, 0, 3, 2, 1, 1, 1, 3, 0, 0, 0, 2, 1, 2, 3, 1, 3, 3, 2, 3, 2, 0, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1036. And steps were 38 and the episode is 4927 and the total_steps are 225945\n",
      "Done condition: collision\n",
      "[0, 3, 1, 0, 1, 2, 0, 1, 1, 0, 2, 1, 2, 0, 0, 0, 0, 1, 0, 2, 1, 3, 0, 1, 3, 0, 0, 2, 2, 2, 3, 3, 0, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 37 and the episode is 4928 and the total_steps are 225982\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4928     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8110     |\n",
      "|    total_timesteps  | 225982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.88     |\n",
      "|    n_updates        | 43995    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 2, 0, 1, 0, 2, 3, 1, 1, 0, 3, 0, 0, 2, 3, 3, 1, 3, 0, 1, 2, 0, 0, 1, 1, 0, 3, 3, 3, 1, 2, 3, 3, 1, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 36 and the episode is 4929 and the total_steps are 226018\n",
      "Done condition: collision\n",
      "[0, 0, 0, 2, 2, 3, 3, 3, 3, 3, 1, 3, 3, 0, 1, 3, 3, 3, 1, 1, 1, 2, 3, 0, 0, 3, 0, 3, 1, 1, 2, 3]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 32 and the episode is 4930 and the total_steps are 226050\n",
      "Done condition: collision\n",
      "[0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 1, 1, 0, 2, 3, 3, 1, 3, 0, 3, 1, 2, 1, 1, 3, 2, 2, 2, 0, 0, 0]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 31 and the episode is 4931 and the total_steps are 226081\n",
      "Done condition: collision\n",
      "[1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2, 1, 1, 0, 0, 3, 1, 3, 3, 3, 3, 3, 2, 0, 1, 0, 3, 0, 2, 1, 1, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 34 and the episode is 4932 and the total_steps are 226115\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4932     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8116     |\n",
      "|    total_timesteps  | 226115   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.85     |\n",
      "|    n_updates        | 44028    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 0, 1, 0, 2, 1, 1, 0, 0, 0, 1, 2, 3, 1, 3, 3, 1, 3, 0, 3, 1, 2, 0, 2, 0, 2, 3, 1, 0, 2, 2, 3, 2, 2, 3, 1, 3, 1, 3, 0, 1, 1, 3, 1, 2, 0, 0, 1, 2, 0, 0, 0, 3, 1, 1, 1, 2, 3, 1, 0, 2, 1, 0, 2, 0, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1050. And steps were 70 and the episode is 4933 and the total_steps are 226185\n",
      "Done condition: collision\n",
      "[3, 3, 1, 3, 1, 2, 2, 0, 2, 1, 0, 2, 3, 0, 1, 3, 0, 1, 3, 1, 0, 2, 1, 3, 3, 0, 3, 3, 1, 2, 2, 0]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 32 and the episode is 4934 and the total_steps are 226217\n",
      "Done condition: collision\n",
      "[1, 2, 0, 0, 2, 1, 3, 3, 2, 3, 3, 3, 0, 0, 1, 1, 2, 3, 3, 2, 1, 2, 1, 3, 0, 0, 0, 2, 2, 3, 3, 1, 0, 1, 2, 0, 1, 3, 3, 3, 1, 0, 0, 3, 1, 0, 2, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -989. And steps were 51 and the episode is 4935 and the total_steps are 226268\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 2, 1, 3, 2, 1, 2, 1, 1, 0, 1, 1, 3, 3, 2, 2, 1, 3, 1, 3, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 25 and the episode is 4936 and the total_steps are 226293\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4936     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8124     |\n",
      "|    total_timesteps  | 226293   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.3     |\n",
      "|    n_updates        | 44073    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 3, 3, 0, 1, 2, 2, 0, 2, 0, 3, 3, 0, 2, 1, 3, 3, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -986. And steps were 30 and the episode is 4937 and the total_steps are 226323\n",
      "Done condition: collision\n",
      "[0, 2, 3, 2, 2, 0, 0, 3, 0, 3, 0, 2, 0, 3, 3, 0, 0, 0, 0, 3, 2, 0, 2, 3, 3, 2, 3, 1, 0, 3, 2, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1032. And steps were 34 and the episode is 4938 and the total_steps are 226357\n",
      "Done condition: collision\n",
      "[2, 1, 0, 1, 2, 3, 2, 3, 1, 1, 3, 3, 2, 0, 0, 0, 3, 1, 3, 3, 3, 2, 1, 0, 3, 3, 2, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 30 and the episode is 4939 and the total_steps are 226387\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 3, 3, 2, 2, 2, 1, 3, 3, 2, 3, 1, 1, 3, 3, 0, 1, 1, 1, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 4940 and the total_steps are 226413\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4940     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8129     |\n",
      "|    total_timesteps  | 226413   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.62     |\n",
      "|    n_updates        | 44103    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 1, 3, 0, 1, 0, 3, 1, 2, 0, 1, 3, 0, 3, 1, 2, 2, 0, 1, 3, 3, 0, 2, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4941 and the total_steps are 226441\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 3, 2, 3, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2, 0, 2, 0, 3, 0, 2, 3]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 30 and the episode is 4942 and the total_steps are 226471\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 3, 2, 2, 3, 0, 0, 1, 2, 1, 0, 1, 1, 0, 0, 3, 2, 2, 3, 2, 3, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 26 and the episode is 4943 and the total_steps are 226497\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 1, 1, 3, 2, 2, 3, 2, 2, 2, 2, 0, 0, 3, 3, 3, 1, 0, 2, 3, 2, 0, 2, 1, 2, 2, 2, 1, 3, 0, 0, 0, 0, 2, 3, 1, 0, 2]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 41 and the episode is 4944 and the total_steps are 226538\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | -941     |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4944     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8135     |\n",
      "|    total_timesteps  | 226538   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 60.3     |\n",
      "|    n_updates        | 44134    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 2, 3, 0, 0, 0, 1, 1, 3, 1, 2, 3, 2, 2, 2, 2, 1, 1, 2, 3, 2, 1, 0, 1, 3, 1, 2, 2, 3, 1, 3, 1, 1, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -1007. And steps were 37 and the episode is 4945 and the total_steps are 226575\n",
      "Done condition: collision\n",
      "[1, 2, 0, 2, 2, 0, 1, 2, 1, 0, 3, 2, 1, 0, 1, 2, 0, 2, 3, 3, 2, 0, 0, 0, 3, 0, 2, 0, 3, 3, 2, 1, 2, 0, 1, 1, 2, 3, 3, 2, 3, 2, 3, 1, 0, 1, 3, 0]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 48 and the episode is 4946 and the total_steps are 226623\n",
      "Done condition: collision\n",
      "[1, 0, 3, 2, 1, 3, 3, 1, 1, 2, 2, 1, 0, 2, 3, 2, 2, 1, 2, 3, 1, 0, 0, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -984. And steps were 26 and the episode is 4947 and the total_steps are 226649\n",
      "Done condition: collision\n",
      "[3, 1, 0, 2, 0, 3, 1, 1, 3, 1, 3, 2, 1, 2, 0, 2, 3, 3, 0, 3, 3, 0, 1, 3, 0, 1, 3, 2, 1, 0, 1, 1, 3, 2, 0, 2, 1, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 40 and the episode is 4948 and the total_steps are 226689\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4948     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8142     |\n",
      "|    total_timesteps  | 226689   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.4     |\n",
      "|    n_updates        | 44172    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 2, 3, 1, 2, 3, 2, 3, 0, 1, 1, 3, 3, 1, 1, 2, 1, 1, 1, 2, 2, 1, 3, 0, 1, 2, 2, 0, 1, 1, 0, 3, 0, 2, 0, 1]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 37 and the episode is 4949 and the total_steps are 226726\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 0, 1, 3, 2, 2, 2, 3, 1, 3, 3, 2, 0, 2, 3, 0, 3, 1, 1, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 0, 3, 2, 1, 2, 3, 0, 3, 0, 2, 1, 3, 3, 0, 3, 3, 3, 3, 0, 0, 3, 2, 3, 1, 0, 0, 3, 1, 1, 0, 0, 2, 2, 3, 3, 0, 3, 0, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 77 and the episode is 4950 and the total_steps are 226803\n",
      "Done condition: collision\n",
      "[3, 1, 2, 1, 1, 0, 1, 1, 3, 0, 3, 0, 3, 0, 0, 3, 2, 1, 0, 3, 0, 2, 1, 1, 3, 1, 2, 0, 1, 2, 1, 0, 2, 3, 0, 3, 3, 3, 3, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -964. And steps were 42 and the episode is 4951 and the total_steps are 226845\n",
      "Done condition: collision\n",
      "[3, 0, 1, 2, 3, 1, 2, 2, 2, 2, 1, 2, 2, 1, 0, 1, 1, 3, 2, 0, 3, 2, 3, 2, 0, 0, 3, 3, 2, 0, 1, 0, 0, 0, 1, 3, 3, 2, 2, 3, 0, 0, 2, 3, 2, 2, 0, 1, 2, 3, 0, 3, 2, 3, 0, 2, 2, 3, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1058. And steps were 60 and the episode is 4952 and the total_steps are 226905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4952     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8151     |\n",
      "|    total_timesteps  | 226905   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 44226    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 1, 1, 3, 0, 1, 3, 1, 3, 1, 0, 1, 0, 1, 1, 2, 1, 1, 2, 3, 1, 1, 3, 3, 3, 1, 2, 2, 3, 0, 3, 0, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -976. And steps were 36 and the episode is 4953 and the total_steps are 226941\n",
      "Done condition: collision\n",
      "[3, 3, 0, 2, 0, 1, 1, 0, 3, 0, 0, 2, 0, 2, 2, 0, 1, 2, 0, 2, 3, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -966. And steps were 36 and the episode is 4954 and the total_steps are 226977\n",
      "Done condition: collision\n",
      "[1, 2, 1, 2, 3, 1, 1, 2, 1, 0, 1, 0, 1, 0, 0, 2, 2, 0, 0, 2, 2, 2, 3, 1, 2, 0, 2, 3, 0, 2, 1, 1]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 32 and the episode is 4955 and the total_steps are 227009\n",
      "Done condition: collision\n",
      "[1, 0, 3, 3, 0, 2, 1, 2, 2, 3, 3, 3, 3, 1, 0, 0, 0, 0, 3, 2, 2, 1, 1, 0, 1, 1, 1, 0, 2, 1, 2, 2, 1, 0, 1, 1, 0, 0, 1, 0, 2, 3, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 45 and the episode is 4956 and the total_steps are 227054\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | -940     |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4956     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8158     |\n",
      "|    total_timesteps  | 227054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.16     |\n",
      "|    n_updates        | 44263    |\n",
      "----------------------------------\n",
      "End is Reached\n",
      "Done condition: end flag\n",
      "[2, 2, 3, 1, 3, 0, 0, 3, 1, 2, 1, 2, 0, 2, 0, 3, 2, 0, 0, 1, 3, 1]\n",
      "The environmnet has been reset. The total reward was 1021. And steps were 22 and the episode is 4957 and the total_steps are 227076\n",
      "Done condition: collision\n",
      "[1, 0, 3, 0, 1, 1, 2, 2, 1, 2, 0, 0, 3, 1, 0, 2, 1, 1, 2, 0, 3, 3, 3, 0, 3, 1, 0, 1, 3, 1, 3, 0, 1, 1, 3, 1, 0, 2, 1, 1, 1, 0, 3, 0, 0, 2, 3, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 0, 3, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1005. And steps were 63 and the episode is 4958 and the total_steps are 227139\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 2, 2, 0, 3, 3, 0, 1, 1, 3, 0, 2, 3, 1, 0, 2, 2, 0, 2, 3, 3, 1, 2, 0, 3, 1, 1, 0, 3, 0, 1, 1, 3, 2, 1]\n",
      "The environmnet has been reset. The total reward was -988. And steps were 38 and the episode is 4959 and the total_steps are 227177\n",
      "Done condition: collision\n",
      "[2, 3, 1, 3, 0, 2, 2, 1, 0, 2, 1, 1, 3, 1, 0, 1, 3, 3, 2, 3, 1, 2, 1, 3, 1, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 4960 and the total_steps are 227205\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4960     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8165     |\n",
      "|    total_timesteps  | 227205   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.52     |\n",
      "|    n_updates        | 44301    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 3, 1, 3, 2, 0, 3, 1, 3, 3, 0, 3, 2, 0, 1, 2, 3, 0, 1, 3, 2, 2, 2, 2, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 28 and the episode is 4961 and the total_steps are 227233\n",
      "Done condition: collision\n",
      "[3, 2, 3, 1, 1, 3, 0, 3, 3, 1, 2, 2, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1014. And steps were 16 and the episode is 4962 and the total_steps are 227249\n",
      "Done condition: collision\n",
      "[3, 1, 0, 3, 1, 0, 1, 1, 1, 2, 1, 3, 1, 1, 0, 2, 3, 3, 0, 0, 0, 0, 2, 1, 0, 2, 1, 3, 3, 1, 1, 3, 3, 0, 0, 2, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 38 and the episode is 4963 and the total_steps are 227287\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[0, 2, 0, 0, 3, 3, 0, 3, 0, 3, 2, 0, 1, 1, 1, 1, 1, 3, 3, 0, 1, 0, 1, 3, 3, 3, 1, 0, 2, 3, 2, 2, 2, 1, 3, 1, 3, 0, 2, 2, 1, 3, 2, 1, 0, 2, 1, 2, 3, 2, 1, 1, 1, 0, 2, 2, 2, 2, 3, 1, 0, 1, 0]\n",
      "The environmnet has been reset. The total reward was -1045. And steps were 63 and the episode is 4964 and the total_steps are 227350\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.9     |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4964     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8171     |\n",
      "|    total_timesteps  | 227350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34       |\n",
      "|    n_updates        | 44337    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 0, 1, 0, 0, 1, 3, 1, 0, 1, 1, 0, 1, 1, 1, 2, 3, 3, 1, 3, 2, 2, 0, 0, 3, 3, 2, 3, 0, 1, 1, 0, 0, 1, 2, 3, 0, 2, 1, 0, 0, 0, 2, 1, 3, 0, 1, 1, 0, 0, 0, 1, 0, 2, 3, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -1015. And steps were 59 and the episode is 4965 and the total_steps are 227409\n",
      "Done condition: collision\n",
      "[0, 2, 3, 3, 2, 3, 1, 2, 1, 1, 0, 1, 2, 2, 2, 0, 0, 1, 0, 2, 2, 2, 0, 1, 0, 3, 0, 1, 3, 2, 0, 0, 3, 0, 2, 3, 1, 3, 3, 3, 0, 1, 2, 0, 1, 1, 2, 1, 2, 0, 2, 2, 3, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 56 and the episode is 4966 and the total_steps are 227465\n",
      "Done condition: collision\n",
      "[0, 0, 2, 1, 1, 3, 1, 1, 3, 1, 3, 3, 1, 1, 0, 3, 1, 1, 1, 0, 0, 3, 3, 0, 3, 2, 3, 2, 0, 0, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 32 and the episode is 4967 and the total_steps are 227497\n",
      "Done condition: collision\n",
      "[1, 2, 2, 1, 0, 0, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 3, 0, 3, 3, 2]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 23 and the episode is 4968 and the total_steps are 227520\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.9     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4968     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8178     |\n",
      "|    total_timesteps  | 227520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.51     |\n",
      "|    n_updates        | 44379    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 2, 3, 1, 3, 2, 1, 1, 1, 0, 2, 1, 3, 2, 1, 3, 1, 0, 2, 3, 0, 1, 2, 3, 1, 0, 3, 3, 1, 1, 1, 1, 1, 2, 2, 1, 2, 0, 2, 2, 2, 3, 0, 0, 3, 0, 1, 0, 1]\n",
      "The environmnet has been reset. The total reward was -963. And steps were 49 and the episode is 4969 and the total_steps are 227569\n",
      "Done condition: collision\n",
      "[2, 1, 2, 2, 1, 3, 1, 1, 1, 1, 3, 0, 2, 1, 3, 0, 2, 0, 0, 1, 0, 2, 1, 3, 0, 2, 1, 2]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 28 and the episode is 4970 and the total_steps are 227597\n",
      "Done condition: collision\n",
      "[3, 0, 3, 3, 1, 3, 0, 2, 3, 2, 0, 0, 1, 1, 3, 3, 1, 1, 2, 1, 3, 1, 3, 1, 1, 0, 2, 0]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 28 and the episode is 4971 and the total_steps are 227625\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 1, 1, 0, 1, 3, 2, 3, 1, 3, 0, 0, 2, 3, 0, 0, 2, 3, 0, 0, 0, 1, 2, 1, 3, 1, 0, 1, 0, 1, 1, 0, 1, 2, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -1012. And steps were 40 and the episode is 4972 and the total_steps are 227665\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.4     |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4972     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8185     |\n",
      "|    total_timesteps  | 227665   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 44416    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 1, 1, 2, 2, 1, 2, 0, 0, 1, 3, 1, 3, 3, 2, 0, 2, 2, 2, 2, 0, 1, 2, 1, 2, 0, 3, 2]\n",
      "The environmnet has been reset. The total reward was -1026. And steps were 28 and the episode is 4973 and the total_steps are 227693\n",
      "Done condition: collision\n",
      "[0, 0, 1, 1, 0, 1, 1, 1, 2, 3, 1, 2, 1, 2, 3, 1, 3, 2, 2, 1, 0, 3, 2, 3, 0, 3, 0, 2, 2, 2]\n",
      "The environmnet has been reset. The total reward was -996. And steps were 30 and the episode is 4974 and the total_steps are 227723\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 1, 0, 3, 3, 2, 1, 2, 1, 2, 3, 2, 2, 2, 1, 0, 3, 1, 0, 3, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1004. And steps were 26 and the episode is 4975 and the total_steps are 227749\n",
      "Done condition: collision\n",
      "[3, 2, 1, 1, 0, 1, 3, 3, 3, 2, 3, 3, 2, 1, 0, 3, 0, 2, 0, 0, 2, 1, 0, 1, 1, 2, 2, 0, 1, 2, 2, 3, 1, 3, 0, 3, 1, 1, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 42 and the episode is 4976 and the total_steps are 227791\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.1     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4976     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8191     |\n",
      "|    total_timesteps  | 227791   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.48     |\n",
      "|    n_updates        | 44447    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 0, 3, 2, 3, 2, 0, 2, 1, 1, 1, 1, 2, 2, 2, 3, 2, 0, 1, 1, 0, 0, 1, 2, 1, 3]\n",
      "The environmnet has been reset. The total reward was -998. And steps were 26 and the episode is 4977 and the total_steps are 227817\n",
      "Done condition: collision\n",
      "[1, 1, 2, 0, 0, 0, 1, 3, 1, 3, 0, 1, 0, 1, 0, 2, 2, 3, 1, 0, 3, 0, 0, 2, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -1000. And steps were 28 and the episode is 4978 and the total_steps are 227845\n",
      "Done condition: collision\n",
      "[0, 3, 0, 1, 2, 3, 0, 0, 3, 1, 1, 0, 0, 0, 3, 1, 2, 0, 2, 1, 2, 0, 3, 3, 1, 2, 3, 2, 3, 3, 0, 0, 3, 0, 3, 1, 2, 3, 0, 2, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 44 and the episode is 4979 and the total_steps are 227889\n",
      "Done condition: collision\n",
      "[0, 3, 0, 0, 2, 1, 1, 0, 3, 2, 1, 0, 0, 0, 1, 2, 2, 0, 0, 1, 3, 0, 2, 2, 3, 3, 3, 0, 0, 2, 0, 1, 2, 3, 0, 1, 1, 2, 0, 2, 1, 3, 2, 0, 3, 0, 1, 1, 0, 3, 3, 3, 1, 0, 0, 1, 3, 1, 2, 0, 1, 3, 3, 0, 1, 2, 2, 0, 3, 3, 2, 3, 0, 2, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -940. And steps were 78 and the episode is 4980 and the total_steps are 227967\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4980     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8199     |\n",
      "|    total_timesteps  | 227967   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 64.2     |\n",
      "|    n_updates        | 44491    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 1, 1, 3, 2, 0, 2, 3, 1, 1, 3, 0, 2, 3, 2, 3, 0, 3, 1, 0, 2, 1, 2, 2, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 27 and the episode is 4981 and the total_steps are 227994\n",
      "Done condition: collision\n",
      "[0, 3, 3, 0, 1, 0, 2, 0, 2, 1, 2, 3, 2, 0, 1, 3, 0, 1, 3, 3, 2, 3, 1, 2, 1, 2, 2, 0, 1, 2, 0, 3, 1, 2, 2, 0, 0, 2, 0, 3, 2, 0, 3, 3, 3, 0, 1, 0, 3, 2, 2, 2, 3, 0, 3, 3, 3, 1, 1, 2, 2, 3, 1, 0, 2, 1]\n",
      "The environmnet has been reset. The total reward was -980. And steps were 66 and the episode is 4982 and the total_steps are 228060\n",
      "Done condition: collision\n",
      "[2, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 3, 1, 1, 2, 2, 1, 1, 2, 1, 3, 3]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 22 and the episode is 4983 and the total_steps are 228082\n",
      "Done condition: collision\n",
      "[0, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 1, 2, 3, 2, 1, 0, 2, 2, 1, 1, 3, 3, 2, 0, 2, 2]\n",
      "The environmnet has been reset. The total reward was -983. And steps were 27 and the episode is 4984 and the total_steps are 228109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4984     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8206     |\n",
      "|    total_timesteps  | 228109   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 44527    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[2, 3, 1, 2, 3, 2, 2, 1, 3, 2, 3, 0, 3, 0, 2, 2, 0, 2, 2, 2, 1, 0, 1, 1, 0, 3, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -993. And steps were 29 and the episode is 4985 and the total_steps are 228138\n",
      "Done condition: collision\n",
      "[2, 1, 1, 1, 1, 1, 2, 1, 3, 1, 3, 0, 3, 0, 2, 1, 2, 0, 3, 1, 2, 2, 0, 3, 1, 0, 1, 1]\n",
      "The environmnet has been reset. The total reward was -992. And steps were 28 and the episode is 4986 and the total_steps are 228166\n",
      "Done condition: collision\n",
      "[0, 3, 3, 1, 0, 0, 2, 0, 0, 2, 1, 3, 3, 3, 0]\n",
      "The environmnet has been reset. The total reward was -1013. And steps were 15 and the episode is 4987 and the total_steps are 228181\n",
      "Done condition: collision\n",
      "[1, 2, 2, 0, 0, 1, 3, 3, 0, 1, 2, 3, 0, 3, 1, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 2, 1, 1, 1, 0, 0, 0, 2, 1, 3, 0, 0, 1, 1, 2, 0, 0, 3, 3, 1, 3, 2, 0, 3, 1, 1, 1, 3, 3, 3, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1017. And steps were 57 and the episode is 4988 and the total_steps are 228238\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4988     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8212     |\n",
      "|    total_timesteps  | 228238   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 124      |\n",
      "|    n_updates        | 44559    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[0, 3, 1, 1, 2, 2, 0, 2, 0, 2, 3, 3, 1, 3, 1, 0, 0, 1, 2, 0, 1, 2, 1, 2, 3, 0, 3, 0, 1, 2, 1]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 31 and the episode is 4989 and the total_steps are 228269\n",
      "Done condition: collision\n",
      "[2, 2, 0, 3, 1, 2, 1, 0, 3, 1, 1, 3, 2, 1, 1, 0, 3, 0, 1, 2, 0, 3, 1, 0, 2, 2, 1, 0, 0, 3, 2, 1, 2, 3, 0]\n",
      "The environmnet has been reset. The total reward was -981. And steps were 35 and the episode is 4990 and the total_steps are 228304\n",
      "Done condition: collision\n",
      "[0, 0, 1, 3, 0, 2, 1, 1, 1, 1, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 0, 1, 3, 2, 0]\n",
      "The environmnet has been reset. The total reward was -1023. And steps were 25 and the episode is 4991 and the total_steps are 228329\n",
      "Done condition: collision\n",
      "[0, 0, 0, 1, 2, 3, 2, 1, 0, 0, 1, 3, 2, 2, 3, 3, 2, 1, 1, 3, 1, 1, 1, 3, 2, 3, 1, 2, 2, 3, 2, 1, 2, 3, 1, 1, 0]\n",
      "The environmnet has been reset. The total reward was -975. And steps were 37 and the episode is 4992 and the total_steps are 228366\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4992     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8218     |\n",
      "|    total_timesteps  | 228366   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 33.3     |\n",
      "|    n_updates        | 44591    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[3, 2, 1, 2, 2, 1, 0, 2, 1, 3, 3, 3, 3, 3, 2, 3, 2, 0, 0, 1, 2, 1, 1, 3, 1, 0, 3, 0, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 31 and the episode is 4993 and the total_steps are 228397\n",
      "Done condition: collision\n",
      "[1, 1, 0, 2, 3, 3, 2, 3, 2, 3, 1, 1, 3, 0, 3, 0, 1, 0, 1, 3, 2, 0, 2, 2, 3, 2, 1, 2, 2, 0, 2, 1, 0, 2, 3, 1, 0, 0, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1006. And steps were 40 and the episode is 4994 and the total_steps are 228437\n",
      "Done condition: collision\n",
      "[2, 3, 3, 3, 2, 1, 1, 0, 1, 1, 3, 2, 2, 0, 1, 3, 1, 2, 0, 3, 3, 3, 2, 2, 1, 3, 0, 1, 2, 2, 0, 1, 0, 2, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 36 and the episode is 4995 and the total_steps are 228473\n",
      "Done condition: collision\n",
      "[3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 0, 0, 3, 1, 2, 1, 3, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 1, 0, 0]\n",
      "The environmnet has been reset. The total reward was -1001. And steps were 35 and the episode is 4996 and the total_steps are 228508\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.7     |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4996     |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 8224     |\n",
      "|    total_timesteps  | 228508   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 34.7     |\n",
      "|    n_updates        | 44626    |\n",
      "----------------------------------\n",
      "Done condition: collision\n",
      "[1, 0, 2, 3, 0, 3, 0, 3, 1, 2, 3, 0, 3, 3, 1, 0, 3, 3, 2, 2, 1, 1, 0, 2, 2, 3, 3, 2, 1, 0, 0, 2, 0, 3, 3, 1, 3, 2, 2, 1, 1, 3, 1, 1, 0, 0, 0, 2]\n",
      "The environmnet has been reset. The total reward was -974. And steps were 48 and the episode is 4997 and the total_steps are 228556\n",
      "Done condition: collision\n",
      "[2, 1, 0, 0, 0, 3, 1, 3, 3, 3, 0, 1, 2, 0, 0, 0, 2, 2, 0, 3, 1, 1, 0, 0, 2, 2, 3, 1, 1, 3, 0, 3, 3]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 33 and the episode is 4998 and the total_steps are 228589\n",
      "Done condition: collision\n",
      "[0, 2, 0, 3, 0, 3, 3, 2, 0, 1, 1, 3, 3, 0, 0, 0, 1, 1, 0, 1, 2, 3, 0, 2, 3, 1, 0, 0, 1, 0, 3, 0, 1, 1, 1, 1, 1, 1, 1, 2, 0, 2, 3, 3]\n",
      "The environmnet has been reset. The total reward was -1008. And steps were 44 and the episode is 4999 and the total_steps are 228633\n",
      "Done condition: collision\n",
      "[3, 3, 0, 1, 3, 3, 2, 3, 2, 3, 1, 3, 2, 0, 1, 0, 1, 1, 1, 3, 3, 1, 3, 1, 3, 3, 1]\n",
      "The environmnet has been reset. The total reward was -1025. And steps were 27 and the episode is 5000 and the total_steps are 228660\n",
      "Stopping training with a total of 228660 steps because the DQN model reached max_episodes=5000, by playing for 5000 episodes \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Note = 'vegetation + globally guided + start_point_fixed+ limited end poin endpoints[5:20]'     \n",
    "models_dir = f\"models/DQN_DC_PP_synchronous\"\n",
    "logdir = f\"trainingdir/DQN_logs_trainig_DC_PP_synchronous\"\n",
    "Attempt =  '5000_episodes'\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "\n",
    "# model = PPO('CnnPolicy',actor, verbose=1,  tensorboard_log=logdir)\n",
    "# actor.render_mode = None\n",
    "# model.learn(total_timesteps=1000000, reset_num_timesteps=False ,log_interval = 4, callback=callback_max_episodes)\n",
    "\n",
    "policy = 'ActorCriticCnnPolicy'\n",
    "model = DQN('CnnPolicy',actor, verbose=1, buffer_size=10000, tensorboard_log=logdir)\n",
    "actor.render_mode = None\n",
    "model.learn(total_timesteps=10000000 , callback=callback_max_episodes,log_interval = 4)\n",
    "reset_num_timesteps=False\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"The self.camera_observation is {actor.camera_observation}\" )\n",
    "\n",
    "if actor.actor_lst:\n",
    "    actor.destroy_all_actors()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{models_dir}/model_{Attempt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This can not be deleted\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "try:\n",
    "    print(model)\n",
    "except:\n",
    "    print(\"This can not be deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.seconds_per_episode\n",
    "model = DQN.load(f'{models_dir}/model_{Attempt}.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[117, 126, 135],\n",
      "        [113, 121, 131],\n",
      "        [117, 124, 133],\n",
      "        ...,\n",
      "        [ 77, 115, 129],\n",
      "        [ 81, 120, 134],\n",
      "        [ 77, 118, 130]],\n",
      "\n",
      "       [[117, 125, 135],\n",
      "        [115, 124, 134],\n",
      "        [119, 127, 137],\n",
      "        ...,\n",
      "        [ 53,  96, 101],\n",
      "        [ 56,  98, 105],\n",
      "        [ 53,  98, 102]],\n",
      "\n",
      "       [[122, 131, 139],\n",
      "        [119, 127, 136],\n",
      "        [115, 124, 135],\n",
      "        ...,\n",
      "        [ 77, 118, 128],\n",
      "        [ 59, 101, 104],\n",
      "        [ 42,  86,  81]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[128, 138, 148],\n",
      "        [133, 145, 153],\n",
      "        [141, 152, 162],\n",
      "        ...,\n",
      "        [ 93, 102, 110],\n",
      "        [ 93, 101, 110],\n",
      "        [ 91,  99, 109]],\n",
      "\n",
      "       [[135, 145, 155],\n",
      "        [142, 152, 162],\n",
      "        [145, 155, 165],\n",
      "        ...,\n",
      "        [ 91, 101, 109],\n",
      "        [ 93, 101, 109],\n",
      "        [ 95, 102, 112]],\n",
      "\n",
      "       [[145, 155, 165],\n",
      "        [145, 154, 164],\n",
      "        [143, 154, 163],\n",
      "        ...,\n",
      "        [ 93, 101, 110],\n",
      "        [ 93, 102, 110],\n",
      "        [ 93, 102, 110]]], dtype=uint8), {'velocity': [], 'location': []})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(obs)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "The environmnet has been reset. The total reward was 0. And steps were 0 and the episode is 5038 and the total_steps are 231324\n",
      "Skiping this step\n",
      "Done condition: collision\n",
      "[array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(0, dtype=int64)]\n",
      "[array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(0, dtype=int64)]\n",
      "The environmnet has been reset. The total reward was -859. And steps were 153 and the episode is 5039 and the total_steps are 231477\n",
      "Done condition: collision\n",
      "[array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64)]\n",
      "[array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64)]\n",
      "The environmnet has been reset. The total reward was -990. And steps were 108 and the episode is 5040 and the total_steps are 231585\n",
      "Done condition: collision\n",
      "[array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64)]\n",
      "[array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64)]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 79 and the episode is 5041 and the total_steps are 231664\n",
      "Done condition: collision\n",
      "[array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64)]\n",
      "[array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64)]\n",
      "The environmnet has been reset. The total reward was -1104. And steps were 106 and the episode is 5042 and the total_steps are 231770\n",
      "Done condition: collision\n",
      "[array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64)]\n",
      "[array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64)]\n",
      "The environmnet has been reset. The total reward was -999. And steps were 71 and the episode is 5043 and the total_steps are 231841\n",
      "Done condition: collision\n",
      "[array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64)]\n",
      "[array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64)]\n",
      "The environmnet has been reset. The total reward was -991. And steps were 79 and the episode is 5044 and the total_steps are 231920\n",
      "Done condition: collision\n",
      "[array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64)]\n",
      "[array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64)]\n",
      "The environmnet has been reset. The total reward was -958. And steps were 94 and the episode is 5045 and the total_steps are 232014\n",
      "Done condition: collision\n",
      "[array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64)]\n",
      "[array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64)]\n",
      "The environmnet has been reset. The total reward was -994. And steps were 76 and the episode is 5046 and the total_steps are 232090\n",
      "Done condition: collision\n",
      "[array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64)]\n",
      "[array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64)]\n",
      "The environmnet has been reset. The total reward was -1002. And steps were 74 and the episode is 5047 and the total_steps are 232164\n",
      "Done condition: collision\n",
      "[array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64)]\n",
      "[array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64)]\n",
      "The environmnet has been reset. The total reward was -1031. And steps were 101 and the episode is 5048 and the total_steps are 232265\n",
      "The self.camera_observation is [[[ 91  99 109]\n",
      "  [ 91 101 110]\n",
      "  [ 93 102 112]\n",
      "  ...\n",
      "  [ 99 113 122]\n",
      "  [ 83 102 112]\n",
      "  [ 75  99 109]]\n",
      "\n",
      " [[ 91  99 110]\n",
      "  [ 90  99 109]\n",
      "  [ 91 101 110]\n",
      "  ...\n",
      "  [ 79  91  98]\n",
      "  [ 75  90  98]\n",
      "  [ 69  86  93]]\n",
      "\n",
      " [[ 90  98 108]\n",
      "  [ 90  99 109]\n",
      "  [ 91 101 110]\n",
      "  ...\n",
      "  [ 79  88  96]\n",
      "  [ 59  66  73]\n",
      "  [ 50  56  61]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 66  64  75]\n",
      "  [ 66  64  75]\n",
      "  [ 66  66  77]\n",
      "  ...\n",
      "  [ 75  83  93]\n",
      "  [ 77  85  95]\n",
      "  [ 71  77  88]]\n",
      "\n",
      " [[ 66  66  77]\n",
      "  [ 66  66  75]\n",
      "  [ 66  64  75]\n",
      "  ...\n",
      "  [ 81  88  98]\n",
      "  [ 77  85  95]\n",
      "  [ 77  85  93]]\n",
      "\n",
      " [[ 66  64  75]\n",
      "  [ 66  66  77]\n",
      "  [ 66  66  77]\n",
      "  ...\n",
      "  [ 81  90  99]\n",
      "  [ 79  86  96]\n",
      "  [ 81  88  98]]]\n"
     ]
    }
   ],
   "source": [
    "obs,info = actor.reset()\n",
    "\n",
    "for i in range(10):\n",
    "    actions = []\n",
    "    while True:\n",
    "        action, _states= model.predict(observation = obs, deterministic=True)\n",
    "        actions.append(action)\n",
    "        obs, reward,_, terminated, info = actor.step(action)\n",
    "    \n",
    "        if terminated:\n",
    "            print(actions)\n",
    "            obs, info = actor.reset()\n",
    "            break\n",
    "\n",
    "print(f\"The self.camera_observation is {actor.camera_observation}\" )\n",
    "\n",
    "if actor.actor_lst:\n",
    "    actor.destroy_all_actors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
