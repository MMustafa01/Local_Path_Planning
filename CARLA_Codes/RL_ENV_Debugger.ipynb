{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Env deebugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from RL_envdirectcontrol import CarENV\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import DQN\n",
    "import os \n",
    "import stable_baselines3\n",
    "print(stable_baselines3.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end_dic = {147:[146]\n",
    "                 \n",
    "                 }\n",
    "start_end_dic = {132:[6,7,8,9,11,12,15,16,20]}\n",
    "\n",
    "actor = CarENV(show_local_view=True, no_render_mode=False, Debugger= False , start_end_dic= start_end_dic, action_space_type='Discrete') \n",
    "# from stable_baselines3.common.env_checker import check_env\n",
    "# check_env(actor, warn=True, skip_render_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import StopTrainingOnMaxEpisodes\n",
    "\n",
    "\n",
    "callback_max_episodes = StopTrainingOnMaxEpisodes(max_episodes= 3, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "[Actor(id=264, type=vehicle.tesla.model3)]\n",
      "[]\n",
      "The environmnet has been reset. The total reward was 0. And steps were 0 and the episode is 0 and the total_steps are 0\n",
      "Logging to trainingdir/checking_box\\DQN_42\n",
      "the action is [steering, throttle] = 4\n",
      "Done condition: collision\n",
      "[Actor(id=268, type=vehicle.tesla.model3)]\n",
      "[4]\n",
      "The environmnet has been reset. The total reward was -1010. And steps were 1 and the episode is 1 and the total_steps are 1\n",
      "the action is [steering, throttle] = 0\n",
      "the action is [steering, throttle] = 2\n",
      "the action is [steering, throttle] = 4\n",
      "the action is [steering, throttle] = 2\n",
      "the action is [steering, throttle] = 3\n",
      "the action is [steering, throttle] = 0\n",
      "the action is [steering, throttle] = 1\n",
      "the action is [steering, throttle] = 4\n",
      "Done condition: off road\n",
      "[Actor(id=272, type=vehicle.tesla.model3)]\n",
      "[0, 2, 4, 2, 3, 0, 1, 4]\n",
      "The environmnet has been reset. The total reward was -780. And steps were 8 and the episode is 2 and the total_steps are 9\n",
      "the action is [steering, throttle] = 0\n",
      "the action is [steering, throttle] = 0\n",
      "the action is [steering, throttle] = 4\n",
      "the action is [steering, throttle] = 4\n",
      "the action is [steering, throttle] = 3\n",
      "the action is [steering, throttle] = 2\n",
      "the action is [steering, throttle] = 0\n",
      "the action is [steering, throttle] = 3\n",
      "the action is [steering, throttle] = 4\n",
      "the action is [steering, throttle] = 1\n",
      "the action is [steering, throttle] = 2\n",
      "the action is [steering, throttle] = 4\n",
      "the action is [steering, throttle] = 0\n",
      "the action is [steering, throttle] = 0\n",
      "the action is [steering, throttle] = 3\n",
      "Done condition: off road\n",
      "[Actor(id=276, type=vehicle.tesla.model3)]\n",
      "[0, 0, 4, 4, 3, 2, 0, 3, 4, 1, 2, 4, 0, 0, 3]\n",
      "The environmnet has been reset. The total reward was 250. And steps were 15 and the episode is 3 and the total_steps are 24\n",
      "Stopping training with a total of 24 steps because the DQN model reached max_episodes=3, by playing for 3 episodes \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Note = 'vegetation + globally guided + start_point_fixed+ limited end poin endpoints[5:20]'     \n",
    "models_dir = f\"models/checking_box\" #DQN_overfitting_2\"\n",
    "logdir = f\"trainingdir/checking_box\"\n",
    "Attempt =  'triall'\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "\n",
    "# model = PPO('CnnPolicy',actor, verbose=1,  tensorboard_log=logdir)\n",
    "# actor.render_mode = None\n",
    "# model.learn(total_timesteps=1000000, reset_num_timesteps=False ,log_interval = 4, callback=callback_max_episodes)\n",
    "\n",
    "policy = 'ActorCriticCnnPolicy'\n",
    "model = DQN('CnnPolicy',actor, verbose=1, buffer_size=10000, tensorboard_log=logdir)\n",
    "actor.render_mode = None\n",
    "model.learn(total_timesteps=10000000 , callback=callback_max_episodes,log_interval = 4)\n",
    "reset_num_timesteps=False\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Actor(id=280, type=vehicle.tesla.model3)]\n"
     ]
    }
   ],
   "source": [
    "# print(f\"The self.camera_observation is {actor.camera_observation}\" )\n",
    "\n",
    "if actor.actor_lst:\n",
    "    actor.destroy_all_actors()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save(f'{models_dir}/model_{Attempt}')\n",
    "type(np.array([1])) == type(np.array([0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This can not be deleted\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "try:\n",
    "    print(model)\n",
    "except:\n",
    "    print(\"This can not be deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.seconds_per_episode\n",
    "model = DQN.load(f'{models_dir}/model_{Attempt}.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs,info = actor.reset()\n",
    "\n",
    "# for i in range(10):\n",
    "#     actions = []\n",
    "#     while True:s\n",
    "#         action, _states= model.predict(observation = obs, deterministic=True)\n",
    "#         actions.append(action)\n",
    "#         obs, reward,_, terminated, info = actor.step(action)\n",
    "    \n",
    "#         if terminated:\n",
    "#             print(actions)\n",
    "#             obs, info = actor.reset()\n",
    "#             break\n",
    "\n",
    "# print(f\"The self.camera_observation is {actor.camera_observation}\" )\n",
    "\n",
    "# if actor.actor_lst:\n",
    "#     actor.destroy_all_actors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
